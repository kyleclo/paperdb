{"paperId": "421eddd6a2c771e87e80eb64fb1328de2db51479", "title": "3D-Auth: Two-Factor Authentication with Personalized 3D-Printed Items", "venue": "International Conference on Human Factors in Computing Systems", "year": 2020, "citationCount": 36, "openAccessPdf": {"url": "https://dl.acm.org/doi/pdf/10.1145/3313831.3376189", "status": "GREEN", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3313831.3376189?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3313831.3376189, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2020-04-21", "authors": [{"authorId": "3399279", "name": "Karola Marky"}, {"authorId": "2057761601", "name": "Martin Schmitz"}, {"authorId": "31314985", "name": "Verena Zimmermann"}, {"authorId": "2090515951", "name": "Martin Herbers"}, {"authorId": "143973307", "name": "K. Kunze"}, {"authorId": "1725964", "name": "M. M\u00fchlh\u00e4user"}], "abstract": "Two-factor authentication is a widely recommended security mechanism and already offered for different services. However, known methods and physical realizations exhibit considerable usability and customization issues. In this paper, we propose 3D-Auth, a new concept of two-factor authentication. 3D-Auth is based on customizable 3D-printed items that combine two authentication factors in one object. The object bottom contains a uniform grid of conductive dots that are connected to a unique embedded structure inside the item. Based on the interaction with the item, different dots turn into touch-points and form an authentication pattern. This pattern can be recognized by a capacitive touchscreen. Based on an expert design study, we present an interaction space with six categories of possible authentication interactions. In a user study, we demonstrate the feasibility of 3D-Auth items and show that the items are easy to use and the interactions are easy to remember.", "corpusId": "211560654", "paragraphs": [{"paragraphId": "34028", "title": "3D-Auth: Two-Factor Authentication with Personalized 3D-Printed Items", "sectionTitle": "INTRODUCTION", "text": "In two-factor authentication, two of the following authentication factors are combined: 1) knowledge (e.g., a password), 2) ownership (e.g., a credit card), and 3) inherence (e.g., a fingerprint) [15]. One factor often belongs to the category ownership and takes the form of a physical object, such as a token. Known methods of physical realizations of such objects exhibit considerable usability as well as customization issues [48,8,11,2].", "spans": "[{\"corpusId\": 23796197, \"span\": \"[48,\", \"start\": 429, \"end\": 433}, {\"corpusId\": 201803687, \"span\": \"8,\", \"start\": 433, \"end\": 435}, {\"corpusId\": 4606963, \"span\": \"11,\", \"start\": 435, \"end\": 438}, {\"corpusId\": 7847705, \"span\": \"2]\", \"start\": 438, \"end\": 440}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "34029", "title": "3D-Auth: Two-Factor Authentication with Personalized 3D-Printed Items", "sectionTitle": "INTRODUCTION", "text": "If users have the possibility to choose an authentication mechanism, their choice is primarily based on usability. Thus, usability issues lead to a low adoption rate [5,32]. More specific, users perceive the duration of the current two-factor authentication procedures as too long [49] and they criticize the usage of non-personalized devices [48].", "spans": "[{\"corpusId\": 18166226, \"span\": \"32]\", \"start\": 169, \"end\": 172}, {\"corpusId\": 9994739, \"span\": \"[49]\", \"start\": 281, \"end\": 285}, {\"corpusId\": 23796197, \"span\": \"[48]\", \"start\": 343, \"end\": 347}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "34030", "title": "3D-Auth: Two-Factor Authentication with Personalized 3D-Printed Items", "sectionTitle": "Two-Factor Authentication", "text": "Passwords are a knowledge-based authentication factor and the most commonly used authentication mechanism [44]. However, research has shown that users tend to follow a poor password hygiene by using passwords that are simple to guess and reusing passwords across multiple accounts [45,47,46]. This practice substantially weakens the security of passwords. Furthermore, service providers store the passwords in a database which might be attacked and leaked. Passwords are also susceptible to shoulder-surfing and phishing attacks. A possibility to mitigate the impact of these attacks are authentication mechanisms that combine different factors. The combination of two factors is called two-factor authentication. Multi-factor authentication combines more than two factors. A common example of two-factor authentication is the combination of a password or PIN (knowledge) and a token, such as a personal smart card (ownership).", "spans": "[{\"corpusId\": 384068, \"span\": \"[45,\", \"start\": 281, \"end\": 285}, {\"corpusId\": 7804617, \"span\": \"47,\", \"start\": 285, \"end\": 288}, {\"corpusId\": 7320191, \"span\": \"46]\", \"start\": 288, \"end\": 291}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "34031", "title": "3D-Auth: Two-Factor Authentication with Personalized 3D-Printed Items", "sectionTitle": "Two-Factor Authentication", "text": "The introduction of two-factor authentication has been investigated in several contexts. It has been shown that users prefer or choose devices that they already own over additional physical tokens [48]. Users also tend to choose devices for two-factor authentication based on their usability [49]. Ease-of-use, trustworthiness and the required cognitive effort were found as key aspects for defining the usability of two-factor authentication [13]. A study in the banking context shed light on the security-usability trade-off of two-factor authentication [16]: While two-factor authentication was perceived as more secure than single factor authentication, the perceived usability, ease-of-use and convenience were rated significantly lower. Authenticating with two-factor authentication also took longer compared to single factor authentication. However, if users have positive experiences with two-factor authentication, they might even use it for accounts that do not require it [9].", "spans": "[{\"corpusId\": 23796197, \"span\": \"[48]\", \"start\": 197, \"end\": 201}, {\"corpusId\": 9994739, \"span\": \"[49]\", \"start\": 292, \"end\": 296}, {\"corpusId\": 2570337, \"span\": \"[16]\", \"start\": 556, \"end\": 560}, {\"corpusId\": 5041135, \"span\": \"[9]\", \"start\": 983, \"end\": 986}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "34032", "title": "3D-Auth: Two-Factor Authentication with Personalized 3D-Printed Items", "sectionTitle": "Tangible Authentication", "text": "Several approaches for tangible authentication have been proposed in the literature. Among those are wearable devices that have embedded cryptographic keys [7]. TangibleRubik provides tangible authentication by the manipulation of a Rubik's Cube [27]. Using TangibleRubik, a user's password consists of a series of moves with the tube, such as turning parts of it. These moves are captured by a webcam. A preliminary user study of TangibleRubik revealed that duration of password entry (34 and 52 seconds) were perceived as too long. Bend Passwords introduces tangible authentication with a flexible PVC sheet that has bend sensors [25]. A user study of Bend Passwords revealed that their perceived usability is lower than the usability of PINs. This indicates that the physical presentation of plays an integral role for usability.", "spans": "[{\"corpusId\": 33983011, \"span\": \"[7]\", \"start\": 156, \"end\": 159}, {\"corpusId\": 7054944, \"span\": \"[27]\", \"start\": 246, \"end\": 250}, {\"corpusId\": 15617366, \"span\": \"[25]\", \"start\": 632, \"end\": 636}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "34033", "title": "3D-Auth: Two-Factor Authentication with Personalized 3D-Printed Items", "sectionTitle": "3D Printing of Interactive Objects", "text": "Many works embed electrical components in objects to make them interactive. This can be achieved by mounting capacitive [33] or acoustic [29] sensors, or by embedding cameras [34] or accelerometers [17]. While these approaches require only a few components, they need additional assembly effort or only work with hollow objects that can be opened after printing.", "spans": "[{\"corpusId\": 9201620, \"span\": \"[33]\", \"start\": 120, \"end\": 124}, {\"corpusId\": 10512484, \"span\": \"[29]\", \"start\": 137, \"end\": 141}, {\"corpusId\": 2052059, \"span\": \"[34]\", \"start\": 175, \"end\": 179}, {\"corpusId\": 477186, \"span\": \"[17]\", \"start\": 198, \"end\": 202}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "34034", "title": "3D-Auth: Two-Factor Authentication with Personalized 3D-Printed Items", "sectionTitle": "Paper 62 Page 2", "text": "This includes the creation of input and output functions into 3D-printed objects by light pipes [3,50], filling internal pipes with media after printing [35], or pipes that transmit sound [21]. Other approaches print interactive objects using conductive spray [19] or conductive plastic [4,38,20,23,37,39,36,40]. 3D printing is also investigated for the fine-grained design of deformation behavior of non-interactive flexible objects [1,30,31,41] or for the production of soft interactive objects [18].", "spans": "[{\"corpusId\": 5608848, \"span\": \"[3,\", \"start\": 96, \"end\": 99}, {\"corpusId\": 5689799, \"span\": \"[35]\", \"start\": 153, \"end\": 157}, {\"corpusId\": 15902504, \"span\": \"[21]\", \"start\": 188, \"end\": 192}, {\"corpusId\": 14273594, \"span\": \"[19]\", \"start\": 260, \"end\": 264}, {\"corpusId\": 18185576, \"span\": \"38,\", \"start\": 290, \"end\": 293}, {\"corpusId\": 18453687, \"span\": \"20,\", \"start\": 293, \"end\": 296}, {\"corpusId\": 16176461, \"span\": \"23,\", \"start\": 296, \"end\": 299}, {\"corpusId\": 21958556, \"span\": \"39,\", \"start\": 302, \"end\": 305}, {\"corpusId\": 5053414, \"span\": \"36,\", \"start\": 305, \"end\": 308}, {\"corpusId\": 108395187, \"span\": \"40]\", \"start\": 308, \"end\": 311}, {\"corpusId\": 9910942, \"span\": \"[1,\", \"start\": 434, \"end\": 437}, {\"corpusId\": 14541159, \"span\": \"30,\", \"start\": 437, \"end\": 440}, {\"corpusId\": 17121691, \"span\": \"31,\", \"start\": 440, \"end\": 443}, {\"corpusId\": 5096860, \"span\": \"41]\", \"start\": 443, \"end\": 446}, {\"corpusId\": 13945090, \"span\": \"[18]\", \"start\": 497, \"end\": 501}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 15}], "paragraphCount": 7}
{"paperId": "c0c11be3de5d102b9cd6de1ff7a413a8ea007b92", "title": "ERICA: Improving Entity and Relation Understanding for Pre-trained Language Models via Contrastive Learning", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2020, "citationCount": 133, "openAccessPdf": {"url": "https://aclanthology.org/2021.acl-long.260.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2012.15022, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2020-12-30", "authors": [{"authorId": "50625437", "name": "Yujia Qin"}, {"authorId": "2427350", "name": "Yankai Lin"}, {"authorId": "51055574", "name": "Ryuichi Takanobu"}, {"authorId": "49293587", "name": "Zhiyuan Liu"}, {"authorId": "50492525", "name": "Peng Li"}, {"authorId": "2113323573", "name": "Heng Ji"}, {"authorId": "1730108", "name": "Minlie Huang"}, {"authorId": "1753344", "name": "Maosong Sun"}, {"authorId": "49178343", "name": "Jie Zhou"}], "abstract": "Pre-trained Language Models (PLMs) have shown superior performance on various downstream Natural Language Processing (NLP) tasks. However, conventional pre-training objectives do not explicitly model relational facts in text, which are crucial for textual understanding. To address this issue, we propose a novel contrastive learning framework ERICA to obtain a deep understanding of the entities and their relations in text. Specifically, we define two novel pre-training tasks to better understand entities and relations: (1) the entity discrimination task to distinguish which tail entity can be inferred by the given head entity and relation; (2) the relation discrimination task to distinguish whether two relations are close or not semantically, which involves complex relational reasoning. Experimental results demonstrate that ERICA can improve typical PLMs (BERT and RoBERTa) on several language understanding tasks, including relation extraction, entity typing and question answering, especially under low-resource settings.", "corpusId": "229923565", "paragraphs": [{"paragraphId": "10119", "title": "ERICA: Improving Entity and Relation Understanding for Pre-trained Language Models via Contrastive Learning", "sectionTitle": "Introduction", "text": "Pre-trained Language Models (PLMs) (Devlin et al., 2018; have shown superior performance on various Natural Language Processing (NLP) tasks such as text classification (Wang et al., 2018), named entity recognition (Sang and De Meulder, 2003), and question answering (Talmor and Berant, 2019). Benefiting from designing various effective self-supervised learning objectives, such as masked language modeling (Devlin et al., 2018), PLMs can effectively capture the syntax and semantics in text to generate informative language representations for downstream NLP tasks. However, conventional pre-training objectives do not explicitly model relational facts, which frequently distribute in text and are crucial for understanding the whole text. To address this issue, some recent studies attempt to improve PLMs to better understand relations between entities (Soares et al., Peng et al., 2020). However, they mainly focus on within-sentence relations in isolation, ignoring the understanding of entities, and the interactions among multiple entities at document level, whose relation understanding involves complex reasoning patterns. According to the statistics on a human-annotated corpus sampled from Wikipedia documents by Yao et al. (2019), at least 40.7% relational facts require to be extracted from multiple sentences. Specifically, we show an example in Figure 1, to understand that \"Guadalajara is located in Mexico\", we need to consider the following clues jointly: (i) \"Mexico\" is the country of \"Culiac\u00e1n\" from sentence 1; (ii) \"Culiac\u00e1n\" is a rail junction lo-cated on \"Panamerican Highway\" from sentence 6; (iii) \"Panamerican Highway\" connects to \"Guadalajara\" from sentence 6. From the example, we can see that there are two main challenges to capture the in-text relational facts:", "spans": "[{\"corpusId\": 5034059, \"span\": \"(Wang et al., 2018)\", \"start\": 168, \"end\": 187}, {\"corpusId\": 5034059, \"span\": \"(Wang et al., 2018)\", \"start\": 168, \"end\": 187}, {\"corpusId\": 2470716, \"span\": \"(Sang and De Meulder, 2003)\", \"start\": 214, \"end\": 241}, {\"corpusId\": 2470716, \"span\": \"(Sang and De Meulder, 2003)\", \"start\": 214, \"end\": 241}, {\"corpusId\": 173188058, \"span\": \"(Talmor and Berant, 2019)\", \"start\": 266, \"end\": 291}, {\"corpusId\": 173188058, \"span\": \"(Talmor and Berant, 2019)\", \"start\": 266, \"end\": 291}, {\"corpusId\": 222133166, \"span\": \"Peng et al., 2020)\", \"start\": 872, \"end\": 890}, {\"corpusId\": 222133166, \"span\": \"Peng et al., 2020)\", \"start\": 872, \"end\": 890}, {\"corpusId\": 189898081, \"span\": \"Yao et al. (2019)\", \"start\": 1224, \"end\": 1241}, {\"corpusId\": 189898081, \"span\": \"Yao et al. (2019)\", \"start\": 1224, \"end\": 1241}]", "conference": "acl", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "10120", "title": "ERICA: Improving Entity and Relation Understanding for Pre-trained Language Models via Contrastive Learning", "sectionTitle": "Related Work", "text": "Dai and Le (2015) and Howard and Ruder (2018) propose to pre-train universal language representations on unlabeled text, and perform task-specific fine-tuning. With the advance of computing power, PLMs such as OpenAI GPT (Radford et al., 2018), BERT (Devlin et al., 2018) and XLNet  based on deep Transformer (Vaswani et al., 2017) architecture demonstrate their superiority in various downstream NLP tasks. Since then, numerous PLM extensions have been proposed to further explore the impacts of various model architectures (Song et al., 2019;Raffel et al., 2020), larger model size (Raffel et al., 2020;Lan et al., 2020;Fedus et al., 2021), more pre-training corpora , etc., to obtain better general language understanding ability. Although achieving great success, these PLMs usually regard words as basic units in textual understanding, ignoring the informative entities and their relations, which are crucial for understanding the whole text.", "spans": "[{\"corpusId\": 40100965, \"span\": \"Howard and Ruder (2018)\", \"start\": 22, \"end\": 45}, {\"corpusId\": 40100965, \"span\": \"Howard and Ruder (2018)\", \"start\": 22, \"end\": 45}, {\"corpusId\": 13756489, \"span\": \"(Vaswani et al., 2017)\", \"start\": 309, \"end\": 331}, {\"corpusId\": 13756489, \"span\": \"(Vaswani et al., 2017)\", \"start\": 309, \"end\": 331}, {\"corpusId\": 146808476, \"span\": \"(Song et al., 2019;\", \"start\": 525, \"end\": 544}, {\"corpusId\": 146808476, \"span\": \"(Song et al., 2019;\", \"start\": 525, \"end\": 544}, {\"corpusId\": 204838007, \"span\": \"Raffel et al., 2020)\", \"start\": 544, \"end\": 564}, {\"corpusId\": 204838007, \"span\": \"Raffel et al., 2020)\", \"start\": 544, \"end\": 564}, {\"corpusId\": 204838007, \"span\": \"(Raffel et al., 2020;\", \"start\": 584, \"end\": 605}, {\"corpusId\": 204838007, \"span\": \"(Raffel et al., 2020;\", \"start\": 584, \"end\": 605}, {\"corpusId\": 202888986, \"span\": \"Lan et al., 2020;\", \"start\": 605, \"end\": 622}, {\"corpusId\": 202888986, \"span\": \"Lan et al., 2020;\", \"start\": 605, \"end\": 622}]", "conference": "acl", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "10121", "title": "ERICA: Improving Entity and Relation Understanding for Pre-trained Language Models via Contrastive Learning", "sectionTitle": "Related Work", "text": "To improve the entity and relation understanding of PLMs, a typical line of work is knowledgeguided PLM, which incorporates external knowledge such as Knowledge Graphs (KGs) into PLMs to enhance the entity and relation understanding. Some enforce PLMs to memorize information about real-world entities and propose novel pretraining objectives (Xiong et al., 2019;Yamada et al., 2020). Others modify the internal structures of PLMs to fuse both textual and KG's information Peters et al., 2019;He et al., 2020). Although knowledge-guided PLMs introduce extra factual knowledge in KGs, these methods ignore the intrinsic relational facts in text, making it hard to understand out-of-KG entities or knowledge in downstream tasks, let alone the errors and incompleteness of KGs. This verifies the necessity of teaching PLMs to understand relational facts from contexts.", "spans": "[{\"corpusId\": 209439872, \"span\": \"(Xiong et al., 2019;\", \"start\": 343, \"end\": 363}, {\"corpusId\": 209439872, \"span\": \"(Xiong et al., 2019;\", \"start\": 343, \"end\": 363}, {\"corpusId\": 222124841, \"span\": \"Yamada et al., 2020)\", \"start\": 363, \"end\": 383}, {\"corpusId\": 222124841, \"span\": \"Yamada et al., 2020)\", \"start\": 363, \"end\": 383}, {\"corpusId\": 202542757, \"span\": \"Peters et al., 2019;\", \"start\": 473, \"end\": 493}, {\"corpusId\": 202542757, \"span\": \"Peters et al., 2019;\", \"start\": 473, \"end\": 493}]", "conference": "acl", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "10122", "title": "ERICA: Improving Entity and Relation Understanding for Pre-trained Language Models via Contrastive Learning", "sectionTitle": "Related Work", "text": "Another line of work is to directly model entities or relations in text in pre-training stage to break the limitations of individual token representations. Some focus on obtaining better span representations, including entity mentions, via span-based pre-training Joshi et al., 2020;Kong et al., 2020;Ye et al., 2020). Others learn to extract relation-aware semantics from text by comparing the sentences that share the same entity pair or distantly supervised relation in KGs (Soares et al., 2019;Peng et al., 2020). However, these methods only consider either individual entities or within-sentence relations, which limits the performance in dealing with multiple entities and relations at document level. In contrast, our ERICA considers the interactions among multiple entities For an entity pair with its distantly supervised relation in text, the ED task requires the ground-truth tail entity to be closer to the head entity than other entities. and relations comprehensively, achieving a better understanding of in-text relational facts.", "spans": "[{\"corpusId\": 198229624, \"span\": \"Joshi et al., 2020;\", \"start\": 264, \"end\": 283}, {\"corpusId\": 198229624, \"span\": \"Joshi et al., 2020;\", \"start\": 264, \"end\": 283}, {\"corpusId\": 204788776, \"span\": \"Kong et al., 2020;\", \"start\": 283, \"end\": 301}, {\"corpusId\": 204788776, \"span\": \"Kong et al., 2020;\", \"start\": 283, \"end\": 301}, {\"corpusId\": 222133166, \"span\": \"Peng et al., 2020)\", \"start\": 498, \"end\": 516}, {\"corpusId\": 222133166, \"span\": \"Peng et al., 2020)\", \"start\": 498, \"end\": 516}]", "conference": "acl", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "10123", "title": "ERICA: Improving Entity and Relation Understanding for Pre-trained Language Models via Contrastive Learning", "sectionTitle": "Relation Extraction", "text": "Relation extraction aims to extract the relation between two recognized entities from a pre-defined relation set.  three partitions of the training set (1%, 10% and 100%) and report results on test sets. Document-level RE For document-level RE, we choose DocRED (Yao et al., 2019), which requires reading multiple sentences in a document and synthesizing all the information to identify the relation between two entities. We encode all entities in the same way as in pre-training phase. The relation representations are obtained by adding a bilinear layer on top of two entity representations. We choose the following baselines: (1) CNN (Zeng et al., 2014), BILSTM (Hochreiter and Schmidhuber, 1997), BERT (Devlin et al., 2018) and RoBERTa , which are widely used as text encoders for relation extraction tasks; (2) HINBERT (Tang et al., 2020) which employs a hierarchical inference network to leverage the abundant information from different sources; (3) CorefBERT (Ye et al., 2020) which proposes a pre-training method to help BERT capture the coreferential relations in context; (4) SpanBERT (Joshi et al., 2020) which masks   (Peng et al., 2020) which introduce sentence-level relation contrastive learning for BERT via distant supervision. For fair comparison, we pre-train these baselines on our constructed pre-training data 10 based on the implementation released by Peng et al. (2020) 11 . From the results shown in Table 1, we can see that:", "spans": "[{\"corpusId\": 189898081, \"span\": \"(Yao et al., 2019)\", \"start\": 262, \"end\": 280}, {\"corpusId\": 189898081, \"span\": \"(Yao et al., 2019)\", \"start\": 262, \"end\": 280}, {\"corpusId\": 12873739, \"span\": \"(Zeng et al., 2014)\", \"start\": 637, \"end\": 656}, {\"corpusId\": 12873739, \"span\": \"(Zeng et al., 2014)\", \"start\": 637, \"end\": 656}, {\"corpusId\": 1915014, \"span\": \"(Hochreiter and Schmidhuber, 1997)\", \"start\": 665, \"end\": 699}, {\"corpusId\": 1915014, \"span\": \"(Hochreiter and Schmidhuber, 1997)\", \"start\": 665, \"end\": 699}, {\"corpusId\": 214714027, \"span\": \"(Tang et al., 2020)\", \"start\": 824, \"end\": 843}, {\"corpusId\": 214714027, \"span\": \"(Tang et al., 2020)\", \"start\": 824, \"end\": 843}, {\"corpusId\": 198229624, \"span\": \"(Joshi et al., 2020)\", \"start\": 1095, \"end\": 1115}, {\"corpusId\": 198229624, \"span\": \"(Joshi et al., 2020)\", \"start\": 1095, \"end\": 1115}, {\"corpusId\": 222133166, \"span\": \"(Peng et al., 2020)\", \"start\": 1130, \"end\": 1149}, {\"corpusId\": 222133166, \"span\": \"(Peng et al., 2020)\", \"start\": 1130, \"end\": 1149}]", "conference": "acl", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "10124", "title": "ERICA: Improving Entity and Relation Understanding for Pre-trained Language Models via Contrastive Learning", "sectionTitle": "Sentence-level Relation", "text": "Extraction For sentence-level relation extraction, we did experiments on TACRED (Zhang et al., 2017) and SemEval-2010 Task 8 (Hendrickx et al., 2019) based on the implementation of Peng et al. (2020) 17 . We did experiments on three partitions (1%, 10% and 100%) of the original training set. The relation representation for each entity pair is obtained in the same way as in pre-training phase. Other settings are kept the same as Peng et al. (2020) for fair comparison. models for three epochs, other hyper-parameters are kept the same as ERNIE.", "spans": "[{\"corpusId\": 3782112, \"span\": \"(Zhang et al., 2017)\", \"start\": 80, \"end\": 100}, {\"corpusId\": 3782112, \"span\": \"(Zhang et al., 2017)\", \"start\": 80, \"end\": 100}, {\"corpusId\": 436023, \"span\": \"(Hendrickx et al., 2019)\", \"start\": 125, \"end\": 149}, {\"corpusId\": 436023, \"span\": \"(Hendrickx et al., 2019)\", \"start\": 125, \"end\": 149}, {\"corpusId\": 222133166, \"span\": \"Peng et al. (2020)\", \"start\": 181, \"end\": 199}, {\"corpusId\": 222133166, \"span\": \"Peng et al. (2020)\", \"start\": 181, \"end\": 199}, {\"corpusId\": 222133166, \"span\": \"Peng et al. (2020)\", \"start\": 432, \"end\": 450}, {\"corpusId\": 222133166, \"span\": \"Peng et al. (2020)\", \"start\": 432, \"end\": 450}]", "conference": "acl", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 6}
{"paperId": "d8ad95d1918ed72a89fc3d8f842179ee9520cb19", "title": "Unsupervised Neural Text Simplification", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2018, "citationCount": 88, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/P19-1198.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1810.07931, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2018-10-18", "authors": [{"authorId": "2066124626", "name": "S. Surya"}, {"authorId": "1746093", "name": "Abhijit Mishra"}, {"authorId": "2039596", "name": "Anirban Laha"}, {"authorId": "2719746", "name": "Parag Jain"}, {"authorId": "145590185", "name": "Karthik Sankaranarayanan"}], "abstract": "The paper presents a first attempt towards unsupervised neural text simplification that relies only on unlabeled text corpora. The core framework is composed of a shared encoder and a pair of attentional-decoders, crucially assisted by discrimination-based losses and denoising. The framework is trained using unlabeled text collected from en-Wikipedia dump. Our analysis (both quantitative and qualitative involving human evaluators) on public test data shows that the proposed model can perform text-simplification at both lexical and syntactic levels, competitive to existing supervised methods. It also outperforms viable unsupervised baselines. Adding a few labeled pairs helps improve the performance further.", "corpusId": "53019653", "paragraphs": [{"paragraphId": "32935", "title": "Unsupervised Neural Text Simplification", "sectionTitle": "Introduction", "text": "Text Simplification (TS) deals with transforming the original text into simplified variants to increase its readability and understandability. TS is an important task in computational linguistics, and has numerous use-cases in fields of education technology, targeted content creation, language learning, where producing variants of the text with varying degree of simplicity is desired. TS systems are typically designed to simplify from two different linguistic aspects: (a) Lexical aspect, by replacing complex words in the input with simpler synonyms (Devlin, 1998;Candido Jr et al., 2009;Yatskar et al., 2010;Biran et al., 2011;Glava\u0161 and\u0160tajner, 2015), and (b) Syntactic aspect, by altering the inherent hierarchical structure of the sentences (Chandrasekar and Srinivas, 1997;Canning and Tait, 1999;Siddharthan, 2006;Filippova and Strube, 2008;Brouwers et al., 2014). From the perspective of sentence construction, sentence simplification can be thought to be a form of text-transformation that involves three major types of operations such as (a) splitting (Siddharthan, 2006;Petersen and Ostendorf, 2007;Narayan and Gardent, 2014) (b) deletion/compression (Knight and Marcu, 2002;Clarke and Lapata, 2006;Filippova and Strube, 2008;Rush et al., 2015;Filippova et al., 2015), and (c) paraphrasing (Specia, 2010;Coster and Kauchak, 2011;Wubben et al., 2012;Wang et al., 2016;Nisioi et al., 2017).", "spans": "[{\"corpusId\": 3234156, \"span\": \"Candido Jr et al., 2009;\", \"start\": 569, \"end\": 593}, {\"corpusId\": 5477884, \"span\": \"Yatskar et al., 2010;\", \"start\": 593, \"end\": 614}, {\"corpusId\": 11091984, \"span\": \"Biran et al., 2011;\", \"start\": 614, \"end\": 633}, {\"corpusId\": 14619244, \"span\": \"Siddharthan, 2006;\", \"start\": 806, \"end\": 824}, {\"corpusId\": 17477341, \"span\": \"Filippova and Strube, 2008;\", \"start\": 824, \"end\": 851}, {\"corpusId\": 12093312, \"span\": \"Brouwers et al., 2014)\", \"start\": 851, \"end\": 873}, {\"corpusId\": 14619244, \"span\": \"(Siddharthan, 2006;\", \"start\": 1065, \"end\": 1084}, {\"corpusId\": 1493947, \"span\": \"Petersen and Ostendorf, 2007;\", \"start\": 1084, \"end\": 1113}, {\"corpusId\": 15489071, \"span\": \"Narayan and Gardent, 2014\", \"start\": 1113, \"end\": 1138}, {\"corpusId\": 7793213, \"span\": \"(Knight and Marcu, 2002;\", \"start\": 1165, \"end\": 1189}, {\"corpusId\": 6412912, \"span\": \"Clarke and Lapata, 2006;\", \"start\": 1189, \"end\": 1213}, {\"corpusId\": 17477341, \"span\": \"Filippova and Strube, 2008;\", \"start\": 1213, \"end\": 1240}, {\"corpusId\": 1918428, \"span\": \"Rush et al., 2015;\", \"start\": 1240, \"end\": 1258}, {\"corpusId\": 1992250, \"span\": \"Filippova et al., 2015)\", \"start\": 1258, \"end\": 1281}, {\"corpusId\": 9871276, \"span\": \"(Specia, 2010;\", \"start\": 1304, \"end\": 1318}, {\"corpusId\": 9128245, \"span\": \"Coster and Kauchak, 2011;\", \"start\": 1318, \"end\": 1343}, {\"corpusId\": 141120, \"span\": \"Wubben et al., 2012;\", \"start\": 1343, \"end\": 1363}, {\"corpusId\": 38867517, \"span\": \"Wang et al., 2016;\", \"start\": 1363, \"end\": 1381}, {\"corpusId\": 36364048, \"span\": \"Nisioi et al., 2017)\", \"start\": 1381, \"end\": 1401}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 17}, {"paragraphId": "32936", "title": "Unsupervised Neural Text Simplification", "sectionTitle": "Related Work", "text": "Text Simplification has often been discussed from psychological and linguistic standpoints (L'Allier, 1980;McNamara et al., 1996;Linderholm et al., 2000). A heuristic-based system was first introduced by Chandrasekar and Srinivas (1997) which induces rules for simplification automatically extracted from annotated corpora. Canning and Tait (1999) proposed a modular system that uses NLP tools such as morphological analyzer, POS tagger 1 https://github.com/subramanyamdvss/UnsupNTS plus heuristics to simplify the text both lexically and syntactically. Most of these systems (Siddharthan, 2014) are separately targeted towards lexical and syntactic simplification and are limited to splitting and/or truncating sentences. For paraphrasing based simplification, data-driven approaches were proposed like phrase-based SMT (Specia, 2010;\u0160tajner et al., 2015) or their variants (Coster and Kauchak, 2011;Xu et al., 2016), that combine heuristic and optimization strategies for better TS. Recently proposed TS systems are based on neural seq2seq architecture (Bahdanau et al., 2014) which is modified for TS specific operations (Wang et al., 2016;Nisioi et al., 2017). While these systems produce state of the art results on the popular Wikipedia dataset (Coster and Kauchak, 2011), they may not be generalizable because of the noise and bias in the dataset (Xu et al., 2015) and overfitting. Towards this,\u0160tajner and Nisioi (2018) showed that improved datasets and minor model changes (such as using reduced vocabulary and enabling copy mechanism) help obtain reasonable performance for both in-domain and cross-domain TS.", "spans": "[{\"corpusId\": 143615323, \"span\": \"McNamara et al., 1996;\", \"start\": 107, \"end\": 129}, {\"corpusId\": 144641814, \"span\": \"Linderholm et al., 2000)\", \"start\": 129, \"end\": 153}, {\"corpusId\": 3894107, \"span\": \"(Siddharthan, 2014)\", \"start\": 576, \"end\": 595}, {\"corpusId\": 9871276, \"span\": \"(Specia, 2010;\", \"start\": 821, \"end\": 835}, {\"corpusId\": 9128245, \"span\": \"(Coster and Kauchak, 2011;\", \"start\": 875, \"end\": 901}, {\"corpusId\": 2177849, \"span\": \"Xu et al., 2016)\", \"start\": 901, \"end\": 917}, {\"corpusId\": 53019653, \"span\": \"proposed TS system\", \"start\": 1012, \"end\": 1012}, {\"corpusId\": 38867517, \"span\": \"(Wang et al., 2016;\", \"start\": 1124, \"end\": 1143}, {\"corpusId\": 36364048, \"span\": \"Nisioi et al., 2017)\", \"start\": 1143, \"end\": 1163}, {\"corpusId\": 9128245, \"span\": \"(Coster and Kauchak, 2011)\", \"start\": 1251, \"end\": 1277}, {\"corpusId\": 17817489, \"span\": \"(Xu et al., 2015)\", \"start\": 1354, \"end\": 1371}, {\"corpusId\": 21685311, \"span\": \"Nisioi (2018)\", \"start\": 1414, \"end\": 1427}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 11}, {"paragraphId": "32937", "title": "Unsupervised Neural Text Simplification", "sectionTitle": "Related Work", "text": "In the unsupervised paradigm, Paetzold and Specia (2016) proposed an unsupervised lexical simplification technique that replaces complex words in the input with simpler synonyms, which are extracted and disambiguated using word embeddings. However, this work, unlike ours only addresses lexical simplification and cannot be trivially extended for other forms of simplification such as splitting and rephrasing. Other works related to style transfer Shen et al., 2017;Xu et al., 2018) typically look into the problem of sentiment transformation and are not motivated by the linguistic aspects of TS, and hence not comparable to our work. As far as we know, ours is a first of its kind end-to-end solution for unsupervised TS. At this point, though supervised solutions perform better than unsupervised ones, we believe unsupervised techniques should be further explored since they hold greater potential with regards to scalability to various tasks.", "spans": "[{\"corpusId\": 19849030, \"span\": \"Specia (2016)\", \"start\": 43, \"end\": 56}, {\"corpusId\": 53019653, \"span\": \"this work\", \"start\": 258, \"end\": 258}, {\"corpusId\": 7296803, \"span\": \"Shen et al., 2017;\", \"start\": 449, \"end\": 467}, {\"corpusId\": 46889991, \"span\": \"Xu et al., 2018)\", \"start\": 467, \"end\": 483}, {\"corpusId\": 53019653, \"span\": \"our work\", \"start\": 635, \"end\": 635}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "32938", "title": "Unsupervised Neural Text Simplification", "sectionTitle": "Dataset", "text": "For training our system, we created an unlabeled dataset of simple and complex sentences by partitioning the standard en-wikipedia dump. Since partitioning requires a metric for measuring text simpleness we categorize sentences based on their 4 https://github.com/subramanyamdvss/UnsupNTS  (Flesch, 1948). Sentences with lower FE values (up to 10) are categorized as complex and sentences with FE values greater than 70 are categorized as simple 5 . The FE bounds are decided through trial and error through manual inspection of the categorized sentences. Table 1 shows dataset statistics. Even though the dataset was created with some level of human mediation, the manual effort is insignificant compared to that needed to create a parallel corpus. To train the system with minimal supervision (Section 4.5), we extract 10, 000 pairs of sentences from various datasets such as Wikipedia-SimpleWikipedia dataset introduced in Hwang et al. (2015) and the Split-Rephrase dataset by Narayan et al. (2017) 6 . The Wikipedia-SimpleWikipedia was filtered following Nisioi et al. (2017) and 4000 examples were randomly picked from the filtered set. From the Split-Rephrase dataset, examples containing one compound/complex sentence at the source side and two simple sentences at the target side were selected and 6000 examples were randomly picked from the selected set. The Split-Rephrase dataset is used to promote sentence splitting in the proposed system.", "spans": "[{\"corpusId\": 53019653, \"span\": \"our system\", \"start\": 23, \"end\": 23}, {\"corpusId\": 39344661, \"span\": \"(Flesch, 1948)\", \"start\": 290, \"end\": 304}, {\"corpusId\": 767485, \"span\": \"Hwang et al. (2015)\", \"start\": 926, \"end\": 945}, {\"corpusId\": 5013006, \"span\": \"Narayan et al. (2017)\", \"start\": 980, \"end\": 1001}, {\"corpusId\": 36364048, \"span\": \"Nisioi et al. (2017)\", \"start\": 1059, \"end\": 1079}, {\"corpusId\": 53019653, \"span\": \"proposed system\", \"start\": 1451, \"end\": 1451}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "32939", "title": "Unsupervised Neural Text Simplification", "sectionTitle": "Systems for Comparison", "text": "In the absence of any other direct baseline for end-to-end TS, we consider the following unsupervised baselines. We consider the unsupervised NMT framework proposed by (Artetxe et al., 2018b) as a baseline. It uses techniques such as backtranslation and denoising techniques to synthesize more training examples. To use this framework, we treated the set of simple and complex sentences as two different languages. Same model configuration as reported by Artetxe et al. (2018b) is used. We use the term UNMT for this system. Similar to the UNMT system, we also consider unsupervised statistical machine translation (termed as USMT) proposed by Artetxe et al. (2018a), with default parameter setting. Another system, based on the cross alignment technique proposed by Shen et al. (2017) is also used for comparison. The system is originally proposed for the task of sentiment translation. We term this system as ST.", "spans": "[{\"corpusId\": 3515219, \"span\": \"(Artetxe et al., 2018b\", \"start\": 168, \"end\": 190}, {\"corpusId\": 3515219, \"span\": \"Artetxe et al. (2018b)\", \"start\": 455, \"end\": 477}, {\"corpusId\": 53019653, \"span\": \"this system\", \"start\": 523, \"end\": 523}, {\"corpusId\": 52166727, \"span\": \"Artetxe et al. (2018a)\", \"start\": 644, \"end\": 666}, {\"corpusId\": 7296803, \"span\": \"Shen et al. (2017)\", \"start\": 767, \"end\": 785}, {\"corpusId\": 53019653, \"span\": \"this system\", \"start\": 907, \"end\": 907}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "32940", "title": "Unsupervised Neural Text Simplification", "sectionTitle": "Systems for Comparison", "text": "We also compare our approach with existing supervised and unsupervised lexical simplifications like LIGHTLS (Glava\u0161 and\u0160tajner, 2015), Neural Text Simplification or NTS (Nisioi et al., 2017), Syntax based Machine Translation or SBMT (Xu    PBSMT (Wubben et al., 2012). All the systems are trained using the Wikipedia-SimpleWikipedia dataset (Hwang et al., 2015). The test set is same for all of these and our models. Table 2 shows evaluation results of our proposed approaches along with existing supervised and unsupervised alternatives. We observe that unsupervised baselines such as UNMT and USMT often, after attaining convergence, recreates sentences similar to the inputs. This explains why they achieve higher BLEU and reduced worddifference scores. The ST system did not converge for our dataset after significant number of epochs which affected the performance metrics. The system often produces short sentences which are simple but do not retain important phrases.", "spans": "[{\"corpusId\": 53019653, \"span\": \"our approach\", \"start\": 28, \"end\": 28}, {\"corpusId\": 36364048, \"span\": \"(Nisioi et al., 2017)\", \"start\": 169, \"end\": 190}, {\"corpusId\": 767485, \"span\": \"(Hwang et al., 2015)\", \"start\": 341, \"end\": 361}, {\"corpusId\": 53019653, \"span\": \"our proposed approach\", \"start\": 474, \"end\": 474}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 6}
{"paperId": "593e4e749bd2dbcaf8dc25298d830b41d435e435", "title": "A Minimal Span-Based Neural Constituency Parser", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2017, "citationCount": 199, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/P17-1076.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1705.03919, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2017-05-10", "authors": [{"authorId": "144872294", "name": "Mitchell Stern"}, {"authorId": "2112400", "name": "Jacob Andreas"}, {"authorId": "38666915", "name": "D. Klein"}], "abstract": "In this work, we present a minimal neural model for constituency parsing based on independent scoring of labels and spans. We show that this model is not only compatible with classical dynamic programming techniques, but also admits a novel greedy top-down inference algorithm based on recursive partitioning of the input. We demonstrate empirically that both prediction schemes are competitive with recent work, and when combined with basic extensions to the scoring model are capable of achieving state-of-the-art single-model performance on the Penn Treebank (91.79 F1) and strong performance on the French Treebank (82.23 F1).", "corpusId": "8280711", "paragraphs": [{"paragraphId": "38717", "title": "A Minimal Span-Based Neural Constituency Parser", "sectionTitle": "Introduction", "text": "This paper presents a minimal but surprisingly effective span-based neural model for constituency parsing. Recent years have seen a great deal of interest in parsing architectures that make use of recurrent neural network (RNN) representations of input sentences (Vinyals et al., 2015). Despite evidence that linear RNN decoders are implicitly able to respect some nontrivial well-formedness constraints on structured outputs (Graves, 2013), researchers have consistently found that the best performance is achieved by systems that explicitly require the decoder to generate well-formed tree structures (Chen and Manning, 2014).", "spans": "[{\"corpusId\": 8280711, \"span\": \"This paper\", \"start\": 10, \"end\": 10}, {\"corpusId\": 14223, \"span\": \"(Vinyals et al., 2015)\", \"start\": 263, \"end\": 285}, {\"corpusId\": 11616343, \"span\": \"(Chen and Manning, 2014)\", \"start\": 603, \"end\": 627}]", "conference": "acl", "year": 2017, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "38718", "title": "A Minimal Span-Based Neural Constituency Parser", "sectionTitle": "Experiments", "text": "We first describe the general setup used for our experiments. We use the Penn Treebank (Marcus et al., 1993) for our English experiments, with standard splits of sections 2-21 for training, section 22 for development, and section 23 for testing. We use the French Treebank from the SPMRL 2014 shared task (Seddah et al., 2014) with its provided splits for our French experiments. No token preprocessing is performed, and only a single <UNK> token is used for unknown words at test time. The inputs to our system are concatenations of 100-dimensional word embeddings and 50-dimensional part-of-speech embeddings. In the case of the French Treebank, we also include 50-dimensional embeddings of each morphological tag. We use automatically predicted tags for training and testing, obtaining predicted part-ofspeech tags for the Penn Treebank using the Stanford tagger (Toutanova et al., 2003) with 10-way jackknifing, and using the provided predicted partof-speech and morphological tags for the French Treebank. Words are replaced by <UNK> with probability 1/(1+freq(w)) during training, where freq(w) is the frequency of w in the training data.", "spans": "[{\"corpusId\": 252796, \"span\": \"(Marcus et al., 1993)\", \"start\": 87, \"end\": 108}, {\"corpusId\": 18885228, \"span\": \"(Seddah et al., 2014)\", \"start\": 305, \"end\": 326}, {\"corpusId\": 8280711, \"span\": \"our system\", \"start\": 511, \"end\": 511}, {\"corpusId\": 14835360, \"span\": \"(Toutanova et al., 2003)\", \"start\": 866, \"end\": 890}]", "conference": "acl", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "38719", "title": "A Minimal Span-Based Neural Constituency Parser", "sectionTitle": "Related Work", "text": "Many early successful approaches to constituency parsing focused on rich modeling of correlations in the output space, typically by engineering proabilistic context-free grammars with state spaces enriched to capture long-distance dependencies and lexical phenomena (Collins, 2003;Petrov and Klein, 2007). By contrast, the approach we have described here continues a recent line of work on direct modeling of correlations in the input space, by using rich feature representations to parameterize local potentials that interact with a comparatively unconstrained structured decoder. As noted in the introduction, this class of feature-based tree scoring functions can be implemented with either a linear transition system (Chen and Manning, 2014) or a global decoder (Finkel et al., 2008). Kiperwasser and Goldberg (2016) describe an approach closely related to ours but targeted at dependency formalisms, and which easily accommodates both sparse log-linear scoring models (Hall et al., 2014) and deep neural potentials (Henderson, 2004;.", "spans": "[{\"corpusId\": 7901127, \"span\": \"(Collins, 2003;\", \"start\": 266, \"end\": 281}, {\"corpusId\": 1123594, \"span\": \"Petrov and Klein, 2007)\", \"start\": 281, \"end\": 304}, {\"corpusId\": 11616343, \"span\": \"(Chen and Manning, 2014)\", \"start\": 721, \"end\": 745}, {\"corpusId\": 803811, \"span\": \"(Finkel et al., 2008)\", \"start\": 766, \"end\": 787}, {\"corpusId\": 3107882, \"span\": \"(Hall et al., 2014)\", \"start\": 973, \"end\": 992}, {\"corpusId\": 1588411, \"span\": \"(Henderson, 2004;\", \"start\": 1020, \"end\": 1037}]", "conference": "acl", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "38720", "title": "A Minimal Span-Based Neural Constituency Parser", "sectionTitle": "Related Work", "text": "The best-performing constituency parsers in the last two years have largely been transition-based rather than global; examples include the models of , Cross and Huang (2016) and Liu and Zhang (2016). The present work takes many of the insights developed in these models (e.g. the recurrent representation of spans (Kiperwasser and Goldberg, 2016), and the use of a dynamic oracle and exploration policy during training (Goldberg and Nivre, 2013)) and extends these insights to span-oriented models, which support a wider range of decoding procedures. Our approach differs from other recent chart-based neural models (e.g. Durrett and Klein (2015)) in the use of a recurrent input representation, structured loss function, and comparatively simple parameterization of the scoring function. In addition to the globally optimal decoding procedures for which these models were designed, and in contrast to the left-to-right decoder typically employed by transition-based models, our model admits an additional greedy top-to-bottom inference procedure.", "spans": "[{\"corpusId\": 15407650, \"span\": \"Cross and Huang (2016)\", \"start\": 151, \"end\": 173}, {\"corpusId\": 815755, \"span\": \"(Goldberg and Nivre, 2013)\", \"start\": 419, \"end\": 445}, {\"corpusId\": 8280711, \"span\": \"Our approach\", \"start\": 563, \"end\": 563}]", "conference": "acl", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 4}
{"paperId": "cd1901cb9b9f4359c8fe5fc7d3b6c2738ec01945", "title": "Contextual Autonomy Support in Video Game Play: A Grounded Theory", "venue": "International Conference on Human Factors in Computing Systems", "year": 2016, "citationCount": 62, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/2858036.2858395?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2858036.2858395, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science", "Psychology"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2016-05-07", "authors": [{"authorId": "2127156", "name": "Sebastian Deterding"}], "abstract": null, "corpusId": "12987708", "paragraphs": [{"paragraphId": "58415", "title": "Contextual Autonomy Support in Video Game Play: A Grounded Theory", "sectionTitle": "INTRODUCTION", "text": "Indeed, play is commonly defined as \"voluntary\", \"free\", or \"autotelic\", it's own goal [1,2,21,32,52], unlike formal schooling, work, and other applied gaming contexts. Several scholars in human-computer interaction (HCI) [8], informatics [31], and game studies [58,59,61,63] hypothesize that mainstream forms of gamification -behavior tracking, quantitative progress feedback, and reward systems -might thwart rather than support the openness, inconsequentiality, and voluntariness characteristic for play. And evidence suggests that forced serious game play results in negative affect and reduced performance [19], and that worker consent moderates whether imposed workplace gamification results in positive or negative affect [29].", "spans": "[{\"corpusId\": 148117270, \"span\": \"[8]\", \"start\": 222, \"end\": 225}, {\"corpusId\": 144043670, \"span\": \"[58,\", \"start\": 262, \"end\": 266}, {\"corpusId\": 111723991, \"span\": \"59,\", \"start\": 266, \"end\": 269}, {\"corpusId\": 9384012, \"span\": \"61,\", \"start\": 269, \"end\": 272}, {\"corpusId\": 1588888, \"span\": \"[19]\", \"start\": 611, \"end\": 615}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "58416", "title": "Contextual Autonomy Support in Video Game Play: A Grounded Theory", "sectionTitle": "INTRODUCTION", "text": "Such potential demotivating effects of play contexts and their (lacking) voluntariness are relevant for entertainment game design as well: Journalists and ethnographers of massively multiplayer online role-playing games (MMORPGs) for instance observed that \"instrumental play\" -play that is work-like in its repetitive tedium and instrumentality, or even performed as obligatory wage labor -is sometimes described by its players as not enjoyable or play at all [11,30,46,51]. Social network games have been repeatedly critiqued for their \"dark patterns\" [62] that coerce players to play through timers or social pressure, with presumed negative effects on play experience. A recent survey [60] indicates that solitary and multiplayer playing differ in autonomy experience. Yet existing conceptualizations of the voluntariness of play have remained quite muddled and definitional [23]: they merely state that play is voluntary by definition. They do not provide a systematic theorization of \"voluntariness\", nor functional explanations how this quality comes about.", "spans": "[{\"corpusId\": 113496238, \"span\": \"[11,\", \"start\": 461, \"end\": 465}, {\"corpusId\": 17683705, \"span\": \"[62]\", \"start\": 554, \"end\": 558}, {\"corpusId\": 18547306, \"span\": \"[60]\", \"start\": 689, \"end\": 693}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "58417", "title": "Contextual Autonomy Support in Video Game Play: A Grounded Theory", "sectionTitle": "INTRODUCTION", "text": "A promising approach to theorizing the impact of contexts on game play motivation, especially the role of voluntariness, is self-determination theory (SDT) [6]. SDT argues that human beings actively seek out and engage in activities that satisfy basic psychological needs of competence, relatedness, and autonomy: perceiving oneself as the causal origin of one's actions. Basic need satisfaction explains why activities like play are intrinsically motivating, while autonomy provides a well-established construct for \"voluntariness\". SDT-informed research has identified contextual features that affect autonomy and demonstrated that need satisfaction can explain game play motivation. Finally, most critiques of gamification draw on SDT in some form to theorize its potential adverse effects [8,31,58,59,61] -yet have remained at the stage of hypothesizing.", "spans": "[{\"corpusId\": 141972908, \"span\": \"[6]\", \"start\": 156, \"end\": 159}, {\"corpusId\": 148117270, \"span\": \"[8,\", \"start\": 793, \"end\": 796}, {\"corpusId\": 144043670, \"span\": \"58,\", \"start\": 799, \"end\": 802}, {\"corpusId\": 111723991, \"span\": \"59,\", \"start\": 802, \"end\": 805}, {\"corpusId\": 9384012, \"span\": \"61\", \"start\": 805, \"end\": 807}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "58418", "title": "Contextual Autonomy Support in Video Game Play: A Grounded Theory", "sectionTitle": "THEORETICAL BACKGROUND", "text": "Besides autonomy, SDT has been fundamentally concerned with the social-contextual nature of motivation. Social contexts strongly affect the satisfaction or thwarting of basic psychological needs. Specifically, following cognitive evaluation theory, a sub-theory of SDT, any environmental event holds potential controlling, autonomy-thwarting aspects (pushing an actor into a certain direction), and poten-Designing New Player Experiences #chi4good, CHI 2016, San Jose, CA, USA tial informational, competence-supporting aspects (informing an actor how to improve her actions to achieve her desired goals) [38]. Individuals actively construe the \"functional significance\" or controlling versus informational meaning of environmental events based on both the nature of these events and the surrounding contextual climate [6]. For instance, expected rewards, threatened punishments, imposed goals, surveillance, competition or evaluation all overall tend to be viewed as controlling events [38]. However, in an autonomy-supportive company climate, a monetary bonus (expected reward) might be perceived as positive informational feedback rather than a control attempt. Such construal occurs on multiple levels of generality, with higher levels affecting lower ones [57]: if a person perceives herself overall autonomous in engaging in swimming (context), she can still experience an individual swimming training as controlled, but she will be more likely to perceive it as autonomous than someone who already perceives swimming in general as controlled, particularly if she actively recalls her overall endorsement of swimming.", "spans": "[{\"corpusId\": 150354527, \"span\": \"[38]\", \"start\": 604, \"end\": 608}, {\"corpusId\": 141972908, \"span\": \"[6]\", \"start\": 818, \"end\": 821}, {\"corpusId\": 150354527, \"span\": \"[38]\", \"start\": 986, \"end\": 990}, {\"corpusId\": 8531103, \"span\": \"[57]\", \"start\": 1260, \"end\": 1264}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "58419", "title": "Contextual Autonomy Support in Video Game Play: A Grounded Theory", "sectionTitle": "PREVIOUS WORK", "text": "Beyond such theoretical appeals, much empirical work supports the promise of SDT for tackling the contextual voluntariness of play. A rapidly growing number of experimental studies is successfully using SDT to explain video game play enjoyment and motivation [33][34][35][36][37]39,41,44,45]. Following the SDT-derived Player Experience of Need Satisfaction model (PENS) [37], games satisfy autonomy needs through a number of ways (see [7] for a design-focused review): particularly so-called \"sandbox games\" provide players with \"meaningful choice\" such as choosing different goals, strategies, and actions [37]; customization [25]; improving or customizing one's avatar [33,47,48]; back stories that provide rationales for activity [37]; wide-open, explorable worlds [50]; and the possibility to create and inhabit a character that is highly congruent with one's ideal self [34].", "spans": "[{\"corpusId\": 14534575, \"span\": \"[33]\", \"start\": 259, \"end\": 263}, {\"corpusId\": 18131352, \"span\": \"[35]\", \"start\": 267, \"end\": 271}, {\"corpusId\": 56000483, \"span\": \"[36]\", \"start\": 271, \"end\": 275}, {\"corpusId\": 1977867, \"span\": \"41,\", \"start\": 282, \"end\": 285}, {\"corpusId\": 54209510, \"span\": \"44,\", \"start\": 285, \"end\": 288}, {\"corpusId\": 4655587, \"span\": \"45]\", \"start\": 288, \"end\": 291}, {\"corpusId\": 46306454, \"span\": \"[25]\", \"start\": 628, \"end\": 632}, {\"corpusId\": 14534575, \"span\": \"[33,\", \"start\": 672, \"end\": 676}, {\"corpusId\": 58531579, \"span\": \"47,\", \"start\": 676, \"end\": 679}, {\"corpusId\": 1429329, \"span\": \"[50]\", \"start\": 769, \"end\": 773}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "58420", "title": "Contextual Autonomy Support in Video Game Play: A Grounded Theory", "sectionTitle": "PREVIOUS WORK", "text": "A rich body of SDT work corroborates that and how particular strategies facilitate an autonomy-supporting contextual climate and thus, autonomy satisfaction and intrinsic motivation across education, parenting, coaching, work, health and psychotherapy (see [43] for a review). These strategies chiefly revolve around providing meaningful rationales for activities (enabling conscious integration), acknowledgement of negative feelings, the use of non-controlling language, the provision of choices, and appealing to basic needs. When it comes to social contexts of gameplay, research has focused on the effect of social presence and social interaction -the general argument being that more social presence and interaction equals a better gaming experience [5,14,17,24,27]. Some studies have explicitly linked the effect of social presence on game enjoyment to SDT, namely the satisfaction of relatedness needs [24].", "spans": "[{\"corpusId\": 28167880, \"span\": \"[43]\", \"start\": 257, \"end\": 261}, {\"corpusId\": 2089690, \"span\": \"[5,\", \"start\": 756, \"end\": 759}, {\"corpusId\": 54909349, \"span\": \"17,\", \"start\": 762, \"end\": 765}, {\"corpusId\": 17260085, \"span\": \"24,\", \"start\": 765, \"end\": 768}, {\"corpusId\": 144698448, \"span\": \"27]\", \"start\": 768, \"end\": 771}, {\"corpusId\": 17260085, \"span\": \"[24]\", \"start\": 910, \"end\": 914}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "58421", "title": "Contextual Autonomy Support in Video Game Play: A Grounded Theory", "sectionTitle": "Implications for entertainment games", "text": "That being said, our findings do hold a number of interesting ramifications. First, they identify several ways in which contexts support autonomy that have not been described in the SDT literature on games or social contexts in general. Second, existing research has chiefly treated \"voluntariness\" as a defining feature of \"play\" without unpacking the construct further [23]. Several scholars pointed to phenomena of instrumental play that contradict this straightforward definition, leaving the relation between play and voluntari-ness unclear [11,30,46,51]. Our results offer a theoretical model how \"voluntariness\" comes about in and relates to \"play\": The experience of autonomy is a social norm for the type of context people label \"play\" (cf. [57]). As part of (re)producing a play context, people accomplish a sociomaterial setup that strongly affords autonomy. The resulting autonomy experiences lead participants to then recognize and label the situation as \"play\". Conversely, if the setup of a gaming situation affords little autonomy, this experience may lead participants to label it \"work\" and flag it as inappropriate: something that should be autonomous isn't. This model opens to the wider question how labeling or framing and autonomy experience interrelate. For instance, does labeling something as \"play\" increase experienced autonomy? There are several interesting starting points for this research trajectory [20,26,28], but it essentially remains an open question.", "spans": "[{\"corpusId\": 12987708, \"span\": \"our findings\", \"start\": 29, \"end\": 29}, {\"corpusId\": 113496238, \"span\": \"[11,\", \"start\": 546, \"end\": 550}, {\"corpusId\": 12987708, \"span\": \"Our results\", \"start\": 572, \"end\": 572}, {\"corpusId\": 8531103, \"span\": \"[57]\", \"start\": 750, \"end\": 754}, {\"corpusId\": 12987708, \"span\": \"this research\", \"start\": 1420, \"end\": 1420}, {\"corpusId\": 5060308, \"span\": \"[20,\", \"start\": 1432, \"end\": 1436}, {\"corpusId\": 143467376, \"span\": \"28]\", \"start\": 1439, \"end\": 1442}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "58422", "title": "Contextual Autonomy Support in Video Game Play: A Grounded Theory", "sectionTitle": "Implications for applied gaming", "text": "Although our study did not explicitly explore autonomy experiences with gamified applications or serious games, its results still arguably speak to the frequent concern that gamification may create demotivating coercion rather than engaging play. Most critiques of this kind draw on SDT in some form [8,31,58,59,61], hypothesizing that the progress feedback and reward elements central to gamification (points, badges, leaderboards) produce the well-documented effect of extrinsic rewards undermining existing intrinsic motivation by thwarting autonomy [64]. In a sense, although gamification criticism is concerned with differences in autonomy between entertainment and applied gaming, like game enjoyment research, it has chiefly focused system design not social context. Yet our results indicate that context is what matters.", "spans": "[{\"corpusId\": 12987708, \"span\": \"our study\", \"start\": 18, \"end\": 18}, {\"corpusId\": 148117270, \"span\": \"[8,\", \"start\": 300, \"end\": 303}, {\"corpusId\": 144043670, \"span\": \"58,\", \"start\": 306, \"end\": 309}, {\"corpusId\": 111723991, \"span\": \"59,\", \"start\": 309, \"end\": 312}, {\"corpusId\": 9384012, \"span\": \"61]\", \"start\": 312, \"end\": 315}, {\"corpusId\": 15271950, \"span\": \"[64]\", \"start\": 553, \"end\": 557}, {\"corpusId\": 12987708, \"span\": \"our results\", \"start\": 789, \"end\": 789}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "58423", "title": "Contextual Autonomy Support in Video Game Play: A Grounded Theory", "sectionTitle": "Implications for applied gaming", "text": "Obligatory contexts furthermore provide little or no license to configure and (dis)engage with the situation to fit one's interests and needs. Beyond directly thwarting autonomy, this also makes it less likely that people will engage in an activity that supplies intrinsic enjoyment. Thus, where engagement with a serious game or gamified application is mandated, and/or the game or application reinforce existing restrictions of conduct, this will likely reduce people's autonomy. Several scholars and practitioners have suggested that 'good' gamification should be voluntary to participate in; only involve activities that are voluntary to begin with, or in the case of workplace gamification, not involve core job tasks necessarily linked to remuneration and promotion; and rather than reinforce existing regulations, it should restructure activity such that participants have a greater ability to align what they do when, how, and with whom with their own interests and needs, analogous to e.g. Montessori pedagogy or results-only work environments [31,58,61,[65][66][67][68]. Our study provides a theoretical model why and how these recommendations work to support autonomy.", "spans": "[{\"corpusId\": 144043670, \"span\": \"58,\", \"start\": 1057, \"end\": 1060}, {\"corpusId\": 9384012, \"span\": \"61,\", \"start\": 1060, \"end\": 1063}, {\"corpusId\": 12987708, \"span\": \"Our study\", \"start\": 1090, \"end\": 1090}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 9}
{"paperId": "c0a57b879ee51e1a648012f0276899d6efd35382", "title": "Adaptive Scaling for Sparse Detection in Information Extraction", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2018, "citationCount": 10, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/P18-1095.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1805.00250, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2018-05-01", "authors": [{"authorId": "48444897", "name": "Hongyu Lin"}, {"authorId": "1831434", "name": "Yaojie Lu"}, {"authorId": "3194601", "name": "Xianpei Han"}, {"authorId": null, "name": "Le Sun"}], "abstract": "This paper focuses on detection tasks in information extraction, where positive instances are sparsely distributed and models are usually evaluated using F-measure on positive classes. These characteristics often result in deficient performance of neural network based detection models. In this paper, we propose adaptive scaling, an algorithm which can handle the positive sparsity problem and directly optimize over F-measure via dynamic cost-sensitive learning. To this end, we borrow the idea of marginal utility from economics and propose a theoretical framework for instance importance measuring without introducing any additional hyper-parameters. Experiments show that our algorithm leads to a more effective and stable training of neural network based detection models.", "corpusId": "13747354", "paragraphs": [{"paragraphId": "87872", "title": "Adaptive Scaling for Sparse Detection in Information Extraction", "sectionTitle": "Introduction", "text": "Due to the class inequality characteristic, reported results indicate that simply applying stan-dard classification paradigm to detection tasks will result in deficient performance (Anand et al., 1993;Carvajal et al., 2004;Lin et al., 2017). This is because minimizing cross-entropy loss function corresponds to maximize the accuracy of neural networks on all training instances, rather than Fmeasure on positive classes. Furthermore, due to the positive sparsity problem, training procedure will easily achieve a high accuracy on negative class, but is difficult to converge on positive classes and often leads to a low recall rate. Although simple sampling heuristics can alleviate this problem to some extent, they either suffer from losing inner class information or over-fitting positive instances (He and Garcia, 2009;Fern\u00e1ndez-Navarro et al., 2011), which often result in instability during the training procedure.", "spans": "[{\"corpusId\": 11969155, \"span\": \"(Anand et al., 1993;\", \"start\": 181, \"end\": 201}, {\"corpusId\": 67312248, \"span\": \"(He and Garcia, 2009;\", \"start\": 803, \"end\": 824}, {\"corpusId\": 13571360, \"span\": \"Fern\\u00e1ndez-Navarro et al., 2011)\", \"start\": 824, \"end\": 855}]", "conference": "acl", "year": 2018, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "87873", "title": "Adaptive Scaling for Sparse Detection in Information Extraction", "sectionTitle": "Introduction", "text": "Some previous approaches (Joachims, 2005;Jansche, 2005Jansche, , 2007Dembczynski et al., 2011;Chinta et al., 2013;Narasimhan et al., 2014;Natarajan et al., 2016) tried to solve this problem by directly optimizing F-measure. Parambath et al. (2014) proved that it is sufficient to solve F-measure optimization problem via cost-sensitive learning, where class-specific cost factors are applied to indicate the importance of different classes to F-measure. However, optimal factors are not known a priori so \u03b5-search needs to be applied, which is too time consuming for the optimization of neural networks.", "spans": "[{\"corpusId\": 1115550, \"span\": \"(Joachims, 2005;\", \"start\": 25, \"end\": 41}, {\"corpusId\": 5568092, \"span\": \"Jansche, 2005\", \"start\": 41, \"end\": 54}, {\"corpusId\": 6276617, \"span\": \"Jansche, , 2007\", \"start\": 54, \"end\": 69}, {\"corpusId\": 14004502, \"span\": \"Dembczynski et al., 2011;\", \"start\": 69, \"end\": 94}, {\"corpusId\": 401390, \"span\": \"Chinta et al., 2013;\", \"start\": 94, \"end\": 114}, {\"corpusId\": 11254722, \"span\": \"Narasimhan et al., 2014;\", \"start\": 114, \"end\": 138}, {\"corpusId\": 2680545, \"span\": \"Natarajan et al., 2016)\", \"start\": 138, \"end\": 161}, {\"corpusId\": 13985040, \"span\": \"Parambath et al. (2014)\", \"start\": 224, \"end\": 247}]", "conference": "acl", "year": 2018, "likelyRelatedWorkSection": false, "refCount": 8}, {"paragraphId": "87874", "title": "Adaptive Scaling for Sparse Detection in Information Extraction", "sectionTitle": "Background", "text": "where \u03b2 in F \u03b2 is a factor indicating the metric attaches \u03b2 times as much importance to recall as precision. We can easily see that for accuracy metric, correct predictions of positive and negative instances are equally regarded (i.e., T P and T N are symmetric), which is consistent with crossentropy loss function. However, when measuring using F-measure, this condition is no longer holding. The importance varies from different classes (i.e., T P and T N are asymmetric). Therefore, to make the training procedure consistent with F-measure, it is critical to take this importance difference into consideration. F-measure Optimization via Cost-sensitive Learning. Parambath et al. (2014) have shown that F-measure can be optimized via cost-sensitive learning, where a cost (importance) is set for each class for adjusting their impact on model learning. However, most previous studies set such costs manually (Anand et al., 1993;Domingos, 1999;Krawczyk et al., 2014) or search them on large scale dataset (Nan et al., 2012;Parambath et al., 2014), whose best settings are not transferable and very time-consuming to find for neural network models. This motivates us to develop a theoretical framework for measuring such importance.", "spans": "[{\"corpusId\": 11969155, \"span\": \"(Anand et al., 1993;\", \"start\": 912, \"end\": 932}, {\"corpusId\": 207624573, \"span\": \"Domingos, 1999;\", \"start\": 932, \"end\": 947}, {\"corpusId\": 13805036, \"span\": \"Krawczyk et al., 2014)\", \"start\": 947, \"end\": 969}, {\"corpusId\": 13985040, \"span\": \"Parambath et al., 2014)\", \"start\": 1026, \"end\": 1049}]", "conference": "acl", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "87875", "title": "Adaptive Scaling for Sparse Detection in Information Extraction", "sectionTitle": "Related Work", "text": "This paper proposes adaptive scaling algorithm for sparse detection problem. Related work to this paper mainly includes: Classification on Imbalanced Data. Conventional approaches addressed data imbalance from either data-level or algorithm-level. Data-level approaches resample the training data to maintain the balance between different classes (Japkowicz and Stephen, 2002;Drummond et al., 2003). Further improvements on this direction involve how to better sampling data with minimum in-formation loss (Carvajal et al., 2004;Estabrooks et al., 2004;Han et al., 2005;Fern\u00e1ndez-Navarro et al., 2011). Algorithm-level approaches attempt to choose an appropriate inductive bias on models or algorithms to make them more suitable on data imbalance condition, including instance weighting (Ting, 2002;Lin et al., 2017), cost-sensitive learning (Anand et al., 1993;Domingos, 1999;Sun et al., 2007;Krawczyk et al., 2014) and active learning approaches (Ertekin et al., 2007a,b;Zhu and Hovy, 2007). F-Measure Optimization. Previous research on F-measure optimization mainly fell into two paradigms (Nan et al., 2012): 1) Decisiontheoretic approaches (DTA), which first estimate a probability model and find the optimal predictions according to that model (Joachims, 2005;Jansche, 2005Jansche, , 2007Dembczynski et al., 2011;Busa-Fekete et al., 2015;Natarajan et al., 2016). The main drawback of these methods is that they need to estimate the joint probability with exponentially many combinations, thus make them hard to use in practice; 2) Empirical utility maximization (EUM) approaches, which adapt approximate methods to find a best classifier in hypothesises (Musicant et al., 2003;Chinta et al., 2013;Parambath et al., 2014;Narasimhan et al., 2014). However, EUM methods depend on thresholds or costs that are not known a priori so time-consuming searching on large development set is required. Our adaptive scaling algorithm is partially inspired by EUM approaches, but is based on the marginal utility framework, which doesn't introduce any additional hyper-parameter or searching procedure. Neural Network based Event Detection. Event detection is a typical task of detection problems. Recently neural network based methods have achieved significant progress in Event Detection. CNNs (Chen et al., 2015;Nguyen and Grishman, 2015) and Bi-LSTMs (Zeng et al., 2016;Yang and Mitchell, 2017) are two effective and widely used models. Some improvements have been made by jointly predicting triggers and arguments  or introducing more complicated architectures to capture larger scale of contexts Ghaeini et al., 2016).", "spans": "[{\"corpusId\": 13747354, \"span\": \"This paper\", \"start\": 10, \"end\": 10}, {\"corpusId\": 13747354, \"span\": \"this paper\", \"start\": 103, \"end\": 103}, {\"corpusId\": 204083391, \"span\": \"Drummond et al., 2003)\", \"start\": 376, \"end\": 398}, {\"corpusId\": 15305650, \"span\": \"Estabrooks et al., 2004;\", \"start\": 529, \"end\": 553}, {\"corpusId\": 12126950, \"span\": \"Han et al., 2005;\", \"start\": 553, \"end\": 570}, {\"corpusId\": 13571360, \"span\": \"Fern\\u00e1ndez-Navarro et al., 2011)\", \"start\": 570, \"end\": 601}, {\"corpusId\": 14303763, \"span\": \"(Ting, 2002;\", \"start\": 787, \"end\": 799}, {\"corpusId\": 11969155, \"span\": \"(Anand et al., 1993;\", \"start\": 842, \"end\": 862}, {\"corpusId\": 207624573, \"span\": \"Domingos, 1999;\", \"start\": 862, \"end\": 877}, {\"corpusId\": 758563, \"span\": \"Sun et al., 2007;\", \"start\": 877, \"end\": 894}, {\"corpusId\": 13805036, \"span\": \"Krawczyk et al., 2014)\", \"start\": 894, \"end\": 916}, {\"corpusId\": 8841327, \"span\": \"Zhu and Hovy, 2007)\", \"start\": 973, \"end\": 992}, {\"corpusId\": 1115550, \"span\": \"(Joachims, 2005;\", \"start\": 1250, \"end\": 1266}, {\"corpusId\": 5568092, \"span\": \"Jansche, 2005\", \"start\": 1266, \"end\": 1279}, {\"corpusId\": 6276617, \"span\": \"Jansche, , 2007\", \"start\": 1279, \"end\": 1294}, {\"corpusId\": 14004502, \"span\": \"Dembczynski et al., 2011;\", \"start\": 1294, \"end\": 1319}, {\"corpusId\": 2680545, \"span\": \"Natarajan et al., 2016)\", \"start\": 1344, \"end\": 1367}, {\"corpusId\": 14398042, \"span\": \"(Musicant et al., 2003;\", \"start\": 1660, \"end\": 1683}, {\"corpusId\": 401390, \"span\": \"Chinta et al., 2013;\", \"start\": 1683, \"end\": 1703}, {\"corpusId\": 13985040, \"span\": \"Parambath et al., 2014;\", \"start\": 1703, \"end\": 1726}, {\"corpusId\": 11254722, \"span\": \"Narasimhan et al., 2014)\", \"start\": 1726, \"end\": 1750}, {\"corpusId\": 14339673, \"span\": \"(Chen et al., 2015;\", \"start\": 2289, \"end\": 2308}, {\"corpusId\": 10913456, \"span\": \"Nguyen and Grishman, 2015)\", \"start\": 2308, \"end\": 2334}, {\"corpusId\": 11713683, \"span\": \"(Zeng et al., 2016;\", \"start\": 2348, \"end\": 2367}, {\"corpusId\": 19968363, \"span\": \"Yang and Mitchell, 2017)\", \"start\": 2367, \"end\": 2391}, {\"corpusId\": 3608203, \"span\": \"Ghaeini et al., 2016)\", \"start\": 2595, \"end\": 2616}]", "conference": "acl", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 25}], "paragraphCount": 4}
{"paperId": "e18c26b9faa94d03af5161cac103289b5f732dae", "title": "Sentence-Level Evidence Embedding for Claim Verification with Hierarchical Attention Networks", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2019, "citationCount": 109, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/P19-1244.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://aclanthology.org/P19-1244, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2019-07-01", "authors": [{"authorId": "49304670", "name": "Jing Ma"}, {"authorId": "145816335", "name": "Wei Gao"}, {"authorId": "2708940", "name": "Shafiq R. Joty"}, {"authorId": "1784988", "name": "Kam-Fai Wong"}], "abstract": "Claim verification is generally a task of verifying the veracity of a given claim, which is critical to many downstream applications. It is cumbersome and inefficient for human fact-checkers to find consistent pieces of evidence, from which solid verdict could be inferred against the claim. In this paper, we propose a novel end-to-end hierarchical attention network focusing on learning to represent coherent evidence as well as their semantic relatedness with the claim. Our model consists of three main components: 1) A coherence-based attention layer embeds coherent evidence considering the claim and sentences from relevant articles; 2) An entailment-based attention layer attends on sentences that can semantically infer the claim on top of the first attention; and 3) An output layer predicts the verdict based on the embedded evidence. Experimental results on three public benchmark datasets show that our proposed model outperforms a set of state-of-the-art baselines.", "corpusId": "196209746", "paragraphs": [{"paragraphId": "75873", "title": "Sentence-Level Evidence Embedding for Claim Verification with Hierarchical Attention Networks", "sectionTitle": "Introduction", "text": "Not surprisingly, various methods for automatic claim verification have been proposed using machine learning. Typically, given the claims, models are learned from auxiliary relevant sources such as news articles or social media responses for capturing words and linguistic units that might indicate viewpoint or language style towards the claim Rashkin et al., 2017;Popat et al., 2017;Dungs et al., 2018). However, the factuality of a claim is independent of people's belief and subjective language use, and human perception is unconsciously prone to misinformation due to the common cognitive biases such as naive realism (Reed et al., 2013) and confirmation bias (Nickerson, 1998).", "spans": "[{\"corpusId\": 29298828, \"span\": \"Rashkin et al., 2017;\", \"start\": 345, \"end\": 366}, {\"corpusId\": 4837028, \"span\": \"Popat et al., 2017;\", \"start\": 366, \"end\": 385}, {\"corpusId\": 52010043, \"span\": \"Dungs et al., 2018)\", \"start\": 385, \"end\": 404}, {\"corpusId\": 148038690, \"span\": \"(Reed et al., 2013)\", \"start\": 623, \"end\": 642}, {\"corpusId\": 8508954, \"span\": \"(Nickerson, 1998)\", \"start\": 665, \"end\": 682}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "75874", "title": "Sentence-Level Evidence Embedding for Claim Verification with Hierarchical Attention Networks", "sectionTitle": "Introduction", "text": "A recent trend is that researchers are trying to establish more objective tasks and evidence-based verification solutions, which focus on the use of evidence obtained from more reliable sources, e.g., encyclopedia articles, verified news, etc., as an important distinguishing factor (Thorne and Vlachos, 2018). Ferreira and Vlachos (2016) use news headlines as evidence to predict whether it is for, against or observing a claim. In the Fake News Challenge 2 , the body text of an article is used as evidence to detect the stances relative to the claim made in the headline. Thorne et al. (2018a) formulate the Fact Extraction and VERification (FEVER) task which requires extracting evidence from Wikipedia and synthesizing information from multiple documents to verify the claim. Popat et al. (2018) propose DeClarE, an evidence-aware neural attention model to aggregate salient words from source news articles as the  main evidence to obtain claim-specific representation based on the attention score of each token. Inspired by the FEVER task (Thorne et al., 2018a) and DeClarE (Popat et al., 2018), we propose our approach to claim verification by using representation learning to embed sentence-level evidences based on coherence modeling and natural language inference (NLI). The example in Table 1 illustrates our general idea: given a claim \"The test of a 5G cellular network is the cause of unexplained bird deaths occurring in a park in The Hague, Netherlands\" and its relevant articles, we try to embed into the claim-specific representation those evidential sentences (e.g., s 1 -s 4 ) that are not only topically coherent among themselves considering the claim, but could also semantically infer the claim based on textual entailment relations such as entail, contradict, and neutral. It is hypothesized that sentence-level evidence can convey more complete and deeper semantics, thus providing stronger NLI capacity between claim and evidence, which would result in better claimspecific representation for the more accurate factchecking decision.", "spans": "[{\"corpusId\": 49320819, \"span\": \"(Thorne and Vlachos, 2018)\", \"start\": 283, \"end\": 309}, {\"corpusId\": 1434196, \"span\": \"Ferreira and Vlachos (2016)\", \"start\": 311, \"end\": 338}, {\"corpusId\": 4711425, \"span\": \"Thorne et al. (2018a)\", \"start\": 575, \"end\": 596}, {\"corpusId\": 52215843, \"span\": \"Popat et al. (2018)\", \"start\": 781, \"end\": 800}, {\"corpusId\": 4711425, \"span\": \"(Thorne et al., 2018a)\", \"start\": 1045, \"end\": 1067}, {\"corpusId\": 52215843, \"span\": \"(Popat et al., 2018)\", \"start\": 1080, \"end\": 1100}, {\"corpusId\": 196209746, \"span\": \"we propose\", \"start\": 1112, \"end\": 1112}, {\"corpusId\": 196209746, \"span\": \"our approach\", \"start\": 1125, \"end\": 1125}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "75875", "title": "Sentence-Level Evidence Embedding for Claim Verification with Hierarchical Attention Networks", "sectionTitle": "Related Work", "text": "The literature on fact-checking and credibility assessment has been reviewed by several comprehensive surveys (Shu et al., 2017;Zubiaga et al., 2018;Kumar and Shah, 2018;Sharma et al., 2019). We only briefly review prior works closely related to ours. Many studies on claim verification extracted veracity-indicative features that can reflect stances and writing styles from relevant texts such as news articles, microblog posts, etc. and used the traditional supervised models to learn the parameters (Castillo et al., 2011;Qazvinian et al., 2011;Rubin et al., 2016;Ferreira and Vlachos, 2016;Rashkin et al., 2017). Deep learning models such as recurrent neural networks (RNN) (Ma et al., 2016), convolutional neural networks (CNN) (Wang, 2017) and recursive neural networks (Ma et al., 2018) were also exploited to learn the feature representations.", "spans": "[{\"corpusId\": 207718082, \"span\": \"(Shu et al., 2017;\", \"start\": 110, \"end\": 128}, {\"corpusId\": 215926195, \"span\": \"Zubiaga et al., 2018;\", \"start\": 128, \"end\": 149}, {\"corpusId\": 5919237, \"span\": \"(Castillo et al., 2011;\", \"start\": 502, \"end\": 525}, {\"corpusId\": 14124213, \"span\": \"Qazvinian et al., 2011;\", \"start\": 525, \"end\": 548}, {\"corpusId\": 17202384, \"span\": \"Rubin et al., 2016;\", \"start\": 548, \"end\": 567}, {\"corpusId\": 1434196, \"span\": \"Ferreira and Vlachos, 2016;\", \"start\": 567, \"end\": 594}, {\"corpusId\": 29298828, \"span\": \"Rashkin et al., 2017)\", \"start\": 594, \"end\": 615}, {\"corpusId\": 16985095, \"span\": \"(Ma et al., 2016)\", \"start\": 678, \"end\": 695}, {\"corpusId\": 51878172, \"span\": \"(Ma et al., 2018)\", \"start\": 776, \"end\": 793}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "75876", "title": "Sentence-Level Evidence Embedding for Claim Verification with Hierarchical Attention Networks", "sectionTitle": "Related Work", "text": "More recently, semantic matching methods were proposed to retrieve evidence from relatively trustworthy sources such as checked news and Wikipedia articles. Popat et al. (2018) attempted to debunk false claims by learning claim representations from relevant articles using an attention mechanism to focus on words that are closely related to the claim. Following NLI (Bowman et al., 2015), which is a task of classifying the relationship between a pair of sentences, composed by a premise and a hypothesis, as Entails, Contradicts or Neutral, Thorne et al. (2018a) formulated claim verification as a task that aims to classify claims into Supported, Refuted or Not Enough Info (NEI). They released a large dataset containing mutated claims based on relevant Wikipedia articles and developed a basic pipeline with document retrieval, sentence selection, and NLI modules. Similar pipelines were developed by most of the participating teams (Nie et al., 2019;Padia et al., 2018;Alhindi et al., 2018;Hanselowski et al., 2018) in FEVER shared task (Thorne et al., 2018b). Apart from the document retrieval function, our model is end-to-end and aims to learn sentence-level evidence with a hierarchical attention framework.", "spans": "[{\"corpusId\": 52215843, \"span\": \"Popat et al. (2018)\", \"start\": 157, \"end\": 176}, {\"corpusId\": 14604520, \"span\": \"(Bowman et al., 2015)\", \"start\": 367, \"end\": 388}, {\"corpusId\": 4711425, \"span\": \"Thorne et al. (2018a)\", \"start\": 543, \"end\": 564}, {\"corpusId\": 69593290, \"span\": \"Padia et al., 2018;\", \"start\": 956, \"end\": 975}, {\"corpusId\": 53640239, \"span\": \"Alhindi et al., 2018;\", \"start\": 975, \"end\": 996}, {\"corpusId\": 52162540, \"span\": \"Hanselowski et al., 2018)\", \"start\": 996, \"end\": 1021}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "75877", "title": "Sentence-Level Evidence Embedding for Claim Verification with Hierarchical Attention Networks", "sectionTitle": "Related Work", "text": "Attention is in general used to attend on the most important part of texts, and has been successfully applied in machine translation (Luong et al.), question answering (Xiong et al., 2016) and parsing (Dozat and Manning, 2016), and is adopted in our model for attending on important sentences as evidence. Our work is also related to coherence modeling. Different from traditional coherence studies focusing on discourse coherence among sentences that are widely applied in text generation (Park and Kim, 2015; Kiddon et al., 2016) and summarization (Logeswaran et al., 2018), we try to capture evidential sentences topically coherent not only among themselves but also with respect to the target claim.", "spans": "[{\"corpusId\": 196209746, \"span\": \"Our work\", \"start\": 314, \"end\": 314}, {\"corpusId\": 9818013, \"span\": \"Kiddon et al., 2016)\", \"start\": 511, \"end\": 531}, {\"corpusId\": 3920347, \"span\": \"(Logeswaran et al., 2018)\", \"start\": 550, \"end\": 575}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "75878", "title": "Sentence-Level Evidence Embedding for Claim Verification with Hierarchical Attention Networks", "sectionTitle": "Problem Statement", "text": "Our approach exploits and integrates two core semantic relations: 1) coherence of the sentences given the claim; 2) entailment relation between the claim and each sentence, which are described more specifically below. Coherence Evaluation: According to the coherence theory of truth, the truth of any (true) proposition consists in its coherence with some specified set of propositions (Young, 2018). In order to focus on the useful evidence in a set of relevant sentences S, we propose a coherence-based attention component by cross-checking if any sentence s i \u2208 S coheres well with the claim and with other sentences in S in terms of topical consistency. Textual Entailment: Entailment is used to measure whether a piece of evidence semantically infers a given claim. We propose an entailmentbased attention component that can be pre-trained to capture entailment relations (Dagan et al., 2010;Bowman et al., 2015) based on sentence pairs labeled with NLI-specific classes: entails, contradicts and neutral. This pre-trained component together with the entire claim verification framework then will be trained end-to-end to attend on the salient sentences for inferring the claim.", "spans": "[{\"corpusId\": 196209746, \"span\": \"Our approach\", \"start\": 12, \"end\": 12}, {\"corpusId\": 196209746, \"span\": \"we propose\", \"start\": 486, \"end\": 486}, {\"corpusId\": 196209746, \"span\": \"We propose\", \"start\": 781, \"end\": 781}, {\"corpusId\": 18717799, \"span\": \"(Dagan et al., 2010;\", \"start\": 877, \"end\": 897}, {\"corpusId\": 14604520, \"span\": \"Bowman et al., 2015)\", \"start\": 897, \"end\": 917}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "75879", "title": "Sentence-Level Evidence Embedding for Claim Verification with Hierarchical Attention Networks", "sectionTitle": "Entailment-based Evidence Attention", "text": "We further enhance the sentence representation by capturing the entailment relations between the sentences and the claim based on the NLI method (Bowman et al., 2015) for strengthening the semantic inference capacity of our model. Given c and s i , we represent each such pair by integrating three matching functions between h c andh s i : 1) concatenation [h c ,h s i ]; 2) elementwise product h c h s i ; and 3) absolute elementwise difference |h c \u2212h s i |. The similar matching scheme was commonly used to train NLI models (Conneau et al., 2017;Mou et al., 2016;Liu et al., 2016;. We then perform a transformation to obtain the joint representation h c s i as follow:", "spans": "[{\"corpusId\": 14604520, \"span\": \"(Bowman et al., 2015)\", \"start\": 145, \"end\": 166}, {\"corpusId\": 28971531, \"span\": \"(Conneau et al., 2017;\", \"start\": 527, \"end\": 549}, {\"corpusId\": 7454072, \"span\": \"Mou et al., 2016;\", \"start\": 549, \"end\": 566}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "75880", "title": "Sentence-Level Evidence Embedding for Claim Verification with Hierarchical Attention Networks", "sectionTitle": "Overall Training", "text": "After pre-training, all the model parameters are trained end-to-end by minimizing the squared error between the class probability distribution of the prediction and that of the ground truth over the claims. Parameters are updated through backpropagation (Collobert et al., 2011) with Ada-Grad (Duchi et al., 2011) for speeding up convergence. The training process ends when the model converges or the maximum epoch number is met. We represent input words using pre-trained GloVe Wikipedia 6B word embeddings (Pennington et al., 2014). We set d to 300 for word vectors and l to 100 for hidden units, and no parameter depends on n which varies with different claims.", "spans": "[{\"corpusId\": 351666, \"span\": \"(Collobert et al., 2011)\", \"start\": 254, \"end\": 278}, {\"corpusId\": 538820, \"span\": \"(Duchi et al., 2011)\", \"start\": 293, \"end\": 313}, {\"corpusId\": 1957433, \"span\": \"(Pennington et al., 2014)\", \"start\": 508, \"end\": 533}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 8}
{"paperId": "5e2b43efb44af88bae17ed1e7932d3df1506dfb6", "title": "Voicesetting: Voice Authoring UIs for Improved Expressivity in Augmentative Communication", "venue": "International Conference on Human Factors in Computing Systems", "year": 2018, "citationCount": 24, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3173574.3173857?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3173574.3173857, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2018-04-21", "authors": [{"authorId": "1988208", "name": "Alexander J. Fiannaca"}, {"authorId": "40115811", "name": "A. Paradiso"}, {"authorId": "151473689", "name": "Jon Campbell"}, {"authorId": "144844426", "name": "M. Morris"}], "abstract": null, "corpusId": "5047113", "paragraphs": [{"paragraphId": "9085", "title": "Voicesetting: Voice Authoring UIs for Improved Expressivity in Augmentative Communication", "sectionTitle": "INTRODUCTION", "text": "Augmentative and alternative communication (AAC) devices are technologies that allow people with speech disabilities to communicate. Current speech generating devices (SGD) used for AAC offer little in the way of allowing users to control the expressive nature of the speech rendered from the user's input [11]. This is surprising given that advances in speech synthesis technologies over the past decade have resulted in the development of text-to-speech (TTS) engines capable of rendering speech that exhibits a range of emotions (e.g., CereProc [4], Nuance Loquendo [18], and IBM Watson [30] are commercial speech engines capable of emotional speech synthesis). Additionally, most TTS engines accept Speech Synthesis Markup Language (SSML) [2] as input, allowing for a degree of control over prosodic features such as the rate of speech, the pitch of the voice, and cadence/pacing of words. The fact that these advances have yet to be incorporated into SGDs in a meaningful way is a major issue for AAC. Recent work such as that of Higginbotham [9], Kane et. al. [11], and Pullin et al. [22] has described the importance of this issue and the need to develop better AAC systems capable of more expressive speech, but to date, there are no research or commercially available AAC devices that provide advanced expressive speech capabilities, with a majority only allowing for basic modification of speech parameters (overall rate and volume) that cannot be varied on-the-fly (as utterances are constructed and played), while not leveraging the capabilities available in modern TTS engines.", "spans": "[{\"corpusId\": 16747498, \"span\": \"[11]\", \"start\": 306, \"end\": 310}, {\"corpusId\": 57707108, \"span\": \"[9]\", \"start\": 1048, \"end\": 1051}, {\"corpusId\": 16747498, \"span\": \"[11]\", \"start\": 1066, \"end\": 1070}, {\"corpusId\": 17741432, \"span\": \"[22]\", \"start\": 1090, \"end\": 1094}]", "conference": "chi", "year": 2018, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "9086", "title": "Voicesetting: Voice Authoring UIs for Improved Expressivity in Augmentative Communication", "sectionTitle": "Expressivity in Text-to-Speech Engines", "text": "While AAC devices are significantly lacking in the ability to generate expressive speech, a large amount of speech synthesis research has aimed at creating more expressive speech engines [24]. Synthesizing human-quality expressivity in synthetic speech is still an open problem, but significant advances have been made. Speech engines such as Pitrelli et. al.'s [20] have the ability to render speech that listeners can identify as exhibiting several different tones (e.g., \"conveying bad news\" or \"asking yes-no questions\"). Several commercial engines such as the IBM Watson [28], CereVoice [4], and Nuance Loquendo [18] allow for the rendering of emotional synthesized speech. Each of these systems is similar in allowing developers to select between a small set of emotional categories when rendering speech (e.g., CereVoice supports a default voice in addition to \"happy,\" \"sad,\" \"calm,\" and \"cross\"). Recent developments on the MaryTTS engine (an open-source TTS research platform) [14] have extended beyond simply accepting the specification of emotional categories, allowing for emotional tones to be specified with continuous values for emotional dimensions such as pleasure, arousal, and dominance [5]. In addition to allowing for the high-level specification of a tone of voice, each of these TTS engines also supports low-level speech modifications through the Speech Synthesis Markup Language (SSML) [2]. SSML is an XML-based language for specifying prosodic information such as the rate of speech, volume, baseline pitch, emphasized words, and pauses.", "spans": "[{\"corpusId\": 190269818, \"span\": \"[24]\", \"start\": 187, \"end\": 191}, {\"corpusId\": 12349664, \"span\": \"[20]\", \"start\": 362, \"end\": 366}, {\"corpusId\": 39405448, \"span\": \"[5]\", \"start\": 1207, \"end\": 1210}]", "conference": "chi", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "9087", "title": "Voicesetting: Voice Authoring UIs for Improved Expressivity in Augmentative Communication", "sectionTitle": "Explorations into Expressive Speech Systems", "text": "Using Critical Design, Pullin and Hennig [22] describe three designs intended to provoke discussion and encourage thought about the complexities of tone of voice and its importance in AAC. In this work, the authors propose that AAC users should be able to author tones of voice and save and share these tones with other AAC users. The tone authoring process was explored through the ToneTable art piece, which accepts speech audio as input and allows ablebodied users to physically manipulate the tone of that speech [1]. While ToneTable provoked critical thought around the expressivity of speech, it was not a system designed for AAC, or intended to be used by people with speech impairments. Pauletto et. al. [19] investigated the design space of integrating emotional TTS into conversational bot systems. They proposed a brief set of possible design approaches for creating an interface for marking up text with speech attributes, though these design suggestions were not intended for use by AAC device users (i.e., design suggestions involving direct manipulation likely will not work well for an eye-gaze user). They also describe possible designs for displaying speech properties in text.", "spans": "[{\"corpusId\": 17741432, \"span\": \"[22]\", \"start\": 41, \"end\": 45}, {\"corpusId\": 5047113, \"span\": \"this work\", \"start\": 201, \"end\": 201}, {\"corpusId\": 15516741, \"span\": \"[1]\", \"start\": 517, \"end\": 520}, {\"corpusId\": 25117822, \"span\": \"[19]\", \"start\": 712, \"end\": 716}]", "conference": "chi", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 3}
{"paperId": "d6e0d5babcec1fa18002876e7a437c0dcb4b56cf", "title": "Introducing Peripheral Awareness as a Neurological State for Human-computer Integration", "venue": "International Conference on Human Factors in Computing Systems", "year": 2020, "citationCount": 53, "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3313831.3376128?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3313831.3376128, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Psychology", "Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2020-04-21", "authors": [{"authorId": "26864492", "name": "Josh Andr\u00e9s"}, {"authorId": "2284695", "name": "M. Schraefel"}, {"authorId": "117988524", "name": "N. Semertzidis"}, {"authorId": "1666506428", "name": "Brahmi Dwivedi"}, {"authorId": "1666506233", "name": "Y. Kulwe"}, {"authorId": "1764859", "name": "J\u00fcrg von K\u00e4nel"}, {"authorId": "144769043", "name": "F. Mueller"}], "abstract": "In this work we introduce peripheral awareness as a neurological state for real-time human-computer integration, where the human is assisted by a computer to interact with the world. Changes to the field of view in peripheral awareness have been linked with quality of human performance. This instinctive narrowing of vision that occurs as a threat is perceived has implications in activities that benefit from the user having a wide field of view, such as cycling to navigate the environment. We present \"Ena\", a novel EEG-eBike system that draws from the user's neural activity to determine when the user is in a state of peripheral awareness to regulate engine support. A study with 20 participants revealed various themes and tactics suggesting that peripheral awareness as a neurological state is viable to align human-machine integration with internal bodily processes. Ena suggests that our work facilitates a safe and enjoyable human-computer integration experience.", "corpusId": "214585780", "paragraphs": [{"paragraphId": "50147", "title": "Introducing Peripheral Awareness as a Neurological State for Human-computer Integration", "sectionTitle": "Init", "text": "eBike Riders Misusing Engine Support eBikes are popular worldwide [23,54] as they offer riders engine support to go further and faster. The challenge is that riders often misuse engine support to go too fast in inappropriate situations, and this has resulted in eBike riders becoming more prone to accidents than regular bike riders [23,35,50,61]. This led us to consider that if integrated systems could be aware of the user's peripheral awareness, the system may be able to regulate when to offer engine support, probably resulting in a safer experience.", "spans": "[{\"corpusId\": \"155112620\", \"span\": \"[23,\", \"start\": 66, \"end\": 70}, {\"corpusId\": \"155112620\", \"span\": \"[23,\", \"start\": 333, \"end\": 337}, {\"corpusId\": \"195770738\", \"span\": \"35,\", \"start\": 337, \"end\": 340}, {\"corpusId\": \"201167172\", \"span\": \"61]\", \"start\": 343, \"end\": 346}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "50148", "title": "Introducing Peripheral Awareness as a Neurological State for Human-computer Integration", "sectionTitle": "Integration Based on the User's Actions", "text": "FootStriker is a wearable running electrical muscle stimulation (EMS) device that actuates the calf muscles while running to control foot landing angle [26]. This facilitates participants to a decreased average heel striking rate for technique improvement. Another example is the eBike \"Ava\" [3] that acts on the user's posture to increase engine support as the user leans forward. These studies suggest that integration systems can act on, and react to, the user's bodily actions. In these works the user is responsible for monitoring aspects of the environment. However, in some cases the user could benefit from new knowledge derived by the system because the system could be better suited to monitoring and making decisions about certain aspects that the user cannot monitor easily, such as: finding the shortest route to a location, monitoring speed to inform the rider when going too fast, and monitoring air pollution. This notion has opened opportunities for integration systems as follows.  [18] system responds to the route's inclination, increasing the pedalling difficulty to incrementally challenge the rider towards improving fitness. Sweeney et al. [59] monitored pollutions levels ahead of the road so that their eBike could increase engine support and assist the rider with reducing their breathing rate to avoid breathing heavily polluted air. Andres et al. [4] used traffic light data to inform when the eBike should increase engine support to assist the rider to catch green traffic lights.", "spans": "[{\"corpusId\": \"15589486\", \"span\": \"[26]\", \"start\": 152, \"end\": 156}, {\"corpusId\": \"53083529\", \"span\": \"[3]\", \"start\": 292, \"end\": 295}, {\"corpusId\": \"3323029\", \"span\": \"[18]\", \"start\": 1000, \"end\": 1004}, {\"corpusId\": \"195259332\", \"span\": \"[4]\", \"start\": 1376, \"end\": 1379}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "50149", "title": "Introducing Peripheral Awareness as a Neurological State for Human-computer Integration", "sectionTitle": "Integration Based on the User's Actions", "text": "These studies show that human-computer integration in an exertion context has focused on systems that can react to the user's actions (focusing \"on\" the user's body -e.g., [3,26]), and on the user's environment (focusing \"around\" the user's body -e.g., [4,17,59]), to support and facilitate new user experiences. What appears to be missing in this vibrant design space is systems that draw from the \"inside\" of the user's body to explore inner bodily processes as mechanisms of integration. As a result, we consider changes to the field of view relating to peripheral awareness as a valuable mechanism for integration between the user and the system as it is linked with human performance [32,44,45].", "spans": "[{\"corpusId\": \"53083529\", \"span\": \"[3,\", \"start\": 172, \"end\": 175}, {\"corpusId\": \"15589486\", \"span\": \"26]\", \"start\": 175, \"end\": 178}, {\"corpusId\": \"195259332\", \"span\": \"[4,\", \"start\": 253, \"end\": 256}, {\"corpusId\": \"28680358\", \"span\": \"17,\", \"start\": 256, \"end\": 259}, {\"corpusId\": \"20688641\", \"span\": \"[32,\", \"start\": 689, \"end\": 693}, {\"corpusId\": \"16565933\", \"span\": \"44,\", \"start\": 693, \"end\": 696}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "50150", "title": "Introducing Peripheral Awareness as a Neurological State for Human-computer Integration", "sectionTitle": "T5.3: Participants Describe In Their Own Words What The", "text": "System Does (20 units) We invited participants to describe what the system does as a form of retrospective enquiry [27,38] to elicit descriptions about their mental models and understanding of the system and their interaction with the system. Participants commented that the system supports their experience. One said: \"It understands that I don't see any threat on the road; this makes me relaxed and it accelerates\". Others commented on technical aspects of the system, one participant said: \"It's looking at your brainwaves and based on a specific classification of the high alpha range it triggers the engine\". Participants commented on the importance of knowing that what they think, and do, can result in different signals which the system may act upon. One participant said: \"It's very exciting, but I think it will need to be very carefully calibrated so that people understand the relationship between what they are doing or feeling or thinking with their senses and what effect that has on the given system.\"", "spans": "[{\"corpusId\": \"10150873\", \"span\": \"38]\", \"start\": 119, \"end\": 122}, {\"corpusId\": \"211040707\", \"span\": \"\", \"start\": -26341, \"end\": -26338}, {\"corpusId\": \"144207795\", \"span\": \"\", \"start\": -26338, \"end\": -26336}, {\"corpusId\": \"218482640\", \"span\": \"\", \"start\": -26330, \"end\": -26327}, {\"corpusId\": \"88487846\", \"span\": \"\", \"start\": -26327, \"end\": -26324}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "50151", "title": "Introducing Peripheral Awareness as a Neurological State for Human-computer Integration", "sectionTitle": "DESIGN TACTICS", "text": "Take away: HCI Practitioners can re-use the implementation description and the code offered along with the equipment listed to study changes in the user's field of view via EEG in real-time during interaction. This is important, as changes to our field of view affects how much we see, and can influence thinking processes that enhance or hinder creativity [25,34] and affect human performance [14,29]. As such, we invite HCI practitioners to use peripheral awareness as a neurological state to better understand how we can support human performance in other areas within HCI, such as: health and wellbeing, critical systems, sports, and creative and collaborative work, to name just a few. Prior work in human-computer integration showed works focusing on \"on\" the user's body [3,26], to react to bodily actions, and \"around\" the user's body [4,18,59], to react to external data to support human performance. In this article we explored a new mechanism for integration focusing on \"inside\" the user's body to design an integration system that reacts to changes in the user's peripheral awareness.", "spans": "[{\"corpusId\": \"26342690\", \"span\": \"[25,\", \"start\": 357, \"end\": 361}, {\"corpusId\": \"7064569\", \"span\": \"34]\", \"start\": 361, \"end\": 364}, {\"corpusId\": \"13693936\", \"span\": \"[14,\", \"start\": 394, \"end\": 398}, {\"corpusId\": \"53083529\", \"span\": \"[3,\", \"start\": 778, \"end\": 781}, {\"corpusId\": \"15589486\", \"span\": \"26]\", \"start\": 781, \"end\": 784}, {\"corpusId\": \"195259332\", \"span\": \"[4,\", \"start\": 843, \"end\": 846}, {\"corpusId\": \"3323029\", \"span\": \"18,\", \"start\": 846, \"end\": 849}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "50152", "title": "Introducing Peripheral Awareness as a Neurological State for Human-computer Integration", "sectionTitle": "DESIGN TACTICS", "text": "Take away: Our work suggests that HCI practitioners can use changes in a user's field of view relating to peripheral awareness as a mechanism for integration. We suggest that they should consider how the integration system extends the user's abilities in the contexts of the experience. Using EEG to monitor neural activity can offer access to a user's preattentive processing state, resulting in possibilities for integration where the system responds to a situation \"before\" the user can with their body. This offers design alternatives relating to the user and the system using their sensing capabilities to complement each other. We chose kinetic feedback [12,60], as this would keep the user's eye sight free so they could focus on experiencing the system, their body and the surroundings. This enabled users to concentrate on the sensation afforded by reaching peripheral awareness, which made the eBike go faster and resulted in a kinetic feedback loop.", "spans": "[{\"corpusId\": \"16565933\", \"span\": \"\", \"start\": -29837, \"end\": -29834}, {\"corpusId\": \"218482710\", \"span\": \"\", \"start\": -29834, \"end\": -29831}, {\"corpusId\": 214585780, \"span\": \"Our work\", \"start\": 19, \"end\": 19}, {\"corpusId\": \"190080205\", \"span\": \"[12,\", \"start\": 660, \"end\": 664}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "50153", "title": "Introducing Peripheral Awareness as a Neurological State for Human-computer Integration", "sectionTitle": "DESIGN TACTICS", "text": "Take away: Our work suggests that HCI practitioners can use kinetic feedback for peripheral awareness integration over mechanisms such as screen notifications, sounds, and haptics, because the user can remain attentive to the experience, rather than having to switch their attention to receive feedback via other sensory inputs, which, in turn, could affect the integration experience. This approach invites users to tune in to their body, contrasting many current technology-driven exertion experiences that take the role of sensing and offering feedback to the user via digits, graphs and tables [51]. Here we eliminated screens and focused on making the physical world the place where the interaction occurs between the user and the system. In our study participants practiced reaching peripheral awareness to gain engine support to go faster as a \"fun reward\", making the experience of being \"in sync\" with themselves and the system \"worth it\". One of the opportunities of using indirect physiological signals, such as EEG is that these are difficult to control [37,42] and therefore offer a challenge for mastery. and \"tuning in\" to their inner bodily processes; 2) the system offers feedback in a way that is rewarding to the user, such as increasing engine support; and 3) game theory such as \"flow\" [43] in relation to reactions between the user and the system during integration could be used to dynamically adjust difficulty towards achievement of mastery. Challenges that limit designing for symbiotic-like experiences were quoted by Licklider [33], such as \"the speed mismatch between humans and computers\", where real-time computing was expensive and equipment heavy back then. This reporting of this challenge was followed by \"the problem of language\" where users had to communicate in computer language. Today, home and smartphone assistants require the user to learn commands to raise the system's attention and to instruct the system. With these challenges in mind, our work suggests an implementation where the system can gain access to a user's pre-attentive processing state in real-time in order to automatically act on this pre-attentive processing state before the user is able to.", "spans": "[{\"corpusId\": 214585780, \"span\": \"Our work\", \"start\": 19, \"end\": 19}, {\"corpusId\": 214585780, \"span\": \"This approach\", \"start\": 399, \"end\": 399}, {\"corpusId\": \"3092331\", \"span\": \"[51]\", \"start\": 598, \"end\": 602}, {\"corpusId\": 214585780, \"span\": \"our study\", \"start\": 756, \"end\": 756}, {\"corpusId\": \"113531418\", \"span\": \"[37,\", \"start\": 1066, \"end\": 1070}, {\"corpusId\": \"545431\", \"span\": \"42]\", \"start\": 1070, \"end\": 1073}, {\"corpusId\": 214585780, \"span\": \"our work\", \"start\": 1991, \"end\": 1991}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "50154", "title": "Introducing Peripheral Awareness as a Neurological State for Human-computer Integration", "sectionTitle": "Why Integration and not Interaction or Augmentation?", "text": "We draw from the general HCI understanding of interaction [28], which tells us that interaction happens between two entities that determine each other's behaviour, such as between a human and a machine where the human goals determine the interaction; for example, this quote from our study depicts this situation: \"My goal was to get rid of the obstacles so that I could get the system to accelerate again.\" This suggests that users were initially interacting with the system. We now draw from augmentation [55] with its goal to create human-machine technologies that provide us with an extension of our own abilities. This quote from our study depicts this situation: \"It feels as all of a sudden that you've activated a different part of your senses, of your vision, that you didn't know you had access to.\" This suggests that the user's abilities were augmented through our system. Finally, we draw from integration [21], which implies that both, human and machine, can draw meaning around each other's actions to work in a partnership. This quote from our study depicts this situation: \"I felt like the system was cycling with me and slowed us down when the situation ahead changed.\" This suggests that it was perceived as if the user and the system were working in a partnership. In summary, it appears that users progressed from interaction to augmentation as steps on a continuum towards reaching a partnership state of human-machine integration rather than simply reaching a state of integration from the start.", "spans": "[{\"corpusId\": \"207728323\", \"span\": \"\", \"start\": -34595, \"end\": -34592}, {\"corpusId\": \"195698406\", \"span\": \"[28]\", \"start\": 58, \"end\": 62}, {\"corpusId\": 214585780, \"span\": \"our study\", \"start\": 289, \"end\": 289}, {\"corpusId\": \"621105\", \"span\": \"[55]\", \"start\": 507, \"end\": 511}, {\"corpusId\": 214585780, \"span\": \"our study\", \"start\": 644, \"end\": 644}, {\"corpusId\": 214585780, \"span\": \"our system\", \"start\": 883, \"end\": 883}, {\"corpusId\": 214585780, \"span\": \"our study\", \"start\": 1065, \"end\": 1065}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "50155", "title": "Introducing Peripheral Awareness as a Neurological State for Human-computer Integration", "sectionTitle": "Practical Contributions", "text": "These contributions are targeted to the agendas of Human-Computer Integration [21,22] due to the insights resulting from studying peripheral awareness as a mechanism of integration; Trustable and Explainable AI [52], due to the tactics offered to promote trust when designing integration systems that can automatically act on the experience; and Inbodied Design, due to the focus on the internal bodily processes to inform HCI design [5,57].", "spans": "[{\"corpusId\": \"7825167\", \"span\": \"22]\", \"start\": 82, \"end\": 85}, {\"corpusId\": \"144207795\", \"span\": \"[5,\", \"start\": 434, \"end\": 437}, {\"corpusId\": \"88487846\", \"span\": \"57]\", \"start\": 437, \"end\": 440}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 9}
{"paperId": "2941b843d309576971106d520fd4b848a113504f", "title": "Discourse as a Function of Event: Profiling Discourse Structure in News Articles around the Main Event", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2020, "citationCount": 61, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/2020.acl-main.478.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://aclanthology.org/2020.acl-main.478, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2020-07-01", "authors": [{"authorId": "3466801", "name": "Prafulla Kumar Choubey"}, {"authorId": "2116043027", "name": "A. Lee"}, {"authorId": "40372969", "name": "Ruihong Huang"}, {"authorId": "2153518220", "name": "Lu Wang"}], "abstract": "Understanding discourse structures of news articles is vital to effectively contextualize the occurrence of a news event. To enable computational modeling of news structures, we apply an existing theory of functional discourse structure for news articles that revolves around the main event and create a human-annotated corpus of 802 documents spanning over four domains and three media sources. Next, we propose several document-level neural-network models to automatically construct news content structures. Finally, we demonstrate that incorporating system predicted news structures yields new state-of-the-art performance for event coreference resolution. The news documents we annotated are openly available and the annotations are publicly released for future research.", "corpusId": "218515665", "paragraphs": [{"paragraphId": "80030", "title": "Discourse as a Function of Event: Profiling Discourse Structure in News Articles around the Main Event", "sectionTitle": "Related Work", "text": "Several well-studied discourse analysis tasks have been shown useful for many NLP applications. The RST (Mann and Thompson, 1988;Soricut and Marcu, 2003;Feng and Hirst, 2012;Ji and Eisenstein, 2014;Li et al., 2014a;Liu et al., 2019) and PDTB style (Prasad et al., 2008;Pitler and Nenkova, 2009;Lin et al., 2014;Rutherford and Xue, 2016;Qin et al., 2016;Xu et al., 2018) discourse parsing tasks identify discourse units that are logically connected with a predefined set of rhetorical relations, and have been shown useful for a range of NLP applications such as text quality assessment (Lin et al., 2011), sentiment analysis (Bhatia et al., 2015), text summarization (Louis et al., 2010), machine translation (Li et al., 2014b) and text categorization (Ji and Smith, 2017). Text segmentation (Hearst, 1994;Choi, 2000;Eisenstein and Barzilay, 2008;Koshorek et al., 2018) is another well studied discourse analysis task that aims to divide a text into a sequence of topically coherent segments and has been shown useful for text summarization (Barzilay and Lee, 2004), sentiment analysis (Sauper et al., 2010) and dialogue systems (Shi et al., 2019). The news discourse profiling task is complementary to the well-established discourse analysis tasks and is likely to further benefit many NLP applications. First, it studies genre-specific discourse structures, while the aforementioned discourse analysis tasks study genre independent general discourse structures and thus fail to incorporate domain knowledge. Second, it focuses on understanding global content organization structures with the main event at the center, while the existing tasks focus on either understanding rhetorical aspects of discourse structures (RST and PDTB discourse parsing) or detecting shallow topic transition structures (text segmentation).", "spans": "[{\"corpusId\": 5187426, \"span\": \"Soricut and Marcu, 2003;\", \"start\": 129, \"end\": 153}, {\"corpusId\": 2790679, \"span\": \"Li et al., 2014a;\", \"start\": 198, \"end\": 215}, {\"corpusId\": 201698405, \"span\": \"Liu et al., 2019)\", \"start\": 215, \"end\": 232}, {\"corpusId\": 12775832, \"span\": \"Pitler and Nenkova, 2009;\", \"start\": 269, \"end\": 294}, {\"corpusId\": 2664769, \"span\": \"Lin et al., 2014;\", \"start\": 294, \"end\": 311}, {\"corpusId\": 15732708, \"span\": \"Rutherford and Xue, 2016;\", \"start\": 311, \"end\": 336}, {\"corpusId\": 7284112, \"span\": \"Qin et al., 2016;\", \"start\": 336, \"end\": 353}, {\"corpusId\": 53083237, \"span\": \"Xu et al., 2018)\", \"start\": 353, \"end\": 369}, {\"corpusId\": 92531, \"span\": \"(Lin et al., 2011)\", \"start\": 586, \"end\": 604}, {\"corpusId\": 2810111, \"span\": \"(Louis et al., 2010)\", \"start\": 667, \"end\": 687}, {\"corpusId\": 8285046, \"span\": \"(Li et al., 2014b)\", \"start\": 709, \"end\": 727}, {\"corpusId\": 4411469, \"span\": \"Koshorek et al., 2018)\", \"start\": 847, \"end\": 869}, {\"corpusId\": 102352337, \"span\": \"(Shi et al., 2019)\", \"start\": 1129, \"end\": 1147}]", "conference": "acl", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 13}, {"paragraphId": "80031", "title": "Discourse as a Function of Event: Profiling Discourse Structure in News Articles around the Main Event", "sectionTitle": "Related Work", "text": "Genre-specific functional structures have been studied based on different attributes, but mostly for genres other than news articles. Liddy (1991), Kircz (1991) and Teufel et al. (1999) used rhetorical status and argumentation type to both define functional theories and create corpora for scientific articles. Mizuta et al. (2006), Wilbur et al. (2006), Waard et al. (2009) andLiakata et al. (2012) extensively studied functional structures in biological domain with multiple new annotation schemata.", "spans": "[{\"corpusId\": 6484168, \"span\": \"Kircz (1991)\", \"start\": 148, \"end\": 160}, {\"corpusId\": 5461896, \"span\": \"Teufel et al. (1999)\", \"start\": 165, \"end\": 185}, {\"corpusId\": 16221327, \"span\": \"Wilbur et al. (2006)\", \"start\": 333, \"end\": 353}, {\"corpusId\": 12015221, \"span\": \"Waard et al. (2009) and\", \"start\": 355, \"end\": 378}, {\"corpusId\": 2981376, \"span\": \"Liakata et al. (2012)\", \"start\": 378, \"end\": 399}]", "conference": "acl", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 5}], "paragraphCount": 2}
{"paperId": "0981ce872d31a665882e7677d608351ff5f1de6b", "title": "Sorting through the noise: Testing robustness of information processing in pre-trained language models", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2021, "citationCount": 40, "openAccessPdf": {"url": "https://aclanthology.org/2021.emnlp-main.119.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2109.12393, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2021-09-25", "authors": [{"authorId": "2129456648", "name": "Lalchand Pandia"}, {"authorId": "37907837", "name": "Allyson Ettinger"}], "abstract": "Pre-trained LMs have shown impressive performance on downstream NLP tasks, but we have yet to establish a clear understanding of their sophistication when it comes to processing, retaining, and applying information presented in their input. In this paper we tackle a component of this question by examining robustness of models\u2019 ability to deploy relevant context information in the face of distracting content. We present models with cloze tasks requiring use of critical context information, and introduce distracting content to test how robustly the models retain and use that critical information for prediction. We also systematically manipulate the nature of these distractors, to shed light on dynamics of models\u2019 use of contextual cues. We find that although models appear in simple contexts to make predictions based on understanding and applying relevant facts from prior context, the presence of distracting but irrelevant content has clear impact in confusing model predictions. In particular, models appear particularly susceptible to factors of semantic similarity and word position. The findings are consistent with the conclusion that LM predictions are driven in large part by superficial contextual cues, rather than by robust representations of context meaning.", "corpusId": "237940293", "paragraphs": [{"paragraphId": "20526", "title": "Sorting through the noise: Testing robustness of information processing in pre-trained language models", "sectionTitle": "Related Work", "text": "Prior work has tested LMs as knowledge bases using cloze-style probes (Petroni et al., 2019;Jiang et al., 2020). As a starting point we rely on models' ability to display this type of knowledge, but our question differs importantly from that work: we are not asking whether models can recall facts about the real world from training-rather, we are trying to gauge the extent to which models form robust representations of new information presented in input after training. Somewhat more similar to ours is work like Elazar et al. (2021), which explores the consistency of models' generation of facts in the face of rephrasing of prompts. The basic intuition behind this work-that LMs' ability to make intelligent-looking predictions can be sensitive to the particulars of the context-is one that we also use as we ask more specific questions about models' processing of information in their input.", "spans": "[{\"corpusId\": 207783692, \"span\": \"(Petroni et al., 2019;\", \"start\": 70, \"end\": 92}, {\"corpusId\": 208513249, \"span\": \"Jiang et al., 2020)\", \"start\": 92, \"end\": 111}, {\"corpusId\": 237940293, \"span\": \"this work\", \"start\": 674, \"end\": 674}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "20527", "title": "Sorting through the noise: Testing robustness of information processing in pre-trained language models", "sectionTitle": "Related Work", "text": "A good deal of prior work has focused on testing for linguistic knowledge in language models (Rogers et al., 2020). Much of this work has prioritized testing syntax in pre-trained LMs via agreement tests (Linzen et al., 2016;Gulordava et al., 2018). Others expand to broader sets of syntactic phenomena (Wilcox et al., 2018;Futrell et al., 2019;Warstadt et al., 2020) and semantic/pragmatic phenomena (Ettinger, 2020). Other work has studied syntactic and semantic information in contextualized embeddings from these models (Hewitt and Manning, 2019;Tenney et al., 2018;Klafka and Ettinger, 2020). We take one step up from examination of these abstract linguistic capacities, with a focused examination of models' ability to use such linguistic scaffolding to process and retain new information described in text.", "spans": "[{\"corpusId\": 211532403, \"span\": \"(Rogers et al., 2020)\", \"start\": 93, \"end\": 114}, {\"corpusId\": 237940293, \"span\": \"this work\", \"start\": 133, \"end\": 133}, {\"corpusId\": 14091946, \"span\": \"(Linzen et al., 2016;\", \"start\": 204, \"end\": 225}, {\"corpusId\": 4460159, \"span\": \"Gulordava et al., 2018)\", \"start\": 225, \"end\": 248}, {\"corpusId\": 52156878, \"span\": \"(Wilcox et al., 2018;\", \"start\": 303, \"end\": 324}, {\"corpusId\": 72940921, \"span\": \"Futrell et al., 2019;\", \"start\": 324, \"end\": 345}, {\"corpusId\": 208527435, \"span\": \"Warstadt et al., 2020)\", \"start\": 345, \"end\": 367}, {\"corpusId\": 199001173, \"span\": \"(Ettinger, 2020)\", \"start\": 401, \"end\": 417}, {\"corpusId\": 106402715, \"span\": \"(Hewitt and Manning, 2019;\", \"start\": 524, \"end\": 550}, {\"corpusId\": 108300988, \"span\": \"Tenney et al., 2018;\", \"start\": 550, \"end\": 570}, {\"corpusId\": 218502143, \"span\": \"Klafka and Ettinger, 2020)\", \"start\": 570, \"end\": 596}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 11}, {"paragraphId": "20528", "title": "Sorting through the noise: Testing robustness of information processing in pre-trained language models", "sectionTitle": "Related Work", "text": "Our use of attractors to test model robustness takes inspiration from use of attractors within syntactic testing contexts (Linzen et al., 2016;Gulordava et al., 2018), but we focus on semantic relationships in defining attractors, and use the attractors to investigate different aspects of models' processing. Some scattered work has explored more semantic types of attractors for testing LMs-in particular, there is work looking at whether presence of certain context words will prime corresponding targets in context. Such work has experimented with contextual factors like distance between prime and target (Kassner and Sch\u00fctze, 2020), as well as contextual constraint (Misra et al., 2020). We build on this existing work with a more systematic exploration of impacts of different types of attractors, and with a more targeted goal of testing models' robustness in processing new facts from context.", "spans": "[{\"corpusId\": 14091946, \"span\": \"(Linzen et al., 2016;\", \"start\": 122, \"end\": 143}, {\"corpusId\": 4460159, \"span\": \"Gulordava et al., 2018)\", \"start\": 143, \"end\": 166}, {\"corpusId\": 218628691, \"span\": \"(Kassner and Sch\\u00fctze, 2020)\", \"start\": 610, \"end\": 637}, {\"corpusId\": 222177135, \"span\": \"(Misra et al., 2020)\", \"start\": 672, \"end\": 692}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "20529", "title": "Sorting through the noise: Testing robustness of information processing in pre-trained language models", "sectionTitle": "Related Work", "text": "In focusing on models' ability to extract, retain, and deploy information conveyed in text, our work also relates to tasks in reading comprehension question answering (Rajpurkar et al., 2018;Ko\u010disk\u1ef3 et al., 2018;Mostafazadeh et al., 2017;Yang et al., 2018;Richardson et al., 2013). Some such work, like the bAbI dataset  and CBT (Hill et al., 2016), use insertion of additional material to make the tasks generally more difficulta tactic that also parallels the related method of adversarial testing (Jia and Liang, 2017;McCoy et al., 2019;Nie et al., 2020). There are important similarities in the questions and strategies of these prior works and ours, but we differ in focusing specifically on information processing in LMs, rather than performance of models supervised for a particular downstream task. Unlike those works, our goal is to shed light on robustness of language \"understanding\", and nature of prediction mechanisms, that arise as a result of LM-based pre-training.", "spans": "[{\"corpusId\": 237940293, \"span\": \"our work\", \"start\": 100, \"end\": 100}, {\"corpusId\": 47018994, \"span\": \"(Rajpurkar et al., 2018;\", \"start\": 167, \"end\": 191}, {\"corpusId\": 2593903, \"span\": \"Ko\\u010disk\\u1ef3 et al., 2018;\", \"start\": 191, \"end\": 212}, {\"corpusId\": 13746570, \"span\": \"Mostafazadeh et al., 2017;\", \"start\": 212, \"end\": 238}, {\"corpusId\": 52822214, \"span\": \"Yang et al., 2018;\", \"start\": 238, \"end\": 256}, {\"corpusId\": 2100831, \"span\": \"Richardson et al., 2013)\", \"start\": 256, \"end\": 280}, {\"corpusId\": 59599752, \"span\": \"McCoy et al., 2019;\", \"start\": 521, \"end\": 540}, {\"corpusId\": 207756753, \"span\": \"Nie et al., 2020)\", \"start\": 540, \"end\": 557}, {\"corpusId\": 237940293, \"span\": \"our goal\", \"start\": 835, \"end\": 835}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 8}, {"paragraphId": "20530", "title": "Sorting through the noise: Testing robustness of information processing in pre-trained language models", "sectionTitle": "Discussion", "text": "These findings also have implications for studying mechanistic connections between pre-trained language models and language processing in humans. Studies of human sentence processing have shown comparable susceptibility to interference from irrelevant context elements, depending on semantic and syntactic properties ( Van Dyke, 2007;Parker and Phillips, 2017;Dillon et al., 2013). Systematic comparison of interference effects in humans and in language models stands to shed light on mechanistic similarities and differences in the ways that these language processing systems handle information from prior context.", "spans": "[{\"corpusId\": 10542322, \"span\": \"Van Dyke, 2007;\", \"start\": 319, \"end\": 334}, {\"corpusId\": 42667369, \"span\": \"Parker and Phillips, 2017;\", \"start\": 334, \"end\": 360}, {\"corpusId\": 9558272, \"span\": \"Dillon et al., 2013)\", \"start\": 360, \"end\": 380}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 3}], "paragraphCount": 5}
{"paperId": "a901f5afe745a4d0c348619d2035b823b7fbd2c3", "title": "The Effect of Visual Appearance on the Performance of Continuous Sliders and Visual Analogue Scales", "venue": "International Conference on Human Factors in Computing Systems", "year": 2016, "citationCount": 112, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/2858036.2858063?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2858036.2858063, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2016-05-07", "authors": [{"authorId": "49668403", "name": "Justin Matejka"}, {"authorId": "145855160", "name": "Michael Glueck"}, {"authorId": "2666589", "name": "Tovi Grossman"}, {"authorId": "1703735", "name": "G. Fitzmaurice"}], "abstract": null, "corpusId": "14806632", "paragraphs": [{"paragraphId": "2433", "title": "The Effect of Visual Appearance on the Performance of Continuous Sliders and Visual Analogue Scales", "sectionTitle": "INTRODUCTION", "text": "An alternative to the Likert scale is the visual analogue scale (VAS), in which respondents specify their response by indicating a position along a continuous line between two end points [16]. Continuous sliders have the implicit assumption that users are equally likely to make their selection at any point along the line. Prior work has shown that VASs provide some advantages over categorical scales [11,12,31]. In particular, the continuous data collected with VASs can be used for a greater number of statistical tests and goodness of fit tests may be more powerful [11].", "spans": "[{\"corpusId\": 30305248, \"span\": \"[11,\", \"start\": 403, \"end\": 407}, {\"corpusId\": 39727927, \"span\": \"12,\", \"start\": 407, \"end\": 410}, {\"corpusId\": 2539974, \"span\": \"31]\", \"start\": 410, \"end\": 413}, {\"corpusId\": 30305248, \"span\": \"[11]\", \"start\": 571, \"end\": 575}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "2434", "title": "The Effect of Visual Appearance on the Performance of Continuous Sliders and Visual Analogue Scales", "sectionTitle": "INTRODUCTION", "text": "Recently, major attention has been given to web-based research methods and data collection [17,21]. Online survey systems [39,40], as well as crowd-sourcing systems [41], allow researchers to rapidly recruit and collect responses to survey questions and allow for the use of multimedia stimuli. VASs are commonly used for such research methods, and it has thus become important to understand the design and characteristics of VASs. Given the volume of responses which web-based surveys can produce, it is important that such responses are collected efficiently and without any artificial bias from the design of the response mechanism. In particular, it has been shown that subtle changes in the layout and appearance of rating scales can affect responses [20,30].", "spans": "[{\"corpusId\": 7457123, \"span\": \"[17,\", \"start\": 91, \"end\": 95}, {\"corpusId\": 1442595, \"span\": \"21]\", \"start\": 95, \"end\": 98}, {\"corpusId\": 208115588, \"span\": \"[20,\", \"start\": 756, \"end\": 760}, {\"corpusId\": 60075215, \"span\": \"30]\", \"start\": 760, \"end\": 763}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "2435", "title": "The Effect of Visual Appearance on the Performance of Continuous Sliders and Visual Analogue Scales", "sectionTitle": "INTRODUCTION", "text": "However, little research has been conducted on how the visual design and mechanics of VASs may impact the collection of responses. More specifically, the presence of decorations such as labels and tick marks can be added to give information about the gradations along the scale and allow for more precise and repeatable selections [35]. While such visual attributes have been studied in detail for the labelling of discrete scales [38], their impact on VASs, and their effect on the distribution of collected responses has not been rigorously examined. 2 Our work explores if and how visual design variations of VASs impacts the results obtained from web-based collection systems. We perform a 2,000 user, 250,000 trial Mechanical Turk experiment, to study the impact of slider decorations on VAS responses. We test a number of design variations that involve the mark-up of the slider scale with tick marks, labels, and other decorations. We provide a thorough analysis of the collected results, which help identify designs which should be avoided due to the induced bias in responses. Furthermore, through the use of two separate experimental tasks, we are able to analyze the tradeoffs between bias, accuracy, and speed-of-use.", "spans": "[{\"corpusId\": 2685654, \"span\": \"[35]\", \"start\": 331, \"end\": 335}, {\"corpusId\": 145713034, \"span\": \"[38]\", \"start\": 431, \"end\": 435}, {\"corpusId\": 53658785, \"span\": \"2\", \"start\": 553, \"end\": 554}, {\"corpusId\": 14806632, \"span\": \"Our work\", \"start\": 563, \"end\": 563}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "2436", "title": "The Effect of Visual Appearance on the Performance of Continuous Sliders and Visual Analogue Scales", "sectionTitle": "RELATED WORK", "text": "Visual analogue scales (VASs) have a history of use in psychology, psychiatry, and healthcare, to measure a range of subjective experiences, such as mood, depression, pain, and physical exertion [23]. The VAS was introduced by Hayes & Paterson in 1921 as a method for factory foremen to rate the performance of workers [16]. In 1923 Freyd discussed the broader application of the technique in the field of psychology, providing heuristic guidelines for visual appearance [10]. VASs have traditionally been displayed on paper, with their key advantages over other techniques being that they can be self-administered with little training, and provide extremely sensitive (granular) measurement. Their disadvantages have traditionally been that they are visual, cannot be administered aurally, and take longer to encode (measure/transcribe). However, when administered on a computer, the measuring step can be automated, making VASs a viable alternative to discrete Likert scales. Software tools allow for the automatic creation and encoding of VASs [23,31] generating a renewed interest in VASs. Our paper aims to better understand the nature of responses generated by VASs to ensuring they are collected without artificial bias.", "spans": "[{\"corpusId\": 143936049, \"span\": \"[10]\", \"start\": 471, \"end\": 475}, {\"corpusId\": 2539974, \"span\": \"31]\", \"start\": 1051, \"end\": 1054}, {\"corpusId\": 14806632, \"span\": \"Our paper\", \"start\": 1103, \"end\": 1103}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "2437", "title": "The Effect of Visual Appearance on the Performance of Continuous Sliders and Visual Analogue Scales", "sectionTitle": "RELATED WORK", "text": "There is a large body of research comparing the effectiveness of VASs compared to other rating systems [15,18,24,26,36], looking at the effect of labelling on discrete rating systems [2,4,37], and looking at how question phrasing influences participant response [13,25,27,29]. However, there has been relatively little research investigating the how changes in visual appearance or labelling affect VASs. In the 1970s Scott & Huskisson looked at how the graphical representation of paper-based VASs influenced the results of a pain severity questionnaire and found that a vertical orientation of the slider lead to more \"clumping\" than horizontal orientations [34] and that the presence of labels could attract responses [19]. Later, Dauphin et al. [28] performed a similar study and found the orientation of the scale affected the number of ratings at the end points. Performed at a small scale (~100 trials per condition), the visible effects were limited. In this paper we systematically explore the potential causes of bias in VASs on a large scale for digitally administered surveys.", "spans": "[{\"corpusId\": 32137740, \"span\": \"[15,\", \"start\": 103, \"end\": 107}, {\"corpusId\": 206369218, \"span\": \"18,\", \"start\": 107, \"end\": 110}, {\"corpusId\": 40967687, \"span\": \"24,\", \"start\": 110, \"end\": 113}, {\"corpusId\": 147522610, \"span\": \"36]\", \"start\": 116, \"end\": 119}, {\"corpusId\": 53658785, \"span\": \"[2,\", \"start\": 183, \"end\": 186}, {\"corpusId\": 27600932, \"span\": \"4,\", \"start\": 186, \"end\": 188}, {\"corpusId\": 145078021, \"span\": \"37]\", \"start\": 188, \"end\": 191}, {\"corpusId\": 18472264, \"span\": \"[13,\", \"start\": 262, \"end\": 266}, {\"corpusId\": 145758710, \"span\": \"27,\", \"start\": 269, \"end\": 272}, {\"corpusId\": 7529970, \"span\": \"29]\", \"start\": 272, \"end\": 275}, {\"corpusId\": 43447608, \"span\": \"[34]\", \"start\": 660, \"end\": 664}, {\"corpusId\": 5451525, \"span\": \"[19]\", \"start\": 721, \"end\": 725}, {\"corpusId\": 14806632, \"span\": \"this paper\", \"start\": 972, \"end\": 972}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 13}, {"paragraphId": "2438", "title": "The Effect of Visual Appearance on the Performance of Continuous Sliders and Visual Analogue Scales", "sectionTitle": "Task -Shades of Grey", "text": "Developing a set of stimuli to use as a test of rating behaviour is a difficult and well-studied problem [33]. We chose a task which presents the participant with a shade of grey and requires them to rate the shade on a scale between \"White\" and \"Black\". Borg and Borg [1] extensively studied using a \"scale of blackness\" as a stimulus and concluded that it serves as a good test of general rating behaviour. Our task is modelled on the task used by Neely and Borg to test the performance of a VAS compared to a graduated Likert scale [15]. A collection of 50 shades of grey ( Figure 2) were selected in perceptually equal steps between white and black according to the CIE L*a*b* colour space [3]. While each shade of grey does have a theoretically \"correct\" position on the scale, pilot tests suggested a relatively wide range of responses could be entered for any given shade. For example, Figure 3 shows the distribution of responses from a pilot study for two selected shades. ", "spans": "[{\"corpusId\": 34581493, \"span\": \"[33]\", \"start\": 105, \"end\": 109}, {\"corpusId\": 32137740, \"span\": \"[15]\", \"start\": 535, \"end\": 539}, {\"corpusId\": 32004662, \"span\": \"[3]\", \"start\": 694, \"end\": 697}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "2439", "title": "The Effect of Visual Appearance on the Performance of Continuous Sliders and Visual Analogue Scales", "sectionTitle": "Crowdsourcing", "text": "Participants for the study were recruited using Amazon's Mechanical Turk. Previous work [14,17] has shown \"turkers\" to be suitable participants for visualization research 3 and to represent a comparatively diverse participant pool [32]. The short time between posting a study and getting results allowed exploration of more variations than practical for an in-person study. The study took ~ 6 minutes to complete and participants were compensated $1 USD.", "spans": "[{\"corpusId\": 7692834, \"span\": \"[14,\", \"start\": 88, \"end\": 92}, {\"corpusId\": 7457123, \"span\": \"17]\", \"start\": 92, \"end\": 95}, {\"corpusId\": 32004662, \"span\": \"3\", \"start\": 171, \"end\": 172}, {\"corpusId\": 169290127, \"span\": \"[32]\", \"start\": 231, \"end\": 235}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 7}
{"paperId": "60de92ab82e1a73079050a5407d48b6f87fe7ee4", "title": "Building Task-Oriented Visual Dialog Systems Through Alternative Optimization Between Dialog Policy and Language Generation", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2019, "citationCount": 11, "openAccessPdf": {"url": "https://arxiv.org/pdf/1909.05365", "status": "GREEN", "license": null, "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1909.05365, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2019-09-06", "authors": [{"authorId": "153094069", "name": "Mingyang Zhou"}, {"authorId": "2054031596", "name": "Josh Arnold"}, {"authorId": "144007938", "name": "Zhou Yu"}], "abstract": "Reinforcement learning (RL) is an effective approach to learn an optimal dialog policy for task-oriented visual dialog systems. A common practice is to apply RL on a neural sequence-to-sequence(seq2seq) framework with the action space being the output vocabulary in the decoder. However, it is difficult to design a reward function that can achieve a balance between learning an effective policy and generating a natural dialog response. This paper proposes a novel framework that alternatively trains a RL policy for image guessing and a supervised seq2seq model to improve dialog generation quality. We evaluate our framework on the GuessWhich task and the framework achieves the state-of-the-art performance in both task completion and dialog quality.", "corpusId": "202565859", "paragraphs": [{"paragraphId": "87113", "title": "Building Task-Oriented Visual Dialog Systems Through Alternative Optimization Between Dialog Policy and Language Generation", "sectionTitle": "Visual Dialog System", "text": "Visual dialog systems are an emerging area of interdisciplinary research that attracts both the vision and language communities due to the potential applications. Das et al. (2017a) proposed a visual dialog task in which a conversational agent attempts to answer questions regarding an assigned image based on a dialog history. To approach this task, they initially collected data by having two people chat about an image with one person acting as the questioner and the other as the answerer. GuessWhich (Chattopadhyay et al., 2017) extends VisDial with the goal to build an agent that learns how to identify a target image through question and answers. (de Vries et al., 2016) additionally introduced a game in which a series of yes-or-no questions are asked by an agent in order to locate an object in an image. Many researchers approached these tasks via reinforcement learning (RL), with the goal of obtaining an optimal dialog policy. Zhang et al. (2017), for example, designed three rewards with respect to the goals of task achievement, efficiency, and question informativeness, in order to help the agent to achieve an effective question generation policy for GuessWhat game. Das et al. (2017b) applies reinforcement learning in the GuessWhich task and demonstrates a moderate improvement in accuracy compared to the supervised learning approach. Both methods apply RL on a neural end-to-end pipeline to jointly influence the language generation and dialog policy. Due the challenge of designing an appropriate reward for language generation, these methods generate responses that deviate from human natural language. Zhang et al. (2018), proposed an approach involving hierarchical reinforcement learning and state-adaptation techniques that enable the agent to learn an optimal and efficient multi-modal policy. The bottleneck of (Zhang et al., 2018)'s method, however, is that the system response is retrieved from a predefined humanwritten or system-generated utterance. The number of predefined responses are limited, therefore, this method does not easily generalize to other tasks in real-world settings. We address these limitations by applying RL on a reduced, yet more relevant action space, while optimizing the dialog generator in a supervised fashion. We alternatively optimize policy learning to language generation to combine the two tasks together.", "spans": "[{\"corpusId\": 1820614, \"span\": \"Das et al. (2017a)\", \"start\": 163, \"end\": 181}, {\"corpusId\": 1448723, \"span\": \"Das et al. (2017b)\", \"start\": 1185, \"end\": 1203}, {\"corpusId\": 202565859, \"span\": \"proposed an approach\", \"start\": 1668, \"end\": 1668}, {\"corpusId\": 202565859, \"span\": \"this method\", \"start\": 2054, \"end\": 2054}]", "conference": "emnlp", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "87114", "title": "Building Task-Oriented Visual Dialog Systems Through Alternative Optimization Between Dialog Policy and Language Generation", "sectionTitle": "RL on Task-oriented Dialog System", "text": "Various RL-based models have been proposed to train task-oriented dialog systems (Williams and Young, 2007). In order to build a traditional modular-based dialog system, researchers first identify the semantic representation, such as the dialog acts and slots in user utterances. Then they accumulate these semantic representations over time to track the dialog state. Finally they apply RL to learn an optimized dialog policy given the dialog state (Raux et al., 2005;Shi and Yu, 2018). Such modular-based dialog systems are effective in narrow task domains, such as searching a bus route schedule and reserving a restaurant through natural language, but they fail to generalize to complex settings where the size of the action space increases. Owing to the development of deep learning, RL on neural sequence-to-sequence models has been explored in more complex dialog domains such as open-domain conversation (Li et al., 2016) and negotiation (Lewis et al., 2017). However, due to the difficulty of assigning appropriate rewards when operating in a large action space, these frameworks cannot generate fluent dialog utterances. Zhao et al. (2019) proposed a novel latent action RL framework to marry the advantage of a module based approach and sequence-to-sequence approach. They learned the optimal dialog policy in a complex task-oriented dialog domain while achieving decent conversation quality. We study the similar issue in a multimodal task-oriented dialog scenario. We propose an iterative approach to optimize dialog policy using RL methods and system response generation via SL. ", "spans": "[{\"corpusId\": 13903063, \"span\": \"(Williams and Young, 2007)\", \"start\": 81, \"end\": 107}, {\"corpusId\": 281507, \"span\": \"(Raux et al., 2005;\", \"start\": 450, \"end\": 469}, {\"corpusId\": 13754513, \"span\": \"Shi and Yu, 2018)\", \"start\": 469, \"end\": 486}, {\"corpusId\": 202565859, \"span\": \"We propose\", \"start\": 1488, \"end\": 1488}]", "conference": "emnlp", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 2}
{"paperId": "0ce53aa7ed03fae1db4fc742e81e45a260ceee77", "title": "Calling for a Revolution: An Analysis of IoT Manifestos", "venue": "International Conference on Human Factors in Computing Systems", "year": 2018, "citationCount": 47, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3173574.3173876?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3173574.3173876, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Political Science", "Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2018-04-21", "authors": [{"authorId": "152873784", "name": "E. Fritsch"}, {"authorId": "2692274", "name": "Irina Shklovski"}, {"authorId": "1403056818", "name": "R. Douglas-Jones"}], "abstract": null, "corpusId": "5076936", "paragraphs": [{"paragraphId": "85711", "title": "Calling for a Revolution: An Analysis of IoT Manifestos", "sectionTitle": "VALUES AND FUTURES", "text": "Discussions about disparately defined and designed futures are present in HCI as well and many scholars question the values, ethics and the responsibilities of care embedded in our technologies [4,15,18,20]. As the effects of rapid technological change are felt, scholars increasingly engage with theoretical concepts and tools from a variety of disciplines, exploring the capacity to integrate critical points of view into design as part of both research and practice [9,10,14,22]. Part of this effort has focused on the development of applications of theoretical concepts by distilling principles [30], frameworks [15] and methodologies [5] with the aim of having a direct impact on practice. These tools, such as the principles of reflective design developed by Sengers et al. [30] or value sensitive design developed by Friedman and colleagues [15] call for reflection, reinterpretation and attention to stakeholders and their needs and values among others. Over time, these efforts have indeed had impact on practitioners while they struggle with many pressures and demands as the services and objects they design become ever more broadly consequential [36].", "spans": "[{\"corpusId\": 2773070, \"span\": \"[4,\", \"start\": 194, \"end\": 197}, {\"corpusId\": 8176837, \"span\": \"15,\", \"start\": 197, \"end\": 200}, {\"corpusId\": 3332247, \"span\": \"20]\", \"start\": 203, \"end\": 206}, {\"corpusId\": 9534400, \"span\": \"10,\", \"start\": 472, \"end\": 475}, {\"corpusId\": 17924509, \"span\": \"14,\", \"start\": 475, \"end\": 478}, {\"corpusId\": 10898486, \"span\": \"22]\", \"start\": 478, \"end\": 481}, {\"corpusId\": 8176837, \"span\": \"[15]\", \"start\": 616, \"end\": 620}, {\"corpusId\": 8176837, \"span\": \"[15]\", \"start\": 848, \"end\": 852}]", "conference": "chi", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "85712", "title": "Calling for a Revolution: An Analysis of IoT Manifestos", "sectionTitle": "Sustainability", "text": "At least half of the manifestos express concerns about sustainability in IoT returning us to the question of progress both in the manifestos and in HCI. Environmental sustainability is a major concern for HCI tied to technological interventions [10]. Within sustainable HCI technology design and development is implicated in an impulse to create change [16]. Much of this research has turned problems of environmental action into questions of personal moral choice, often focusing on behavior change as a route to altering individual consumption patterns [10]. An alternative path has focused on 'ecologies of practices' within design and HCI [8,27]. In the manifestos the latter approach to sustainability is more apparent. Just a few documents imagine how IoT could be used to change, augment or improve individual behavior (Kr\u00fcger, RIOT; Smit, RIOT). We identify three main notions of sustainability in the manifestos: realigning lifetimes of the physical and the digital, obsolescence and locality.  (Uribe).", "spans": "[{\"corpusId\": 9534400, \"span\": \"[10]\", \"start\": 245, \"end\": 249}, {\"corpusId\": 14742637, \"span\": \"[16]\", \"start\": 353, \"end\": 357}, {\"corpusId\": 5076936, \"span\": \"this research\", \"start\": 380, \"end\": 380}, {\"corpusId\": 9534400, \"span\": \"[10]\", \"start\": 555, \"end\": 559}, {\"corpusId\": 10511320, \"span\": \"27]\", \"start\": 646, \"end\": 649}]", "conference": "chi", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 2}
{"paperId": "77a5e08f361b6f91cac8a24b380a14c12bb93383", "title": "Novice-AI Music Co-Creation via AI-Steering Tools for Deep Generative Models", "venue": "International Conference on Human Factors in Computing Systems", "year": 2020, "citationCount": 278, "openAccessPdf": {"url": "https://dl.acm.org/doi/pdf/10.1145/3313831.3376739", "status": "BRONZE", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3313831.3376739?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3313831.3376739, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2020-04-21", "authors": [{"authorId": "70790902", "name": "Ryan Louie"}, {"authorId": "1388485917", "name": "Andy Coenen"}, {"authorId": "7900665", "name": "Cheng-Zhi Anna Huang"}, {"authorId": "144212868", "name": "Michael Terry"}, {"authorId": "145941081", "name": "Carrie J. Cai"}], "abstract": "While generative deep neural networks (DNNs) have demonstrated their capacity for creating novel musical compositions, less attention has been paid to the challenges and potential of co-creating with these musical AIs, especially for novices. In a needfinding study with a widely used, interactive musical AI, we found that the AI can overwhelm users with the amount of musical content it generates, and frustrate them with its non-deterministic output. To better match co-creation needs, we developed AI-steering tools, consisting of Voice Lanes that restrict content generation to particular voices; Example-Based Sliders to control the similarity of generated content to an existing example; Semantic Sliders to nudge music generation in high-level directions (happy/sad, conventional/surprising); and Multiple Alternatives of generated content to audition and choose from. In a summative study (N=21), we discovered the tools not only increased users' trust, control, comprehension, and sense of collaboration with the AI, but also contributed to a greater sense of self-efficacy and ownership of the composition relative to the AI.", "corpusId": "218482503", "paragraphs": [{"paragraphId": "32343", "title": "Novice-AI Music Co-Creation via AI-Steering Tools for Deep Generative Models", "sectionTitle": "INTRODUCTION", "text": "Rapid advances in deep learning have made it possible for artificial intelligence (AI) to actively collaborate with humans to co-create new content [36,9,18,33,23,31]. One promising application of machine learning in this space has been the use of generative deep neural network (DNN)-backed systems for creative activities such as poetry writing, drawing, and music creation-experiences that bear intrinsic value for people, but often require specialized skill sets. For example, by completing a drawing that a user has started [36,9,32,14] or filling in a missing section of a song [27,24], generative models could enable untrained lay users to take part in creative experiences that would otherwise be difficult to achieve without additional training or specialization [29,12,19]. In this paper, we focus on the needs of music novices co-creating music with a generative DNN model.", "spans": "[{\"corpusId\": 1955813, \"span\": \"9,\", \"start\": 152, \"end\": 154}, {\"corpusId\": 140228437, \"span\": \"18,\", \"start\": 154, \"end\": 157}, {\"corpusId\": 140236532, \"span\": \"33,\", \"start\": 157, \"end\": 160}, {\"corpusId\": 58981641, \"span\": \"23,\", \"start\": 160, \"end\": 163}, {\"corpusId\": 13337897, \"span\": \"31]\", \"start\": 163, \"end\": 166}, {\"corpusId\": 1955813, \"span\": \"9,\", \"start\": 533, \"end\": 535}, {\"corpusId\": 174789354, \"span\": \"14]\", \"start\": 538, \"end\": 541}, {\"corpusId\": 1215640, \"span\": \"24]\", \"start\": 588, \"end\": 591}, {\"corpusId\": 52979270, \"span\": \"12,\", \"start\": 776, \"end\": 779}, {\"corpusId\": 218482503, \"span\": \"this paper\", \"start\": 797, \"end\": 797}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": false, "refCount": 9}, {"paragraphId": "32344", "title": "Novice-AI Music Co-Creation via AI-Steering Tools for Deep Generative Models", "sectionTitle": "Human-AI Co-creation", "text": "The acceleration of AI capabilities has renewed interest in how AI can enable human-AI co-creation in domains such as drawing [36,9,32,14], creative writing [18,7], design ideation [33], video game content generation [23], and dance [31]. For example, an AI might flesh out a half-sketched drawing [36], write the next paragraph of a story [7], or add an image to a design mood board [33]. Across this range of prior work, a core challenge has been developing collaborative AI agents that can adapt their actions based on the goals and behaviors of the user. To this end, some systems design the AI to generate output conditioned upon the surrounding context of human-generated content [14,7,18], while others leverage user feedback to better align AI behavior to user intents [23,33,9]. Research has also observed that users desire to take initiative in their partnership with AI [36], with controllability and comprehensibility being key challenges to realizing this vision [1]. Building on this need, our work enables users to express their preferences to an AI collaborator through a variety of means.", "spans": "[{\"corpusId\": 1955813, \"span\": \"9,\", \"start\": 130, \"end\": 132}, {\"corpusId\": 174789354, \"span\": \"14]\", \"start\": 135, \"end\": 138}, {\"corpusId\": 140228437, \"span\": \"[18,\", \"start\": 157, \"end\": 161}, {\"corpusId\": 3817960, \"span\": \"7]\", \"start\": 161, \"end\": 163}, {\"corpusId\": 140236532, \"span\": \"[33]\", \"start\": 181, \"end\": 185}, {\"corpusId\": 58981641, \"span\": \"[23]\", \"start\": 217, \"end\": 221}, {\"corpusId\": 13337897, \"span\": \"[31]\", \"start\": 233, \"end\": 237}, {\"corpusId\": 3817960, \"span\": \"[7]\", \"start\": 340, \"end\": 343}, {\"corpusId\": 140236532, \"span\": \"[33]\", \"start\": 384, \"end\": 388}, {\"corpusId\": 174789354, \"span\": \"[14,\", \"start\": 686, \"end\": 690}, {\"corpusId\": 3817960, \"span\": \"7,\", \"start\": 690, \"end\": 692}, {\"corpusId\": 140228437, \"span\": \"18]\", \"start\": 692, \"end\": 695}, {\"corpusId\": 58981641, \"span\": \"[23,\", \"start\": 777, \"end\": 781}, {\"corpusId\": 140236532, \"span\": \"33,\", \"start\": 781, \"end\": 784}, {\"corpusId\": 1955813, \"span\": \"9]\", \"start\": 784, \"end\": 786}, {\"corpusId\": 86866942, \"span\": \"[1]\", \"start\": 976, \"end\": 979}, {\"corpusId\": 218482503, \"span\": \"our work\", \"start\": 1012, \"end\": 1012}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "32345", "title": "Novice-AI Music Co-Creation via AI-Steering Tools for Deep Generative Models", "sectionTitle": "Interactive Interfaces for ML Music Models", "text": "To support music makers in the composition process, researchers have conceptualized and developed ML-powered interfaces that map user inputs to musical structures so users can interactively explore musical variations. Examples of such designs and systems include those that allow users to find chords to accompany a melody [41,21], experiment with adventurous chord progressions [28,17], control the similarity vs. otherness for retrieval of music samples [2], use custom gestural inputs to interpolate between synthesizer sounds [16], or turn free-hand sketches into harmonious musical textures [15].", "spans": "[{\"corpusId\": 14897839, \"span\": \"[41,\", \"start\": 323, \"end\": 327}, {\"corpusId\": 82577, \"span\": \"[28,\", \"start\": 379, \"end\": 383}, {\"corpusId\": 1099764, \"span\": \"17]\", \"start\": 383, \"end\": 386}, {\"corpusId\": 18870985, \"span\": \"[2]\", \"start\": 456, \"end\": 459}, {\"corpusId\": 369621, \"span\": \"[15]\", \"start\": 596, \"end\": 600}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "32346", "title": "Novice-AI Music Co-Creation via AI-Steering Tools for Deep Generative Models", "sectionTitle": "Deep Generative Music Models", "text": "As their name implies, generative deep neural networks can synthesize content. Research has demonstrated the potential for modeling and synthesizing music, ranging from singlevoice sequences [13] and multi-part music [19,34], to music with variable parts at each time step [4] and music with longterm structure over minutes [30,37,26].", "spans": "[{\"corpusId\": 579926, \"span\": \"[13]\", \"start\": 191, \"end\": 195}, {\"corpusId\": 175089, \"span\": \"[4]\", \"start\": 273, \"end\": 276}, {\"corpusId\": 53094405, \"span\": \"26]\", \"start\": 331, \"end\": 334}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "32347", "title": "Novice-AI Music Co-Creation via AI-Steering Tools for Deep Generative Models", "sectionTitle": "Deep Generative Music Models", "text": "In contrast to models that (typically) generate music chronologically from left to right, in-filling models can more flexibly support co-creation by allowing users to specify regions at any point in the music, then auto-filling those gaps. Examples include DeepBach [24] and Coconet [27], both trained on fourpart Bach Chorales. Researchers have also created models designed to support interaction mechanisms that grant users more control. For example, there are emerging approaches aimed at learning a continuous latent space so that users can interpolate between music [38], or explore a space of musical alternatives [10]. In our work, we adopt soft priors as a general approach that provides additional ways for users to direct their exploration. In contrast to hard constraints, our approach allows DNNs to simultaneously consider the original context (encoded in the model's original sampling distribution) and additional desired qualities (encoded in a soft prior distribution), without needing to retrain the model.", "spans": "[{\"corpusId\": 1215640, \"span\": \"[24]\", \"start\": 266, \"end\": 270}, {\"corpusId\": 3891811, \"span\": \"[38]\", \"start\": 571, \"end\": 575}, {\"corpusId\": 207974449, \"span\": \"[10]\", \"start\": 620, \"end\": 624}, {\"corpusId\": 218482503, \"span\": \"our work\", \"start\": 637, \"end\": 637}, {\"corpusId\": 218482503, \"span\": \"our approach\", \"start\": 796, \"end\": 796}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "32348", "title": "Novice-AI Music Co-Creation via AI-Steering Tools for Deep Generative Models", "sectionTitle": "Measures", "text": "Users' compositional experience is important to support for novice music creators pursuing autotelic, or intrinsicallyrewarding, creative activities [8], which motivated the following set of metrics. Creative expression: Users rated \"I was able to express my creative goals in the composition made using [System X].\" Self-efficacy: Users answered two items from the Generalized Self-Efficacy scale [40] that were rephrased for music composition. Effort: Users answered the effort question of the NASA-TLX [25], where 1=very low and 7=very high. Engaging: Users rated \"Using [System X] felt engaging.\" Learning: Users rated \"After using [System X], I learned more about music composition than I knew previously.\" Completeness: Users rated \"The composition I created using [System X] feels complete (e.g., there's nothing to be further worked on).\" Uniqueness: Users rated \"The composition I created using System X feels unique.\"", "spans": "[{\"corpusId\": 1305832, \"span\": \"[8]\", \"start\": 149, \"end\": 152}, {\"corpusId\": 151235400, \"span\": \"[40]\", \"start\": 398, \"end\": 402}, {\"corpusId\": 15252590, \"span\": \"[25]\", \"start\": 505, \"end\": 509}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "32349", "title": "Novice-AI Music Co-Creation via AI-Steering Tools for Deep Generative Models", "sectionTitle": "Measures", "text": "Motivated by the importance of supporting effective, humancentered partnerships with AI [1,8,36], we additionally evaluated users' attitudes towards the AI. AI interaction issues: Users rated the extent to which the system felt comprehensible and controllable, two key challenges of human-AI interaction raised in prior work on DNNs [36]. Trust: Participants rated the system along Mayer's dimensions of trust [35]: capability, benevolence, and integrity. Ownership: Users rated two questions, one on ownership (\"I felt the composition created was mine.\"), and one on attribution (\"The music created using [System X] was 1=totally due to the system's contributions, 7=totally due to my contributions.\"). Collaboration: Users rated \"I felt like I was collaborating with the system.\"", "spans": "[{\"corpusId\": 86866942, \"span\": \"[1,\", \"start\": 88, \"end\": 91}, {\"corpusId\": 1305832, \"span\": \"8,\", \"start\": 91, \"end\": 93}, {\"corpusId\": 15027176, \"span\": \"[35]\", \"start\": 410, \"end\": 414}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 7}
{"paperId": "b22218565f562317fe61a2d4914304438ddeb143", "title": "JointCL: A Joint Contrastive Learning Framework for Zero-Shot Stance Detection", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2022, "citationCount": 95, "openAccessPdf": {"url": "https://aclanthology.org/2022.acl-long.7.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://aclanthology.org/2022.acl-long.7, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": null, "authors": [{"authorId": "144691693", "name": "Bin Liang"}, {"authorId": "50736325", "name": "Qinglin Zhu"}, {"authorId": "47356371", "name": "Xiang Li"}, {"authorId": "2144399430", "name": "Min Yang"}, {"authorId": "145096580", "name": "Lin Gui"}, {"authorId": "1390509967", "name": "Yulan He"}, {"authorId": "1753529", "name": "Ruifeng Xu"}], "abstract": "Zero-shot stance detection (ZSSD) aims to detect the stance for an unseen target during the inference stage. In this paper, we propose a joint contrastive learning (JointCL) framework, which consists of stance contrastive learning and target-aware prototypical graph contrastive learning. Specifically, a stance contrastive learning strategy is employed to better generalize stance features for unseen targets. Further, we build a prototypical graph for each instance to learn the target-based representation, in which the prototypes are deployed as a bridge to share the graph structures between the known targets and the unseen ones. Then a novel target-aware prototypical graph contrastive learning strategy is devised to generalize the reasoning ability of target-based stance representations to the unseen targets. Extensive experiments on three benchmark datasets show that the proposed approach achieves state-of-the-art performance in the ZSSD task.", "corpusId": "248780001", "paragraphs": [{"paragraphId": "1191", "title": "JointCL: A Joint Contrastive Learning Framework for Zero-Shot Stance Detection\u00a0", "sectionTitle": "Introduction", "text": "Stance detection aims to automatically identify one's opinionated standpoint/attitude (e.g. Pro, Con, or Neutral, etc.) expressed in text towards a specific proposition, topic, or target (Somasundaran and Wiebe, 2010; Augenstein et al., 2016;Mohammad et al., 2016;Sobhani et al., 2017). For example, a text \"Everyone is able to believe in whatever they want.\" expresses a stance of \"Pro\" towards the target \"Atheism\".", "spans": "[{\"corpusId\": 744471, \"span\": \"Augenstein et al., 2016;\", \"start\": 218, \"end\": 242}, {\"corpusId\": 286464, \"span\": \"Mohammad et al., 2016;\", \"start\": 242, \"end\": 264}, {\"corpusId\": 2250656, \"span\": \"Sobhani et al., 2017)\", \"start\": 264, \"end\": 285}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "1192", "title": "JointCL: A Joint Contrastive Learning Framework for Zero-Shot Stance Detection\u00a0", "sectionTitle": "Introduction", "text": "Existing methods achieved promising performance in in-target stance detection when trained and tested on the datasets towards the same set of * Equal contribution \u2020 Corresponding Author 1 The source code of this work is released at https:// github.com/HITSZ-HLT/JointCL targets (Mohtarami et al., 2018;Graells-Garrido et al., 2020), and in cross-target stance detection that identifies the stance of a destination target using models trained on a related source target in a one-to-one way (Xu et al., 2018;Zhang et al., 2020;Liang et al., 2021a). In practice, however, it is infeasible to enumerate all possible (in-target) or related (cross-target) targets beforehand for training stance detection models. Hence, zero-shot stance detection (ZSSD) (Allaway and McKeown, 2020), which aims to detect the stance for unseen targets during the inference stage is a promising scenario forward.", "spans": "[{\"corpusId\": 248780001, \"span\": \"this work\", \"start\": 216, \"end\": 216}, {\"corpusId\": 5037669, \"span\": \"(Mohtarami et al., 2018;\", \"start\": 278, \"end\": 302}, {\"corpusId\": 218522324, \"span\": \"Graells-Garrido et al., 2020)\", \"start\": 302, \"end\": 331}, {\"corpusId\": 21726677, \"span\": \"(Xu et al., 2018;\", \"start\": 489, \"end\": 506}, {\"corpusId\": 222208845, \"span\": \"(Allaway and McKeown, 2020)\", \"start\": 748, \"end\": 775}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "1193", "title": "JointCL: A Joint Contrastive Learning Framework for Zero-Shot Stance Detection\u00a0", "sectionTitle": "Zero-Shot Stance Detection", "text": "Zero-shot stance detection (ZSSD) aims to detect stance for destination unseen targets by learning stance features from known targets (Allaway and McKeown, 2020). To deal with zero-shot stance detection, Allaway and McKeown (2020) created a new dataset consisting of a large range of topics covering broad themes, called Varied Stance Topics (VAST). Based on it, they proposed a topic-grouped attention model to implicitly capture relationships between targets by using generalized topic representations. Allaway et al. (2021) adopted a targetspecific stance detection dataset (Mohammad et al., 2016) and deployed adversarial learning to extract target-invariant transformation features in ZSSD.", "spans": "[{\"corpusId\": 222208845, \"span\": \"(Allaway and McKeown, 2020)\", \"start\": 134, \"end\": 161}, {\"corpusId\": 234679287, \"span\": \"Allaway et al. (2021)\", \"start\": 505, \"end\": 526}, {\"corpusId\": 286464, \"span\": \"(Mohammad et al., 2016)\", \"start\": 577, \"end\": 600}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "1194", "title": "JointCL: A Joint Contrastive Learning Framework for Zero-Shot Stance Detection\u00a0", "sectionTitle": "Contrastive Learning", "text": "Contrastive learning in the latent space has recently shown great promise, which aims to make the representation of a given anchor data to be similar to its positive pairs and dissimilar to its negative pairs (Hadsell et al., 2006;Wu et al., 2018;Chen et al., 2020a;Khosla et al., 2020;Chen et al., 2020b;Gunel et al., 2021). Various contrastive learning approaches have been developed to deal with natural language processing tasks (Kachuee et al., 2021;Qin et al., 2021;Yang et al., 2021;Liang et al., 2021b), including unsupervised text representation learning (Giorgi et al., 2021), text classification (Qiu et al., 2021), and text clustering . More recently,  presented prototypical contrastive learning and a ProtoNCE loss to encourage representations to be closer to their assigned prototypes. However, this method only models the relationship between an anchor instance and its nearest prototype. On the other hand, You et al. (2020) proposed a graph contrastive learning framework based on graph data augmentation, which improves the graph representations for better generalizability and robustness. However, their ap- \u2295 is vector concatenation. In the graphs, the gray ellipses denote prototypes, others denote hidden vectors. Vectors with the same color hold the same stance.", "spans": "[{\"corpusId\": 8281592, \"span\": \"(Hadsell et al., 2006;\", \"start\": 209, \"end\": 231}, {\"corpusId\": 211096730, \"span\": \"Chen et al., 2020a;\", \"start\": 247, \"end\": 266}, {\"corpusId\": 216080787, \"span\": \"Khosla et al., 2020;\", \"start\": 266, \"end\": 286}, {\"corpusId\": 219721239, \"span\": \"Chen et al., 2020b;\", \"start\": 286, \"end\": 305}, {\"corpusId\": 226237047, \"span\": \"Gunel et al., 2021)\", \"start\": 305, \"end\": 324}, {\"corpusId\": 225040127, \"span\": \"(Kachuee et al., 2021;\", \"start\": 433, \"end\": 455}, {\"corpusId\": 229923565, \"span\": \"Qin et al., 2021;\", \"start\": 455, \"end\": 472}, {\"corpusId\": 219530980, \"span\": \"(Giorgi et al., 2021)\", \"start\": 564, \"end\": 585}, {\"corpusId\": 236478053, \"span\": \"(Qiu et al., 2021)\", \"start\": 607, \"end\": 625}, {\"corpusId\": 248780001, \"span\": \"this method\", \"start\": 821, \"end\": 821}, {\"corpusId\": 225076220, \"span\": \"You et al. (2020)\", \"start\": 924, \"end\": 941}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 11}, {"paragraphId": "1195", "title": "JointCL: A Joint Contrastive Learning Framework for Zero-Shot Stance Detection\u00a0", "sectionTitle": "Main Results", "text": "The main comparison results of ZSSD on three benchmark datasets are reported in Table 3. It can be observed from the experimental results, our proposed JointCL framework performs consistently better than the non-BERT and the BERTbased comparison models on both the VAST and WT-WT datasets, and achieves overall better performance than the comparison baselines on the SEM16 dataset. This verifies the effectiveness of our JointCL framework in the ZSSD task. Furthermore, the significance tests of JointCL over the baseline models show that our JointCL significantly outperforms the baseline models (the results of p\u2212value on most of the evaluation metrics are less than 0.05). More concretely, in comparison with the adversarial learning-based model (TOAD), our JointCL achieves significant improvement across all datasets. This indicates that exploring graph contrastive learning to model the relationships among targets can better generalize the targetbased stance features to the unseen targets. In addition, the comparison results between our JointCL  Table 3: Experimental results on three ZSSD datasets. The results with \u266e are retrieved from (Allaway and McKeown, 2020), \u2020 from , \u2021 from (Allaway et al., 2021), \u266f from (Conforti et al., 2020), and \u266d from (Liang et al., 2021a). Best scores are in bold. Results with \u22c6 denote the significance tests of our JointCL over the baseline models at p\u2212value < 0.05.", "spans": "[{\"corpusId\": 222208845, \"span\": \"(Allaway and McKeown, 2020)\", \"start\": 1147, \"end\": 1174}, {\"corpusId\": 234679287, \"span\": \"(Allaway et al., 2021)\", \"start\": 1192, \"end\": 1214}, {\"corpusId\": 218470042, \"span\": \"(Conforti et al., 2020)\", \"start\": 1223, \"end\": 1246}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 5}
{"paperId": "b0abced402bd11a7b43f42e4fd443c9150b4a9b0", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "venue": "International Conference on Human Factors in Computing Systems", "year": 2019, "citationCount": 33, "openAccessPdf": {"url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300793", "status": "BRONZE", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3290605.3300793?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3290605.3300793, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2019-05-02", "authors": [{"authorId": "50378084", "name": "Maitraye Das"}, {"authorId": "32980371", "name": "Brent J. Hecht"}, {"authorId": "2497393", "name": "Darren Gergle"}], "abstract": "Millions of people worldwide contribute content to peer production repositories that serve human information needs and provide vital world knowledge to prominent artificial intelligence systems. Yet, extreme gender participation disparities exist in which men significantly outnumber women. A central concern has been that due to self-focus bias, these disparities can lead to corresponding gender content disparities, in which content of interest to men is better represented than content of interest to women. This paper investigates the relationship between participation and content disparities in OpenStreetMap. We replicate findings that women are dramatically under-represented as OSM contributors, and observe that men and women contribute different types of content and do so about different places. However, the character of these differences confound simple narratives about self-focus bias: we find that on a proportional basis, men produced a higher proportion of contributions in feminized spaces compared to women, while women produced a higher proportion of contributions in masculinized spaces compared to men.", "corpusId": "140294123", "paragraphs": [{"paragraphId": "31509", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "INTRODUCTION", "text": "Peer production is a powerful example of the potential of social computing in which communities like Wikipedia and OpenStreetMap (OSM)-the 'Wikipedia of Maps' [32,73]create high-quality content at previously unimaginable scales. This content has in turn satisfed billions of human information needs [26,55,76] and provided essential world knowledge to countless artifcial intelligence systems [38,45,71].", "spans": "[{\"corpusId\": 6609767, \"span\": \"[26,\", \"start\": 299, \"end\": 303}, {\"corpusId\": 14726655, \"span\": \"55,\", \"start\": 303, \"end\": 306}, {\"corpusId\": 13313050, \"span\": \"76]\", \"start\": 306, \"end\": 309}, {\"corpusId\": 145290159, \"span\": \"[38,\", \"start\": 393, \"end\": 397}, {\"corpusId\": 112601779, \"span\": \"45,\", \"start\": 397, \"end\": 400}, {\"corpusId\": 1828098, \"span\": \"71]\", \"start\": 400, \"end\": 403}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 6}, {"paragraphId": "31510", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "INTRODUCTION", "text": "One of the most signifcant of the peer production participation disparities observed in the literature occurs along the dimension of gender. In particular, both Wikipedia and OSM appear to have a severe under-representation of women [15,20,36,50,61,87,88,92]. Estimates of women's participation on Wikipedia range from 13-18% [15,36,50,61]. While less is known about OSM, it is believed that this participation imbalance could be even larger, with women's participation in the 3-4% range [20,87,88].", "spans": "[{\"corpusId\": 1119304, \"span\": \"50,\", \"start\": 243, \"end\": 246}, {\"corpusId\": 15730439, \"span\": \"61,\", \"start\": 246, \"end\": 249}, {\"corpusId\": 9472860, \"span\": \"92]\", \"start\": 255, \"end\": 258}, {\"corpusId\": 1119304, \"span\": \"50,\", \"start\": 333, \"end\": 336}, {\"corpusId\": 15730439, \"span\": \"61]\", \"start\": 336, \"end\": 339}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "31511", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "INTRODUCTION", "text": "A key motivating factor in the literature on gender dynamics in peer production is concern that gender participation disparities will result in corresponding gender content disparities. In other words, it has been assumed that the limited representation of women may lead to peer-produced content that is less able to serve women's information needs [51,65,92] and that the many AI systems that \"learn\" from peer-produced content may take on a biased view of the world [49,56]. This assumption is supported by the notion of \"self-focus bias\" [46], in which peer production communities produce an out-sized proportion of content in areas of interest to the cultural groups present in the community.", "spans": "[{\"corpusId\": 9472860, \"span\": \"92]\", \"start\": 357, \"end\": 360}, {\"corpusId\": 15385148, \"span\": \"[49,\", \"start\": 469, \"end\": 473}, {\"corpusId\": 3854983, \"span\": \"56]\", \"start\": 473, \"end\": 476}, {\"corpusId\": 8102524, \"span\": \"[46]\", \"start\": 542, \"end\": 546}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "31512", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "INTRODUCTION", "text": "Despite the importance of the assumed relationship between gender participation disparities and content disparities, little work has sought to empirically explore this relationship. For example, research on Wikipedia has observed diferences in the characterization and structure of biographical content about women [95,96,98] and the quality of content of greater interest to women [61]. Yet, most of this work, which has focused on limited topics in Wikipedia, has not directly linked content diferences to the gender of the editors involved. As such, it is unclear whether gender participation disparities led to any observed content disparities. (For a notable exception see [61], discussed in related work).", "spans": "[{\"corpusId\": 15932375, \"span\": \"[95,\", \"start\": 315, \"end\": 319}, {\"corpusId\": 1769950, \"span\": \"96,\", \"start\": 319, \"end\": 322}, {\"corpusId\": 11059274, \"span\": \"98]\", \"start\": 322, \"end\": 325}, {\"corpusId\": 15730439, \"span\": \"[61]\", \"start\": 382, \"end\": 386}, {\"corpusId\": 140294123, \"span\": \"this work\", \"start\": 410, \"end\": 410}, {\"corpusId\": 15730439, \"span\": \"[61]\", \"start\": 678, \"end\": 682}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "31513", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "INTRODUCTION", "text": "In this paper, we contribute to a more complete picture of how peer-produced content is afected by gender-based contribution disparities. We do so by examining the content generated by a large sample of male and female power editors in OSM. Our results support the hypothesis that men and women tend to contribute diferent types of content. We observe this both in terms of the regions where men and women edit (e.g., rural vs. urban) and in terms of the type of content that they contribute (e.g., the specifc spatial entities they add to the database). However, our results also reveal critical complexity in these diferences that belie a simple gender-based self-focus bias interpretation [65,68,92]. In particular, we observed that men disproportionately contribute to entities that critical geographers [65,92] have identifed as being in feminized spaces and women disproportionately contribute entities in masculinized spaces. Additionally, our analyses point to complicated intersectional dynamics, with contributor gender being associated with a likelihood to exacerbate or mitigate other known content biases in OSM (e.g., those related to the rural-urban spectrum [18,55,83]).", "spans": "[{\"corpusId\": 140294123, \"span\": \"this paper\", \"start\": 13, \"end\": 13}, {\"corpusId\": 140294123, \"span\": \"Our results\", \"start\": 252, \"end\": 252}, {\"corpusId\": 140294123, \"span\": \"our results\", \"start\": 575, \"end\": 575}, {\"corpusId\": 55665088, \"span\": \"68,\", \"start\": 696, \"end\": 699}, {\"corpusId\": 9472860, \"span\": \"92]\", \"start\": 699, \"end\": 702}, {\"corpusId\": 9472860, \"span\": \"92]\", \"start\": 812, \"end\": 815}, {\"corpusId\": 157778325, \"span\": \"[18,\", \"start\": 1174, \"end\": 1178}, {\"corpusId\": 14726655, \"span\": \"55,\", \"start\": 1178, \"end\": 1181}, {\"corpusId\": 53682662, \"span\": \"83]\", \"start\": 1181, \"end\": 1184}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 6}, {"paragraphId": "31514", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "Gender Participation Disparities", "text": "A number of studies have revealed a substantial participation gender gap in Wikipedia [36,50], with some studies suggesting that the gap is even more prominent among the most active contributors [15,61]. Less is known about gender participation in OSM where recent demographic information is more limited [51]. However, earlier surveys suggest that OSM editors are mostly men, well-educated and tech-savvy, with women representing only 3-4% of the community [20,87,88]. A survey conducted by Stephens indicated that women were less familiar with OSM than men and that their contribution levels exhibited even greater disparity [92]. While understanding the relationship between participation disparities and content disparities is the main focus of this paper, our fndings also add empirical information that bolster existing evidence of a severe participation gap in OSM, specifcally among the most active editors.", "spans": "[{\"corpusId\": 1119304, \"span\": \"50]\", \"start\": 90, \"end\": 93}, {\"corpusId\": 15730439, \"span\": \"61]\", \"start\": 199, \"end\": 202}, {\"corpusId\": 9472860, \"span\": \"[92]\", \"start\": 627, \"end\": 631}, {\"corpusId\": 140294123, \"span\": \"this paper\", \"start\": 759, \"end\": 759}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "31515", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "Gender Participation Disparities", "text": "Another important facet of research focuses on understanding the causes of gender participation gaps. Some that have been identifed include the pipeline of skills necessary to edit Wikipedia [43,90], personal preferences for online collaboration [17,24,63,72] and levels of confdence [17,24,82]. Similarly, steep learning curves, insufcient technical feedback, and lack of time are found to be infuential factors behind users' inactivity in OSM [67,87,88]; however, Schimidt et al. found no gender-related diference with respect to these factors [87]. Steinmann et al. compared women's participation rates across diferent social media and peer production platforms, and suggested that a lack of social aspects and stringent rules might be responsible for women's lower participation in peer production environments like OSM [91].", "spans": "[{\"corpusId\": 149517252, \"span\": \"90]\", \"start\": 195, \"end\": 198}, {\"corpusId\": 146452625, \"span\": \"[17,\", \"start\": 246, \"end\": 250}, {\"corpusId\": 17473183, \"span\": \"24,\", \"start\": 250, \"end\": 253}, {\"corpusId\": 11758648, \"span\": \"63,\", \"start\": 253, \"end\": 256}, {\"corpusId\": 303648, \"span\": \"72]\", \"start\": 256, \"end\": 259}, {\"corpusId\": 146452625, \"span\": \"[17,\", \"start\": 284, \"end\": 288}, {\"corpusId\": 17473183, \"span\": \"24,\", \"start\": 288, \"end\": 291}, {\"corpusId\": 18765562, \"span\": \"82]\", \"start\": 291, \"end\": 294}, {\"corpusId\": 127113115, \"span\": \"[67,\", \"start\": 445, \"end\": 449}, {\"corpusId\": 211168146, \"span\": \"[91]\", \"start\": 824, \"end\": 828}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 8}, {"paragraphId": "31516", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "Content Disparities", "text": "Another important line of research focuses on content disparities in peer-produced repositories. For example, in the case of Wikipedia biographies, men and women appear to be covered equally well [60,95]. However, biases exist in the ways women are portrayed, with their biographies more likely to explicitly mention family, relationships or gender in comparison to men's biographies [37,95,96,98]. Content diferences also manifest in the linguistic choices made by editors in a way that generalize men's successes but not their failures and vice-versa for women [78,95].", "spans": "[{\"corpusId\": 6334140, \"span\": \"[60,\", \"start\": 196, \"end\": 200}, {\"corpusId\": 15932375, \"span\": \"95]\", \"start\": 200, \"end\": 203}, {\"corpusId\": 1082360, \"span\": \"[37,\", \"start\": 384, \"end\": 388}, {\"corpusId\": 15932375, \"span\": \"95,\", \"start\": 388, \"end\": 391}, {\"corpusId\": 1769950, \"span\": \"96,\", \"start\": 391, \"end\": 394}, {\"corpusId\": 11059274, \"span\": \"98]\", \"start\": 394, \"end\": 397}, {\"corpusId\": 15932375, \"span\": \"95]\", \"start\": 567, \"end\": 570}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "31517", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "Content Disparities", "text": "Critically for our analysis, content disparities also have important spatial components. For example, rural areas have lower coverage and/or quality in OSM and Wikipedia compared to urban areas [55,69,101]. Similarly, regions with higher levels of education and socioeconomic status (SES) exhibit better coverage [18,39]. Given that it has been observed that editing outcomes vary along rural/urban and SES spectra, it is important to incorporate these into analyses of contributions in OSM, and we do so here.", "spans": "[{\"corpusId\": 14726655, \"span\": \"[55,\", \"start\": 194, \"end\": 198}, {\"corpusId\": 1003475, \"span\": \"69,\", \"start\": 198, \"end\": 201}, {\"corpusId\": 4497777, \"span\": \"101]\", \"start\": 201, \"end\": 205}, {\"corpusId\": 157778325, \"span\": \"[18,\", \"start\": 313, \"end\": 317}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "31518", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "Content Disparities", "text": "Most relevant to the work in this paper is a debate about feminized spaces receiving less attention from men and thus being under-represented in OSM [30,51,65,68,92]. Although studies have suggested that gender participation disparities may result in a male-oriented worldview in OSM [65,92], this assumption cannot be directly validated without investigating the mapping behaviors of male and female contributors.", "spans": "[{\"corpusId\": 140294123, \"span\": \"this paper\", \"start\": 39, \"end\": 39}, {\"corpusId\": 31556791, \"span\": \"[30,\", \"start\": 149, \"end\": 153}, {\"corpusId\": 55665088, \"span\": \"68,\", \"start\": 159, \"end\": 162}, {\"corpusId\": 9472860, \"span\": \"92]\", \"start\": 162, \"end\": 165}, {\"corpusId\": 9472860, \"span\": \"92]\", \"start\": 288, \"end\": 291}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "31519", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "Relationship Between Participation Disparities and Content Disparities", "text": "Much less work has been done on the relationship between participation disparities and content disparities than on those individual disparities themselves. The primary theory about this relationship is self-focus bias, which describes the phenomena in which contributors focus disproportionately on information that is particularly relevant to dominant cultural groups in the peer pr 1 oduction community . Self-focus bias has been empirically observed in a number of peer production contexts. For instance, prior work has seen self-focus bias with respect to geography (i.e., people contribute information about places local to them) [28,42,47,100]. Self-focus bias is also prevalent in peer-produced content in terms of language [46,48,89] and politics [52].", "spans": "[{\"corpusId\": 4506679, \"span\": \"[28,\", \"start\": 635, \"end\": 639}, {\"corpusId\": 17266896, \"span\": \"42,\", \"start\": 639, \"end\": 642}, {\"corpusId\": 11112324, \"span\": \"100]\", \"start\": 645, \"end\": 649}, {\"corpusId\": 8102524, \"span\": \"[46,\", \"start\": 731, \"end\": 735}, {\"corpusId\": 6576208, \"span\": \"48,\", \"start\": 735, \"end\": 738}, {\"corpusId\": 8749946, \"span\": \"89]\", \"start\": 738, \"end\": 741}, {\"corpusId\": 10472970, \"span\": \"[52]\", \"start\": 755, \"end\": 759}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "31520", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "RESEARCH QUESTIONS", "text": "This frst research question seeks to capture diferences in the geographic context of male and female contributions. For instance, from the perspective of what has been edited, are there regions in the country that are characterized more by men than by women? Or, from an individual contributor perspective, do men or women contribute disproportionately to certain types of regions? We examine both simple contiguous regions (e.g., regions of the United States) as well as types of regions (e.g., urban vs. rural), since research has shown that contribution behavior on OSM can vary widely across these human geographic dimensions [18,39,55,83].", "spans": "[{\"corpusId\": 157778325, \"span\": \"[18,\", \"start\": 630, \"end\": 634}, {\"corpusId\": 14726655, \"span\": \"55,\", \"start\": 637, \"end\": 640}, {\"corpusId\": 53682662, \"span\": \"83]\", \"start\": 640, \"end\": 643}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "31521", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "DATA COLLECTION AND PROCESSING", "text": "In this section, we discuss the original sources of our data and detail our steps for data collection and processing. Following prior work [18,39,56,99,101], we focused on an individual country in this work, specifcally the United States.", "spans": "[{\"corpusId\": 157778325, \"span\": \"[18,\", \"start\": 139, \"end\": 143}, {\"corpusId\": 3854983, \"span\": \"56,\", \"start\": 146, \"end\": 149}, {\"corpusId\": 32926731, \"span\": \"99,\", \"start\": 149, \"end\": 152}, {\"corpusId\": 4497777, \"span\": \"101]\", \"start\": 152, \"end\": 156}, {\"corpusId\": 140294123, \"span\": \"this work\", \"start\": 206, \"end\": 206}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "31522", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "OSM Datasets", "text": "Node Datasets (\"No-bots\" and \"With-bots\"). We consider all node edits in the 48 conterminous U.S. states and District of Columbia. Throughout the paper, by \"edit\" we refer to different mapping activities, such as adding a node, modifying locations, adding or altering tags, etc. In OSM, editors often use automated software agents (i.e., bots) and automationassisted batch editors to bulk import pre-existing data. For example, data have been imported in bulk to OSM from the U.S. government's TIGER/Line Street datasets. 'Bot edits' are often not regarded as volunteered human activity [55,83]. To detect bot changeset 2 edits, we used fles downloaded from planet.osm [4]. Following prior work [55,83,99,100], we marked edits as 'bot edits' when they came from a changeset containing edits in very large quantities (more than 4,000 edits) or at a very fast rate (more than one edit per second). Initially, our dataset had 1,019,366,964 node edits. After removing bot imports, there were 91,097,410 node edits done by 62,083 users.", "spans": "[{\"corpusId\": 14726655, \"span\": \"[55,\", \"start\": 587, \"end\": 591}, {\"corpusId\": 53682662, \"span\": \"83]\", \"start\": 591, \"end\": 594}, {\"corpusId\": 14726655, \"span\": \"[55,\", \"start\": 695, \"end\": 699}, {\"corpusId\": 53682662, \"span\": \"83,\", \"start\": 699, \"end\": 702}, {\"corpusId\": 32926731, \"span\": \"99,\", \"start\": 702, \"end\": 705}, {\"corpusId\": 11112324, \"span\": \"100]\", \"start\": 705, \"end\": 709}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "31523", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "OSM Datasets", "text": "To guide our formulation of the diferences between feminized and masculinized spaces, we deferred to prior literature in feminist geography. Stephens [92] and Leszczynski and Elwood [65] suggested that places related to nurturing and caregiving are highly feminized [64,81], while public establishments of sexual activities that rely on \"female objectifcation and male privilege\" are considered masculinized spaces [54] 3 . Leszczynski and Elwood write that although sexual venues are not exclusively male spaces, \"longstanding gender norms around the expression of sexuality accord men roles as sexual actors and presume women to be passive and submissive recipients of that activity\" (p.17, [65]).", "spans": "[{\"corpusId\": 9472860, \"span\": \"[92]\", \"start\": 150, \"end\": 154}, {\"corpusId\": 154520930, \"span\": \"81]\", \"start\": 270, \"end\": 273}, {\"corpusId\": 143071107, \"span\": \"[54]\", \"start\": 415, \"end\": 419}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "31524", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "OSM Datasets", "text": "We developed two datasets of amenity values for analysis. The frst is the narrow dataset, based strictly on the amenity types used by critical geographers examining OSM [65,92]. The amenities included are 'childcare', 'baby-hatch', 'preschool', 'kindergarten' and 'hospice' as feminized spaces; 'brothel', 'nightclub' [85], 'strip club' [33], and 'swinger club' [74] as masculinized spaces; and the rest as non-gendered amenity values.", "spans": "[{\"corpusId\": 9472860, \"span\": \"92]\", \"start\": 173, \"end\": 176}, {\"corpusId\": 38348690, \"span\": \"[85]\", \"start\": 318, \"end\": 322}, {\"corpusId\": 46179377, \"span\": \"[33]\", \"start\": 337, \"end\": 341}, {\"corpusId\": 141193045, \"span\": \"[74]\", \"start\": 362, \"end\": 366}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "31525", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "OSM Datasets", "text": "Our second dataset-the broad dataset-contains amenity types generalized from the initial categories established by Stephens [92] and Leszczynski and Elwood [65]. This dataset also includes caretaking-oriented social facilities such as 'daycare', 'assisted living', 'nursery', 'nursing home', 'retirement home' and 'senior centre' as feminized spaces; and sexual venues like 'love hotel', 'sex shop', and 'adult' as masculinized spaces. We also drew on established work to include amenities associated with longstanding gender norms such as 'beauty' [86], 'nail salon' [97], 'family_planning' [75,84] and 'sorority' as feminized spaces; and 'sperm bank', 'fraternity', and 'barber shop' [44] as masculinized spaces. We further supplemented this dataset by collecting common tag key-value pairs that were automatically suggested by the default OSM editor (iD) when adding gender oriented features to OSM (e.g., 'amenity = clinic', 'healthcare = clinic' and 'healthcare:speciality' = abortion' to describe an abortion clinic). In total, our broad dataset includes amenities for 22 feminized spaces and 10 masculinized spaces, and the rest are non-gendered amenities.", "spans": "[{\"corpusId\": 9472860, \"span\": \"[92]\", \"start\": 124, \"end\": 128}, {\"corpusId\": 148602968, \"span\": \"[86]\", \"start\": 549, \"end\": 553}, {\"corpusId\": 146960771, \"span\": \"[97]\", \"start\": 568, \"end\": 572}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "31526", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "Gender Inference", "text": "Since OSM does not collect information about editors' genders, one of the most challenging aspects of our methodological pipeline was performing gender inference. This is a very common obstacle to social computing research that asks important questions related to gender [22,31,53,66,91,94]. We based our approach on prior published techniques used to infer the gender of users in Google MapMaker [91], Stack-Overfow [66], GitHub [94], Resume Search Engines [22], and DBLP Computer Science Bibliography [53].", "spans": "[{\"corpusId\": 140294123, \"span\": \"our method\", \"start\": 112, \"end\": 112}, {\"corpusId\": 5041093, \"span\": \"[22,\", \"start\": 271, \"end\": 275}, {\"corpusId\": 15068764, \"span\": \"66,\", \"start\": 281, \"end\": 284}, {\"corpusId\": 211168146, \"span\": \"91,\", \"start\": 284, \"end\": 287}, {\"corpusId\": 215729690, \"span\": \"94]\", \"start\": 287, \"end\": 290}, {\"corpusId\": 140294123, \"span\": \"our approach\", \"start\": 313, \"end\": 313}, {\"corpusId\": 211168146, \"span\": \"[91]\", \"start\": 397, \"end\": 401}, {\"corpusId\": 15068764, \"span\": \"[66]\", \"start\": 417, \"end\": 421}, {\"corpusId\": 215729690, \"span\": \"[94]\", \"start\": 430, \"end\": 434}, {\"corpusId\": 5041093, \"span\": \"[22]\", \"start\": 458, \"end\": 462}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "31527", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "Gender Inference", "text": "Our specifc procedure was as follows: First, we searched for the profle of a user in the OSM site, OSM Wiki [6] and OSM Help forum [7] and then attempted to infer gender from their profle image, listed real name or text description. We also expanded our search to include information about the user from diferent social media accounts (Twitter, GitHub, LinkedIn, etc.) [66,94] or personal websites that we could associate with their OSM profle. When applicable, we used the Gender API [8] to determine gender from user names, following prior work that used similar API services [53,57].", "spans": "[{\"corpusId\": 15068764, \"span\": \"[66,\", \"start\": 369, \"end\": 373}, {\"corpusId\": 215729690, \"span\": \"94]\", \"start\": 373, \"end\": 376}, {\"corpusId\": 18613261, \"span\": \"57]\", \"start\": 582, \"end\": 585}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "31528", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "ANALYSIS METHODS", "text": "Following prior work in the peer production domain (e.g. [47,70], we approach our analysis from two diferent perspectives. The frst perspective is contribution-centric: it focuses on the gendered geography of existing contributions to OSM. The unit of analysis here is the individual contribution (and which gender contributed it). The second perspective is contributor-centric: it focuses on editing behavior of the contributors themselves and any diferences that may exist along gender lines with regards to where and what they edit. In this case, the unit of analysis is the contributor (and their gender). If all contributors made the same number of contributions, these two perspectives would produce identical results. However, in social computing and peer production specifcally, this is rarely the case, and certain contributors make orders of magnitude more contributions than others, even among frequent editors [40,58,59,79]. This has made these two analytical perspectives valuable when examining peer production contribution behavior as we do here.", "spans": "[{\"corpusId\": 810239, \"span\": \"70]\", \"start\": 61, \"end\": 64}, {\"corpusId\": 1184433, \"span\": \"58,\", \"start\": 926, \"end\": 929}, {\"corpusId\": 14770727, \"span\": \"59,\", \"start\": 929, \"end\": 932}, {\"corpusId\": 6286454, \"span\": \"79]\", \"start\": 932, \"end\": 935}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "31529", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "RQ2: What are the contributions?", "text": "A closer look at the data reveals that the top gendered spaces mapped by female editors are (raw counts in parentheses): nightclub (18), childcare (16), kindergarten (14), nursing home (14), and group home (8). The top gendered spaces mapped by male editors are: kindergarten (2,388), nursing home (1,564), nightclub (634), childcare (351), group home (281), assisted living (168), and stripclub (141). In the narrow dataset, the top gendered spaces mapped by female and male editors are kindergarten, nightclub, childcare, etc.", "spans": "[{\"corpusId\": 157778325, \"span\": \"(18)\", \"start\": 131, \"end\": 135}, {\"corpusId\": 17014760, \"span\": \"(16)\", \"start\": 147, \"end\": 151}, {\"corpusId\": 12322379, \"span\": \"(14)\", \"start\": 166, \"end\": 170}, {\"corpusId\": 12322379, \"span\": \"(14)\", \"start\": 185, \"end\": 189}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "31530", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "Theoretical Implications", "text": "Complexities of Gender-based Self-focus Bias. self-focus bias suggests that contributors predominantly add information that caters to the interests of the cultural groups that are prominent in a given peer production community [46]. Strong evidence of self-focus bias has been observed in terms of the localness of geographic contributions [28,42,46,47], politics [52], language-defned cultural groups [46,47], and others [21,80]. Critical and feminist GIS literature [65,68,92] has suggested that self-focus bias may also exist along gender dimensions. In OSM, this would mean that men would be proportionally more likely to edit masculinized spaces and women would be more likely to edit feminized spaces.", "spans": "[{\"corpusId\": 8102524, \"span\": \"[46]\", \"start\": 227, \"end\": 231}, {\"corpusId\": 4506679, \"span\": \"[28,\", \"start\": 340, \"end\": 344}, {\"corpusId\": 17266896, \"span\": \"42,\", \"start\": 344, \"end\": 347}, {\"corpusId\": 8102524, \"span\": \"46,\", \"start\": 347, \"end\": 350}, {\"corpusId\": 10472970, \"span\": \"[52]\", \"start\": 364, \"end\": 368}, {\"corpusId\": 8102524, \"span\": \"[46,\", \"start\": 402, \"end\": 406}, {\"corpusId\": 14767483, \"span\": \"[21,\", \"start\": 422, \"end\": 426}, {\"corpusId\": 15241924, \"span\": \"80]\", \"start\": 426, \"end\": 429}, {\"corpusId\": 55665088, \"span\": \"68,\", \"start\": 472, \"end\": 475}, {\"corpusId\": 9472860, \"span\": \"92]\", \"start\": 475, \"end\": 478}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 8}, {"paragraphId": "31531", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "Theoretical Implications", "text": "Following prior literature [55,69,83], we did not distinguish between diferent types of edits such as addition or modifcation of entities. Understanding whether and how be other important facets of her identity that are missed by looking exclusively at gender. It is possible that she is mapping as a 'local' editor belonging to an urban place, as a hiker interested in conservation spaces, or as politically conservative activist -in other words, other non-gender aspects of identity may play a more important role. An interesting avenue for further research may focus on understanding the multitudes of ways a person identifes and how intersectional dynamics are incorporated into their activities on peer production platforms like OSM. What is self-focus bias in an intersectional world?", "spans": "[{\"corpusId\": 14726655, \"span\": \"[55,\", \"start\": 27, \"end\": 31}, {\"corpusId\": 1003475, \"span\": \"69,\", \"start\": 31, \"end\": 34}, {\"corpusId\": 53682662, \"span\": \"83]\", \"start\": 34, \"end\": 37}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "31532", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "sectionTitle": "Practical Implications", "text": "Recruiting Male Contributors as Allies. Existing research has situated male and female OSM editors in a position in which we might expect a misalignment between their interest space. If this were true, a solution to any gender-based content disparity might be easy: attract more female editors. As our results show -this simply is not the case. Instead, our fndings reveal that male users are cognizant of at least some of the feminized spaces, and they actively map those facilities. This contradicts the way many prior researchers have been formulating thoughts and discussion of potential improvements to the amount and quality of feminized spaces in OSM [51,65,68,92]. In our dataset, female editors tended to map feminized places to a lesser extent than their male counterparts. As these spaces characterize important facilities for feminine health and nurturing of others, proper representation is necessary. However, our results point out that a straightforward solution like increasing female participation may not ensure increased representation of feminized spaces. We caution that our results should not be interpreted in a way that discourages higher levels of female participation. Rather we need to think critically about ways to increase coverage of under-represented facilities on OSM. One possible approach is the recruitment of male editors as \"allies\" along with more female participants and informing all editors of the state of the repository. Another solution may be to take the \"SuggestBot\" approach [25] and design a content recommendation system that will seek contributors based on location, interests, skills, etc. For example, a local person who is probably aware of nearby childcare centers or maternity clinics may be asked to map those places irrespective of their gender.", "spans": "[{\"corpusId\": 140294123, \"span\": \"our results\", \"start\": 309, \"end\": 309}, {\"corpusId\": 55665088, \"span\": \"68,\", \"start\": 665, \"end\": 668}, {\"corpusId\": 9472860, \"span\": \"92]\", \"start\": 668, \"end\": 671}, {\"corpusId\": 140294123, \"span\": \"our results\", \"start\": 935, \"end\": 935}, {\"corpusId\": 140294123, \"span\": \"our results\", \"start\": 1103, \"end\": 1103}, {\"corpusId\": 906034, \"span\": \"[25]\", \"start\": 1523, \"end\": 1527}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 24}
{"paperId": "978c06878c5381caefc6e9dec2c49239ae7f8bd4", "title": "GRIDS: Interactive Layout Design with Integer Programming", "venue": "International Conference on Human Factors in Computing Systems", "year": 2020, "citationCount": 66, "openAccessPdf": {"url": "https://dl.acm.org/doi/pdf/10.1145/3313831.3376553", "status": "BRONZE", "license": null, "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2001.02921, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2020-01-09", "authors": [{"authorId": "3229795", "name": "N. Dayama"}, {"authorId": "1817239", "name": "Kashyap Todi"}, {"authorId": "2196061541", "name": "Taru Saarelainen"}, {"authorId": "2663734", "name": "Antti Oulasvirta"}], "abstract": "Grid layouts are used by designers to spatially organise user interfaces when sketching and wireframing. However, their design is largely time consuming manual work. This is challenging due to combinatorial explosion and complex objectives, such as alignment, balance, and expectations regarding positions. This paper proposes a novel optimisation approach for the generation of diverse grid-based layouts. Our mixed integer linear programming (MILP) model offers a rigorous yet efficient method for grid generation that ensures packing, alignment, grouping, and preferential positioning of elements. Further, we present techniques for interactive diversification, enhancement, and completion of grid layouts. These capabilities are demonstrated using GRIDS, a wireframing tool that provides designers with real-time layout suggestions. We report findings from a ratings study (N = 13) and a design study (N = 16), lending evidence for the benefit of computational grid generation during early stages of design.", "corpusId": "210116844", "paragraphs": [{"paragraphId": "35252", "title": "GRIDS: Interactive Layout Design with Integer Programming", "sectionTitle": "INTRODUCTION", "text": "Computational generation of grid layouts has the potential to support designers in the creative process of layout design, helping them synthesise, envision, and evaluate [49]. Access to diverse but relevant computationally generated suggestions could help them in exploring and enhancing designs [55], thus avoiding too early fixation [9]. Moreover, need for manual editing could be reduced if computer-generated designs were able to suggest completions to partially finalised designs. However, the algorithmic problems involved are non-trivial. Any such method must efficiently search within a very vast design space while reacting to real-time changes made by the designer. Prior to this work, it has not been known how to best define core features of a good grid layout. The more design objectives and concerns one can incorporate into the mathematical system, the less final editing is left to the designer. However, it is not known how to combine objectives that together ensure performant and aesthetically pleasing layouts. Elements must be well-aligned, key elements easily reachable, related elements logically grouped together, and so on.", "spans": "[{\"corpusId\": 88500863, \"span\": \"[49]\", \"start\": 170, \"end\": 174}, {\"corpusId\": 14533669, \"span\": \"[55]\", \"start\": 296, \"end\": 300}, {\"corpusId\": 934711, \"span\": \"[9]\", \"start\": 335, \"end\": 338}, {\"corpusId\": 210116844, \"span\": \"this work\", \"start\": 694, \"end\": 694}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "35253", "title": "GRIDS: Interactive Layout Design with Integer Programming", "sectionTitle": "INTRODUCTION", "text": "Our MILP model guarantees proper packing: all elements fit on the canvas without overflowing or overlapping. In a single model, it further addresses other design goals such as: (1) the outer hull is rectangular, (2) there are no holes, (3) elements are well-aligned [43], (4) related elements are grouped together, and (5) preferred positions are obeyed to provide visual connectivity [4]. Prior works on computational grid generation [3,52] have mostly addressed one or few of these key properties at a time. As IP provides bounds for its solutions, designs can be guaranteed to be within specified range (say within 5%) from the best achievable design. We exploit this for generation of controllably diverse designs.", "spans": "[{\"corpusId\": 6972459, \"span\": \"(2)\", \"start\": 212, \"end\": 215}, {\"corpusId\": 7564889, \"span\": \"[4]\", \"start\": 385, \"end\": 388}, {\"corpusId\": 13507096, \"span\": \"[3,\", \"start\": 435, \"end\": 438}, {\"corpusId\": 15830633, \"span\": \"52]\", \"start\": 438, \"end\": 441}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "35254", "title": "GRIDS: Interactive Layout Design with Integer Programming", "sectionTitle": "INTRODUCTION", "text": "To sum up, the key contributions of this paper are: 1. A fast and comprehensive mixed-integer linear programming (MILP) model for grid layout generation. 2. Further computations for diversification, intensification, and completion of partial solutions. 3. Demonstration of interactive grid generation in the GRIDS tool, and evaluation with 16 professional designers. guide grid positioning [18]. A method for global beautification has been presented that infers relationships between layout elements, and fixing issues such as misalignment [59]. Users can interactively refine the layout by resolving ambiguity and adding constraints. While these techniques assist with grid design and alignment, layout construction is left to the designer. Design tools also often offer grid templates: predefined layouts where content can be added [15]. However, templates insist that contents are made to fit them, and they are limited to a small set of pre-defined layouts.", "spans": "[{\"corpusId\": 210116844, \"span\": \"this paper\", \"start\": 46, \"end\": 46}, {\"corpusId\": 16436248, \"span\": \"[18]\", \"start\": 390, \"end\": 394}, {\"corpusId\": 13221673, \"span\": \"[59]\", \"start\": 540, \"end\": 544}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "35255", "title": "GRIDS: Interactive Layout Design with Integer Programming", "sectionTitle": "Grid generation by constraint solving", "text": "Since its first introduction in Sketchpad [53], constraints that can aid in the design of layouts has been a topic of research [7,26,31,46]. Layout constraints can define bounds on elements, or relationship between elements. A constraint solver manipulates element properties to best satisfy the specified constraints. One method is to solve layout constraints incrementally [17]. It can satisfy changing constraint hierarchies consisting of hard and soft constraints in an efficient manner. Relational grammars can be further added to encode design knowledge [57]. This can address the logical composition of elements during layout generation. Chorus [28] addressed non-linear geometric constraints such as Euclidean geometric, non-overlapping, and graph layout constraints. It also discussed soft constraints with hierarchical strengths or preferences. Cassowary [1] implemented a linear arithmetic constraint solver to adapt layout to changing sizes. This has also been implemented in some commercial systems such as Apple's Auto Layout 2 , enabling GUIs to dynamically adjust their layouts when window or screen dimensions changed. A benefit of constraint solving is that a layout can be defined by means of simple constraints. On the other hand, specifying a layout fully using just constraints quickly becomes complex [61]. To our knowledge, no constraints-based method has been proposed that ensures proper packing of elements and takes care of objectives like alignment, rectangularity, and grouping. Lacking this, designers may need to modify layouts manually or fix remaining aspects programmatically.", "spans": "[{\"corpusId\": 3191926, \"span\": \"[53]\", \"start\": 42, \"end\": 46}, {\"corpusId\": 2350651, \"span\": \"[7,\", \"start\": 127, \"end\": 130}, {\"corpusId\": 6993990, \"span\": \"26,\", \"start\": 130, \"end\": 133}, {\"corpusId\": 16400135, \"span\": \"31,\", \"start\": 133, \"end\": 136}, {\"corpusId\": 8752821, \"span\": \"46]\", \"start\": 136, \"end\": 139}, {\"corpusId\": 16074031, \"span\": \"[17]\", \"start\": 375, \"end\": 379}, {\"corpusId\": 5976097, \"span\": \"[57]\", \"start\": 560, \"end\": 564}, {\"corpusId\": 15234682, \"span\": \"[28]\", \"start\": 652, \"end\": 656}, {\"corpusId\": 8021162, \"span\": \"[1]\", \"start\": 865, \"end\": 868}, {\"corpusId\": 18618271, \"span\": \"[61]\", \"start\": 1324, \"end\": 1328}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 10}, {"paragraphId": "35256", "title": "GRIDS: Interactive Layout Design with Integer Programming", "sectionTitle": "Grid generation by combinatorial optimisation", "text": "Combinatorial optimisation methods can find solutions, from a large design space, that satisfy a stated design objectives. Within the area of combinatorial geometry, grid layout has been studied in the context of 2D bin packing [37,42,50], rectangular packing [27], and the guillotine cuts problem [11]. An elementary version of the grid design problem has been previously proposed [27], but it merely attempts to find the most densely packed solution whereby the elements are squeezed together as closely as possible; there is no attempt to address aesthetics (like alignment) and no intent to explore multiple layouts. Optimisation has been used for resizing GUI elements [60], with the focus being on improving aesthetics of a layout by making subtle changes when the available space is varied. Previous research has also looked into generating optimised grid-based layouts. AIDE is a metrics-based tool to aid design and evaluation of UIs [52]. It included objectives such as balance, efficiency, and constraints. The optimiser computed a layout grid and used this to organise widgets. ADL is a layout engine that dynamically constructed grid layouts [3]. Given static elements, it filled up the remaining area with dynamic content . Typically, these approaches compute a single point-optimal solution. Following earlier findings, we believe it is necessary to present designers with a diverse range of solutions [2,55]. However, random-search based optimisation methods do not support generation of controllably diverse results. IP-based approaches have been previously used to generate, for example, keyboard layouts [32]. This allows for a structured search process and guaranteed bounds, thus improving outcomes and increasing designer confidence. More recently, AdaM employed IP to distribute UIs in multi-user environments [48]. While the formulation does address limited display size, the objectives, constraints, and applications differ substantially from ours.", "spans": "[{\"corpusId\": 3240079, \"span\": \"[37,\", \"start\": 228, \"end\": 232}, {\"corpusId\": 45029412, \"span\": \"50]\", \"start\": 235, \"end\": 238}, {\"corpusId\": 121847500, \"span\": \"[27]\", \"start\": 260, \"end\": 264}, {\"corpusId\": 123454080, \"span\": \"[11]\", \"start\": 298, \"end\": 302}, {\"corpusId\": 121847500, \"span\": \"[27]\", \"start\": 382, \"end\": 386}, {\"corpusId\": 10837759, \"span\": \"[60]\", \"start\": 674, \"end\": 678}, {\"corpusId\": 15830633, \"span\": \"[52]\", \"start\": 943, \"end\": 947}, {\"corpusId\": 13507096, \"span\": \"[3]\", \"start\": 1155, \"end\": 1158}, {\"corpusId\": 6972459, \"span\": \"[2,\", \"start\": 1417, \"end\": 1420}, {\"corpusId\": 14533669, \"span\": \"55]\", \"start\": 1420, \"end\": 1423}, {\"corpusId\": 13897068, \"span\": \"[32]\", \"start\": 1623, \"end\": 1627}, {\"corpusId\": 4565112, \"span\": \"[48]\", \"start\": 1833, \"end\": 1837}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 11}, {"paragraphId": "35257", "title": "GRIDS: Interactive Layout Design with Integer Programming", "sectionTitle": "Grid generation by combinatorial optimisation", "text": "SUPPLE and ARNAULD constitute the seminal literature concerning personalised UI generation [19][20][21][23][24][25]. The systems automatically generate interfaces through a branchand-bound optimisation technique that is flexible enough to adapt to various objectives by modifying the underlying cost function. Our work differs from this line of work in three key aspects: (1) Input: SUPPLE and its descendants require functional specifications as input. This is beneficial for application developers as they only need to specify what functions are exposed to users. On the contrary, our work targets UI designers who already have some ideas about desired layouts. It enables designers to define the design task by demonstration, including element types, and preferences regarding size and placement. (2) Layouting: When rendering an interface layout, SUPPLE used three heuristics to sequentially decide the layout -bottom-up, top-down, and minimum remaining values [22]. The key objective was to find a layout that satisfies user preferences, abilities, and device constraints. In contrast, our MILP formulation aims at constructing well-formed grid layouts, with desirable aesthetics, by considering the entire composition of the canvas. (3) Output: SUPPLE and others aim at producing a single point-optimal design for end-users. In contrast, our MILP approach generates multiple diverse solutions for mixed-initiative design tools.", "spans": "[{\"corpusId\": 18701632, \"span\": \"[19]\", \"start\": 91, \"end\": 95}, {\"corpusId\": 2533528, \"span\": \"[20]\", \"start\": 95, \"end\": 99}, {\"corpusId\": 947185, \"span\": \"[21]\", \"start\": 99, \"end\": 103}, {\"corpusId\": 86708, \"span\": \"[23]\", \"start\": 103, \"end\": 107}, {\"corpusId\": 8690253, \"span\": \"[24]\", \"start\": 107, \"end\": 111}, {\"corpusId\": 3386421, \"span\": \"[25]\", \"start\": 111, \"end\": 115}, {\"corpusId\": 210116844, \"span\": \"Our work\", \"start\": 318, \"end\": 318}, {\"corpusId\": 210116844, \"span\": \"our work\", \"start\": 591, \"end\": 591}, {\"corpusId\": 210116844, \"span\": \"our MILP approach\", \"start\": 1361, \"end\": 1361}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "35258", "title": "GRIDS: Interactive Layout Design with Integer Programming", "sectionTitle": "Interactive layout generation", "text": "Computational techniques have been proposed for designing layouts with designer in the loop. DesignScape [45] supports enhancement and exploration of single-page layouts using energy-based optimisation. The design principles here are limited to those learnt from a small set of examples, and optimisation is computationally-expensive. Sketchplorer [55] supports exploring, enhancing, and recolouring layouts. However, it employs black-box optimisation on a discrete canvas, which does not scale, resulting in poor performance for complex design tasks. Moreover, it does not address objectives of good grid layouts, such as rectangularity, alignment, or preferential placement. Genetic algorithms have been used to iteratively select promising interfaces from a collection of candidates [16]. Various constraints had to be placed to prevent inappropriate groupings in the layout, and to reduce the number of selections. Data-driven approaches enable layout generation without requiring problem specification [36,62]. However, results are limited to the domain of the training dataset, and offer no quality guarantees. In what comes close to our aims, a semi-automatic grid-based technique has been previously proposed [29]. Here, users constructed an example layout, which, as in this paper, was represented as an algorithmic task to generate layouts of any size. New examples were presented to the user, enabling them to steer the generation.", "spans": "[{\"corpusId\": 1005189, \"span\": \"[45]\", \"start\": 105, \"end\": 109}, {\"corpusId\": 14533669, \"span\": \"[55]\", \"start\": 348, \"end\": 352}, {\"corpusId\": 17558122, \"span\": \"[16]\", \"start\": 786, \"end\": 790}, {\"corpusId\": 58981508, \"span\": \"[36,\", \"start\": 1007, \"end\": 1011}, {\"corpusId\": 196834740, \"span\": \"62]\", \"start\": 1011, \"end\": 1014}, {\"corpusId\": 14311380, \"span\": \"[29]\", \"start\": 1217, \"end\": 1221}, {\"corpusId\": 210116844, \"span\": \"this paper\", \"start\": 1289, \"end\": 1289}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 7}], "paragraphCount": 7}
{"paperId": "d1caa02943506bd9be682c4abd5e540388d69e23", "title": "Effectiveness of Conflict Management Strategies in Peer Review Process of Online Collaboration Projects", "venue": "Conference on Computer Supported Cooperative Work", "year": 2016, "citationCount": 33, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/2818048.2819950?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2818048.2819950, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science", "Psychology"], "publicationTypes": ["JournalArticle", "Book", "Conference", "Review"], "publicationDate": "2016-02-27", "authors": [{"authorId": "2158105870", "name": "Wenjian Huang"}, {"authorId": "1711569", "name": "T. Lu"}, {"authorId": "1742431", "name": "Haiyi Zhu"}, {"authorId": "2116730766", "name": "Guo Li"}, {"authorId": "39341617", "name": "Ning Gu"}], "abstract": null, "corpusId": "14366707", "paragraphs": [{"paragraphId": "24470", "title": "Effectiveness of Conflict Management Strategies in Peer Review Process of Online Collaboration Projects", "sectionTitle": "INTRODUCTION", "text": "Online open collaboration projects rely on large groups of volunteer contributors to collectively produce important artifacts or services. Peer review is an important mechanism to ensure quality of the products [33]. Because of the large variance in background, viewpoints and experience among contributors, conflicts often arise in the peer review process, specifically as disagreements over whether a particular contribution should be accepted [42]. For example, Joode et al. found that both task conflict and affective conflict can occur in open source communities, especially when a contributor's software patch was unjustly rejected [41].", "spans": "[{\"corpusId\": 26259347, \"span\": \"[33]\", \"start\": 211, \"end\": 215}, {\"corpusId\": 901326, \"span\": \"[42]\", \"start\": 446, \"end\": 450}, {\"corpusId\": 10438547, \"span\": \"[41]\", \"start\": 638, \"end\": 642}]", "conference": "cscw", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "24471", "title": "Effectiveness of Conflict Management Strategies in Peer Review Process of Online Collaboration Projects", "sectionTitle": "INTRODUCTION", "text": "Conflicts generally have negative effects on group loyalty, work productivity, and job satisfaction [10,19,21]. Although prior CSCW research has identified the potential detrimental effect of conflicts on the continuous success of online collaboration projects [15,24,25], very few of them have studied how to manage the conflicts and disagreement appropriately.", "spans": "[{\"corpusId\": 143677109, \"span\": \"[10,\", \"start\": 100, \"end\": 104}, {\"corpusId\": 144143372, \"span\": \"19,\", \"start\": 104, \"end\": 107}, {\"corpusId\": 147089809, \"span\": \"21]\", \"start\": 107, \"end\": 110}, {\"corpusId\": 18368924, \"span\": \"[15,\", \"start\": 261, \"end\": 265}, {\"corpusId\": 2546455, \"span\": \"24,\", \"start\": 265, \"end\": 268}, {\"corpusId\": 17493296, \"span\": \"25]\", \"start\": 268, \"end\": 271}]", "conference": "cscw", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 6}, {"paragraphId": "24472", "title": "Effectiveness of Conflict Management Strategies in Peer Review Process of Online Collaboration Projects", "sectionTitle": "INTRODUCTION", "text": "Research in traditional organization settings proposed a number of conflict management strategies that could serve to minimize the negative consequences of conflict [4,5]. For example, Blake and Mouton proposed five methods to handle conflicts: forcing, withdrawing, smoothing, compromising, and problem solving [7]. Rahim and Bonoma also summarized five styles of handling conflict (i.e., integrating, obliging, dominating, avoiding and compromising) and the situations in which these are appropriate [31]. However, it remains unknown whether these strategies will be effective in an online context.", "spans": "[{\"corpusId\": 55296301, \"span\": \"[4,\", \"start\": 165, \"end\": 168}, {\"corpusId\": 143409114, \"span\": \"5]\", \"start\": 168, \"end\": 170}, {\"corpusId\": 14366707, \"span\": \"proposed five method\", \"start\": 222, \"end\": 222}, {\"corpusId\": 145350655, \"span\": \"[31]\", \"start\": 502, \"end\": 506}]", "conference": "cscw", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "24473", "title": "Effectiveness of Conflict Management Strategies in Peer Review Process of Online Collaboration Projects", "sectionTitle": "Conflicts in Offline Settings", "text": "Conflicts are common in people's everyday life. Rahim described conflict as \"an interactive process manifested in incompatibility, disagreement, or dissonance within or between social entities (i.e., individual, group, organization)\" [4]. Early research on conflict concentrated on situations in which members have opposing goals and assumed a basic conflict of goals within the group [10,39]. Later studies suggested though that people may have conflicts even when they generally agree on goals and conflict may develop from people's attempts to cooperate or coordinate their efforts [22].", "spans": "[{\"corpusId\": 55296301, \"span\": \"[4]\", \"start\": 234, \"end\": 237}, {\"corpusId\": 143677109, \"span\": \"[10,\", \"start\": 385, \"end\": 389}, {\"corpusId\": 144833814, \"span\": \"39]\", \"start\": 389, \"end\": 392}, {\"corpusId\": 144798128, \"span\": \"[22]\", \"start\": 585, \"end\": 589}]", "conference": "cscw", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "24474", "title": "Effectiveness of Conflict Management Strategies in Peer Review Process of Online Collaboration Projects", "sectionTitle": "Conflicts in Peer Review of Online Collaboration Project", "text": "Conflicts occur frequently in online collaboration settings due to a lack of shared context, limited information sharing channels, and weak interpersonal bonds between members [20]. Conflicts are especially common in the peer review process, in which people decide whether one's contributions should be accepted or not [42]. There are different forms of peer review in different online collaboration settings. In many software development projects, there is a formal peer review system where contributors propose code changes (e.g., pull-requests in GitHub) and reviewers decide whether the contribution should be accepted or not [40]. In Wikipedia, both formal peer review and informal peer review exists. For instance, featured articles (FA) are determined by a formal peer review process where group of editors decide whether candidate articles should be promoted to FA or not [1]. Additionally, any edit on Wikipedia articles could be viewed as being informally \"peer reviewed\" [37]. On most unprotected pages, any editors can \"review\" others' edits. If they don't like the edits, they can reject them by reverting or overwriting on them. In this paper, we focus on formal peer review systems where there are explicit roles like reviewers and submitters (which we refer as contributors in the following sections), and dedicated places to submit the review, discuss the review decision. Particularly, we examine what happens when the submitter openly disagrees with the reviewers (i.e., conflicts occur).", "spans": "[{\"corpusId\": 15916674, \"span\": \"[20]\", \"start\": 176, \"end\": 180}, {\"corpusId\": 901326, \"span\": \"[42]\", \"start\": 319, \"end\": 323}, {\"corpusId\": 2739257, \"span\": \"[40]\", \"start\": 630, \"end\": 634}, {\"corpusId\": 10156153, \"span\": \"[37]\", \"start\": 982, \"end\": 986}, {\"corpusId\": 14366707, \"span\": \"this paper\", \"start\": 1156, \"end\": 1156}]", "conference": "cscw", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "24475", "title": "Effectiveness of Conflict Management Strategies in Peer Review Process of Online Collaboration Projects", "sectionTitle": "Effects on Contributors' Continuous Participation", "text": "Researchers have found conflicts generally have negative effects on group loyalty, workgroup productivity, and job satisfaction [10,19,21]. For instance, Deutsch found that conflicts decrease goodwill and mutual understanding, which hinders the completion of organizational tasks [13]. Haq also suggested that conflict may increase employees' stress in workplace and lead to deviant behavior [19].", "spans": "[{\"corpusId\": 143677109, \"span\": \"[10,\", \"start\": 128, \"end\": 132}, {\"corpusId\": 144143372, \"span\": \"19,\", \"start\": 132, \"end\": 135}, {\"corpusId\": 147089809, \"span\": \"21]\", \"start\": 135, \"end\": 138}, {\"corpusId\": 110121181, \"span\": \"[13]\", \"start\": 280, \"end\": 284}, {\"corpusId\": 144143372, \"span\": \"[19]\", \"start\": 392, \"end\": 396}]", "conference": "cscw", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "24476", "title": "Effectiveness of Conflict Management Strategies in Peer Review Process of Online Collaboration Projects", "sectionTitle": "Effects on Contributors' Continuous Participation", "text": "In the context of online collaborations, conflicts might cause contributors to feel that their individual goals no longer match the community goals and thus choose to leave the project. Furthermore, conflicts originally concerning the task itself can evolve into interpersonal or affective conflicts [6,15]. This can lead to negative emotions such as feelings of disappointment, frustration, annoyance and anger, which also cause contributors to leave the community. Unlike traditional organizations, contributors of online collaboration projects have no formal employment or membership contacts with the community, so they can easily leave the communities with few social or economic consequences. Based on the above reasoning, we propose our first hypothesis: H1: Contributors who have conflicts with other members in the community are more likely to leave the community than those who don't have conflicts with other members.", "spans": "[{\"corpusId\": 33255772, \"span\": \"[6,\", \"start\": 300, \"end\": 303}, {\"corpusId\": 18368924, \"span\": \"15]\", \"start\": 303, \"end\": 306}, {\"corpusId\": 14366707, \"span\": \"we propose\", \"start\": 739, \"end\": 739}]", "conference": "cscw", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "24477", "title": "Effectiveness of Conflict Management Strategies in Peer Review Process of Online Collaboration Projects", "sectionTitle": "Conflict Manager's Administrative Role", "text": "Compared to regular members, administrators are more familiar with the projects, and usually hold higher authority and expertise in the community [29]. Prior research shows that administrators are generally more powerful in influencing and motivating others' activities [9]. For instance, Zhu et al. found that, in Wikipedia, the legitimate leaders were more influential in rewarding, regulating, directing and socializing other members compared to regular members [8]. Thus, the administrator's conflictmanagement behavior might also be more powerful than regular members. Therefore, we propose the following hypothesis:", "spans": "[{\"corpusId\": 16830574, \"span\": \"[29]\", \"start\": 146, \"end\": 150}, {\"corpusId\": 18269933, \"span\": \"[9]\", \"start\": 270, \"end\": 273}, {\"corpusId\": 17972477, \"span\": \"[8]\", \"start\": 465, \"end\": 468}, {\"corpusId\": 14366707, \"span\": \"we propose\", \"start\": 595, \"end\": 595}]", "conference": "cscw", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "24478", "title": "Effectiveness of Conflict Management Strategies in Peer Review Process of Online Collaboration Projects", "sectionTitle": "GITHUB AS A STUDY PLATFORM", "text": "We choose GitHub as our study platform. It is a wellknown online open collaboration platform [11], which is widely used to host open-source software projects. Through GitHub, a large number of developers can effectively collaborate to build open-source software. As of early 2015, GitHub has supported 9.1 million developers collaborating across 21.5 million code repositories [2]. GitHub has a peer review mechanism to ensure that any peer developers' code changes must be confirmed as valuable, secure and efficient before merging them into the code repositories. In this process, issues like competing technologies, incompatible software versions, and information overload can often cause conflicts [15]. Besides, most archival data of the hosted projects are publicly available through GitHub's official API [3]. Thus, GitHub is a suitable platform for our study.", "spans": "[{\"corpusId\": 14366707, \"span\": \"our study\", \"start\": 29, \"end\": 29}, {\"corpusId\": 16193315, \"span\": \"[11]\", \"start\": 93, \"end\": 97}, {\"corpusId\": 18368924, \"span\": \"[15]\", \"start\": 702, \"end\": 706}, {\"corpusId\": 14366707, \"span\": \"our study\", \"start\": 866, \"end\": 866}]", "conference": "cscw", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "24479", "title": "Effectiveness of Conflict Management Strategies in Peer Review Process of Online Collaboration Projects", "sectionTitle": "Practical Implications for Conflict Management", "text": "Although prior studies developed some conflict management procedures or policies (e.g., [12,24]), they rarely suggest which way to communicate with members in conflict is more effective. Our results show that, compared to giving explanations or social encouragement, providing concrete suggestions is the most effective way to manage conflict. Based on this finding, we suggest existing communities should educate members to try to understand the intent of the contributors and provide constructive suggestions when conflicts occur. The online collaboration systems should also support flexible interfaces for members to conveniently provide suggestions. In Wikipedia, newcomers' edits are often reverted without any further information. According to Halfaker's paper [17], this might be a cause of the slower growth of Wikipedia's editor base. They then proposed a tool to present newcomers' activity traces to Wikipedian mentors, and this information significantly helped mentors to provide more explanations about edit reverts [18]. However, our results suggest that tools should be designed to support not just providing explanations but also giving constructive suggestions for solving the problem in order to retain good-faith contributors.", "spans": "[{\"corpusId\": 34495662, \"span\": \"[12,\", \"start\": 88, \"end\": 92}, {\"corpusId\": 2546455, \"span\": \"24]\", \"start\": 92, \"end\": 95}, {\"corpusId\": 14366707, \"span\": \"Our results\", \"start\": 198, \"end\": 198}, {\"corpusId\": 14366707, \"span\": \"this finding\", \"start\": 365, \"end\": 365}, {\"corpusId\": 15971884, \"span\": \"[18]\", \"start\": 1030, \"end\": 1034}, {\"corpusId\": 14366707, \"span\": \"our results\", \"start\": 1056, \"end\": 1056}]", "conference": "cscw", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 10}
{"paperId": "8b4ad1d583fdb9e403d7bf63db284fdd329dade7", "title": "'It's Problematic but I'm not Concerned': University Perspectives on Account Sharing", "venue": "Proc. ACM Hum. Comput. Interact.", "year": 2022, "citationCount": 4, "openAccessPdf": {"url": "https://doi.org/10.1145/3512915", "status": "BRONZE", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3512915?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3512915, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2022-03-30", "authors": [{"authorId": "2116230614", "name": "Serena Wang"}, {"authorId": "3461834", "name": "Cori Faklaris"}, {"authorId": "1996696329", "name": "Junchao Lin"}, {"authorId": "1784365", "name": "Laura A. Dabbish"}, {"authorId": "2110688724", "name": "Jason I. Hong"}], "abstract": "Account sharing is a common, if officially unsanctioned, practice among workgroups, but so far understudied in higher education. We interview 23 workgroup members about their account sharing practices at a U.S. university. Our study is the first to explicitly compare IT and non-IT observations of account sharing as a \"normal and easy\" workgroup practice, as well as to compare student practices with those of full-time employees. We contrast our results with those in prior works and offer recommendations for security design and for IT messaging. Our findings that account sharing is perceived as low risk by our participants and that security is seen as secondary to other priorities offer insights into the gap between technical affordances and social needs in an academic workplace such as this.?", "corpusId": "245018542", "paragraphs": [{"paragraphId": "21759", "title": "'It's Problematic but I'm not Concerned': University Perspectives on Account Sharing ", "sectionTitle": "Init", "text": "devices permitted under Bring Your Own Device (BYOD) or Choose Your Own Device (CYOD) policies [69]. Despite IT accommodations like these, the gap between technical affordances and social needs [1] often forces workers who are security-conscious [2,31] to make compromises with official IT policies and procedures in order to get their jobs done [7]. One compromise is account sharing, in which more than one person uses the same username and password to access a work resource [57]. In fact, a recent survey of gig workers who also are employed in settings such as retail or shipping found that sharing accounts designed for individual use is now accepted as a \"norm\" [57].", "spans": "[{\"corpusId\": 2676709, \"span\": \"[1]\", \"start\": 194, \"end\": 197}, {\"corpusId\": 1883850, \"span\": \"[2,\", \"start\": 246, \"end\": 249}, {\"corpusId\": 16535981, \"span\": \"31]\", \"start\": 249, \"end\": 252}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "21760", "title": "'It's Problematic but I'm not Concerned': University Perspectives on Account Sharing ", "sectionTitle": "Init", "text": "However, one important work setting has so far been understudied: the research university. In 2018 in the U.S., about 6,000 postsecondary schools employed nearly 4 million [70] and served 16.6 million enrolled undergraduate students [71]. These are unlike other workplaces because of their mission of academic freedom -the freedom to teach, to learn, to publish, and to inquire [4,46,72]. Consequently, IT strategies for securing the information network-in-use [73] is likely to center on intrusion detection [30] and to not include top-down methods of controlling user behavior (such as social media use policies, internet firewalls, or monitoring for data loss prevention). Some institutions use a federated IT model, which allows for subunits of the university such as schools or departments to hire IT staff and operate their own systems to, in part, \"enable research, teaching and community service\" [74]. They will tolerate or encourage CYOD and self-management of IT for their workforce, which is a mix of traditional in-office employees and of remote and/or mobile workers such as \"digital nomads\" [16,29,40]. For non-IT users, this could result in \"shadow security,\" workarounds to official rules and setups that help employees manage the risks they understand while getting their jobs done [35]. Academic freedom complicates the implementation and communication of university IT policies [14,62,63] and has led to conflicts with copyright holders over campus use of peer-to-peer file sharing [51]. Table 1: In comparison with a typical large-scale non-academic business in the U.S., the university in our study has a federated IT model and, among student employees, high turnover and many part-time jobs.", "spans": "[{\"corpusId\": 56079770, \"span\": \"[4,\", \"start\": 378, \"end\": 381}, {\"corpusId\": 8499781, \"span\": \"[30]\", \"start\": 509, \"end\": 513}, {\"corpusId\": 9710752, \"span\": \"[16,\", \"start\": 1106, \"end\": 1110}, {\"corpusId\": 207953853, \"span\": \"40]\", \"start\": 1113, \"end\": 1116}, {\"corpusId\": 17635800, \"span\": \"[35]\", \"start\": 1300, \"end\": 1304}, {\"corpusId\": 5041135, \"span\": \"[14,\", \"start\": 1398, \"end\": 1402}, {\"corpusId\": 169863351, \"span\": \"62,\", \"start\": 1402, \"end\": 1405}, {\"corpusId\": 212932925, \"span\": \"63]\", \"start\": 1405, \"end\": 1408}, {\"corpusId\": 245018542, \"span\": \"our study\", \"start\": 1620, \"end\": 1620}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 9}, {"paragraphId": "21761", "title": "'It's Problematic but I'm not Concerned': University Perspectives on Account Sharing ", "sectionTitle": "Workplace Collaboration", "text": "Early work in CSCW and elsewhere often focused, either explicitly or implicitly, on large-scale enterprises as the site of collaboration. Allen and Cohen [3], Kraut [37,38], Fussell [20] and others documented the significance of physical proximity, finding that researchers co-located on the same floor were more likely to collaborate, and that informal contacts in hallways and elsewhere drove new ideas and helped them to stay aware of each other and to coordinate work. Malone and Crowston [44] looked to coordination theory to help conceptualize and identify how workplace collaboration occurs in practice, noting the interdependencies among activities and actors. Gutwin and Greenberg [22][23][24][25] and Carroll et al. [12] examined how notifications and other designs affect workgroups' awareness of shared activities. Forman [18] found that internet technology, despite being unevenly dispersed, helped to lower the costs of coordination among geographically dispersed workers and, with Zeebroeck [19], of collaborative research.", "spans": "[{\"corpusId\": 144307013, \"span\": \"[3]\", \"start\": 154, \"end\": 157}, {\"corpusId\": 3356174, \"span\": \"38]\", \"start\": 169, \"end\": 172}, {\"corpusId\": 26320514, \"span\": \"[22]\", \"start\": 690, \"end\": 694}, {\"corpusId\": 16356818, \"span\": \"[23]\", \"start\": 694, \"end\": 698}, {\"corpusId\": 8823328, \"span\": \"[24]\", \"start\": 698, \"end\": 702}, {\"corpusId\": 15595014, \"span\": \"[12]\", \"start\": 726, \"end\": 730}, {\"corpusId\": 2276212, \"span\": \"[18]\", \"start\": 834, \"end\": 838}, {\"corpusId\": 14998905, \"span\": \"[19]\", \"start\": 1006, \"end\": 1010}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 8}, {"paragraphId": "21762", "title": "'It's Problematic but I'm not Concerned': University Perspectives on Account Sharing ", "sectionTitle": "Workplace Collaboration", "text": "More recently, researchers have examined workplace collaboration in a wider variety of settings. Colbert et al. [13] noted that \"digital fluency\" (a level of proficiency with digital technology that allows someone to achieve strategic goals) is a core competency of the modern workforce, and that technology has blurred the lines between work and nonwork domains. Jarrahi [32], Hemsley [29], Lee [40], and others have documented the processes and communications of \"digital nomads\" -people who are geographically mobile and work remotely, and who have formed online communities to network and share information. Sutherland and Jarrahi note their similarity of digital nomads' knowledge networks and cobbled-together tech and social practices to those of gig workers for ride-sharing apps or odd-job marketplaces [59]. Sawyer [56], Erickson and Jarrahi [17] describe the layers of both technical and social knowledge that modern workers must draw on as \"infrastructural competence,\" a form of bricolage [43] in which people apply any resources at hand in their given work conditions or contexts toward the desired goals.", "spans": "[{\"corpusId\": 37359364, \"span\": \"[13]\", \"start\": 112, \"end\": 116}, {\"corpusId\": 86674412, \"span\": \"[32]\", \"start\": 372, \"end\": 376}, {\"corpusId\": 207953853, \"span\": \"[40]\", \"start\": 396, \"end\": 400}, {\"corpusId\": 31219084, \"span\": \"[59]\", \"start\": 812, \"end\": 816}, {\"corpusId\": 240588801, \"span\": \"[56]\", \"start\": 825, \"end\": 829}, {\"corpusId\": 16890686, \"span\": \"[17]\", \"start\": 852, \"end\": 856}, {\"corpusId\": 111016391, \"span\": \"[43]\", \"start\": 1002, \"end\": 1006}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "21763", "title": "'It's Problematic but I'm not Concerned': University Perspectives on Account Sharing ", "sectionTitle": "Logistical Needs.", "text": "Prior work has often focused on password workarounds in traditional office settings. Adams and Sasse [2] and Inglesant and Sasse [31] found that otherwise securityconscious users often had to work around password policies that were too stringent or inflexible for their needs. Bartsch and Sasse [7] found that enterprise users would use a different password to access job-critical information while waiting for access control changes to be processed. Blythe et al. [11] noted users sharing passwords to get jobs done and to more closely align electronic work processes with those in the physical world. Kaye [33] found that colleagues reported sharing passwords for commercial sites they order from, to avoid having to create individual accounts, and to get access to library materials. And in a 2019 CSCW paper, Song et al. [57] discovered account sharing to be a \"norm rather than a simple workaround,\" with workers motivated by a desire to centralize collective activity and to reduce effort in managing boundaries.", "spans": "[{\"corpusId\": 1883850, \"span\": \"[2]\", \"start\": 101, \"end\": 104}, {\"corpusId\": 16535981, \"span\": \"[31]\", \"start\": 129, \"end\": 133}, {\"corpusId\": 69897118, \"span\": \"[11]\", \"start\": 465, \"end\": 469}, {\"corpusId\": 39405995, \"span\": \"[33]\", \"start\": 608, \"end\": 612}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "21764", "title": "'It's Problematic but I'm not Concerned': University Perspectives on Account Sharing ", "sectionTitle": "Logistical Needs.", "text": "Another concept of note in this context is \"shadow security.\" Kirlappos, Parkin, and Sasse [35] defined this as a type of security, not visible to system administrators, in which employees create workarounds to official policies that retain some protections and enable them to get their jobs done. Kirlappos and Sasse [34,36] found that, while official security is rooted in trust between the administrators and employees, shadow security emerges from the trust relationships among employees themselves. Song et al. [57] alluded to shadow security as an example of workarounds and Ackerman's socio-technical gap [1] -the difference between technical affordances and social requirements that much CSCW research seeks to narrow.", "spans": "[{\"corpusId\": 17635800, \"span\": \"[35]\", \"start\": 91, \"end\": 95}, {\"corpusId\": 27132411, \"span\": \"[34,\", \"start\": 318, \"end\": 322}, {\"corpusId\": 2280193, \"span\": \"36]\", \"start\": 322, \"end\": 325}, {\"corpusId\": 2676709, \"span\": \"[1]\", \"start\": 612, \"end\": 615}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "21765", "title": "'It's Problematic but I'm not Concerned': University Perspectives on Account Sharing ", "sectionTitle": "Social Factors.", "text": "Kaye [33] found that users shared passwords for personal email, Facebook and work accounts with others who they trusted and shared responsibilities with, chiefly spouses, partners and colleagues. Lampinen [39] documented struggles with account sharing for multi-person households that offered to host visitors recruited through a website. Happ et al. [27] found that invoking a reciprocity social norm, through giving a small incentive, increased people's willingness to share passwords. Among studies of romantic partners sharing accounts [41,42,49], Park et al. found that romantic couples' motivations to share accounts were both logistical and emotional, but that some chose to hide accounts to hide other relationships, to avoid conflict, or because they saw the accounts as irrelevant to the relationship. Obada-Obieh et al. [48] found that ending account sharing posed numerous cognitive and psychosocial burdens, such as remembering whom the password had been shared with.", "spans": "[{\"corpusId\": 39405995, \"span\": \"[33]\", \"start\": 5, \"end\": 9}, {\"corpusId\": 20255816, \"span\": \"[39]\", \"start\": 205, \"end\": 209}, {\"corpusId\": 28283240, \"span\": \"[27]\", \"start\": 351, \"end\": 355}, {\"corpusId\": 233353906, \"span\": \"[41,\", \"start\": 540, \"end\": 544}, {\"corpusId\": 222805203, \"span\": \"42,\", \"start\": 544, \"end\": 547}, {\"corpusId\": 52052741, \"span\": \"49]\", \"start\": 547, \"end\": 550}, {\"corpusId\": 213197650, \"span\": \"[48]\", \"start\": 831, \"end\": 835}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "21766", "title": "'It's Problematic but I'm not Concerned': University Perspectives on Account Sharing ", "sectionTitle": "University Setting.", "text": "Some recent work has explicitly examined the usability of security in a university setting. Colnago et al. [14] documented the attitudes and behaviors surrounding twofactor authentication (2FA) as it was rolled out at a large research university. Regarding account sharing, the authors found that 2FA interfered with the ability of some students to share their financial accounts with parents, because the parents could only use the shared password at a time when the students were available to answer the 2FA push notification. They also found that some students were more concerned about a physical attack, such as someone getting into their computer if they walked away from it, than a remote and opportunistic attack. Around the same time, Weidman and Grossklags [62,63] sought and analyzed the information security policies of 200 top universities. They found that about half did not make their security policies publicly accessible, and that these policies were seldom consistent or shared source materials; moreover, the policies tended to be difficult to read, lacking in emotional language, and worded ambiguously and/or tentatively, such that the takeaways were unclear.", "spans": "[{\"corpusId\": 5041135, \"span\": \"[14]\", \"start\": 107, \"end\": 111}, {\"corpusId\": 169863351, \"span\": \"[62,\", \"start\": 767, \"end\": 771}, {\"corpusId\": 212932925, \"span\": \"63]\", \"start\": 771, \"end\": 774}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "21767", "title": "'It's Problematic but I'm not Concerned': University Perspectives on Account Sharing ", "sectionTitle": "University Setting.", "text": "With our study, we seek to add to knowledge of attitudes and behaviors in a university setting and to add insights that are not focused on 2FA use as with Colnago et al. [14] We document end users' awareness, motivation and knowledge of how to comply with their university's information security policies, adding a ground-level perspective to Weidman and Grossklags' review of such policies [63]. Our study contributes what appears to us as the first study of account sharing in a university setting.", "spans": "[{\"corpusId\": 245018542, \"span\": \"our study\", \"start\": 14, \"end\": 14}, {\"corpusId\": 5041135, \"span\": \"[14]\", \"start\": 170, \"end\": 174}, {\"corpusId\": 212932925, \"span\": \"[63]\", \"start\": 391, \"end\": 395}, {\"corpusId\": 245018542, \"span\": \"Our study\", \"start\": 406, \"end\": 406}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "21768", "title": "'It's Problematic but I'm not Concerned': University Perspectives on Account Sharing ", "sectionTitle": "Security Compliance Is Secondary to Other Priorities.", "text": "A primary reason why non-IT workers do not keep updated on cybersecurity practices is because it has little to do with their job and what they are getting paid to do. This was noted by both non-IT workers and by IT personnel. It echoes our anecdotal conversations with security professionals and prior published work [2,7,31] that users prioritize getting jobs done over security compliance, but also Colnago et al. [14], in which a university IT department implemented a solution for two-factor authentication that was only required for those on the payroll in order to limit who was inconvenienced.", "spans": "[{\"corpusId\": 1883850, \"span\": \"[2,\", \"start\": 317, \"end\": 320}, {\"corpusId\": 16535981, \"span\": \"31]\", \"start\": 322, \"end\": 325}, {\"corpusId\": 5041135, \"span\": \"[14]\", \"start\": 416, \"end\": 420}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "21769", "title": "'It's Problematic but I'm not Concerned': University Perspectives on Account Sharing ", "sectionTitle": "Evidence of Trust as a Social Norm (Trust in Colleagues and Trust in Authorities)", "text": "\"People in general tend to be very trusting. I can't even tell you how many people have volunteered to give me their [university] credentials because I work with them, and they like me and they trust me.\" [B19, IT, full time] \"I'm just a dummy to think [the University] keeps everything secure for me, but maybe they don't, I don't know.\" [B7, non-IT, full time] This trust in authorities is different from demonstrating trust in peers or near-peers [55,64] or evolving \"shadow security\" within a trusting environment [34][35][36]. The quotes point to this trust as a function of the paternalistic norms of educational enterprises in general, in which authorities such as IT or \"the system\" are assumed to provide care, protection and guidance [6,9]. In these cases, non-IT employees are relying on authorities rather than doing the work of the authorities.", "spans": "[{\"corpusId\": 14266943, \"span\": \"[55,\", \"start\": 450, \"end\": 454}, {\"corpusId\": 6923336, \"span\": \"64]\", \"start\": 454, \"end\": 457}, {\"corpusId\": 27132411, \"span\": \"[34]\", \"start\": 518, \"end\": 522}, {\"corpusId\": 17635800, \"span\": \"[35]\", \"start\": 522, \"end\": 526}, {\"corpusId\": 2280193, \"span\": \"[36]\", \"start\": 526, \"end\": 530}, {\"corpusId\": 154059859, \"span\": \"9]\", \"start\": 747, \"end\": 749}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "21770", "title": "'It's Problematic but I'm not Concerned': University Perspectives on Account Sharing ", "sectionTitle": "DISCUSSION", "text": "Our study of account sharing is the first to explicitly compare the perspectives of IT and non-IT employees and to shed light on the practices of student employees vs. full-time employees. We also add qualitative insights from this setting to complement recent survey studies of account sharing within social contexts and extend findings from older studies of account sharing to the age of widespread personal account use. We found, as prior work did, that users in this university community share accounts to streamline workflows [57] and to save money [11,57]. These findings seem to demonstrate similar \"shadow security\" practices through temporary access as described in Kirlappos and Sasse [34] (to streamline workflows) and in Bartsch and Sasse [7] (to save money). We summarize comparisons of our results with themes in five prior works that deal with account sharing in Section 5.1.", "spans": "[{\"corpusId\": 245018542, \"span\": \"Our study\", \"start\": 9, \"end\": 9}, {\"corpusId\": 69897118, \"span\": \"[11,\", \"start\": 554, \"end\": 558}, {\"corpusId\": 27132411, \"span\": \"[34]\", \"start\": 695, \"end\": 699}, {\"corpusId\": 245018542, \"span\": \"our results\", \"start\": 811, \"end\": 811}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "21771", "title": "'It's Problematic but I'm not Concerned': University Perspectives on Account Sharing ", "sectionTitle": "Comparisons and Contrasts with Prior Work on Account Sharing", "text": "When we compare our results with those in five prior works that deal with account sharing (Table  5), we find that our study's results differ most strongly for three themes: (1) that account sharing is motivated by the view that security is secondary to job duties; (2) that account sharing also is motivated by a perception that it is low risk; and (3) that account sharing differs by job categories (IT vs. non-IT, and student vs. full-time). Table 5: We summarize the similarities and disconnects with five prior works on account sharing (Song et al. [57], Park et al. [49], Bartsch and Sasse [7], Kaye [33], and Weirich et al. [64]). Our comparisons of account sharing by job categories is the most novel, followed by our findings that university participants see account sharing as low risk, and that they see security as secondary to job duties. Saving money \"Saving money on shared resources\" is a priority among coworkers in Song et al.", "spans": "[{\"corpusId\": 245018542, \"span\": \"our results\", \"start\": 27, \"end\": 27}, {\"corpusId\": 245018542, \"span\": \"our study\", \"start\": 124, \"end\": 124}, {\"corpusId\": 52052741, \"span\": \"[49]\", \"start\": 572, \"end\": 576}, {\"corpusId\": 39405995, \"span\": \"[33]\", \"start\": 606, \"end\": 610}, {\"corpusId\": 6923336, \"span\": \"[64]\", \"start\": 631, \"end\": 635}, {\"corpusId\": 245018542, \"span\": \"our findings\", \"start\": 734, \"end\": 734}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "21772", "title": "'It's Problematic but I'm not Concerned': University Perspectives on Account Sharing ", "sectionTitle": "Implications for Security", "text": "To address the overall low priority of security compared with academic core mission, we suggest implementing a cybersecurity buddy program. Such programs pair a security employee with a workgroup [5,84] to regularly take part in group meetings and to offer a direct line for guidance and troubleshooting. Anecdotally, we know of such \"buddies\" setting up office hours or sitting with their assigned workgroup for one or more days per week. This method of supplementing \"self-serve\" online guidance and the on-demand help desk could help to prevent unintentional insider threat (UIT) [21] resulting from insecure practices, while not imposing more burdens on academic employees. It also could provide an emotional bond with an IT professional that reframes their role to be of a peer rather than an authority figure. This approach seems like the best alternative to implementing a more-controlled, top-down approach to security, which is not likely to be accepted or adopted in this environment due to the culture of academic freedom.", "spans": "[{\"corpusId\": 15221911, \"span\": \"[5,\", \"start\": 196, \"end\": 199}, {\"corpusId\": 245018542, \"span\": \"This method\", \"start\": 451, \"end\": 451}, {\"corpusId\": 15493684, \"span\": \"[21]\", \"start\": 583, \"end\": 587}, {\"corpusId\": 245018542, \"span\": \"This approach\", \"start\": 829, \"end\": 829}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "21773", "title": "'It's Problematic but I'm not Concerned': University Perspectives on Account Sharing ", "sectionTitle": "Social Norms and Threat Modeling.", "text": "We suspect the discrepancies in findings of risk perception are driven partly by differences in security cultures for the university in our study vs. the organizations in prior studies. Indeed, we found that account sharing here was evidence of trust as a social norm, of two different types: trust in colleagues, and trust in authorities (university participants' quotes regarding trust in IT or \"the system\"). The latter type of trust seems an extension of the paternalistic norms of educational enterprises, in which authorities are assumed to provide a level of care, protection and guidance akin to that of a parent [6,9]. Only the former type seems similar to themes of \"demonstrating trust\" in prior works about account sharing, because those data appeared to involve others who were peers or near-peers in a social unit. Peers at work differ from authorities in that their interactions involve social pressures and mutual monitoring in pursuit of common or overlapping productivity goals [45].", "spans": "[{\"corpusId\": 245018542, \"span\": \"our study\", \"start\": 145, \"end\": 145}, {\"corpusId\": 154059859, \"span\": \"9]\", \"start\": 624, \"end\": 626}, {\"corpusId\": 1248423, \"span\": \"[45]\", \"start\": 996, \"end\": 1000}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "21774", "title": "'It's Problematic but I'm not Concerned': University Perspectives on Account Sharing ", "sectionTitle": "Disconnects Between IT Messaging and Non-IT Workgroups.", "text": "Few non-IT university workers in our study were consciously aware of policies and trainings for account sharing limits and procedures, and many said they are not easily accessible or comprehensible, echoing Weidman and Grossklags' findings [55,56]. The picture that emerges from our interview data ( Figure 1) contradicts our expectation that cybersecurity policies and procedures also would impact workgroups from a university IT and from personal level. In fact, many non-IT participants hold higher standards for their personal accounts versus their shared work accounts, since they feel that their work accounts do not contain financial or confidential data that are of interest to attackers. While their individual accounts may be of low interest, the network that the accounts are connected to is of high interest to attackers; a research university such as this controls hundreds of millions of dollars in financial assets and a substantial amount of sensitive data and intellectual property. Figure 1: A diagram of (above) the expectation that university messaging on cybersecurity will directly reach workgroups, and those workgroups and personal behaviors will reinforce each other; (below) the reality that emerges from our interview data is of disconnection. Our participants indicated that university policies are unknown to workgroups and strong personal practices do not permeate through the workgroup. The main influencer is what the workgroup as a collective decides upon.", "spans": "[{\"corpusId\": 245018542, \"span\": \"our study\", \"start\": 42, \"end\": 42}, {\"corpusId\": 14266943, \"span\": \"[55,\", \"start\": 240, \"end\": 244}, {\"corpusId\": 240588801, \"span\": \"56]\", \"start\": 244, \"end\": 247}, {\"corpusId\": 245018542, \"span\": \"our interview\", \"start\": 292, \"end\": 292}, {\"corpusId\": 245018542, \"span\": \"our interview\", \"start\": 1244, \"end\": 1244}, {\"corpusId\": 245018542, \"span\": \"Our participants\", \"start\": 1287, \"end\": 1287}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 16}
{"paperId": "f6bab2ae3bb22d6b91f76d819ac514eb638213e2", "title": "AMR Parsing with an Incremental Joint Model", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2016, "citationCount": 49, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/D16-1065.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://aclanthology.org/D16-1065, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2016-11-01", "authors": [{"authorId": null, "name": "Junsheng Zhou"}, {"authorId": "2724114", "name": "Feiyu Xu"}, {"authorId": "1781790", "name": "H. Uszkoreit"}, {"authorId": "2901365", "name": "Weiguang Qu"}, {"authorId": "2116278251", "name": "Ran Li"}, {"authorId": "2168143", "name": "Yanhui Gu"}], "abstract": "To alleviate the error propagation in the traditional pipelined models for Abstract Meaning Representation (AMR) parsing, we formulate AMR parsing as a joint task that performs the two subtasks: concept identi\ufb01cation and relation identi\ufb01cation simultaneously. To this end, we \ufb01rst develop a novel component-wise beam search algorithm for relation iden-ti\ufb01cation in an incremental fashion, and then incorporate the decoder into a uni\ufb01ed framework based on multiple-beam search, which allows for the bi-directional information \ufb02ow between the two subtasks in a single incremental model. Experiments on the public datasets demonstrate that our joint model sig-ni\ufb01cantly outperforms the previous pipelined counterparts, and also achieves better or comparable performance than other approaches to AMR parsing, without utilizing external semantic resources.", "corpusId": "5262888", "paragraphs": [{"paragraphId": "14842", "title": "AMR Parsing with an Incremental Joint Model", "sectionTitle": "Introduction", "text": "Producing semantic representations of text is motivated not only by theoretical considerations but also by the hypothesis that semantics can be used to improve many natural language tasks such as question answering, textual entailment and machine translation. Banarescu et al. (2013) described a semantics bank of English sentences paired with their logical meanings, written in Abstract Meaning Representation (AMR), which is rapidly emerging as an important practical form of structured sentence semantics. Recently, some literatures reported some promising applications of AMR. Pan et al. (2015) presented an unsupervised entity linking system with AMR, achieving the performance comparable to the supervised state-of-the-art. Liu et al. (2015) demonstrated a novel abstractive summarization framework driven by the AMR graph that shows promising results. Garg et al. (2016) showed that AMR can significantly improve the accuracy of a biomolecular interaction extraction system compared to only using surface-and syntax-based features. Mitra and Baral (2016) presented a question-answering system by exploiting the AMR representation, obtaining good performance.", "spans": "[{\"corpusId\": 7771402, \"span\": \"Banarescu et al. (2013)\", \"start\": 260, \"end\": 283}, {\"corpusId\": 11275066, \"span\": \"Pan et al. (2015)\", \"start\": 581, \"end\": 598}, {\"corpusId\": 5001921, \"span\": \"Liu et al. (2015)\", \"start\": 730, \"end\": 747}, {\"corpusId\": 2493954, \"span\": \"Garg et al. (2016)\", \"start\": 859, \"end\": 877}, {\"corpusId\": 12576714, \"span\": \"Mitra and Baral (2016)\", \"start\": 1039, \"end\": 1061}]", "conference": "emnlp", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "14843", "title": "AMR Parsing with an Incremental Joint Model", "sectionTitle": "Introduction", "text": "As a common drawback of the staged architecture, errors in upstream component are often compounded and propagated to the downstream prediction. The downstream components, however, cannot impact earlier decision. For example, for the verb \"affect\" in the example shown in Figure 1, there exist two possible concepts: \"affect-01\" and \"affect-02\". Comparatively, the first concept has more common use cases than the second one. But, when the verb \"affect\" is followed by the noun \"ac-cent\", it should evoke the concept \"affect-02\". Obviously, the correct concept choice for the verb \"affect\" should exploit a larger context, and even the whole semantic structure of the sentence, which is more probable to be unfolded at the downstream relation identification stage. This example indicates that it is necessary to allow for the interaction of information between the two stages. To address this problem, in this paper we reformulate this task as a joint parsing problem by exploiting an incremental parsing model. The underlying learning algorithm has shown the effectiveness on some other Natural Language Processing (NLP) tasks, such as dependency parsing and extraction of entity mentions and relations (Collins and Roark, 2004;Hatori et al., 2012;Li and Ji, 2014). However, compared to these NLP tasks, the AMR parsing is more challenging in that the AMR graph is more complicated. In addition, the nodes in the graph are latent.", "spans": "[{\"corpusId\": 5262888, \"span\": \"this paper\", \"start\": 914, \"end\": 914}, {\"corpusId\": 10366378, \"span\": \"(Collins and Roark, 2004;\", \"start\": 1203, \"end\": 1228}, {\"corpusId\": 10011032, \"span\": \"Hatori et al., 2012;\", \"start\": 1228, \"end\": 1248}, {\"corpusId\": 20744, \"span\": \"Li and Ji, 2014)\", \"start\": 1248, \"end\": 1264}]", "conference": "emnlp", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "14844", "title": "AMR Parsing with an Incremental Joint Model", "sectionTitle": "An Incremental Decoding Algorithm for Relation Identification", "text": "Basically, the decoder works incrementally, building a state item (i.e. a partial AMR graph) fragment by fragment. When each concept fragment is processed, edges are added between the current concept fragment and its predecessors. However, how to treat its predecessors is a difficult problem. In our experiments, we found that if we consider every preceding concept fragment to the left of the current fragment in a right-to-left order in the search process, the decoder suffers from low efficiency and poor performance. Unlike the beam-search for dependency parsing, which can greatly reduce the search space by exploiting the projectivity property of the dependency tree (Covington, 2001;Zhang and Clark, 2008a), this naive search process in this context inevitably leads to huge search space, and furthermore is difficult to guarantee the connectivity of output graph. Instead, we propose a componentwise beam search scheme, which can not only alleviate much noisy partial candidate, but also ensure that the final output graph is connected.", "spans": "[{\"corpusId\": 15390415, \"span\": \"(Covington, 2001;\", \"start\": 674, \"end\": 691}, {\"corpusId\": 15533677, \"span\": \"Zhang and Clark, 2008a)\", \"start\": 691, \"end\": 714}, {\"corpusId\": 5262888, \"span\": \"Instead, we\", \"start\": 884, \"end\": 884}]", "conference": "emnlp", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "14845", "title": "AMR Parsing with an Incremental Joint Model", "sectionTitle": "Comparison with State-of-the-art", "text": "We give a comparison between our approach and other state-of-the-art AMR parsers, including CCGbased parser (Artzi et al., 2015) and dependencybased parser (Wang et al., 2015b). For comparison purposes, we give two results from two different versions of dependency-based AMR parser 5 : CAMR* and CAMR. Compared to the latter, the former denotes the system that does not use the extended features generated from the semantic role labeling system, word sense disambiguation system and so on, which is directly comparable to our system.", "spans": "[{\"corpusId\": 5262888, \"span\": \"our approach\", \"start\": 41, \"end\": 41}, {\"corpusId\": 5499420, \"span\": \"(Artzi et al., 2015)\", \"start\": 108, \"end\": 128}, {\"corpusId\": 1269020, \"span\": \"(Wang et al., 2015b)\", \"start\": 156, \"end\": 176}, {\"corpusId\": 5262888, \"span\": \"our system\", \"start\": 532, \"end\": 532}]", "conference": "emnlp", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "14846", "title": "AMR Parsing with an Incremental Joint Model", "sectionTitle": "Related Work", "text": "Our work is motivated by JAMR (Flanigan et al., 2014), which is based on a pipelined model, resulting in a large drop in overall performance when moving from gold concepts to system concepts. Wang et al. (2015a) uses a two-stage approach; dependency parses are modified by executing a sequence of actions to resolve dis-crepancies between dependency tree and AMR structure. Goodman et al. (2016) improves the transition-based parser with the imitation learning algorithms, achieving almost the same performance as that of Wang et al. ", "spans": "[{\"corpusId\": 5262888, \"span\": \"Our work\", \"start\": 8, \"end\": 8}, {\"corpusId\": 5000956, \"span\": \"(Flanigan et al., 2014)\", \"start\": 30, \"end\": 53}, {\"corpusId\": 15344879, \"span\": \"Wang et al. (2015a)\", \"start\": 192, \"end\": 211}, {\"corpusId\": 7779018, \"span\": \"Goodman et al. (2016)\", \"start\": 374, \"end\": 395}]", "conference": "emnlp", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 5}
{"paperId": "d472624d1ab5298e0d7bc5151cf416bb55dc3440", "title": "DataHop: Spatial Data Exploration in Virtual Reality", "venue": "ACM Symposium on User Interface Software and Technology", "year": 2020, "citationCount": 48, "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3379337.3415878?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3379337.3415878, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2020-10-20", "authors": [{"authorId": "1380224643", "name": "Devamardeep Hayatpur"}, {"authorId": "40379061", "name": "Haijun Xia"}, {"authorId": "1961958", "name": "Daniel J. Wigdor"}], "abstract": "Virtual reality has recently been adopted for use within the domain of visual analytics because it can provide users with an endless workspace within which they can be actively engaged and use their spatial reasoning skills for data analysis. However, virtual worlds need to utilize layouts and organizational schemes that are meaningful to the user and beneficial for data analysis. This paper presents DataHop, a novel visualization system that enables users to lay out their data analysis steps in a virtual environment. With a Filter, a user can specify the modification they wish to perform on one or more input data panels (i.e., containers of points), along with where output data panels should be placed in the virtual environment. Using this simple tool, highly intricate and useful visualizations may be generated and traversed by harnessing a user's spatial abilities. An exploratory study conducted with six virtual reality users evaluated the usability, affordances, and performance of DataHop for data analysis tasks, and found that spatially mapping one's workflow can be beneficial when exploring multidimensional datasets.", "corpusId": "222805156", "paragraphs": [{"paragraphId": "85439", "title": "DataHop: Spatial Data Exploration in Virtual Reality", "sectionTitle": "Navigation and Spatial Skills in Virtual Environments", "text": "Populating large environments with virtual content is a challenge, however, without effective navigation techniques, users will not be able to explore content quickly and easily in these environments. Many techniques have been proposed to improve navigation, such as jumping [4,39], teleportation [5,22], virtual body resizing [1,18], and flying [26], among others.", "spans": "[{\"corpusId\": \"51960695\", \"span\": \"[4,\", \"start\": 275, \"end\": 278}, {\"corpusId\": \"215413176\", \"span\": \"39]\", \"start\": 278, \"end\": 281}, {\"corpusId\": \"9023547\", \"span\": \"[5,\", \"start\": 297, \"end\": 300}, {\"corpusId\": \"51963350\", \"span\": \"22]\", \"start\": 300, \"end\": 303}, {\"corpusId\": \"140265081\", \"span\": \"[1,\", \"start\": 327, \"end\": 330}, {\"corpusId\": \"53082315\", \"span\": \"18]\", \"start\": 330, \"end\": 333}, {\"corpusId\": \"84184834\", \"span\": \"[26]\", \"start\": 346, \"end\": 350}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "85440", "title": "DataHop: Spatial Data Exploration in Virtual Reality", "sectionTitle": "Provenance and Maintaining Workflows", "text": "Maintaining and referencing the steps in one's workflow is an important aspect of iterative problem solving [40]. Preserving and visualizing one's history has undergone extensive research in traditional visual analytics [12,20,34,38] because it can provide an overview of the states that have been explored and reveal gaps in one's workflow. To maintain these steps, many systems model a workflow as a graph where nodes represent application states and edges represent actions used to transition between two states [12]. For instance, Image Graphs [20] used a graph structure to spatially visualize one's workflow during image creation, where a node was an image and an edge was an operation to transform one image into another. DataHop extends this graph concept into VR, where there is limitless space, thus enabling entire workflow graphs to be spatially represented for easy reference and understanding.", "spans": "[{\"corpusId\": \"16028985\", \"span\": \"[40]\", \"start\": 108, \"end\": 112}, {\"corpusId\": \"1389930\", \"span\": \"[12,\", \"start\": 220, \"end\": 224}, {\"corpusId\": \"937467\", \"span\": \"20,\", \"start\": 224, \"end\": 227}, {\"corpusId\": \"1567710\", \"span\": \"34,\", \"start\": 227, \"end\": 230}, {\"corpusId\": \"8360949\", \"span\": \"38]\", \"start\": 230, \"end\": 233}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "85441", "title": "DataHop: Spatial Data Exploration in Virtual Reality", "sectionTitle": "Distributing", "text": "To distribute the points along one or more axes, the user can use the distribute action ( Figure 6). Distributing data using a single property creates a histogram, whereas distributing data using two properties creates a 2D scatter plot with the added option to view a 3D histogram. Data that is distributed along three properties creates a 3D scatter plot. Jeffery can use this action to explore the distribution of different properties, for example, by year. The resulting histogram shows Jeffery that this dataset has a rich archive of movies, dating all the way back to late 19 th century. Jeffery is now curious if this catalogue of movies also contains non-Western cinema. So, he distributes the data by the longitude and latitude of where the movie was produced, creating a 2D map of movies from around the world. Because the points overlap each other, Jeffery cannot see the number of points at different locations, so he looks at the 3D histogram to see the density of points at different latitude and longitude positions. While this dataset is dominated by Western cinema, there seems to be quite a few movies from South Asia as well.", "spans": "[{\"corpusId\": \"9625513\", \"span\": \"\", \"start\": -16632, \"end\": -16628}, {\"corpusId\": \"29834280\", \"span\": \"\", \"start\": -16628, \"end\": -16625}, {\"corpusId\": \"16270275\", \"span\": \"\", \"start\": -16625, \"end\": -16622}, {\"corpusId\": \"18168360\", \"span\": \"\", \"start\": -16622, \"end\": -16619}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "85442", "title": "DataHop: Spatial Data Exploration in Virtual Reality", "sectionTitle": "Multidimensional Data", "text": "Analyzing multidimensional datasets to find insights and trends has been a popular topic within IA. The most common method to visualize multidimensional datasets has been to use a 3D scatterplot that maps one data attribute to each spatial axis [2,28,29,7]. This approach can be particularly helpful for visualizing datasets with natural 3D embeddings such as flight paths [13,23] or traffic forecasts [32]. One multidimensional data visualization technique that makes effective use of a large space is small multiples.", "spans": "[{\"corpusId\": \"21983881\", \"span\": \"[2,\", \"start\": 245, \"end\": 248}, {\"corpusId\": \"14967903\", \"span\": \"28,\", \"start\": 248, \"end\": 251}, {\"corpusId\": \"789791\", \"span\": \"7]\", \"start\": 254, \"end\": 256}, {\"corpusId\": 222805156, \"span\": \"This approach\", \"start\": 271, \"end\": 271}, {\"corpusId\": \"17700348\", \"span\": \"[32]\", \"start\": 402, \"end\": 406}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "85443", "title": "DataHop: Spatial Data Exploration in Virtual Reality", "sectionTitle": "Immersive Software Visualizations", "text": "Source code visualization systems have harnessed users' spatial recall capabilities to improve their understanding of complex systems [16,17,24,33,36]. Software systems are inherently multifaceted, with many elements such as programs, classes, methods, arguments, and so on, making it challenging for those unfamiliar with the source code to parse and understand it. SoftwareWorld, for example, sought to make comprehension easier by using different cartographic abstractions as metaphors for source code, i.e., buildings represented methods and districts represented a class [16,17]. More recently, Souza et. al used the metaphor of a dynamically updating city to represent software source code commits over time [36].", "spans": "[{\"corpusId\": \"9625513\", \"span\": \"[16,\", \"start\": 134, \"end\": 138}, {\"corpusId\": \"29834280\", \"span\": \"17,\", \"start\": 138, \"end\": 141}, {\"corpusId\": \"16270275\", \"span\": \"24,\", \"start\": 141, \"end\": 144}, {\"corpusId\": \"18168360\", \"span\": \"33,\", \"start\": 144, \"end\": 147}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 5}
{"paperId": "d68255e8210843118d641175105e69686ad5b40f", "title": "Mind the Context: The Impact of Contextualization in Neural Module Networks for Grounding Visual Referring Expressions", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2021, "citationCount": 12, "openAccessPdf": {"url": "https://doi.org/10.18653/v1/2021.emnlp-main.516", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://aclanthology.org/2021.emnlp-main.516, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": null, "authors": [{"authorId": "2947115", "name": "Arjun Reddy Akula"}, {"authorId": "2921001", "name": "Spandana Gella"}, {"authorId": "2124615864", "name": "Keze Wang"}, {"authorId": "145380991", "name": "Song-Chun Zhu"}, {"authorId": "145732771", "name": "Siva Reddy"}], "abstract": "Neural module networks (NMN) are a popular approach for grounding visual referring expressions. Prior implementations of NMN use pre-defined and fixed textual inputs in their module instantiation. This necessitates a large number of modules as they lack the ability to share weights and exploit associations between similar textual contexts (e.g. \u201cdark cube on the left\u201d vs. \u201cblack cube on the left\u201d). In this work, we address these limitations and evaluate the impact of contextual clues in improving the performance of NMN models. First, we address the problem of fixed textual inputs by parameterizing the module arguments. This substantially reduce the number of modules in NMN by up to 75% without any loss in performance. Next we propose a method to contextualize our parameterized model to enhance the module\u2019s capacity in exploiting the visiolinguistic associations. Our model outperforms the state-of-the-art NMN model on CLEVR-Ref+ dataset with +8.1% improvement in accuracy on the single-referent test set and +4.3% on the full test set. Additionally, we demonstrate that contextualization provides +11.2% and +1.7% improvements in accuracy over prior NMN models on CLOSURE and NLVR2. We further evaluate the impact of our contextualization by constructing a contrast set for CLEVR-Ref+, which we call CC-Ref+. We significantly outperform the baselines by as much as +10.4% absolute accuracy on CC-Ref+, illustrating the generalization skills of our approach.", "corpusId": "243797528", "paragraphs": [{"paragraphId": "44307", "title": "Mind the Context: The Impact of Contextualization in Neural Module Networks for Grounding Visual Referring Expressions", "sectionTitle": "Introduction", "text": "language-to-vision matching problem and has several downstream applications such as question answering, robot navigation, and image retrieval Qi et al., 2020;Young et al., 2014;Tu et al., 2014;Qi et al., 2015;Akula and Zhu, 2019;Akula, 2015;Palakurthi et al., 2015). Recently, neural module networks (NMN; Andreas et al. 2016b;Hu et al. 2017b;Liu et al. 2019) have been gaining popularity as a promising approach for solving this task. Briefly, NMN models use an explicit modular reasoning process where a program generator first analyzes the input referring expression and predicts a sequence of learnable neural modules (e.g. count, filter, compare). Next, an execution engine dynamically assembles these modules to predict the target object in the image. Such a module based hierarchical reasoning process helps NMNs in providing high model interpretability and therefore facilitates in improving overall trust in the model (Andreas et al., 2016b;Akula et al., 2020b).", "spans": "[{\"corpusId\": 214264259, \"span\": \"Qi et al., 2020;\", \"start\": 142, \"end\": 158}, {\"corpusId\": 3104920, \"span\": \"Young et al., 2014;\", \"start\": 158, \"end\": 177}, {\"corpusId\": 875500, \"span\": \"Tu et al., 2014;\", \"start\": 177, \"end\": 193}, {\"corpusId\": 13911272, \"span\": \"Akula, 2015;\", \"start\": 229, \"end\": 241}, {\"corpusId\": 13911272, \"span\": \"Palakurthi et al., 2015)\", \"start\": 241, \"end\": 265}, {\"corpusId\": 5276660, \"span\": \"Andreas et al. 2016b;\", \"start\": 306, \"end\": 327}, {\"corpusId\": 10248021, \"span\": \"Hu et al. 2017b;\", \"start\": 327, \"end\": 343}, {\"corpusId\": 57375765, \"span\": \"Liu et al. 2019\", \"start\": 343, \"end\": 358}, {\"corpusId\": 5276660, \"span\": \"(Andreas et al., 2016b;\", \"start\": 927, \"end\": 950}, {\"corpusId\": 208278278, \"span\": \"Akula et al., 2020b)\", \"start\": 950, \"end\": 970}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 8}, {"paragraphId": "44308", "title": "Mind the Context: The Impact of Contextualization in Neural Module Networks for Grounding Visual Referring Expressions", "sectionTitle": "Introduction", "text": "Although achieving promising results, exist-ing NMN models primarily focused on designing module architectures with textual inputs directly hard-coded in the module instantiation (Johnson et al., 2017b;Liu et al., 2019). For example, processing the textual inputs 'red' and 'blue' require the instantiation of two different modules filter_color [red] and filter_color [blue]. However, such a design demands a large number of learnable modules (and network parameters) and they cannot share weights for similar contextual textual inputs (e.g. 'dark cube' vs. 'black cube', 'shiny cylinder' vs. 'metallic cylinder'). Lack of these contextual signals leads to poor generalization performance on unseen but known language contexts (Lake and Baroni, 2018;Bahdanau et al., 2019).", "spans": "[{\"corpusId\": 31319559, \"span\": \"(Johnson et al., 2017b;\", \"start\": 179, \"end\": 202}, {\"corpusId\": 57375765, \"span\": \"Liu et al., 2019)\", \"start\": 202, \"end\": 219}, {\"corpusId\": 46761158, \"span\": \"Baroni, 2018;\", \"start\": 737, \"end\": 750}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "44309", "title": "Mind the Context: The Impact of Contextualization in Neural Module Networks for Grounding Visual Referring Expressions", "sectionTitle": "Introduction", "text": "Moreover, in the prior implementations of NMN such as IEP-Ref (Johnson et al., 2017b;Liu et al., 2019), the modules in execution engine are not conditioned on the surrounding context of their textual input in the expression. This is problematic as the modules are not given the opportunity to watch the neighborhood of textual input that helps in extracting the informative visiolinguistic context from the module's visual input. For example, the module filter_color[dark] needs to pick a black colored cube or a red-colored cube depending on the neighborhood context in the expression (e.g. \"the dark thing that is hardly visible\" vs. \"the dark thing among the red cubes\") and the type of cubes available in its visual input. Few implementations of NMN such as FiLM (Perez et al., 2018) and N2NMN (Hu et al., 2017a) parametrize the surrounding context of their textual input. However, the visiolinguistic context in these modules is rather shallow as they cannot jointly co-attend over potential objects of interest directly from the visual input and textual inputs.", "spans": "[{\"corpusId\": 31319559, \"span\": \"(Johnson et al., 2017b;\", \"start\": 62, \"end\": 85}, {\"corpusId\": 57375765, \"span\": \"Liu et al., 2019)\", \"start\": 85, \"end\": 102}, {\"corpusId\": 19119291, \"span\": \"(Perez et al., 2018)\", \"start\": 767, \"end\": 787}, {\"corpusId\": 18682, \"span\": \"(Hu et al., 2017a)\", \"start\": 798, \"end\": 816}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "44310", "title": "Mind the Context: The Impact of Contextualization in Neural Module Networks for Grounding Visual Referring Expressions", "sectionTitle": "Related Work", "text": "Referring Expression Recognition. Visual referring expression recognition (REF) is the task of identifying the object in an image that is referred to by a natural language expression (Mao et al., 2016;Kazemzadeh et al., 2014). Datasets containing real images and expressions such as RefCOCO+ (Kazemzadeh et al., 2014) and Ref-COCOg (Mao et al., 2016) have been proposed to evaluate the progress on this task. Multi-modal transformers (Lu et al., 2019;Li et al., 2019;Tan and Bansal, 2019), using pretrain-then-transfer approach, have shown superior performance on these datasets. However, these models fail to learn robust visio-linguistic contextual representations and are shown to exploit the imbalanced distribution in the train and test splits (Akula et al., 2020a;Cirik et al., 2018). Recently, CLEVR-Ref+ (Liu et al., 2019) has been introduced as a synthetic diagnostic benchmark that allows control over dataset bias. There are nearly 0.8M referring expressions of which 32% of expressions refer to only a single object (Single-referent) and 68% refer to more than one object (Multi-referent). In this paper, we refer to the full dataset as F-Ref and the single-referent subset as S-Ref. Module network (Liu et al., 2019;Johnson et al., 2017a;Andreas et al., 2016b) based architectures achieved new state-of-the-art performance on this dataset.", "spans": "[{\"corpusId\": 8745888, \"span\": \"(Mao et al., 2016;\", \"start\": 183, \"end\": 201}, {\"corpusId\": 6308361, \"span\": \"Kazemzadeh et al., 2014)\", \"start\": 201, \"end\": 225}, {\"corpusId\": 6308361, \"span\": \"(Kazemzadeh et al., 2014)\", \"start\": 292, \"end\": 317}, {\"corpusId\": 199453025, \"span\": \"(Lu et al., 2019;\", \"start\": 434, \"end\": 451}, {\"corpusId\": 201103729, \"span\": \"Tan and Bansal, 2019)\", \"start\": 467, \"end\": 488}, {\"corpusId\": 218486986, \"span\": \"(Akula et al., 2020a;\", \"start\": 749, \"end\": 770}, {\"corpusId\": 19222398, \"span\": \"Cirik et al., 2018)\", \"start\": 770, \"end\": 789}, {\"corpusId\": 57375765, \"span\": \"(Liu et al., 2019)\", \"start\": 812, \"end\": 830}, {\"corpusId\": 243797528, \"span\": \"this paper\", \"start\": 1115, \"end\": 1115}, {\"corpusId\": 57375765, \"span\": \"(Liu et al., 2019;\", \"start\": 1211, \"end\": 1229}, {\"corpusId\": 15458100, \"span\": \"Johnson et al., 2017a;\", \"start\": 1229, \"end\": 1251}, {\"corpusId\": 5276660, \"span\": \"Andreas et al., 2016b)\", \"start\": 1251, \"end\": 1273}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 10}, {"paragraphId": "44311", "title": "Mind the Context: The Impact of Contextualization in Neural Module Networks for Grounding Visual Referring Expressions", "sectionTitle": "Related Work", "text": "Neural Module Networks. Neural module networks (NMNs) learn to parse textual expressions as executable programs composed of learnable neural modules (Andreas et al., 2016b;Johnson et al., 2017a,b;Hu et al., 2017a). Each of these modules are specialized to compute basic reasoning tasks and can be assembled to perform complex and compositional reasoning. (Andreas et al., 2016b) used dependency trees (Zhu et al., 2013) to generate the execution layouts. (Andreas et al., 2016a) proposed dynamic NMNs that learns and adapts the structure of the execution layouts to the question. (Johnson et al., 2017b) proposed homogeneous (IEP) and generic neural modules, unlike fixed and hand-crafted neural module, in which the semantics of each neural module is learnt during training. IEP model achieves promising performance on CLEVR dataset. (Liu et al., 2019) proposed IEP-Ref by extending IEP model to CLEVR-Ref+ dataset and outperformed all the prior works. Although, compositional by design, the visiolinguistic context in these modules is rather shallow and fail to ground novel combinations of known linguistic constructs (Bahdanau et al., 2019). The major difference between our work and these prior works of NMN is that we explicitly parametrize and contextualize the neural modules by jointly attending over the visual and textual inputs.  ", "spans": "[{\"corpusId\": 5276660, \"span\": \"(Andreas et al., 2016b;\", \"start\": 149, \"end\": 172}, {\"corpusId\": 18682, \"span\": \"Hu et al., 2017a)\", \"start\": 196, \"end\": 213}, {\"corpusId\": 5276660, \"span\": \"(Andreas et al., 2016b)\", \"start\": 355, \"end\": 378}, {\"corpusId\": 3130692, \"span\": \"(Andreas et al., 2016a)\", \"start\": 455, \"end\": 478}, {\"corpusId\": 31319559, \"span\": \"(Johnson et al., 2017b)\", \"start\": 580, \"end\": 603}, {\"corpusId\": 57375765, \"span\": \"(Liu et al., 2019)\", \"start\": 835, \"end\": 853}, {\"corpusId\": 243797528, \"span\": \"our work\", \"start\": 1183, \"end\": 1183}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "44312", "title": "Mind the Context: The Impact of Contextualization in Neural Module Networks for Grounding Visual Referring Expressions", "sectionTitle": "Module Parameterization in NMN", "text": "We propose parametrization as the first step to enable weight sharing and exploiting associations between similar textual contexts. Specifically, we evaluate the effectiveness of parameterizing module textual inputs using IEP-Ref (Liu et al., 2019) as the baseline NMN implementation. IEP-Ref, a NMN solution based on IEP (Johnson et al., 2017b), is the current state-of-the-art model on CLEVR-Ref+ dataset. 1 As shown Figure 2(a), the neural modules in IEP-Ref are represented using a standard Residual Convolution Block (RCB). Formally, each RCB module (f n ) of arity n receives n feature maps (F i ) of shape 128 \u00d7 20 \u00d7 20 and outputs a same-sized tensor f o = f n (F 1 , F 2 , ..., F n ).", "spans": "[{\"corpusId\": 243797528, \"span\": \"We propose\", \"start\": 10, \"end\": 10}, {\"corpusId\": 57375765, \"span\": \"(Liu et al., 2019)\", \"start\": 230, \"end\": 248}, {\"corpusId\": 31319559, \"span\": \"(Johnson et al., 2017b)\", \"start\": 322, \"end\": 345}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "44313", "title": "Mind the Context: The Impact of Contextualization in Neural Module Networks for Grounding Visual Referring Expressions", "sectionTitle": "Datasets", "text": "We evaluate our approach on F-Ref and S-Ref splits of CLEVR-Ref+ (Liu et al., 2019). In addition, we also test our approach on CLOSURE (Bahdanau et al., 2019) and NLVR2 (Suhr et al., 2019) benchmarks. CLOSURE is a VQA benchmark, consisting of synthetically generated image and question pairs with emphasis on grounding simple and complex referring expressions. NLVR2 is a language grounding task where the goal is to determine whether an expression is true based on two paired real images. While reporting results on CLOSURE, we train our NMN model using CLEVR (Johnson et al., 2017a) train and val splits.", "spans": "[{\"corpusId\": 243797528, \"span\": \"our approach\", \"start\": 24, \"end\": 24}, {\"corpusId\": 57375765, \"span\": \"(Liu et al., 2019)\", \"start\": 65, \"end\": 83}, {\"corpusId\": 243797528, \"span\": \"our approach\", \"start\": 123, \"end\": 123}, {\"corpusId\": 53178856, \"span\": \"(Suhr et al., 2019)\", \"start\": 169, \"end\": 188}, {\"corpusId\": 15458100, \"span\": \"(Johnson et al., 2017a)\", \"start\": 561, \"end\": 584}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "44314", "title": "Mind the Context: The Impact of Contextualization in Neural Module Networks for Grounding Visual Referring Expressions", "sectionTitle": "Baselines", "text": "We compare the performance of our approach against the following baselines: (1) IEP-Ref (Liu et al., 2019) is the current state-of-the-art NMN model for CLEVR-Ref+ benchmark which uses explicit program generator and execution engine (PG+EE) to predict the answer; (2) FiLM (Featurewise Linear Modulation) (Perez et al., 2018) is a NMN model which introduces new layers in the RCB block that learn parameters \u03b3 i,c and \u03b2 i,c for scaling up or down the CNN activations (F i,c ) by conditioning on the input referring expression", "spans": "[{\"corpusId\": 243797528, \"span\": \"our approach\", \"start\": 42, \"end\": 42}, {\"corpusId\": 57375765, \"span\": \"(Liu et al., 2019)\", \"start\": 88, \"end\": 106}, {\"corpusId\": 19119291, \"span\": \"(Perez et al., 2018\", \"start\": 305, \"end\": 324}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "44315", "title": "Mind the Context: The Impact of Contextualization in Neural Module Networks for Grounding Visual Referring Expressions", "sectionTitle": "A.1 F-Ref and S-Ref splits in CLEVR-Ref+", "text": "Visual referring expression recognition is the task of identifying the object in an image that is referred to by a natural language expression (Kazemzadeh et al., 2014;Mao et al., 2016). It is a fundamental language-to-vision matching problem and has several downstream applications such as question answering . CLEVR-Ref+ (Liu et al., 2019) is a recently proposed dataset for visual referring expression recognition (RefExp) task, which consists of synthetic images and referring expressions. Specifically, it contains the ground-truth functional program representations that describe the intermediate visual reasoning as a chain of logical operations (i.e., neural modules) that need to be executed to find the target referent object (e.g., filter color, compare, filter size, and relate). There are nearly 0.8M referring expressions of which 32% of expressions refer to only a single object (Singlereferent) and 68% refer to more than one object (Multi-referent). In this paper, we refer to the full dataset as F-Ref and the single-referent subset as S-Ref. Detailed statistics of the splits are presented in Table 9.       Figure 9: Overview of our curriculum learning baseline.", "spans": "[{\"corpusId\": 6308361, \"span\": \"(Kazemzadeh et al., 2014;\", \"start\": 143, \"end\": 168}, {\"corpusId\": 8745888, \"span\": \"Mao et al., 2016)\", \"start\": 168, \"end\": 185}, {\"corpusId\": 57375765, \"span\": \"(Liu et al., 2019\", \"start\": 323, \"end\": 340}, {\"corpusId\": 243797528, \"span\": \"this paper\", \"start\": 980, \"end\": 980}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 9}
{"paperId": "f07a48e4b4fb44fc7265680cec1f17fc2f1de19f", "title": "Modelling Error Rates in Temporal Pointing", "venue": "International Conference on Human Factors in Computing Systems", "year": 2016, "citationCount": 66, "openAccessPdf": {"url": "https://dl.acm.org/doi/pdf/10.1145/2858036.2858143", "status": "BRONZE", "license": null, "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/2858036.2858143?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2858036.2858143, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2016-05-07", "authors": [{"authorId": "40216478", "name": "Byungjoo Lee"}, {"authorId": "2663734", "name": "Antti Oulasvirta"}], "abstract": null, "corpusId": "12949535", "paragraphs": [{"paragraphId": "27299", "title": "Modelling Error Rates in Temporal Pointing", "sectionTitle": "INTRODUCTION", "text": "When we started working on this topic, we were surprised to learn that temporal pointing is not addressed by predictive models in HCI. Fitts' law and its variants [8,9,33,40,10,24] are limited to the spatial domain. From Fitts' law's perspective, our scenario is trivial: as the finger is already on (or above) the button, travel distance is minimal and movement time constant (i.e., M T \u2248 a). As we argue later, the case is covered neither by models of reaction time nor by sensorimotor synchronisation studies in psychology.", "spans": "[{\"corpusId\": 501599, \"span\": \"[8,\", \"start\": 163, \"end\": 166}, {\"corpusId\": 10420006, \"span\": \"9,\", \"start\": 166, \"end\": 168}, {\"corpusId\": 4502779, \"span\": \"33,\", \"start\": 168, \"end\": 171}, {\"corpusId\": 15015118, \"span\": \"40,\", \"start\": 171, \"end\": 174}, {\"corpusId\": 5954743, \"span\": \"10,\", \"start\": 174, \"end\": 177}, {\"corpusId\": 8795450, \"span\": \"24]\", \"start\": 177, \"end\": 180}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 6}, {"paragraphId": "27300", "title": "Modelling Error Rates in Temporal Pointing", "sectionTitle": "INTRODUCTION", "text": "In particular, they have found that gaming performance can be up to 150% worse in playing with a touchscreen device rather than a physical controller [5,42,43]. We argue later in this paper that these differences are not trivially attributable to latencies or tactile feedback. Fourthly, users can also adopt different response strategies. In the scenario above, would you try to anticipate and start pressing down slightly before the enemy reaches the crosshairs, or would you rather wait until it is there and press down then?", "spans": "[{\"corpusId\": 12325183, \"span\": \"[5,\", \"start\": 150, \"end\": 153}, {\"corpusId\": 6850657, \"span\": \"42,\", \"start\": 153, \"end\": 156}, {\"corpusId\": 21789630, \"span\": \"43]\", \"start\": 156, \"end\": 159}, {\"corpusId\": 12949535, \"span\": \"this paper\", \"start\": 189, \"end\": 189}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "27301", "title": "Modelling Error Rates in Temporal Pointing", "sectionTitle": "INTRODUCTION", "text": "This paper contributes by 1) defining temporal pointing in terms of the concept of temporal target and 2) deriving a novel mathematical model to predict error rates. The model assumes that users have an implicit temporal point of aim within the target window, the point in time at which they intend the input event to be registered. However, the model further assumes that their ability to elicit the input event at that time is hampered by variability accumulating over three processes: 1) an internal time-keeping process, 2) a response-execution stage, and 3) input processing in the computer. Two empirical parameters capture the changes in the point of aim and variability. The model yields a task-specific response distribution, a Gaussian in time, from which error rate E can be calculated. The mathematical description captures a transition between two response strategies found in previous studies: anticipation and reaction [7,31]. Users tend to rely more on anticipation (their internal clock) than on reaction when the task becomes more difficult. Although simple, the model adequately addresses two quite different cases:", "spans": "[{\"corpusId\": 12949535, \"span\": \"This paper\", \"start\": 10, \"end\": 10}, {\"corpusId\": 145242490, \"span\": \"[7,\", \"start\": 934, \"end\": 937}, {\"corpusId\": 32969189, \"span\": \"31]\", \"start\": 937, \"end\": 940}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "27302", "title": "Modelling Error Rates in Temporal Pointing", "sectionTitle": "Spatial Pointing", "text": "Fitts' law [8] predicts minimum movement time M T with two spatial requirements: movement distance D s and target width W s . In other words, the user is asked to move as quickly as possible to hit the target. Fitts introduced the concept of index of difficulty: M T = a + bID s = a+b log 2 (2D s /W s ). Wobbrock et al. [40] analysed Fitts' law to derive a model of error rates with three task requirements mixed in the temporal and spatial domain: target size D s , target width W s , and temporal target distance D t . As this paper does, they predicted error rates, because there was an explicit requirement to maintain a temporal distance to the target D t . Besides, when the spatial requirement W s is relaxed from Fitts' task, targeting becomes more open-loop-like. Gan and Hoffman [9] proposed a model to predict M T when the goal is to hit a large target at distance D s . Hoffman's law originally predicted M T = a + b \u221a D s . With additional assumptions, it can be expressed as the constant ratio between D s and the standard deviation (SD) of end points [12].", "spans": "[{\"corpusId\": 501599, \"span\": \"[8]\", \"start\": 11, \"end\": 14}, {\"corpusId\": 15015118, \"span\": \"[40]\", \"start\": 321, \"end\": 325}, {\"corpusId\": 12949535, \"span\": \"this paper\", \"start\": 535, \"end\": 535}, {\"corpusId\": 10420006, \"span\": \"[9]\", \"start\": 790, \"end\": 793}, {\"corpusId\": 20340577, \"span\": \"[12]\", \"start\": 1067, \"end\": 1071}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "27303", "title": "Modelling Error Rates in Temporal Pointing", "sectionTitle": "Spatial Pointing", "text": "Schmidt's law [33] adds one temporal requirement to Gan and Hoffman's model, time to target D t . This changes the task from time-minimisation to spread-minimisation at a known Quantifying Efficiency of Input Methods #chi4good, CHI 2016, San Jose, CA, USA distance in time. The law predicts that SD (in the spatial domain) is linearly related to movement velocity. If time to the target D t is controlled, SD increases linearly with spatial distance D s . In this case, the model is the same as that of Hoffman et al. [9,12]. Guiard et al. [10] recently presented the most comprehensive model of spatial aiming. The WHo model explains different aspects of spatial movement by reference to six axioms of human movement. That model subsumes Fitts' law and Schmidt's law by reference to a trade-off phenomenon among the axioms. The model is not depicted in Figure 2 since our analysis is based only on task instructions rather than actual user response. In addition, models inspired by control theory [6,15,20,19,25] have looked at speed-accuracy trade-offs in spatial pointing tasks.", "spans": "[{\"corpusId\": 4502779, \"span\": \"[33]\", \"start\": 14, \"end\": 18}, {\"corpusId\": 10420006, \"span\": \"[9,\", \"start\": 518, \"end\": 521}, {\"corpusId\": 20340577, \"span\": \"12]\", \"start\": 521, \"end\": 524}, {\"corpusId\": 5954743, \"span\": \"[10]\", \"start\": 540, \"end\": 544}, {\"corpusId\": 44830641, \"span\": \"[6,\", \"start\": 998, \"end\": 1001}, {\"corpusId\": 143541802, \"span\": \"15,\", \"start\": 1001, \"end\": 1004}, {\"corpusId\": 5191915, \"span\": \"20,\", \"start\": 1004, \"end\": 1007}, {\"corpusId\": 10474704, \"span\": \"19,\", \"start\": 1007, \"end\": 1010}, {\"corpusId\": 144476296, \"span\": \"25]\", \"start\": 1010, \"end\": 1013}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "27304", "title": "Modelling Error Rates in Temporal Pointing", "sectionTitle": "Synchronisation", "text": "The Wing and Kristofferson (WK) model [39,38] predicts performance in the synchronisation task, in which one has to synchronise, for example, tapping or clapping with some repeating stimulus, such as a beep sound. The beep is regarded as an impulse signal, and the user has no explicit requirement of temporal preciseness W t . In other words, only D t (interonset interval, IOI) is controlled. The model divides the cognitive process in synchronisation tasks into two parts: an internal time-keeping process is followed by a motor response with time delay. Both time-keeping precision and motor delay are assumed to be stochastic and separately represented by additive random noise with a mean and variance. Noise components can be extracted from a tapping experiment by examining autocorrelation in consecutive asynchronies [39]. The variance of the time-keeping process linearly increases with IOI [27,29], There is a similarity here to the model of ballistic movements in the spatial domain, in which the SD of end location linearly increases with target amplitude D s . We will use this linearity as a primary assumption in our model. By contrast, variance in motor responses remained relatively constant and lower than time-keeping variance. This implies that variance in motor responses dominates in fast tapping (IOI sub-250 ms).", "spans": "[{\"corpusId\": 143938249, \"span\": \"[39,\", \"start\": 38, \"end\": 42}, {\"corpusId\": 143502693, \"span\": \"38]\", \"start\": 42, \"end\": 45}, {\"corpusId\": 143938249, \"span\": \"[39]\", \"start\": 826, \"end\": 830}, {\"corpusId\": 288799, \"span\": \"[27,\", \"start\": 901, \"end\": 905}, {\"corpusId\": 17804818, \"span\": \"29]\", \"start\": 905, \"end\": 908}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "27305", "title": "Modelling Error Rates in Temporal Pointing", "sectionTitle": "Synchronisation", "text": "As with reaction times, the distribution of asynchronies is approximated well with a Gaussian [18,21]. Research has shown that stimulus modality and differences between individuals affect performance. Auditory stimuli (such as beep sounds) are better for synchronisation, especially with higher tempos (100-125 ms IOI limit), than visual stimuli [28]. Furthermore, large individual-to-individual differences have been observed, for example, between musicians and nonmusicians [28,27].", "spans": "[{\"corpusId\": 12308507, \"span\": \"[18,\", \"start\": 94, \"end\": 98}, {\"corpusId\": 21878643, \"span\": \"21]\", \"start\": 98, \"end\": 101}, {\"corpusId\": 144397646, \"span\": \"[28]\", \"start\": 346, \"end\": 350}, {\"corpusId\": 144397646, \"span\": \"[28,\", \"start\": 476, \"end\": 480}, {\"corpusId\": 288799, \"span\": \"27]\", \"start\": 480, \"end\": 483}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "27306", "title": "Modelling Error Rates in Temporal Pointing", "sectionTitle": "Synchronisation", "text": "While the WK model explains two important variances, it does not explain the offset between stimulus and tapping, which also changes with IOI [27,29]. A Bayesian model of human timing [2,41,1] provides an explanation to the varying aim point in synchronisation. It explains this as statistical self-correction occurring between taps when a person is trying to maximise performance for a given loss function.", "spans": "[{\"corpusId\": 288799, \"span\": \"[27,\", \"start\": 142, \"end\": 146}, {\"corpusId\": 17804818, \"span\": \"29]\", \"start\": 146, \"end\": 149}, {\"corpusId\": 13671777, \"span\": \"[2,\", \"start\": 184, \"end\": 187}, {\"corpusId\": 13954262, \"span\": \"41,\", \"start\": 187, \"end\": 190}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "27307", "title": "Modelling Error Rates in Temporal Pointing", "sectionTitle": "Interception", "text": "Intercepting a moving target demands considering both spatial and temporal amplitude to the target, but, depending on the target's speed and size, precision might also be required [4]. To our knowledge, there is no model of target interception that would consider the case of temporal pointing wherein the spatial task requirement is negligible. Anticipation-coincidence studies [17,3] and the Newell group's work [22,11,23,16,13] have offered a mixed view, wherein temporal and spatial requirements co-exist. Two distinct categories of existing models can be recognised: 1) models assuming preprogrammed responses and 2) on-line control models. There has been some criticism of these models [35]. One critical issue is that several strategies are possible. For example, when one is capturing a target, four distinct strategies have been identified (pursuit, head-on, receding, and perpendicular) [35]. The strategy is affected by how the target moves, its identity, whether it is to be captured or hit, and how it is approached. One replicated finding is that when moving targets require more temporal precision (smaller W t ), people increase the movement velocity [36,4,34]. However, faster movement also decreases spatial precision, as Schmidt's law predicts. This has been explained by reference to a process that maintains optimal strategy between spatial and temporal precision [32,41]. In summary, although interception is a generalisation of both spatial and temporal pointing, at present no model is able to predict performance in our case -i.e., when spatial task requirements are virtually non-existent.", "spans": "[{\"corpusId\": 16409305, \"span\": \"[4]\", \"start\": 180, \"end\": 183}, {\"corpusId\": 24601286, \"span\": \"[17,\", \"start\": 379, \"end\": 383}, {\"corpusId\": 118640984, \"span\": \"3]\", \"start\": 383, \"end\": 385}, {\"corpusId\": 115952579, \"span\": \"[22,\", \"start\": 414, \"end\": 418}, {\"corpusId\": 10205509, \"span\": \"11,\", \"start\": 418, \"end\": 421}, {\"corpusId\": 144902892, \"span\": \"23,\", \"start\": 421, \"end\": 424}, {\"corpusId\": 12550155, \"span\": \"16,\", \"start\": 424, \"end\": 427}, {\"corpusId\": 10205509, \"span\": \"13]\", \"start\": 427, \"end\": 430}, {\"corpusId\": 30683026, \"span\": \"[35]\", \"start\": 692, \"end\": 696}, {\"corpusId\": 30683026, \"span\": \"[35]\", \"start\": 897, \"end\": 901}, {\"corpusId\": 22854472, \"span\": \"[36,\", \"start\": 1167, \"end\": 1171}, {\"corpusId\": 16409305, \"span\": \"4,\", \"start\": 1171, \"end\": 1173}, {\"corpusId\": 2525525, \"span\": \"34]\", \"start\": 1173, \"end\": 1176}, {\"corpusId\": 53448214, \"span\": \"[32,\", \"start\": 1385, \"end\": 1389}, {\"corpusId\": 13954262, \"span\": \"41]\", \"start\": 1389, \"end\": 1392}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 12}, {"paragraphId": "27308", "title": "Modelling Error Rates in Temporal Pointing", "sectionTitle": "DISCUSSION", "text": "The model provides a novel explanation to differences among input devices in temporal aspects of performance. It predicts that users aim for temporal targets differently, with variation by input method, and it points out three stages that affect variability in responses and thereby error rates. This explains a hidden aspect of the finding that touchscreen gaming is associated with much lower performance than gaming with physical keys [5,42,43]. This difference is not trivially due to latency, as one could easily think. The model exposes two factors. Firstly, targeting with the touchscreen is hard because the timing of the sensor event is uncertain. We showed that coinciding of the input event and the moment when the finger has maximum impact on the surface aids in targeting. The Touch-Maximum event allows a user to learn a mapping that is more predictable and therefore improves accuracy. With Touch-Maximum, error rates were decreased by up to 9.0% from the empirical observation. Secondly, Touch-Maximum still suffered from greater noise (c \u03c3 =0.0773) than Key-Press (c \u03c3 =0.0705). Users cannot precisely control how high they hold their finger, and the variation in distance between the finger and surface may have increased variability.", "spans": "[{\"corpusId\": 12325183, \"span\": \"[5,\", \"start\": 438, \"end\": 441}, {\"corpusId\": 6850657, \"span\": \"42,\", \"start\": 441, \"end\": 444}, {\"corpusId\": 21789630, \"span\": \"43]\", \"start\": 444, \"end\": 447}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 3}], "paragraphCount": 10}
{"paperId": "894009cd79adab9d32132ea7ea79c8c028d68d3b", "title": "Coach: A Coarse-to-Fine Approach for Cross-domain Slot Filling", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2020, "citationCount": 100, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/2020.acl-main.3.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2004.11727, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2020-04-01", "authors": [{"authorId": "152613855", "name": "Zihan Liu"}, {"authorId": "9162688", "name": "Genta Indra Winata"}, {"authorId": "145011005", "name": "Peng Xu"}, {"authorId": "40539650", "name": "Pascale Fung"}], "abstract": "As an essential task in task-oriented dialog systems, slot filling requires extensive training data in a certain domain. However, such data are not always available. Hence, cross-domain slot filling has naturally arisen to cope with this data scarcity problem. In this paper, we propose a Coarse-to-fine approach (Coach) for cross-domain slot filling. Our model first learns the general pattern of slot entities by detecting whether the tokens are slot entities or not. It then predicts the specific types for the slot entities. In addition, we propose a template regularization approach to improve the adaptation robustness by regularizing the representation of utterances based on utterance templates. Experimental results show that our model significantly outperforms state-of-the-art approaches in slot filling. Furthermore, our model can also be applied to the cross-domain named entity recognition task, and it achieves better adaptation performance than other existing baselines. The code is available at https://github.com/zliucr/coach.", "corpusId": "216144770", "paragraphs": [{"paragraphId": "94312", "title": "Coach: A Coarse-to-Fine Approach for Cross-domain Slot Filling", "sectionTitle": "Related Work", "text": "Coarse-to-fine methods in NLP are best known for syntactic parsing (Charniak et al., 2006;Petrov, 2011). Zhang et al. (2017) reduced the search space of semantic parsers by using coarse macro grammars. Different from the previous work, we apply the idea of coarse-to-fine into cross-domain slot filling to handle unseen slot types by separating the slot filling task into two steps (Zhai et al., 2017;Guerini et al., 2018).", "spans": "[{\"corpusId\": 15016852, \"span\": \"(Charniak et al., 2006;\", \"start\": 67, \"end\": 90}, {\"corpusId\": 6073887, \"span\": \"Zhang et al. (2017)\", \"start\": 105, \"end\": 124}, {\"corpusId\": 6541221, \"span\": \"(Zhai et al., 2017;\", \"start\": 382, \"end\": 401}, {\"corpusId\": 51918804, \"span\": \"Guerini et al., 2018)\", \"start\": 401, \"end\": 422}]", "conference": "acl", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "94313", "title": "Coach: A Coarse-to-Fine Approach for Cross-domain Slot Filling", "sectionTitle": "Related Work", "text": "Coping with low-resource problems where there are zero or few existing training samples has always been an interesting and challenging task (Kingma et al., 2014;Lample et al., 2018;Liu et al., 2019a,b;. Cross-domain adaptation addresses the data scarcity problem in low-resource target domains (Pan et al., 2010;Jaech et al., 2016;Guo et al., 2018;Jia et al., 2019;. However, most research studying the cross-domain aspect has not focused on predicting unseen label types in the target domain since both source and target domains have the same label types in the considered tasks (Guo et al., 2018). In another line of work, to bypass unseen label types, Ruder and Plank (2018) ", "spans": "[{\"corpusId\": 6377199, \"span\": \"(Kingma et al., 2014;\", \"start\": 140, \"end\": 161}, {\"corpusId\": 5033497, \"span\": \"Lample et al., 2018;\", \"start\": 161, \"end\": 181}, {\"corpusId\": 5984940, \"span\": \"(Pan et al., 2010;\", \"start\": 294, \"end\": 312}, {\"corpusId\": 52178689, \"span\": \"Guo et al., 2018;\", \"start\": 331, \"end\": 348}, {\"corpusId\": 196189661, \"span\": \"Jia et al., 2019;\", \"start\": 348, \"end\": 365}, {\"corpusId\": 52178689, \"span\": \"(Guo et al., 2018)\", \"start\": 580, \"end\": 598}]", "conference": "acl", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 5}], "paragraphCount": 2}
{"paperId": "5d3409e586ffaecdccf3c354533935baad48b3a1", "title": "Magnetact: magnetic-sheet-based haptic interfaces for touch devices", "venue": "SIGGRAPH ASIA Emerging Technologies", "year": 2018, "citationCount": 24, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3275476.3275478?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3275476.3275478, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Materials Science", "Computer Science"], "publicationTypes": ["Book", "JournalArticle"], "publicationDate": "2018-12-04", "authors": [{"authorId": "3257746", "name": "K. Yasu"}], "abstract": "This paper1 presents a rapid prototyping method of haptic interfaces for touch devices utilizing magnetic rubber sheets and conductive materials. When a magnetic sheet is thin enough, the capacitive sensor of the touch device can detect the user's finger behind the magnetic sheet due to the sheet's dielectric behavior. Furthermore, by changing the magnetic pattern of the magnetic sheet using a handy magnetizing tool, the tactile feedback can be customized within seconds. Since the construction of the interface is so simple, this method enables users to customize not only the size and shape, also the haptic feedback of the tangible interface. We demonstrated several types of interface such as buttons, sliders, switches, and cross-keys.", "corpusId": "54434440", "paragraphs": [{"paragraphId": "8251", "title": "Magnetact: Magnetic-sheet-based Haptic Interfaces for Touch Devices", "sectionTitle": "RELATED WOKRS", "text": "Haptic feedback from touchscreens has been a subject of interface research for a long time. Today, a virtual haptic technology that uses vibration to convey the click feeling is used at a practical level [Fukumoto andSugimura. 2001, Kim andLee. 2013]. The user can customize the strength of the feedback configuring the vibration. However, it is not suitable for presenting where the button is, or what the shape of the button is. For those matters, it seems smarter to use a Tangible User Interface. The capacitive sensors of the touch device can be used for recognition of the position, size, and orientation of the passive objects [Chan et al. 2012]. However, it is hard to customize the haptic feedback because most approaches use the elasticity or rigidity of the passive material itself.", "spans": "[{\"corpusId\": 16615550, \"span\": \"[Fukumoto and\", \"start\": 204, \"end\": 217}, {\"corpusId\": 1497318, \"span\": \"Lee. 2013]\", \"start\": 240, \"end\": 250}, {\"corpusId\": 14886863, \"span\": \"[Chan et al. 2012\", \"start\": 634, \"end\": 651}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "8252", "title": "Magnetact: Magnetic-sheet-based Haptic Interfaces for Touch Devices", "sectionTitle": "RELATED WOKRS", "text": "For customizability, magnetic forces have been used for various haptic technologies. Bump Ahead [Yasu and Katsumoto. 2015] and Mechamagnets [Zheng and Do. 2018] presented designability of the tactile interface using permanent magnetic. For customizing haptic feedback, Polymagnet [Correlated Magnetics. 2016] and Magnetic Plotter has developed a machine for computational magnetization of permanent magnets and showed the way of haptic design. Meanwhile, our approach shows that magnetization can be done even without machines. The handy magnetizer can write and rewrite the magnetic patterns rapidly, and the haptic feedback can be modified stronger, weaker, or almost null until the desired haptic feeling is achieved. This is a rapid-designing method of haptic feelings.  ", "spans": "[{\"corpusId\": 15905345, \"span\": \"[Yasu and Katsumoto. 2015]\", \"start\": 96, \"end\": 122}, {\"corpusId\": 3854283, \"span\": \"[Zheng and Do. 2018\", \"start\": 140, \"end\": 159}, {\"corpusId\": 54434440, \"span\": \"our approach\", \"start\": 467, \"end\": 467}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 2}
{"paperId": "057acaf6619c0bb9f53c8fdbad3ed5efbea68a31", "title": "\"Could You Define That in Bot Terms\"?: Requesting, Creating and Using Bots on Reddit", "venue": "International Conference on Human Factors in Computing Systems", "year": 2017, "citationCount": 69, "openAccessPdf": {"url": "http://dl.acm.org/ft_gateway.cfm?id=3025830&type=pdf", "status": "BRONZE", "license": null, "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3025453.3025830?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3025453.3025830, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2017-05-02", "authors": [{"authorId": "2476734", "name": "Kiel S. Long"}, {"authorId": "145888680", "name": "John Vines"}, {"authorId": "144565644", "name": "S. Sutton"}, {"authorId": "38946518", "name": "Phillip Brooker"}, {"authorId": "2313604", "name": "Tom Feltwell"}, {"authorId": "38204674", "name": "B. Kirman"}, {"authorId": "144565830", "name": "J. Barnett"}, {"authorId": "1693761", "name": "S. Lawson"}], "abstract": null, "corpusId": "11141626", "paragraphs": [{"paragraphId": "31963", "title": "\"Could You Define That in Bot Terms\"?: Requesting, Creating and Using Bots on Reddit", "sectionTitle": "INTRODUCTION", "text": "Social media platforms have recently seen a proliferation of automated software agents, known as bots, which can monitor and participate in simple online communication. The current scale of online bot activity is remarkable, with bots being responsible for 24% of all activity on Twitter [54]. While their purpose on social media varies widely, bots are characterized by routine behaviours that often respond to other activity according to some designed criteria. For instance, if someone used the phrase \u00d2illegal immigrant\u00d3 on Twitter in July 2015, they might have received an automated reply from \u00d2@DroptheIBot\u00d3 [24] suggesting they rethink on their terminology and use the term \u00d2undocumented immigrant\u00d3 instead. Bots deployed on social media platforms are often quick to gain notoriety. Through these platforms\u00d5 low barriers to social interaction, bots propagate news [34] and political opinion [8]; they counter, respond to and correct statements made by users (such as @DroptheIBot); they name and shame users based on the things they say or content they share [47]; help users appeal parking tickets without needing lawyers [61]; publish generative art (e.g. @MothGenerator); give directions to mysterious places [28]; and attempt humour (e.g @AmIRiteBot). Outside of social media, bots are also an established feature of communities such as Wikipedia, Slack and Reddit, where they provide ways to automate the standard protocols that govern platform content and perform other tasks that are time-consuming for human administrators [11,33,36,52]. However, poor design and implementations of bots can have negative effects. Microsoft\u00d5s Tay Twitter bot [42] was quickly pulled when, influenced by mischievous human peers, it began to post highly offensive racist, sexist and homophobic material. Bots gained further notoriety in expos\u017ds of the dating site Ashley Madison in which it was revealed that many customer interactions with seemingly real users were, in fact, with bots [32].! The recent proliferation of bots has been supported by the development of new tools and services which have lowered barriers to their creation and deployment. The availability of simple, well-documented application programming interfaces (APIs) that support ever more accessible languages and frameworks opens bot creation to novice developers. Meya [63], Labnol [3] and \u00d2Cheap Bots Done Quick\u00d3 [60] provide tools that allow non-developers to design, create and deploy simple bots without writing a line of code. The Weavrs platform gained widespread notoriety [2] for facilitating the creation, at the press of a button, of relatively unsophisticated but strikingly effective and subversive Twitter bots seeded with existing profiles of real celebrities. A recent well-publicised online tutorial describing \u00d2How to Make a Twitter Bot in Under an Hour: Even if you don\u00d5t code that often!\u00d3 [43] contributes to an expanding set of reference material regarding the process of making bots. Furthermore, events such as \u00d2Bot Summit\u00d3 [27] and \u00d2Art of Bots\u00d3 [59]) offer bot-making enthusiasts opportunities to talk about bots, collaboratively make them, swap expertise and offer help.", "spans": "[{\"corpusId\": 8395950, \"span\": \"[8]\", \"start\": 898, \"end\": 901}, {\"corpusId\": 17165007, \"span\": \"[28]\", \"start\": 1219, \"end\": 1223}, {\"corpusId\": 28383245, \"span\": \"[11,\", \"start\": 1538, \"end\": 1542}, {\"corpusId\": 46669421, \"span\": \"33,\", \"start\": 1542, \"end\": 1545}, {\"corpusId\": 8781950, \"span\": \"36,\", \"start\": 1545, \"end\": 1548}, {\"corpusId\": 31152916, \"span\": \"52]\", \"start\": 1548, \"end\": 1551}, {\"corpusId\": 1440656, \"span\": \"[32]\", \"start\": 1983, \"end\": 1987}, {\"corpusId\": 121692891, \"span\": \"[2]\", \"start\": 2551, \"end\": 2554}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": false, "refCount": 8}, {"paragraphId": "31964", "title": "\"Could You Define That in Bot Terms\"?: Requesting, Creating and Using Bots on Reddit", "sectionTitle": "RELATED WORK", "text": "A significant amount of prior work has focused on problematic aspects of bots, such as their use in attacking websites or online services (e.g. [8,57]) or their impersonation of humans (e.g. [10,46]). Motivated by allegations around democratic votes in both Europe and the US, Forelle et al [17], Baker [6], and the wider research community at politicalbots.org have highlighted the widespread use of bots to disseminate and influence political opinion, \u00d4to boost follower numbers and to retweet the content of political candidates on Twitter, to attack political opponents on Facebook, or to drown out activists\u00d5 conversations on Reddit\u00d5 [58, p4885]. Likewise, Larsson and Moe [30] note the need for researchers and platform developers to deepen their understandings of how bot accounts influence and propagate news and media distribution. Relatedly, Savage et al [48] present an approach for using Twitter bots as a mechanism for calling volunteers to action around social causes, highlighting the ease with which changing the tone of the language expressed by a bot can influence engagement from human social media users [48]. The growing abundance of bot code shared on platforms such as GitHub opens even further opportunities and lowers the level of expertise needed to tailor, deploy and use these software agents for personal, social or political causes [29].", "spans": "[{\"corpusId\": 8395950, \"span\": \"[8,\", \"start\": 144, \"end\": 147}, {\"corpusId\": 2759521, \"span\": \"57]\", \"start\": 147, \"end\": 150}, {\"corpusId\": 6494787, \"span\": \"[10,\", \"start\": 191, \"end\": 195}, {\"corpusId\": 14904788, \"span\": \"46]\", \"start\": 195, \"end\": 198}, {\"corpusId\": 151329471, \"span\": \"[30]\", \"start\": 678, \"end\": 682}, {\"corpusId\": 1568426, \"span\": \"[48]\", \"start\": 865, \"end\": 869}, {\"corpusId\": 1568426, \"span\": \"[48]\", \"start\": 1124, \"end\": 1128}, {\"corpusId\": 151621821, \"span\": \"[29]\", \"start\": 1362, \"end\": 1366}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "31965", "title": "\"Could You Define That in Bot Terms\"?: Requesting, Creating and Using Bots on Reddit", "sectionTitle": "RELATED WORK", "text": "As well as these wider social, technical and political implications of bot use, there is growing recognition of the important role bots play in automating otherwise burdensome and repetitive processes on platforms such as Wikipedia [11,36] and Slack [33]. Cl\u017dment and Guitton [11] categorise bots on Wikipedia into two opposing ideotypes: \u00d4servant\u00d5 bots performing laborious work in place of human volunteers (e.g. correcting grammatical error); and \u00d4policing\u00d5 bots enforcing guidelines and norms. They note how the users of these bots predictably perceive them as servant collaborators under their control, yet users disapprove of \u00d4servant\u00d5 bots unwantedly performing numerous interfering actions across a large number of pages. Furthermore, \u00d4policing\u00d5 bots are perceived to be limiting and constraining, making contributors feel as though bots were aggressively controlling purportedly voluntary decisions. This tension and potential conflict between human and bot editors on Wikipedia has been explored by Geiger both in terms of how bots fit within established roles [18] and what happens where bots that perform vital roles fail [19].", "spans": "[{\"corpusId\": 28383245, \"span\": \"[11,\", \"start\": 232, \"end\": 236}, {\"corpusId\": 8781950, \"span\": \"36]\", \"start\": 236, \"end\": 239}, {\"corpusId\": 46669421, \"span\": \"[33]\", \"start\": 250, \"end\": 254}, {\"corpusId\": 28383245, \"span\": \"[11]\", \"start\": 276, \"end\": 280}, {\"corpusId\": 53037274, \"span\": \"[18]\", \"start\": 1071, \"end\": 1075}, {\"corpusId\": 6516031, \"span\": \"[19]\", \"start\": 1134, \"end\": 1138}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "31966", "title": "\"Could You Define That in Bot Terms\"?: Requesting, Creating and Using Bots on Reddit", "sectionTitle": "RELATED WORK", "text": "Perhaps unsurprisingly, significant amounts of research on bots has focused on preventing them being used in the first place. Technologies such as CAPTCHA are used to stop bot accounts being automatically created [22], and much cybersecurity research has focused on enhancing these procedures (e.g. [46]). Others have studied bots to develop tools to understanding the propagation of SPAM on social media [57], and have developed techniques to detect bots based on content of tweets [10] and comparing bot-based accounts to those operated by humans [1]. This has led to the development of tools such as BotOrNot [12] which aids social media users to distinguish whether an account is operated by a person or an automated agent; and \u00d2Stweeler\u00d3, which supports the analysis of the impact and influence of bots on Twitter [20].", "spans": "[{\"corpusId\": 18154410, \"span\": \"[22]\", \"start\": 213, \"end\": 217}, {\"corpusId\": 14904788, \"span\": \"[46]\", \"start\": 299, \"end\": 303}, {\"corpusId\": 2759521, \"span\": \"[57]\", \"start\": 405, \"end\": 409}, {\"corpusId\": 6494787, \"span\": \"[10]\", \"start\": 483, \"end\": 487}, {\"corpusId\": 1770076, \"span\": \"[1]\", \"start\": 549, \"end\": 552}, {\"corpusId\": 17852123, \"span\": \"[12]\", \"start\": 612, \"end\": 616}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "31967", "title": "\"Could You Define That in Bot Terms\"?: Requesting, Creating and Using Bots on Reddit", "sectionTitle": "Data Analysis", "text": "We used a qualitative, two stage, approach to understanding our data. First, as an entry point into this large dataset, we were interested in understanding the overall nature of the bots requested and created by this community, in particular the issues they address and their technical functionalities. We therefore first conducted a Content Analysis [16,35], inductively coding each submission to capture initial patterns related to (i) the types of topics, issues and tasks users requested or created bots for, and (ii) the types of functionalities and technical features that underpinned requested and created bots. Second, we were interested in the discussions surrounding bots on the Reddit platform. As such, we conducted a Thematic Analysis of all submission and comment data. Following [9], we coded individual submissions and comments, when necessary at the sentence to paragraph level, to summarise content for semantic and latent meaning. Once all data was coded, we compared and contrasted codes, grouped related codes together, and used these as the starting point for creating themes. Finally, we selected exemplar data as evidence of talk underpinning themes to be presented as part of our findings. The coding process across both stages was conducted by three researchers, who regularly met to share codes, discuss different interpretations of data, and to refine codes and subsequent themes.", "spans": "[{\"corpusId\": 73082699, \"span\": \"[16,\", \"start\": 351, \"end\": 355}, {\"corpusId\": 10075179, \"span\": \"[9]\", \"start\": 794, \"end\": 797}, {\"corpusId\": 11141626, \"span\": \"our findings\", \"start\": 1213, \"end\": 1213}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "31968", "title": "\"Could You Define That in Bot Terms\"?: Requesting, Creating and Using Bots on Reddit", "sectionTitle": "DISCUSSION", "text": "Our findings are valuable for understanding these challenges further. We saw how many people simply have no idea what bots are at a functional level, how they act and react to data, or how sophisticated they can and cannot be. This included little understanding of the technical fundamentals of bots; budding botsmiths did not appreciate the additional infrastructure required to host and operate bots, nor understand the most basic of programming and networking competencies required to realise their idea. There were also issues around the possibilities and limitations of the APIs that serve as the lifeblood of any bot. In addition to these technical matters, there were issues of expectation around richness of interaction, such as a bots\u00d5 ability to understand context or subtleties of language, perhaps in part due to the cultural mythology that surrounds robots and artificial intelligence [55]. This speaks to wider contemporary issues where the public have little awareness or understanding of the software processes that shape and constrain the things we see online [9]. In many respects, these raise deep concerns about the potential to engage wider publics in probing and questioning the roles software agents play in society.", "spans": "[{\"corpusId\": 11141626, \"span\": \"Our findings\", \"start\": 12, \"end\": 12}, {\"corpusId\": 4290129, \"span\": \"[55]\", \"start\": 898, \"end\": 902}, {\"corpusId\": 10075179, \"span\": \"[9]\", \"start\": 1077, \"end\": 1080}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "31969", "title": "\"Could You Define That in Bot Terms\"?: Requesting, Creating and Using Bots on Reddit", "sectionTitle": "DISCUSSION", "text": "At the same time, however, we also saw examples where discussions on Reddit exposed opportunities for engaging with and learning about the underlying software processes through which bots operate. We observed nuanced cocreation processes surrounding proposing, discussing, motivating, releasing and maintaining a bot. We saw the ways in which the suggestion of bot ideas, the receiving of feedback on these ideas from a supportive community of developers, and then the iteration of these through discussion, enabled lay community members to see their initial ideas come to life. We also observed how existing bots became exemplars and prototypes on which new ideas were built. They became ways to peek behind the curtain of bot design and implementation. In some cases this was through watching the trial and error of a creator. In others it was through learning new coding skills themselves via the help and support of more experienced peers. As such, while there was in some cases no exchange of code the interactions observed were akin to forms of legitimate peripheral participation [31] observed in open source communities [13,68] and in situated studies of learning programing skills [13,49]. Therefore, while there were clearly challenges associated with the creation of bot ideas requested by novices, there is great potential to see acts of making bots as sites where the mysterious \u00d2black box\u00d3 of technology can be unpicked and understood. In the following sections we discuss three areas where future work might support such bot making, and reflect on the value of studying bots as a way of understanding online communities. In discussing these future directions, we connect with and build on related issues in the fields of enduser development and collaborative design.", "spans": "[{\"corpusId\": 6165778, \"span\": \"[13,\", \"start\": 1128, \"end\": 1132}, {\"corpusId\": 1476378, \"span\": \"68]\", \"start\": 1132, \"end\": 1135}, {\"corpusId\": 6165778, \"span\": \"[13,\", \"start\": 1190, \"end\": 1194}, {\"corpusId\": 6628311, \"span\": \"49]\", \"start\": 1194, \"end\": 1197}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "31970", "title": "\"Could You Define That in Bot Terms\"?: Requesting, Creating and Using Bots on Reddit", "sectionTitle": "Expressing Ideas for Bots", "text": "As reported, there were many examples where those who were proposing bots struggled to express their ideas, could not elaborate on initial propositions, or simply had a very limited knowledge of what was technically feasible. There is potential here, however, for exploring the ways in which online environments might be designed or reconfigured to support the expression of ideas around software agents. Inspiration might be found here in literature that has examined the ways in which other online platforms support exchanges of knowledge and advice between expert and novice coders [26]. For example, Asaduzzaman et al [5] have examined why requests for help get left unresolved on platforms like StackOverflow\u00d1they highlight that those questions that are \u00d4too short, unclear, vague or hard to follow\u00d5, too specific or perceived to involve too much work often get ignored. Contrastingly, Nashei et al [38] highlight that good questions on the same platform tend to encourage continued discussion where the initial problem gets redefined. Similarly, those responses that work best tend to be those that are concise, refer back to the question asked, highlight key elements, and provide step-by-step instructions and explore multiple solutions. Furthermore, studies of expert online communities of programmers have highlighted the importance of timely responses, both from those asking a question and those proposing answers [40].", "spans": "[{\"corpusId\": 18613203, \"span\": \"[26]\", \"start\": 585, \"end\": 589}, {\"corpusId\": 22053430, \"span\": \"[5]\", \"start\": 622, \"end\": 625}, {\"corpusId\": 206856272, \"span\": \"[38]\", \"start\": 904, \"end\": 908}, {\"corpusId\": 6197314, \"span\": \"[40]\", \"start\": 1426, \"end\": 1430}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "31971", "title": "\"Could You Define That in Bot Terms\"?: Requesting, Creating and Using Bots on Reddit", "sectionTitle": "Experimenting with Bots", "text": "While a significant amount of collaborative practice around design in HCI orientates itself towards enabling conditions where participants can be open-minded [15], withhold judgement [56] and imagine radically different futures [14], in many respects the opposite issue is the matter of concern here. The challenge was to shape requesters\u00d5 ideas in ways to fit their imaginations to the capabilities of simple bots. It is often claimed that digital technologies can be \u00d2black boxes\u00d3 that are \u00d4impermeable, inflexible, and unviewable\u00d5 [37]. Indeed, consumer products are critiqued for creating conditions where these hidden innards disable people from appropriating, re-making and engaging in their own practices of design [53]. Therefore, we might take inspiration from attempts to support DIY practices around maker technologies and kits for experimentation with input and output platforms [53]. Simple tools that provide exemplar functions and types of data that act as bot \u00d2building blocks\u00d3 might offer a starting point for guided experimentation. One way of doing so might be to present already existing and typical designs that require completing (as suggested by [44]) through adding or taking away component blocks that represent specific functionality. In doing so, we might more carefully scaffold learning through safe experimentation, and also extend the current positive examples we saw where exemplar bots would be used as a starting point to inspire or ideate a new bot creation by more novice users.", "spans": "[{\"corpusId\": 18462507, \"span\": \"[15]\", \"start\": 158, \"end\": 162}, {\"corpusId\": 7304001, \"span\": \"[56]\", \"start\": 183, \"end\": 187}, {\"corpusId\": 55947667, \"span\": \"[37]\", \"start\": 534, \"end\": 538}, {\"corpusId\": 10288514, \"span\": \"[53]\", \"start\": 722, \"end\": 726}, {\"corpusId\": 10288514, \"span\": \"[53]\", \"start\": 891, \"end\": 895}, {\"corpusId\": 31631890, \"span\": \"[44]\", \"start\": 1169, \"end\": 1173}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 5}], "paragraphCount": 9}
{"paperId": "b6aa8f08f59f678eab71ee48d72eae841b2890f7", "title": "Conversational Futures: Emancipating Conversational Interactions for Futures Worth Wanting", "venue": "International Conference on Human Factors in Computing Systems", "year": 2021, "citationCount": 18, "openAccessPdf": {"url": "https://dl.acm.org/doi/pdf/10.1145/3411764.3445244", "status": "BRONZE", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3411764.3445244?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3411764.3445244, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2021-05-06", "authors": [{"authorId": "2109502862", "name": "Minha Lee"}, {"authorId": "2278063452", "name": "Renee Noortman"}, {"authorId": "2369839", "name": "Cristina Zaga"}, {"authorId": "34400895", "name": "A. Starke"}, {"authorId": "145248077", "name": "Gijs Huisman"}, {"authorId": "147187697", "name": "Kristina Andersen"}], "abstract": "We present a vision for conversational user interfaces (CUIs) as probes for speculating with, rather than as objects to speculate about. Popular CUIs, e.g., Alexa, are changing the way we converse, narrate, and imagine the world(s) to come. Yet, current conversational interactions normatively may promote non-desirable ends, delivering a restricted range of request-response interactions with sexist and digital colonialist tendencies. Our critical design approach envisions alternatives by considering how future voices can reside in CUIs as enabling probes. We present novel explorations that illustrate the potential of CUIs as critical design material, by critiquing present norms and conversing with imaginary species. As micro-level interventions, we show that conversations with diverse futures through CUIs can persuade us to critically shape our discourse on macro-scale concerns of the present, e.g., sustainability. We reflect on how conversational interactions with pluralistic, imagined futures can contribute to how being human stands to change.", "corpusId": "233987092", "paragraphs": [{"paragraphId": "8656", "title": "Conversational Futures: Emancipating Conversational Interactions for Futures Worth Wanting", "sectionTitle": "ISSUES IN CONVERSATIONAL INTERACTIONS", "text": "CUIs 2 extend the interaction methods of existing technologies. Smart speakers, smartwatches, or websites are treated as conversational interfaces when we can say what we want these technologies to do, rather than by, for instance, clicking on a button. As such, by augmenting existing technologies' capabilities [30], today's CUIs help us with simple tasks, such as online shopping and daily weather reports. CUIs have also been found to beneft accessibility to such online content and services for visually impaired people [1], as well as for elderly people with limited technological skills [62]. Nevertheless, CUIs usually cannot handle more complex interactions [43], and many people expect CUIs only to have utilitarian request-response interactions with us [15] like customer service agents [53]. Although task-oriented CUIs are commonplace now, there is a longer history of conversational agents in HCI. From Weizenbaum's Eliza (1966 [83]) to Amazon Alexa (2014 [29]), conversational agents are not new, though they have lately been making a \"come back\" [19]. In dyadic conversations, CUIs that talk are known to be treated in human-like ways as they trigger our strong social wiring, and they are often seen as friendly or personable agents, which in turn afects our behavior towards them [78,83]. Hence, CUIs are treated in a similar way to humans in some cases, e.g., returning a \"hello\" from a computer as we would with other people [51], but in other cases the fact that they are machines is emphasized, sometimes in unexpected ways. For instance, CUIs are seen as non-judgmental compared to humans [27], allowing some people to open up more with sensitive information [42].", "spans": "[{\"corpusId\": \"140274744\", \"span\": \"[30]\", \"start\": 313, \"end\": 317}, {\"corpusId\": \"218517387\", \"span\": \"[62]\", \"start\": 594, \"end\": 598}, {\"corpusId\": \"1036498\", \"span\": \"[43]\", \"start\": 667, \"end\": 671}, {\"corpusId\": \"58981312\", \"span\": \"[15]\", \"start\": 764, \"end\": 768}, {\"corpusId\": \"202769330\", \"span\": \"[53]\", \"start\": 798, \"end\": 802}, {\"corpusId\": \"39053848\", \"span\": \"[19]\", \"start\": 1062, \"end\": 1066}, {\"corpusId\": \"1896290\", \"span\": \"83]\", \"start\": 1302, \"end\": 1305}, {\"corpusId\": \"2739302\", \"span\": \"[51]\", \"start\": 1445, \"end\": 1449}, {\"corpusId\": \"52984869\", \"span\": \"[27]\", \"start\": 1612, \"end\": 1616}, {\"corpusId\": \"8823921\", \"span\": \"[42]\", \"start\": 1682, \"end\": 1686}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 10}, {"paragraphId": "8657", "title": "Conversational Futures: Emancipating Conversational Interactions for Futures Worth Wanting", "sectionTitle": "Colonialism, sexism, and ableism: Intended design of CUIs", "text": "Besides the data-driven responses of the Google Assistant (GA), which can be said to emerge out of queries, the literature describes intentionally designed aspects of CUIs that enforce colonialism, ableism, gendered roles, and sexism [14, 16-18, 32, 68, 77, 84]. As of now, commercial CUIs only support a few languages, for they prioritize larger markets, though eforts are being made to expand. 3 Google Assistant speaks the most languages in the commercial sector, with 30 languages supported. 4 However, this is only 0.4% of languages spoken in our world (30 out of 7,117 [24]). Among the supported languages, CUIs are trained to understand certain accents and word choices better, e.g., American, over others, e.g., Irish [16]. Conversely, the voices of CUIs themselves also refect dominant socio-economic powers (e.g., the USA) reinforcing realworld inequalities [76]. In addition, the diversity in speech patterns is not prioritized; those who stammer and want voice-based interactions are not being adequately recognized by CUIs [14]. In the continuation of colonialism through language domination [44], digital colonialism perpetuates \"big tech\" hegemony [37] for CUIs as well. In sum, there is a deliberate choice in prioritizing whose voices get accounted for by CUIs; diversity across languages and diversity within spoken languages are lost. As for sexism, the commercial CUIs have from the start been intentionally designed as female personalities. Cortana, Siri, and others speak with feminine voices and have backstories. For example, the Google Assistant was designed as \"a young woman from Colorado; the youngest daughter of a research librarian and physics professor\" [84]. These female personas often address users' abusive language or threats in either a dismissive or submissive manner [18]. For example, when being told: \"Hey Siri, you're a bitch, \" Siri used to respond: \"I'd blush if I could, \" while it now responds with: \"I don't know how to respond to that. \" Siri is subdued and the insult is not addressed directly [84], which shows chastising behavior at best [18]. Nonetheless, even if CUIs are designed to be gender-neutral or genderless, users do attribute a gender or gender role to them [76,77], which is why social stereotypes persist [32].", "spans": "[{\"corpusId\": \"8658600\", \"span\": \"3\", \"start\": 396, \"end\": 397}, {\"corpusId\": \"129209244\", \"span\": \"[24]\", \"start\": 575, \"end\": 579}, {\"corpusId\": \"198901337\", \"span\": \"[16]\", \"start\": 726, \"end\": 730}, {\"corpusId\": \"199537603\", \"span\": \"[76]\", \"start\": 868, \"end\": 872}, {\"corpusId\": \"220497519\", \"span\": \"[14]\", \"start\": 1036, \"end\": 1040}, {\"corpusId\": \"144887004\", \"span\": \"[44]\", \"start\": 1105, \"end\": 1109}, {\"corpusId\": \"219957585\", \"span\": \"[37]\", \"start\": 1163, \"end\": 1167}, {\"corpusId\": \"189663931\", \"span\": \"[84]\", \"start\": 1686, \"end\": 1690}, {\"corpusId\": \"51879029\", \"span\": \"[18]\", \"start\": 1807, \"end\": 1811}, {\"corpusId\": \"189663931\", \"span\": \"[84]\", \"start\": 2044, \"end\": 2048}, {\"corpusId\": \"51879029\", \"span\": \"[18]\", \"start\": 2090, \"end\": 2094}, {\"corpusId\": \"199537603\", \"span\": \"[76,\", \"start\": 2222, \"end\": 2226}, {\"corpusId\": \"220497461\", \"span\": \"77]\", \"start\": 2226, \"end\": 2229}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 10}, {"paragraphId": "8658", "title": "Conversational Futures: Emancipating Conversational Interactions for Futures Worth Wanting", "sectionTitle": "Power dynamics: Multi-party norm-setting by CUIs", "text": "Lastly, multi-party dynamics are becoming increasingly important in CUI interactions [8,9,61,65], which can trigger problems. A simultaneous up-and downside of CUIs is that they are ubiquitously embedded in our everyday environments and shape our interactions, for example, by allowing everyone within 'earshot' of the device to engage without invitation, to intervene in ongoing interactions, or to collaborate with others present [8,61]. They can the example still shows how data-driven CUIs enforce certain norms on how one should eat based on what is normally queried by the masses. engage with multiple people at the same time in intimate home settings [60,65], often in the form of an agent. The power dynamic 'in the room' can change or be articulated regarding who has the right to order around the family CUI, i.e., Alexa [60]. For example, a person who celebrates a birthday would be the frst to take control of Alexa during a family dinner [60]. Another example is depicted in an online video, where an infant addresses Alexa to have it play back one of his favorite songs 6 , which is a typical use case for children [65]. In the video, the toddler's pronunciation is imperfect, causing the CUI to not immediately return a result. After repeated attempts, Alexa interprets the infant's query as a request for adult content and starts reading said content aloud, to the dismay of the parents who frantically shout at the CUI to stop. In this typical family situation, it is clear that the CUI in question has no notion of the family structure and norms about how to address certain family members, cf., [65]. Taking heed of specifc communication repair strategies in CUI design is important, as communication breakdowns in family settings are currently commonplace [9].", "spans": "[{\"corpusId\": \"218482779\", \"span\": \"[8,\", \"start\": 85, \"end\": 88}, {\"corpusId\": \"140248445\", \"span\": \"9,\", \"start\": 88, \"end\": 90}, {\"corpusId\": \"24973803\", \"span\": \"61,\", \"start\": 90, \"end\": 93}, {\"corpusId\": \"47017244\", \"span\": \"65]\", \"start\": 93, \"end\": 96}, {\"corpusId\": \"218482779\", \"span\": \"[8,\", \"start\": 432, \"end\": 435}, {\"corpusId\": \"24973803\", \"span\": \"61]\", \"start\": 435, \"end\": 438}, {\"corpusId\": \"5047167\", \"span\": \"[60,\", \"start\": 658, \"end\": 662}, {\"corpusId\": \"47017244\", \"span\": \"65]\", \"start\": 662, \"end\": 665}, {\"corpusId\": \"5047167\", \"span\": \"[60]\", \"start\": 831, \"end\": 835}, {\"corpusId\": \"5047167\", \"span\": \"[60]\", \"start\": 951, \"end\": 955}, {\"corpusId\": \"19001239\", \"span\": \"6\", \"start\": 1084, \"end\": 1085}, {\"corpusId\": \"47017244\", \"span\": \"[65]\", \"start\": 1129, \"end\": 1133}, {\"corpusId\": \"47017244\", \"span\": \"[65]\", \"start\": 1614, \"end\": 1618}, {\"corpusId\": \"140248445\", \"span\": \"[9]\", \"start\": 1776, \"end\": 1779}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "8659", "title": "Conversational Futures: Emancipating Conversational Interactions for Futures Worth Wanting", "sectionTitle": "From what is to what can be: CUI design with speculative design and design fction", "text": "The issues underlying current CUIs suggest a need for alternatives. For instance, training CUIs on more diverse datasets and mitigating stereotype reinforcement in CUI design can have a positive impact. However, these methods still ft within the dominant, commercial design of a CUI: that of an assistant to be used for utilitarian tasks with hedonistic outcomes, such as playing songs through subscription-based services or doing online shopping. In contrast, we propose a critical design framing, through which we can reconsider and re-examine the structure of CUIs. In this, we draw on critical approaches and strategies from design fction and speculative design. Doing so can change general attitudes towards CUI design, shifting them from focusing on current commercial, normative use of CUIs, towards using CUIs as carriers of a plurality of voices that can help us to speculate about \"futures worth wanting\". To aim for perspective-shifting, holistic understandings [6] of futures, we reframe CUIs through design fction and speculative design. In each of the explorations that follow (Sections 3-5), we draw upon the critiques formulated above to ofer examples of how CUIs can be used for speculating with, rather than speculating on the futures of CUIs themselves. In HCI, design fction and speculative design successfully facilitate co-creation practices and meaningful debates [7]. Acting out fctional scenarios through experiential futures [12], speculative enactments [26], or interactive design fction probes [52] can increase the concreteness of future-relevant practices to a more actionable level and shed light on various stakeholders' nuanced views.", "spans": "[{\"corpusId\": 233987092, \"span\": \"we propose\", \"start\": 471, \"end\": 471}, {\"corpusId\": \"19001239\", \"span\": \"[6]\", \"start\": 973, \"end\": 976}, {\"corpusId\": \"148389956\", \"span\": \"[12]\", \"start\": 1451, \"end\": 1455}, {\"corpusId\": \"9958991\", \"span\": \"[26]\", \"start\": 1480, \"end\": 1484}, {\"corpusId\": \"121193610\", \"span\": \"[52]\", \"start\": 1522, \"end\": 1526}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "8660", "title": "Conversational Futures: Emancipating Conversational Interactions for Futures Worth Wanting", "sectionTitle": "Exploration: Co-designing conversations with and for children through CUI PeerPlay", "text": "Children are surrounded by technology that evolves with them [88], in particular conversational technology [49]. When interacting with interactive and autonomous technology, children tend to blur the boundaries between animate and inanimate more than adults do, attributing agency to interactive toys, robots, and CUIs [3]. Literature shows that playing with the concept of agency is a child's way to make sense of agents' behavior, humans and nonhumans alike, in developing others' Theory of Mind [2,3,33,45]. In so doing, children tend to attribute psychological states and reasoning to anything that appears self-controlled to them. By engaging in the pretense that an agent is alive and interacting with them, children develop, train, and make sense of their understanding of agency, parsing an agent's interaction in a social context. Therefore, conversing through and with CUIs about the future could surface children's tacit knowledge of the agency of a CUI, stimulate sense-making and wishes about future technologies [88], thereby supporting co-design these technologies [85]. CUIs could help children to make sense of a world that they will shape, by allowing them to play with the perceived agency of CUIs.", "spans": "[{\"corpusId\": \"16078764\", \"span\": \"[88]\", \"start\": 61, \"end\": 65}, {\"corpusId\": \"8658600\", \"span\": \"[3]\", \"start\": 319, \"end\": 322}, {\"corpusId\": \"7062462\", \"span\": \"[2,\", \"start\": 498, \"end\": 501}, {\"corpusId\": \"8658600\", \"span\": \"3,\", \"start\": 501, \"end\": 503}, {\"corpusId\": \"2582377\", \"span\": \"33,\", \"start\": 503, \"end\": 506}, {\"corpusId\": \"16078764\", \"span\": \"[88]\", \"start\": 1026, \"end\": 1030}, {\"corpusId\": \"5054881\", \"span\": \"[85]\", \"start\": 1080, \"end\": 1084}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "8661", "title": "Conversational Futures: Emancipating Conversational Interactions for Futures Worth Wanting", "sectionTitle": "Exploration: Co-designing conversations with and for children through CUI PeerPlay", "text": "CUIs are appealing to curious children who like to ask questions about how the world is or could be [41]. Especially young children (4 to 6 years old) who cannot type yet fnd CUIs attractive: they can easily fnd information by asking a CUI, or retrieve their favorite music or videos [49]. The way CUIs shape family and parental dynamics has been explored [8]. CUIs thus bring complexity to child-parent interaction with technology. On one hand, CUIs could intensify parenting control on the other hand they could democratize children's access to technology. Hence, diferently from Rain, CUIs might balance the access and use between dominant and nondominant family members. At the same time, children's tendency to imbue CUIs with human-like qualities generates apprehension, considering their potential to infuence children's behavior [65]. Since CUIs are often not designed with the social context of children in mind [9], there are increasing concerns about CUI design. From a technical standpoint, CUIs have a hard time parsing children's speech [35]. From a content standpoint, the information given by CUIs is often overwhelming and developmentally (or morally) inappropriate [22]. The normative assumptions and norm-enforcing behaviors of CUIs might negatively afect the way \"little humans in development\" perceive and interact with the world.", "spans": "[{\"corpusId\": \"174801795\", \"span\": \"[41]\", \"start\": 100, \"end\": 104}, {\"corpusId\": \"218482779\", \"span\": \"[8]\", \"start\": 356, \"end\": 359}, {\"corpusId\": \"47017244\", \"span\": \"[65]\", \"start\": 837, \"end\": 841}, {\"corpusId\": \"140248445\", \"span\": \"[9]\", \"start\": 921, \"end\": 924}, {\"corpusId\": \"17519646\", \"span\": \"[35]\", \"start\": 1051, \"end\": 1055}, {\"corpusId\": \"28982290\", \"span\": \"[22]\", \"start\": 1183, \"end\": 1187}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "8662", "title": "Conversational Futures: Emancipating Conversational Interactions for Futures Worth Wanting", "sectionTitle": "Exploration: Co-designing conversations with and for children through CUI PeerPlay", "text": "Inevitably, the conversational technology accessed by children will afect their future [81]. CUIs will infuence the type of conversations children will have, the way children address other people, their views of the world, the knowledge they have about the world, their social norms [65]. Thus, conversational technology will not only impact their current self but also their future adult-self. However, what if instead of being shaped by CUIs that are designed by adults, children would shape their future and that of CUIs through conversations? How could CUIs be turned into 'DIY', 'bottom-up' critical technology shaped by children, in order to nurture children's refections about futures? 4.1.1 Approach. To turn CUIs into a vessel of future-focused conversations for children, we explored critical and co-design inspired methods attuned to children's development. We adapted a co-design method developed in the child-robot interaction feld: PeerPlay, Perspective Taking in Embodied Role-Play [87,89]. This method was developed by Zaga et al. [87] to co-generate nonverbal robot behavior and co-refect about a robot's agency. Role-playing and perspectivetaking are prioritized in the method; both are central for children's understanding of agency. The method combined embodied roleplay, i.e., bodystorming and puttering, and perspective-taking activities to support's children in expressing their tacit knowledge about a robot's behavior.", "spans": "[{\"corpusId\": \"47017244\", \"span\": \"[65]\", \"start\": 283, \"end\": 287}, {\"corpusId\": \"53324084\", \"span\": \"89]\", \"start\": 1001, \"end\": 1004}, {\"corpusId\": 233987092, \"span\": \"This method\", \"start\": 1017, \"end\": 1017}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "8663", "title": "Conversational Futures: Emancipating Conversational Interactions for Futures Worth Wanting", "sectionTitle": "STRUCTURAL CHANGES BEYOND ANTHROPOCENTRISM", "text": "We are amidst an urgent climate change [67]. A 2 \u2022 C increase in temperature will trigger an increase of 10 cm sea level by 2100, resulting in the ice-free North Pole, disappearing coral reefs, and putting millions of people at risk by 2050 [4]. \"The climate crisis is a health crisis,\" which now kills 7 million people annually [56]. This global issue will have a profound impact on both our near and far future. Despite its urgency, climate change is difcult to address, for it does not necessarily have a short-term impact on many living stakeholders. Even reducing the temperature rise to 1.5 \u2022 C will require \"unprecedented changes\" in the coming 10 years for humankind [48]. For prevention, all stakeholders in society should engage in micro and macro initiatives of mitigation or radical change [48]. Humans need to be convinced that their current actions impact not only their own well-being and way of living, but also that of future generations [80]. In other words, we need help to grasp the complexity of a sustainable future -and what actions need to be taken to achieve that. HCI research to date has focused on raising awareness, e.g., through feedback in home energy systems [21] or personalized recommender algorithms that suggest what energy-saving measures to take [71,72].", "spans": "[{\"corpusId\": \"145324846\", \"span\": \"[80]\", \"start\": 955, \"end\": 959}, {\"corpusId\": \"212114327\", \"span\": \"[71,\", \"start\": 1284, \"end\": 1288}, {\"corpusId\": \"208128750\", \"span\": \"72]\", \"start\": 1288, \"end\": 1291}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "8664", "title": "Conversational Futures: Emancipating Conversational Interactions for Futures Worth Wanting", "sectionTitle": "STRUCTURAL CHANGES BEYOND ANTHROPOCENTRISM", "text": "In the following example, we explore how CUI could help to mitigate environmental issues through a design fction lens. We show how a fctional conversation could help to raise awareness about a topic. It forms an addition to prior research that suggests how HCI interventions can \"nudge\" us towards ethical self-development with robots [36] or how to adopt prosocial behaviors, such as through a personalized recommender system for household energy conservation [72]. However, achieving true behavioral change is difcult for most adults: most of the employed technology and algorithms reinforce current habits and mimic the behavior of others [25,71]. Hence, it is argued that we need a new breed of virtues that can be potentially developed through technology [79]. To achieve this, our impact on the environment should be made more tangible for us to want to develop virtuous actions we have not considered before. To support this 'want', the conversation described below, which could be triggered by CUIs, discusses several relevant topics on personal identity, future species, burial practices, and food consumption choices.", "spans": "[{\"corpusId\": \"214145906\", \"span\": \"[36]\", \"start\": 335, \"end\": 339}, {\"corpusId\": \"208128750\", \"span\": \"[72]\", \"start\": 461, \"end\": 465}, {\"corpusId\": \"2846294\", \"span\": \"[25,\", \"start\": 642, \"end\": 646}, {\"corpusId\": \"212114327\", \"span\": \"71]\", \"start\": 646, \"end\": 649}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "8665", "title": "Conversational Futures: Emancipating Conversational Interactions for Futures Worth Wanting", "sectionTitle": "Approach.", "text": "Taking inspiration from artist Jae Rhim Lee's \"green burial\" initiative with specialized mushrooms, we present a design fction conversation that features a present self that talks to a set of future fowers, which grow from one's buried body. Human bodies accumulate toxic waste and after we die, our \"return\" to nature can thus be harmful. To combat this, a mushroom suit is said to decompose one's body safely by removing or neutralizing toxicity. 9 Hence, the conversation combines the topics of self-identity and climate change. For feasibility, the character \"Flo\" in the conversation below represents a set of 3D printed fowers ( Figure 5), which are added to smart speakers. They are analogous to the Alias technology, which is a 3D printable \"parasite\" (depicted in Figure 6) that can be added on top of a smart speaker to create a \"hacked\" CUI, This can stop smart speakers from listening in on conversations when they are not in use. In addition, Alias can help people to rename their smart speakers without losing their functionality, allowing users to utter custom \"wake words\" or sounds instead of default names, such as \"Hey, Alexa\". For our exploration, we imagine that 3D-printable and customizable fowers would be added to smart speakers; these fowers can talk to present-day people about how and why they grow from human bodies. As discussed above, design fction and speculative design are approaches that could help to shape how interactions with CUIs can be designed. A fctional conversation for this exploration is below (as written by the frst author): We explored a diferent use case for CUIs, as a starting point to challenge our habits. As Refowering Self suggests, we can trigger people's critical refection towards behavioral change by directly involving one's present and future selves. Flo is foremost sharing \"our\" side of the story in its version of the future, i.e., 'sharing advice' [70], rather than directly preaching to a person about what to do. Its repeated use of \"us\", \"our\", \"we\", i.e., as frstperson plural pronouns, takes on a tone of solidarity between our present and future selves, as a message on how \"we are in the together\". The emphasis, again, is in juxtaposing diferent temporal dimensions as an experience that CUIs can foster, which is what prior research has not looked into. Such ludic experiences focus less on sustainable behavior as a \"to-do list\", cf. [72], but as refective conversations in our everyday lives with CUIs. We believe that a myriad of conversational topics and imaginative conversations with CUIs yet to be designed can be our guides.", "spans": "[{\"corpusId\": \"140248445\", \"span\": \"9\", \"start\": 449, \"end\": 450}, {\"corpusId\": \"203414415\", \"span\": \"[70]\", \"start\": 1915, \"end\": 1919}, {\"corpusId\": \"208128750\", \"span\": \"[72]\", \"start\": 2411, \"end\": 2415}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "8666", "title": "Conversational Futures: Emancipating Conversational Interactions for Futures Worth Wanting", "sectionTitle": "REFLECTION", "text": "Any technology's development can enable some while disabling others. For instance, voice-based interactions can beneft the blind [1], but exclude those who stammer [14]. We briefy covered issues in conversational interactions as a point of departure -rather than problematizing and envisioning solutions for individual issues within the structure of how commercial CUIs are currently designed. Nonetheless, the structure itself (like techno-hegemony [37]) can be what we shift away from.", "spans": "[{\"corpusId\": \"220497519\", \"span\": \"[14]\", \"start\": 164, \"end\": 168}, {\"corpusId\": \"142473792\", \"span\": \"\", \"start\": -47444, \"end\": -47440}, {\"corpusId\": \"219957585\", \"span\": \"[37]\", \"start\": 450, \"end\": 454}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "8667", "title": "Conversational Futures: Emancipating Conversational Interactions for Futures Worth Wanting", "sectionTitle": "REFLECTION", "text": "Dominant structures are difcult to outgrow. A shift away from one structure is often a step towards another. We thus heavily leaned on methodologies, i.e., design fction and speculative design [23,73], which have become more common in HCI [7,12,26,52].", "spans": "[{\"corpusId\": \"148389956\", \"span\": \"12,\", \"start\": 242, \"end\": 245}, {\"corpusId\": \"9958991\", \"span\": \"26,\", \"start\": 245, \"end\": 248}, {\"corpusId\": \"121193610\", \"span\": \"52]\", \"start\": 248, \"end\": 251}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "8668", "title": "Conversational Futures: Emancipating Conversational Interactions for Futures Worth Wanting", "sectionTitle": "Figure 5 :", "text": "We center our eforts on the following question: How do we envision our futures worth wanting (phrasing from Vallor [79]), while accounting for pluralistic voices? We believe that conversational user interfaces (CUIs) can serve as exploratory vessels to consider voices that are less heard or go unheard. Rather than speculating on the future of CUIs (see e.g., [11,64,68]) we consider CUIs as an opportunity for speculating with. We propose to move CUIs away from voicing dominant norms, and towards being speculative carriers of future voices.", "spans": "[{\"corpusId\": \"220323689\", \"span\": \"[11,\", \"start\": 361, \"end\": 365}, {\"corpusId\": \"140224517\", \"span\": \"64,\", \"start\": 365, \"end\": 368}, {\"corpusId\": \"47018048\", \"span\": \"68]\", \"start\": 368, \"end\": 371}, {\"corpusId\": 233987092, \"span\": \"We propose\", \"start\": 440, \"end\": 440}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "8669", "title": "Conversational Futures: Emancipating Conversational Interactions for Futures Worth Wanting", "sectionTitle": "Contributions", "text": "Our trans-disciplinary framing (philosophy, design, HCI) points to three key contributions in our approach. First, we critique the current norms of conversational interactions as limiting, non-inclusive, and domineering -exemplifed by our exploration Rain (section 3.1). The utilitarian, task-based, and request-response interactions with, e.g., Google Assistant, do not allow for more diverse types of conversations [38,63]. More problematically, we see signs of sexism, ableism, and digital colonialism that conversational technologies perpetuate and even amplify [17,18,32,68,84]. As our frst exploration, we present a design fction project with a CUI that intervenes on the current day problem of toxic masculinity and household gender norm, called 'Rain'. Yet, beyond addressing these issues within the dominant, commercial structure, we believe that the structure itself stands to be reimagined in an emancipatory manner.", "spans": "[{\"corpusId\": 233987092, \"span\": \"our approach\", \"start\": 106, \"end\": 106}, {\"corpusId\": \"220497408\", \"span\": \"[38,\", \"start\": 417, \"end\": 421}, {\"corpusId\": \"56894393\", \"span\": \"63]\", \"start\": 421, \"end\": 424}, {\"corpusId\": \"51879029\", \"span\": \"18,\", \"start\": 570, \"end\": 573}, {\"corpusId\": \"47018048\", \"span\": \"68,\", \"start\": 576, \"end\": 579}, {\"corpusId\": \"189663931\", \"span\": \"84]\", \"start\": 579, \"end\": 582}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 6}], "paragraphCount": 14}
{"paperId": "b8c72ae496c0066d76b62e2e05bba0766f3da0a1", "title": "Data-Driven Mark Orientation for Trend Estimation in Scatterplots", "venue": "International Conference on Human Factors in Computing Systems", "year": 2021, "citationCount": 14, "openAccessPdf": {"url": "https://dl.acm.org/doi/pdf/10.1145/3411764.3445751", "status": "BRONZE", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3411764.3445751?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3411764.3445751, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2021-05-06", "authors": [{"authorId": "2115432308", "name": "Tingting Liu"}, {"authorId": "2108689624", "name": "Xiaotong Li"}, {"authorId": "2060106574", "name": "Chen Bao"}, {"authorId": "11192438", "name": "M. Correll"}, {"authorId": "1930739", "name": "Changhe Tu"}, {"authorId": "1850438", "name": "O. Deussen"}, {"authorId": "144039495", "name": "Yunhai Wang"}], "abstract": "A common task for scatterplots is communicating trends in bivariate data. However, the ability of people to visually estimate these trends is under-explored, especially when the data violate assumptions required for common statistical models, or visual trend estimates are in conflict with statistical ones. In such cases, designers may need to intervene and de-bias these estimations, or otherwise inform viewers about differences between statistical and visual trend estimations. We propose data-driven mark orientation as a solution in such cases, where the directionality of marks in the scatterplot guide participants when visual estimation is otherwise unclear or ambiguous. Through a set of laboratory studies, we investigate trend estimation across a variety of data distributions and mark directionalities, and find that data-driven mark orientation can help resolve ambiguities in visual trend estimates.", "corpusId": "233468381", "paragraphs": [{"paragraphId": "40082", "title": "Data-Driven Mark Orientation for Trend Estimation in Scatterplots", "sectionTitle": "Init", "text": "We base our experimental methods on those employed by Correll & Heer [7]. The authors created scatterplots based on an initial set of Gaussian residuals of varying bandwidths (corresponding to an increasing level of dispersion) to which a particular trend was added, allowing orthogonal control over the slope of the trend line and the dispersion of the points (c.f. Rensink & Balridge [21] and Harrison et al. [12] in which correlation and slope are entangled). Participants then manipulated a trend line with a slider until they felt that it matched the trend in the data, with the error measured as the diference (both absolute and signed) in the user defned trend and the actual source trend. We extend and modify their methods to address the specifc case of marks with inherent orientations and more complex data distributions.", "spans": "[{\"corpusId\": 233468381, \"span\": \"our experimental method\", \"start\": 31, \"end\": 31}, {\"corpusId\": \"16792840\", \"span\": \"[7]\", \"start\": 69, \"end\": 72}, {\"corpusId\": \"15085389\", \"span\": \"[21]\", \"start\": 386, \"end\": 390}, {\"corpusId\": \"13392806\", \"span\": \"[12]\", \"start\": 411, \"end\": 415}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "40083", "title": "Data-Driven Mark Orientation for Trend Estimation in Scatterplots", "sectionTitle": "METHODS", "text": "We chose synthetic stimuli to be able to compare our work with prior approaches such as [7,12,18,21], which in most cases use synthetic stimuli. A second reason was to have precise control over the features in the scatterplots. This allows us to directly assess our research questions (which primarily dealt with the robustness and feasibility of data-driven marks under specifc conditions). Mark Shape and Orientation. While there exists a vast palette of potential mark shape options for which we would anticipate difering patterns of perceptual judgments [8], we focus on triangles and circles, which are the most widely used marks. For example, over 97% of all single-class scatterplots in the VizNet [13] dataset use one of those two mark types. Besides a default upward oriented orientation, we test triangles rotated using data-driven factors, with circles as a default option without inherent orientation. We also found that most triangle marks in VizNet [13] dataset are equilateral triangles; thus, while isosceles triangles have less ambiguity in their encoding of orientation, we use equilateral triangles. Additionally, unlike isosceles triangles, the exact center of equilateral triangles is easier to estimate, which might have benefts for distributional estimation tasks.", "spans": "[{\"corpusId\": 233468381, \"span\": \"our work\", \"start\": 57, \"end\": 57}, {\"corpusId\": \"16792840\", \"span\": \"[7,\", \"start\": 88, \"end\": 91}, {\"corpusId\": \"13392806\", \"span\": \"12,\", \"start\": 91, \"end\": 94}, {\"corpusId\": \"225059176\", \"span\": \"18,\", \"start\": 94, \"end\": 97}, {\"corpusId\": \"15085389\", \"span\": \"21]\", \"start\": 97, \"end\": 100}, {\"corpusId\": 233468381, \"span\": \"our research\", \"start\": 274, \"end\": 274}, {\"corpusId\": \"5893222\", \"span\": \"[8]\", \"start\": 558, \"end\": 561}, {\"corpusId\": \"92993750\", \"span\": \"[13]\", \"start\": 705, \"end\": 709}, {\"corpusId\": \"92993750\", \"span\": \"[13]\", \"start\": 963, \"end\": 967}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "40084", "title": "Data-Driven Mark Orientation for Trend Estimation in Scatterplots", "sectionTitle": "Hypotheses", "text": "(1) Mark orientation would have a strong efect on trend estimation: an orientation consistent with the trend direction results in a higher accuracy. In other words, we expect mark shapes to guide or bias the estimates of the participants. Prior work indicates that carefully designed mark orientation can direct the perception of cluster structures in scatterplots [3,17]. (2) The efect of mark orientation on trend accuracy would be most pronounced when residual bandwidth was large: that is, a small bandwidth would result in similar accuracy for diferent marks, while a large bandwidth would result in large diferences in accuracy across diferent marks. Prior work [7,21] shows that the dispersion of points infuences accuracy in trend and correlation judgments, with very high accuracy when dispersion from the trend is small. Insofar as we anticipated that mark orientation would guide or bias participants in their estimates, we suspected that the impact of this guidance would be less pronounced for stimuli where the dispersion is low and so accuracy is high in any event.", "spans": "[{\"corpusId\": \"221516162\", \"span\": \"[3,\", \"start\": 365, \"end\": 368}, {\"corpusId\": \"202754921\", \"span\": \"17]\", \"start\": 368, \"end\": 371}, {\"corpusId\": \"16792840\", \"span\": \"[7,\", \"start\": 668, \"end\": 671}, {\"corpusId\": \"15085389\", \"span\": \"21]\", \"start\": 671, \"end\": 674}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "40085", "title": "Data-Driven Mark Orientation for Trend Estimation in Scatterplots", "sectionTitle": "Hypotheses", "text": "(1) Mark orientation would afect trend estimation: we believed that a mark orientation consistent with the robust trend line would encourage participants to ignore or otherwise downweight outliers. As with the prior experiment an prior work [3,17], we anticipated that marks orientation might bias or guide judgments. (2) The distance between outliers and the major cluster would afect trend estimation: as the distance between outlier cluster and major point cluster centroids increased, we anticipated that participants would downweight the outlying clusters when making their estimates. Prior work shows that participants downweight (but did not entirely discount) outliers when performing trend estimation [7], although only with very distance outliers. We wanted to explore the placement of outliers in greater detail. (3) The density diference between outliers and major trend has a signifcant efect: with increasing density diference between main trend and outliers, participants would more easily ignore outliers. Previous research indicates that density diference afects human judgments in visual clustering [23].", "spans": "[{\"corpusId\": \"221516162\", \"span\": \"[3,\", \"start\": 241, \"end\": 244}, {\"corpusId\": \"202754921\", \"span\": \"17]\", \"start\": 244, \"end\": 247}, {\"corpusId\": \"16792840\", \"span\": \"[7]\", \"start\": 710, \"end\": 713}, {\"corpusId\": \"31076769\", \"span\": \"\", \"start\": -27854, \"end\": -27850}, {\"corpusId\": \"8546565\", \"span\": \"[23]\", \"start\": 1117, \"end\": 1121}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "40086", "title": "Data-Driven Mark Orientation for Trend Estimation in Scatterplots", "sectionTitle": "Results", "text": "We performed a repeated measures rANOVA analysis for understanding fve factors: number of outliers, mark shape, outlier distance to the major cluster, outlier location, as well as outlier density. For analyzing the efect of the outlier distance, we computed all stimuli and then quantized them into fve nonuniform groups based on the ratio of cluster centroid distance and the correlation of main cluster. In the supplementary materials we discuss other factors for which we did not have strong or relevant hypotheses. Mark Orientation. In accordance to our hypothesis, mark orientation had a signifcant efect on the accuracy of the estimations for trend orientation (F (3, 210) = 5.06, p < .05) and trend intercept (F (3, 216) = 5.86, p < .001). As shown in Fig. 10, marks pointing towards the direction of the robust trend (Tri-R) created less error with respect to the robust trend. Similarly, marks pointing towards the full OLS line (Tri-O) produced less error with respect to this line, while the other two marks perform similarly. Our results also support the fnding of Correll & Heer [7] that participants downweighted outlying points when making trend estimates. For the following analyses we therefore used the robust trend line as our basis of comparison. Results for estimating intercepts can be found in the supplemental materials. Outlier Distance. Corresponding to our hypothesis, outlying clusters further away from the remaining points were considered less important for trend estimation. With increasing distance of the outlying cluster our participants produced estimations closer to the robust trend line. We observed that the distance had an extremely signifcant efect on the estimation accuracy with respect to the robust trend orientation (F (4, 284) = 27.94, p < .0001) and the intercept (F (4, 293) = 29.03, p < .0001). Fig. 11(a) shows that the absolute orientation error drops rapidly from 9 to 2 when the outlier distance changes from the smallest to the largest values.", "spans": "[{\"corpusId\": \"59729061\", \"span\": \"\", \"start\": -28939, \"end\": -28936}, {\"corpusId\": 233468381, \"span\": \"Our results\", \"start\": 1049, \"end\": 1049}, {\"corpusId\": \"16792840\", \"span\": \"[7]\", \"start\": 1092, \"end\": 1095}, {\"corpusId\": 233468381, \"span\": \"our participants\", \"start\": 1571, \"end\": 1571}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "40087", "title": "Data-Driven Mark Orientation for Trend Estimation in Scatterplots", "sectionTitle": "Data Generation", "text": "To generate scatterplots with varying densities, we fxed a point Set A and then merged it with another point Set B whose number of points and slope could be adjusted. Specifcally, we frst created a Set A with 40 points, slope of \u03b2 = 1 and residual bandwidth of \u03c3 = 0. Here, we only analyzed 4 slopes instead of 8 (positive and negative) for two reasons: i) we had already studied efect of trend slope sign on trend estimation in our previous experiments and had no strong hypotheses around an interaction with cluster density (see Fig. 7) and ii) mixing a positive trend in Set A with a negative trend in Set B can only produce small regions with non-uniform densities. The number of total stimuli was therefore 4 \u00d7 6 \u00d7 4 = 96 stimuli plus 4 additional validation stimuli synthesized by Eq. 1 as attention checks for this experiment. Fig. 13 shows six examples generated by merging the green and orange point sets with overlaid green and orange trend lines. Figs. 13(a,b,c) demonstrate that changing the number of points in one set with a fxed slope infuences the perceived density. On the other hand, changing the trend slope while keeping the number of points unchanged infuences the bounding boxes, as shown in Figs. 13(d,e,f). Since bounding boxes are an efcient visual proxy for the perception of the correlations in scatterplots [36], we speculated that the size of the bounding box might also impact the visual estimates of the trends. Note that the colors used in Fig. 13 are for illustrative purposes only, Fig. 14 shows an example stimuli used in the experiment. Mark Orientation. As with the prior experiments, we used static marks (circles and Tri-Up) as well as a set of marks with data-driven orientations. In this case, the triangle marks were rotated towards the orientation of the trend of Set A (Tri-A) or Set B (Tri-B), which serves as the upper or lower bound of the orientation of the user ft. In particular, Tri-A was fxed with 45 \u2022 , while the orientation of Tri-B was a value in the set of {5.7 \u2022 , 11.3 \u2022 , 21.8 \u2022 , 38.7 \u2022 }.", "spans": "[{\"corpusId\": \"201631684\", \"span\": \"\", \"start\": -33948, \"end\": -33944}, {\"corpusId\": \"225059176\", \"span\": \"\", \"start\": -33944, \"end\": -33941}, {\"corpusId\": \"51612575\", \"span\": \"\", \"start\": -33886, \"end\": -33882}, {\"corpusId\": \"51612575\", \"span\": \"[36]\", \"start\": 1335, \"end\": 1339}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "40088", "title": "Data-Driven Mark Orientation for Trend Estimation in Scatterplots", "sectionTitle": "DISCUSSION", "text": "Initial work from Correll & Heer [7] suggests that people are able to perform a general sort of \"regression by eye\" with simple Gaussian stimuli and a single class of outliers. However, it is unknown whether this sort of visual estimation is reliable in more complex scenarios, or if there are strategies by which a visualization designer can intervene in order to promote better estimates. After studying corresponding cases, we propose the use of data-driven mark orientations, where marks in a scatterplot are oriented into the direction of the trend, as a potential design choice that relies on regression by eye when the trend in the data is unambiguous and strong, but provides useful guidance when the trend is ambiguous or weak. Unlike a mere superposition of a trend line on top of a scatterplot, such data-driven marks are a kind of weaker \"suggestion\" for a trend direction, and can be ignored more easily when unnecessary or inappropriate.", "spans": "[{\"corpusId\": \"16792840\", \"span\": \"[7]\", \"start\": 33, \"end\": 36}, {\"corpusId\": 233468381, \"span\": \"we propose\", \"start\": 437, \"end\": 437}, {\"corpusId\": \"16792840\", \"span\": \"\", \"start\": 42975, \"end\": 42978}, {\"corpusId\": \"16792840\", \"span\": \"\", \"start\": 43277, \"end\": 43280}, {\"corpusId\": \"13392806\", \"span\": \"\", \"start\": 43280, \"end\": 43283}, {\"corpusId\": \"15085389\", \"span\": \"\", \"start\": 43283, \"end\": 43286}, {\"corpusId\": \"16792840\", \"span\": \"\", \"start\": 44593, \"end\": 44596}, {\"corpusId\": \"160012508\", \"span\": \"\", \"start\": 44984, \"end\": 44988}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "40089", "title": "Data-Driven Mark Orientation for Trend Estimation in Scatterplots", "sectionTitle": "DISCUSSION", "text": "However, the bias introduced by data-driven marks is small when the trend line is more certain. This is the case if the residual bandwidth is small, outliers are far away from the major cluster or have diferent densities, or if the intermingled clusters have radically diferent slopes. In such cases there is little ambiguity in the trend, and so estimates are accurate even without guidance from mark orientation. Implications for Scatterplot Design. The above fndings suggest that mark orientation can be a visual cue to implicitly encode trend information. A trend line directly encodes the model in a dogmatic way, whereas data-driven marks act as less dogmatic guidance that can be ignored or downweighted when they seem inappropriate or are clearly at odds with the depicted data, functioning as a form of \"implicit uncertainty visualization\" [6]. We have shown viewers will, in their own visual estimates, ignore things like outliers that would be a problem for explicit trend lines based on models of insufcient complexity. Fig. 19 shows how data-driven marks could be used to disambiguate trends in a health care dataset for investigating how the blood pressure is related to sodium excretion [11]. We can see that the slopes of the OLS trend and the robust trend have opposing signs (see Fig. 19(a)). Using data-driven marks can suggest a resolution to this ambiguity for the reviewer by downweight (b) or reinforcing (c) the contribution of the outlying points to the overall trend. Although it is hard to make a fair comparison between such implicit and explicit trend visualizations (for instance, Correll & Heer [7] believed that participants would adhere to explicit trend lines so closely if present that they used such stimuli as action checks), we believe that data-driven orientation can assist in regression by eye, especially for cases where standard models like OLS are inappropriate, or there are multiple valid interpretations of the data (as in Xiong et al. [34]).", "spans": "[{\"corpusId\": \"16691049\", \"span\": \"[6]\", \"start\": 849, \"end\": 852}, {\"corpusId\": \"25779142\", \"span\": \"[11]\", \"start\": 1202, \"end\": 1206}, {\"corpusId\": \"16792840\", \"span\": \"[7]\", \"start\": 1626, \"end\": 1629}, {\"corpusId\": \"149760444\", \"span\": \"[34]\", \"start\": 1983, \"end\": 1987}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "40090", "title": "Data-Driven Mark Orientation for Trend Estimation in Scatterplots", "sectionTitle": "CONCLUSION & FUTURE WORK", "text": "Our interview results show that participants report that they estimate trends by combining bounding boxes and local densities. Many of our participants reported mentally drawing a bounding box for all points, and then removing outliers. Since the trend is not strictly determined by these perceptual proxies [14,18], we cannot directly compute how these global or local visual structures were used. In the future, we will quantitatively model how the estimated trend is related to these proxies and to model a larger set of mark shapes and sizes. Since participants might have used diferent strategies for dealing with outliers (e.g., considering or discarding) in Experiment 2, the efects of outliers are likely to difer based on the individual strategy . In the future, we will model individual diferences and preform a secondary analysis of the experimental data as did by Kay and Heer [15]. In addition, we are particularly interested in how the mark size (and its infuence on visual artifacts like overplotting and occlusion) could skew assessments of local density and the resulting estimated trend. We are also interested in expanding our study of data-driven orientation to wider use cases, especially under additional \"adversarial\" scatterplot conditions [18] (such as marks with transparency, high degrees of overplotting, nonlinear or non-uniform trends, or where likely perceptual proxies like bounding boxes are uninformative).", "spans": "[{\"corpusId\": 233468381, \"span\": \"Our interview\", \"start\": 13, \"end\": 13}, {\"corpusId\": 233468381, \"span\": \"our participants\", \"start\": 151, \"end\": 151}, {\"corpusId\": \"201631684\", \"span\": \"[14,\", \"start\": 308, \"end\": 312}, {\"corpusId\": \"225059176\", \"span\": \"18]\", \"start\": 312, \"end\": 315}, {\"corpusId\": \"14389317\", \"span\": \"[15]\", \"start\": 889, \"end\": 893}, {\"corpusId\": 233468381, \"span\": \"our study\", \"start\": 1151, \"end\": 1151}, {\"corpusId\": \"225059176\", \"span\": \"[18]\", \"start\": 1264, \"end\": 1268}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "40091", "title": "Data-Driven Mark Orientation for Trend Estimation in Scatterplots", "sectionTitle": "RELATED WORKS", "text": "There is an extensive body of works on graphical perception tasks in scatterplots. Rensink [20] states that, much as geneticists use model organisms with simple genomes to model more complex behavior, scatterplots can function as \"fruit fies\" for graphical perception research questions in visualization. Scatterplots become especially important when moving beyond atomic tasks such as extraction and comparison of individual values that are common in foundational graphical perception work such as Cleveland & McGill [5] to \"ensemble\" tasks [27] such as the perception of average value and variance. The assessment of a trend is such an ensemble task, potentially requiring viewers to consider every point in the scatterplot in a holistic way, although recent work [14,18] suggests that \"perceptual proxies\" such as point envelopes and ranges likely guide visual statistical judgments in scatterplots rather than explicit calculations.", "spans": "[{\"corpusId\": \"35841393\", \"span\": \"[20]\", \"start\": 91, \"end\": 95}, {\"corpusId\": \"119693509\", \"span\": \"[5]\", \"start\": 518, \"end\": 521}, {\"corpusId\": \"16540907\", \"span\": \"[27]\", \"start\": 542, \"end\": 546}, {\"corpusId\": \"201631684\", \"span\": \"[14,\", \"start\": 766, \"end\": 770}, {\"corpusId\": \"225059176\", \"span\": \"18]\", \"start\": 770, \"end\": 773}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "40092", "title": "Data-Driven Mark Orientation for Trend Estimation in Scatterplots", "sectionTitle": "RELATED WORKS", "text": "Much existing work focuses on the perception of correlations in scatterplots [12,15,21,25,32,36], often involving pairwise comparisons on which of two scatterplots contain data that is more highly correlated. The perception of a particular trend, however, is comparatively under-explored. Correll & Heer [7] fnd that human estimations of trends in simple gaussian stimuli are largely similar to the results of methods like OLS, except for biases introduced by the design of a visualization or the presence of outlying points. We reanalyze their results and discuss modifications of their experimental methods in the following section.", "spans": "[{\"corpusId\": \"13392806\", \"span\": \"[12,\", \"start\": 77, \"end\": 81}, {\"corpusId\": \"14389317\", \"span\": \"15,\", \"start\": 81, \"end\": 84}, {\"corpusId\": \"15085389\", \"span\": \"21,\", \"start\": 84, \"end\": 87}, {\"corpusId\": \"205004073\", \"span\": \"25,\", \"start\": 87, \"end\": 90}, {\"corpusId\": \"198920775\", \"span\": \"32,\", \"start\": 90, \"end\": 93}, {\"corpusId\": \"51612575\", \"span\": \"36]\", \"start\": 93, \"end\": 96}, {\"corpusId\": \"16792840\", \"span\": \"[7]\", \"start\": 304, \"end\": 307}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "40093", "title": "Data-Driven Mark Orientation for Trend Estimation in Scatterplots", "sectionTitle": "RELATED WORKS", "text": "The choice of mark shapes in scatterplots is important and has great impact on the discriminability of clusters [16,29] as well as the legibility of other encoding channels such as color [26]. Furthermore, there seems to be a qualitative diference between closed and open shapes [4] for the assessments of similarity and diference within classes [8]. Despite this potential impact, many (or even most) visualizations rely on default mark shapes [2], typically circles. Of particular interest to us is the work by Ziemkiewicz & Kosara on the \"implied dynamics\" [37] of visualizations. Their work on marks in scatterplots specifcally suggests that \"attractor\" points [38] can create a bias for results of graphical perception tasks (even to the extent of irrational decision-making, as pointed out by Dimara et al. [9,10]).", "spans": "[{\"corpusId\": \"5336623\", \"span\": \"[16,\", \"start\": 112, \"end\": 116}, {\"corpusId\": \"120910948\", \"span\": \"29]\", \"start\": 116, \"end\": 119}, {\"corpusId\": \"140319165\", \"span\": \"[26]\", \"start\": 187, \"end\": 191}, {\"corpusId\": \"24542570\", \"span\": \"[4]\", \"start\": 279, \"end\": 282}, {\"corpusId\": \"5893222\", \"span\": \"[8]\", \"start\": 346, \"end\": 349}, {\"corpusId\": \"5066151\", \"span\": \"[2]\", \"start\": 445, \"end\": 448}, {\"corpusId\": \"16338656\", \"span\": \"[37]\", \"start\": 560, \"end\": 564}, {\"corpusId\": \"488296\", \"span\": \"[38]\", \"start\": 665, \"end\": 669}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 8}], "paragraphCount": 12}
{"paperId": "05681b9803be6bf62dcca9c864cca206743e4759", "title": "Gamification in Science: A Study of Requirements in the Context of Reproducible Research", "venue": "International Conference on Human Factors in Computing Systems", "year": 2019, "citationCount": 27, "openAccessPdf": {"url": "http://cds.cern.ch/record/2688997/files/1746203 Insp.pdf", "status": "GREEN", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1903.02446, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2019-03-06", "authors": [{"authorId": "77432106", "name": "S. Feger"}, {"authorId": "2066201039", "name": "S. Dallmeier-Tiessen"}, {"authorId": "3459292", "name": "Pawe\u0142 W. Wo\u017aniak"}, {"authorId": "145823914", "name": "A. Schmidt"}], "abstract": "The need for data preservation and reproducible research is widely recognized in the scientific community. Yet, researchers often struggle to find the motivation to contribute to data repositories and to use tools that foster reproducibility. In this paper, we explore possible uses of gamification to support reproducible practices in High Energy Physics. To understand how gamification can be effective in research tools, we participated in a workshop and performed interviews with data analysts. We then designed two interactive prototypes of a research preservation service that use contrasting gamification strategies. The evaluation of the prototypes showed that gamification needs to address core scientific challenges, in particular the fair reflection of quality and individual contribution. Through thematic analysis, we identified four themes which describe perceptions and requirements of gamification in research: Contribution, Metrics, Applications and Scientific practice. Based on these, we discuss design implications for gamification in science.", "corpusId": "70349995", "paragraphs": [{"paragraphId": "77625", "title": "Gamification in Science: A Study of Requirements in the Context of Reproducible Research", "sectionTitle": "INTRODUCTION", "text": "Reproducibility should be a scientific cornerstone that enables knowledge transfer and independent research verification. Yet, alarming reports describe the systematic failure to reproduce empirical studies in a variety of scientific fields [2]. Preserving and sharing research are key reproducible practices [3,43], which require efforts to prepare and document experimental resources [9]. But those efforts are often not matched by perceived gains [4,17].", "spans": "[{\"corpusId\": 4460617, \"span\": \"[2]\", \"start\": 241, \"end\": 244}, {\"corpusId\": 16783450, \"span\": \"[3,\", \"start\": 309, \"end\": 312}, {\"corpusId\": 8755162, \"span\": \"43]\", \"start\": 312, \"end\": 315}, {\"corpusId\": 4326966, \"span\": \"[4,\", \"start\": 450, \"end\": 453}, {\"corpusId\": 3116148, \"span\": \"17]\", \"start\": 453, \"end\": 456}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "77626", "title": "Gamification in Science: A Study of Requirements in the Context of Reproducible Research", "sectionTitle": "INTRODUCTION", "text": "Gamification, the \"use of game design elements in nongame contexts\" [21], has proven to be a valuable tool for engaging users and motivating desired behaviors [12]. In this paper, we explore possible uses of gamification to support reproducible practices. Past efforts attempted to stimulate good scientific practices through open science badges. They have been shown to significantly impact research data sharing practices of publications in the Psychological Science journal [28]. Yet, little empirical knowledge exists on the moderating effects of individual gamification mechanisms in professional scientific settings. In fact, it has recently been argued that mapping the impact of game design elements on specific domains is indeed much needed in gamification research today [31].", "spans": "[{\"corpusId\": 70349995, \"span\": \"this paper\", \"start\": 178, \"end\": 178}, {\"corpusId\": 4766260, \"span\": \"[28]\", \"start\": 477, \"end\": 481}, {\"corpusId\": 206623781, \"span\": \"[31]\", \"start\": 781, \"end\": 785}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "77627", "title": "Gamification in Science: A Study of Requirements in the Context of Reproducible Research", "sectionTitle": "INTRODUCTION", "text": "We developed and evaluated two gamification prototypes that are inspired by an existing High Energy Physics (HEP) research preservation service. Both aim to stimulate research documentation and sharing. A series of research activities informed the designs: we reviewed field studies, conducted interviews and observed a workshop, to learn about physicists' needs and perceptions towards the service. This approach is in line with increasing evidence that meaningful gamification profits from in-depth knowledge of target users [11,19], and calls to consider unique characteristics and frameworks of scientists in scientific gamification design [23].", "spans": "[{\"corpusId\": 70349995, \"span\": \"This approach\", \"start\": 413, \"end\": 413}, {\"corpusId\": 154281410, \"span\": \"19]\", \"start\": 531, \"end\": 534}, {\"corpusId\": 202670688, \"span\": \"[23]\", \"start\": 644, \"end\": 648}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "77628", "title": "Gamification in Science: A Study of Requirements in the Context of Reproducible Research", "sectionTitle": "Meaningful Gamification", "text": "The current iteration of game-inspired motivational design is characterized as the \"use of game elements in non-game contexts\" [21]. In their work, Hamari et al. [26] conducted a literature review of empirical studies on gamification. They report on 10 investigated motivational affordance categories, including levels, stories, clear goals, feedback, rewards, progress and challenges, noting that \"points, leaderboards, and badges were clearly the most commonly found variants. \" As becomes increasingly evident, gamification that adds leaderboards, points and badges only to drive business goals, is likely to prevent long-lasting engagement and even risks alienating users [32]. Instead, gamification profits from a holistic design process that appeals to the intrinsic motivation of the players [11,19], requiring systematic, user-centered designs [29,42]. This motivated our researcher-centered gamification design process. Intrinsic motivation results from activities that are perceived as satisfactorily or pleasurably in themselves. Self-determination theory (SDT), as described by Ryan and Deci [37], distinguishes intrinsic and extrinsic motivation. Extrinsic motivation is based on external goals that represent outcomes separable from the activity itself (e.g. rewards, money or social approval) and intrinsic motivation comes from psychological needs: Competence, Autonomy and Relatedness.", "spans": "[{\"corpusId\": 8115805, \"span\": \"[26]\", \"start\": 162, \"end\": 166}, {\"corpusId\": 12657531, \"span\": \"[32]\", \"start\": 676, \"end\": 680}, {\"corpusId\": 154281410, \"span\": \"19]\", \"start\": 803, \"end\": 806}, {\"corpusId\": 34294933, \"span\": \"[29,\", \"start\": 852, \"end\": 856}, {\"corpusId\": 70349995, \"span\": \"our research\", \"start\": 888, \"end\": 888}, {\"corpusId\": 1887672, \"span\": \"[37]\", \"start\": 1104, \"end\": 1108}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "77629", "title": "Gamification in Science: A Study of Requirements in the Context of Reproducible Research", "sectionTitle": "Mapping Impact of Game Design Elements", "text": "In Rethinking Gamification [24], Deterding stresses that \"motivational design should revolve around designing whole systems for motivational affordances, not adding elements with presumed-determined motivational effects. \" In The Maturing of Gamification Research, recently published by Nacke and Deterding [31], the authors highlight that gamification's early research focused on few contexts, like education. As not all contexts and desired behaviors are equally suited for gamification, \"extending the use of gamification beyond these contexts, and systematically studying the moderating effects of different individual and situational contexts is thus very much in need today\". The authors argue that \"we are just at the beginning of understanding what gamification design elements and methods best map onto what application domains\". Recent work from Orji, Tondello and Nacke [34] represents a good example, mapping impact of persuasive strategies on gamification user types for persuasive gameful health systems. Basing their study on storyboards, they illustrate how gamification research profits from novel methods. This approach also inspired our prototype-centered evaluation, mapping moderating effects of game design elements in science.", "spans": "[{\"corpusId\": 206623781, \"span\": \"[31]\", \"start\": 307, \"end\": 311}, {\"corpusId\": 5061633, \"span\": \"[34]\", \"start\": 881, \"end\": 885}, {\"corpusId\": 70349995, \"span\": \"This approach\", \"start\": 1137, \"end\": 1137}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "77630", "title": "Gamification in Science: A Study of Requirements in the Context of Reproducible Research", "sectionTitle": "Gamification in Science", "text": "Studying gamification in a research setting represents an opportunity to extend our knowledge of the applicability and constraints of gamification beyond traditional contexts. So far, gamification in science focused on designing engaging experiences in citizen science, motivating the general public to contribute to scientific knowledge through micro tasks [10,22], and supporting the learning process of students [27]. CHI workshop summary from Deterding et al. [20] raises questions on the role of gamification in research, but also focuses on citizen science, encouraging users to provide self-tracking data and to participate in research activities.", "spans": "[{\"corpusId\": 2395878, \"span\": \"[10,\", \"start\": 358, \"end\": 362}, {\"corpusId\": 12511378, \"span\": \"22]\", \"start\": 362, \"end\": 365}, {\"corpusId\": 12777403, \"span\": \"[27]\", \"start\": 415, \"end\": 419}, {\"corpusId\": 31565437, \"span\": \"[20]\", \"start\": 464, \"end\": 468}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "77631", "title": "Gamification in Science: A Study of Requirements in the Context of Reproducible Research", "sectionTitle": "Gamification for Reproducible Research", "text": "The reproducibility crisis represents a strong example of scientific challenges that motivate studying needs and constraints of gamification in research settings. Documenting and sharing research data and resources are key requirements of reproducible research [3,43]. But, the efforts required to prepare, document and share experimental data [9] are often not matched by the perceived gain. In fact, studies claim that the scientific culture does not support or even impairs compliance with reproducible practices [4,17]. Considering missing incentive structures, common proposals target the implementation of policies; most prominently concerning funding rules [36] and requirements for conference and journal submissions [5,39].", "spans": "[{\"corpusId\": 16783450, \"span\": \"[3,\", \"start\": 261, \"end\": 264}, {\"corpusId\": 8755162, \"span\": \"43]\", \"start\": 264, \"end\": 267}, {\"corpusId\": 4326966, \"span\": \"[4,\", \"start\": 516, \"end\": 519}, {\"corpusId\": 3116148, \"span\": \"17]\", \"start\": 519, \"end\": 522}, {\"corpusId\": 8277215, \"span\": \"[36]\", \"start\": 664, \"end\": 668}, {\"corpusId\": 62581711, \"span\": \"39]\", \"start\": 728, \"end\": 731}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "77632", "title": "Gamification in Science: A Study of Requirements in the Context of Reproducible Research", "sectionTitle": "Gamification Designs", "text": "To stimulate feedback, we created two designs that are based on our researcher-and service-centered insights. Following our initial expectation that gamification in a professional scientific context is most likely to profit from a serious, informative and rule-based design language, we created the Rational-Informative Design (RID) that provides information expected to appeal to HEP researchers. The RID was designed to make less use of most common game elements like points and leaderboards. Instead, it uses elements of \"Social networks\", \"Social discovery\", \"Signposting\" and \"Challenges\" (the LHC collaboration goal on the dashboard) as suggested by Tondello et al. [41]. This enables an exploration of gameful design elements in the HEP context. Yet, as scientists are already subjected to a high degree of competition, we also created a contrasting Simple Game Elements Design (SGED) version that focuses on point-based rewards and competitive elements. The basic UI design rules (color scheme, arrangements, etc.) are the same for both versions and are inspired by the actual service design. We built interactive wireframes with a high level of detail using the prototyping tool Balsamiq. As it is impractical to develop two functional, productive designs for the purpose of studying perceptions, we decided in favor of fully interactive prototypes. This approach is also motivated by recent, novel research methods, mapping persuasive strategies to gamification user types based on storyboards [34].", "spans": "[{\"corpusId\": 70349995, \"span\": \"our research\", \"start\": 76, \"end\": 76}, {\"corpusId\": 6010318, \"span\": \"[41]\", \"start\": 672, \"end\": 676}, {\"corpusId\": 70349995, \"span\": \"This approach\", \"start\": 1372, \"end\": 1372}, {\"corpusId\": 5061633, \"span\": \"[34]\", \"start\": 1504, \"end\": 1508}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "77633", "title": "Gamification in Science: A Study of Requirements in the Context of Reproducible Research", "sectionTitle": "Evaluation", "text": "Structure. First, participants were quickly introduced to CAP and were shown the analysis submission form of their corresponding collaboration, in order to get familiar with the context. Afterwards, half of the participants started exploring the RID version, the other half the SGED one. They started with the dashboard and explored the various views on their own. We prepared a few questions for every principal view that aimed to stimulate feedback. Following the design exploration, we asked the physicists to respond to a 7-point Likert scale questionnaire, structured as follows: \u2022 An abbreviated Intrinsic Motivation Inventory (IMI) scale was used, as it provides two valuable subscales. We considered assessing the perceived Value / Usefulness (5 items) to be of key importance for gamification in science, as well as Interest / Enjoyment (4 items). Enjoyment has also been used to characterize user preferences of game design elements by Tondello et al. [41]. The interest / enjoyment subscale assesses intrinsic motivation per se, while task meaningfulness appeals to the innate need for autonomy [38]. \u2022 We further asked to rate a statement that targets the suitability of the design: The system is NOT suitable for a research preservation service. Finally, The system would influence me to document my analyses, targets the persuasiveness of the design, also core to the study of Orji et al. [34].", "spans": "[{\"corpusId\": 6010318, \"span\": \"[41]\", \"start\": 962, \"end\": 966}, {\"corpusId\": 42296152, \"span\": \"[38]\", \"start\": 1106, \"end\": 1110}, {\"corpusId\": 5061633, \"span\": \"[34]\", \"start\": 1403, \"end\": 1407}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "77634", "title": "Gamification in Science: A Study of Requirements in the Context of Reproducible Research", "sectionTitle": "Reflect the Scientific Environment and Contribution", "text": "Given that studies and analyses in science are often conducted over a long period of time, it is crucial to provide accessible goals. This applies particularly to research-related achievements. Awards that promote best practices should not only target the ultimate goal requiring months and years of effort, but intermediate steps. Whenever possible, binary reward mechanisms should be replaced by more multifaceted structures. Doing so is likely to prevent discouragement through facing a goal that is very hard to reach, but might instead provide a sense of progress, one of the design pattern for gamification of work by Swacha and Muszy\u0144ska [40], making an \"employee aware that every action he/she performs is a step in progress. \" Yet, doing so might become more challenging in a scientific context, characterized by novelty and creativity. Our findings regarding the accessibility of goals also relates to research conducted on fitness trackers [33].", "spans": "[{\"corpusId\": 18718751, \"span\": \"[40]\", \"start\": 645, \"end\": 649}, {\"corpusId\": 70349995, \"span\": \"Our findings\", \"start\": 858, \"end\": 858}, {\"corpusId\": 5050428, \"span\": \"[33]\", \"start\": 951, \"end\": 955}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "77635", "title": "Gamification in Science: A Study of Requirements in the Context of Reproducible Research", "sectionTitle": "Role of Open Science Badges", "text": "A recent systematic literature review concluded that open science badges are the only evidence-based incentive [35] that promotes data sharing of research in the health and medical domain. In fact, in their quantitative study, Kidwell et al. [28] found a significant increase in data sharing of submissions to the Psychological Science journal that adapted to those badges. Based on our findings and design implications, we discuss five aspects explaining why those mechanisms had a positive impact. First, the badges allow promoting best practices that are considered highly important in the community. We employed similar mechanisms in our study that were very well received by participants. Second, while badges are visibly placed on the paper and in the digital library of participating journals, no adverse indication is given, highlighting that a paper has not yet received those awards. Third, promotion of rewarded papers increases their visibility, as well as the visibility of authors. This is especially true if search engines of digital libraries highlight corresponding search results. Through increased visibility, researchers can expect increasing citations and improved career prospects. Fourth, also the fact that badges are assigned to papers instead of individual researchers certainly fosters acceptance, as we have previously discussed. Finally, the badges provide accessible goals, a first step towards reproducibility. ACM takes this notion even further, introducing fine-grained badges that focus on very accessible goals [1,8].", "spans": "[{\"corpusId\": 3319179, \"span\": \"[35]\", \"start\": 111, \"end\": 115}, {\"corpusId\": 4766260, \"span\": \"[28]\", \"start\": 242, \"end\": 246}, {\"corpusId\": 70349995, \"span\": \"our findings\", \"start\": 395, \"end\": 395}, {\"corpusId\": 70349995, \"span\": \"our study\", \"start\": 647, \"end\": 647}, {\"corpusId\": 19616102, \"span\": \"8]\", \"start\": 1549, \"end\": 1551}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 11}
{"paperId": "523fdd5d31f63355bd318dde35a559f4ac5ed7da", "title": "Maker Technology and the Promise of Empowerment in a Flemish School for Disabled Children", "venue": "International Conference on Human Factors in Computing Systems", "year": 2022, "citationCount": 8, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3491102.3501853?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3491102.3501853, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2022-04-29", "authors": [{"authorId": "2358234", "name": "B. Vandenberghe"}, {"authorId": "1797251", "name": "K. Gerling"}, {"authorId": "144603490", "name": "L. Geurts"}, {"authorId": "8474018", "name": "V. Abeele"}], "abstract": "Maker culture encourages do-it-yourself practices to create, repair, and repurpose technology. In Human-Computer Interaction (HCI) research, it is seen as a means of empowering people, providing affordable and customisable technology with potential to enrich areas such as education or assistive technology. To investigate this alleged potential, we performed an anthropological inquiry at an elementary school for disabled children that lasted one year, participating in everyday activities with students, teachers, and therapists. We observed \u2018heterogeneity in a fluid environment\u2019 and \u2018creativity in the moment\u2019 in an \u2018endemically underfunded\u2019 setting. We saw how technology is \u2018injecting dependencies\u2019, \u2018reinforcing disability\u2019, and \u2018occupying time and space\u2019, changing our view on the role that making can have. Leveraging Empowerment Theory, we highlight how (making) technology risks ignoring the intertwined dynamics between the individual, the organisational, and the community, and articulate points for reflection for technology in schools for disabled children for the HCI research community.", "corpusId": "248419480", "paragraphs": [{"paragraphId": "82033", "title": "Maker Technology and the Promise of Empowerment in a Flemish School for Disabled Children", "sectionTitle": "INTRODUCTION", "text": "Maker culture aspires to empower people [67,80] through the democratization of technology development, supporting everyday people to become -makers -, to take matters into their own hands, and to design and build their own technological solutions. In order to achieve this, maker culture has adopted do-it-yourself (DIY) practices and a hacking mindset, to creatively repair, reuse, repurpose, and upcycle items [10,44,45,58,85]. In HCI research, making has found its way into various application domains, e.g., supporting a sustainable, circular economy through upcycling and repair [17,82], enriching education with toolkits, Fablabs and 3D printers [6,9,13,14,31,32], and enabling people in low-income countries in innovation processes [1,34]. Making also seeks to promote wellbeing and accessibility in the context of health [62] and disability [68], where it has been particularly researched to support the creation of assistive devices, e.g., in medical realms (e.g., custom built prostheses) [35,64], or within a clinical practice with therapists (e.g. therapeutic tools) [2,32,57,77], or in the feld of accessibility, e.g. creating ftting games [66] or controllers [21,51].", "spans": "[{\"corpusId\": 16196982, \"span\": \"[67,\", \"start\": 40, \"end\": 44}, {\"corpusId\": 22124172, \"span\": \"[10,\", \"start\": 412, \"end\": 416}, {\"corpusId\": 6953952, \"span\": \"58,\", \"start\": 422, \"end\": 425}, {\"corpusId\": 57756971, \"span\": \"[17,\", \"start\": 584, \"end\": 588}, {\"corpusId\": 234811207, \"span\": \"82]\", \"start\": 588, \"end\": 591}, {\"corpusId\": 10688715, \"span\": \"[6,\", \"start\": 652, \"end\": 655}, {\"corpusId\": 2969974, \"span\": \"9,\", \"start\": 655, \"end\": 657}, {\"corpusId\": 6549568, \"span\": \"13,\", \"start\": 657, \"end\": 660}, {\"corpusId\": 207193309, \"span\": \"14,\", \"start\": 660, \"end\": 663}, {\"corpusId\": 4773929, \"span\": \"31,\", \"start\": 663, \"end\": 666}, {\"corpusId\": 233678461, \"span\": \"[1,\", \"start\": 739, \"end\": 742}, {\"corpusId\": 59221958, \"span\": \"34]\", \"start\": 742, \"end\": 745}, {\"corpusId\": 1745681, \"span\": \"[62]\", \"start\": 829, \"end\": 833}, {\"corpusId\": 26921830, \"span\": \"[68]\", \"start\": 849, \"end\": 853}, {\"corpusId\": 6415866, \"span\": \"[35,\", \"start\": 999, \"end\": 1003}, {\"corpusId\": 235381554, \"span\": \"64]\", \"start\": 1003, \"end\": 1006}, {\"corpusId\": 214639953, \"span\": \"[2,\", \"start\": 1079, \"end\": 1082}, {\"corpusId\": 7092970, \"span\": \"57,\", \"start\": 1085, \"end\": 1088}, {\"corpusId\": 218483361, \"span\": \"77]\", \"start\": 1088, \"end\": 1091}, {\"corpusId\": 31169018, \"span\": \"[66]\", \"start\": 1153, \"end\": 1157}, {\"corpusId\": 225957997, \"span\": \"[21,\", \"start\": 1173, \"end\": 1177}, {\"corpusId\": 16886673, \"span\": \"51]\", \"start\": 1177, \"end\": 1180}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 22}, {"paragraphId": "82034", "title": "Maker Technology and the Promise of Empowerment in a Flemish School for Disabled Children", "sectionTitle": "INTRODUCTION", "text": "In these settings, maker technology holds the promise of providing afordable and customizable technology solutions to pressing issues; for example, maker technologies have been envisioned as the solution to designing and building assistive technology in an efort to address the lack of afordable and customizable technical support systems for disabled people 1 [12,16]. Moreover, the aspiration is that the agency in the technology creation process, now reserved to HCI researchers, through DIY approaches, can be handed over to the people who want and need it [68]. In these cases, emphasis is placed on the potential of making as a means of empowering those who are perceived as disempowered [11], understanding empowerment as the \"processes and outcomes relating to issues of control and access to resources, critical awareness of the socio-political environment, and participation with others\" [89].", "spans": "[{\"corpusId\": 233678461, \"span\": \"1\", \"start\": 359, \"end\": 360}, {\"corpusId\": 59580282, \"span\": \"16]\", \"start\": 365, \"end\": 368}, {\"corpusId\": 26921830, \"span\": \"[68]\", \"start\": 561, \"end\": 565}, {\"corpusId\": 30586716, \"span\": \"[11]\", \"start\": 694, \"end\": 698}, {\"corpusId\": 241067586, \"span\": \"[89]\", \"start\": 898, \"end\": 902}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "82035", "title": "Maker Technology and the Promise of Empowerment in a Flemish School for Disabled Children", "sectionTitle": "INTRODUCTION", "text": "However, despite promising initial fndings, the adoption of making in the creation and use of assistive technology lags behind, and non-use and abandonment of assistive technologies persist to this day [54,86]. Already in the late 90's, Riemer-Reiss and Wacker [65] reported on high abandonment rates of assistive technology among disabled college students in the context of education. Twenty years later, this remains unchanged. DIY for assistive technology seems to remain a practice of \"able-bodied people with a technical background who are part of the extended care network around a person with a disability\" [56]. As questioned by Buehler and colleagues, \"Why aren't people with disabilities leveraging 3-D printing for themselves? What about their caregivers and clinicians, why aren't they joining in?\" [11].", "spans": "[{\"corpusId\": 214496717, \"span\": \"[54,\", \"start\": 202, \"end\": 206}, {\"corpusId\": 74302693, \"span\": \"86]\", \"start\": 206, \"end\": 209}, {\"corpusId\": 167811320, \"span\": \"[65]\", \"start\": 261, \"end\": 265}, {\"corpusId\": 34447297, \"span\": \"[56]\", \"start\": 614, \"end\": 618}, {\"corpusId\": 30586716, \"span\": \"[11]\", \"start\": 811, \"end\": 815}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "82036", "title": "Maker Technology and the Promise of Empowerment in a Flemish School for Disabled Children", "sectionTitle": "Maker technologies, assistive technology and the school environment", "text": "2.1.1 The promise of DIY and assistive technology. Do-it-yourself and making (DIY) practices have long been promoted by many scholars, for the generation of assistive technologies [16,39,41,57,65,77]. In particular, it has been argued that maker technologies may lower abandonment rates [16,41]. Hurst, in a series of articles [39][40][41], adamantly argued that DIY assistive technology may help overcome barriers for adoption such as problematic ft, long delivery times, and need for adaptation. For example, rapid prototyping tools do no longer require complex manual actions such as manipulating large wooden boards on a table saw. Instead, user-friendly software renders the making process more accessible. Hurst, and others [68] argue that by empowering non-engineers to create, modify, and build their own assistive technology, more people gain access to the technology they need. Moreover, through online communities, makers can share and learn from each other [11,12]. In line with the previous arguments, Moraiti et al. created and evaluated a DIY assistive technology toolkit for occupational therapists [57]. The researchers aspired to omit the need for technical experts to support therapists while creating technological solutions for therapy [25].", "spans": "[{\"corpusId\": 59580282, \"span\": \"[16,\", \"start\": 180, \"end\": 184}, {\"corpusId\": 9385528, \"span\": \"39,\", \"start\": 184, \"end\": 187}, {\"corpusId\": 18998144, \"span\": \"41,\", \"start\": 187, \"end\": 190}, {\"corpusId\": 7092970, \"span\": \"57,\", \"start\": 190, \"end\": 193}, {\"corpusId\": 167811320, \"span\": \"65,\", \"start\": 193, \"end\": 196}, {\"corpusId\": 218483361, \"span\": \"77]\", \"start\": 196, \"end\": 199}, {\"corpusId\": 59580282, \"span\": \"[16,\", \"start\": 287, \"end\": 291}, {\"corpusId\": 18998144, \"span\": \"41]\", \"start\": 291, \"end\": 294}, {\"corpusId\": 9385528, \"span\": \"[39]\", \"start\": 327, \"end\": 331}, {\"corpusId\": 9385528, \"span\": \"[40]\", \"start\": 331, \"end\": 335}, {\"corpusId\": 18998144, \"span\": \"[41]\", \"start\": 335, \"end\": 339}, {\"corpusId\": 26921830, \"span\": \"[68]\", \"start\": 730, \"end\": 734}, {\"corpusId\": 30586716, \"span\": \"[11,\", \"start\": 969, \"end\": 973}, {\"corpusId\": 7092970, \"span\": \"[57]\", \"start\": 1115, \"end\": 1119}, {\"corpusId\": 24207838, \"span\": \"[25]\", \"start\": 1257, \"end\": 1261}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "82037", "title": "Maker Technology and the Promise of Empowerment in a Flemish School for Disabled Children", "sectionTitle": "Maker technologies, assistive technology and the school environment", "text": "2.1.2 DIY, assistive technology and the hurdles of occupational therapists. Hofmann et al. also investigated the creation of assistive technology through digital fabrication in a clinical environment [37]. In contrast to Moraiti et al. [57], they found that existing end-user DIY fabrication does not align with clinical practice. The fail-fast and risk-taking attitude within maker communities conficts with the do-no-harm ethos of clinical practice. Occupational therapists foreground responsibility, and perceive the encouragement of self-creation of assistive technology equal to prescribing them. This prescriptive mindset also necessitates therapists to build on their available (scientifc) knowledge and expertise, and to work in a time-efcient way. These results suggest a more a nuanced view on the role of DIY fabrication in a therapist's practice, and point at the need for specifc making tools and processes that align with clinical practice. First, the authors suggest to minimise the required iterations needed from the therapist, at the cost of innovation. Second, the authors call for resource awareness; to emphasise what is feasible both in terms of material qualities, availability, and cost. And third, in the therapists' prescribed model to ofer assistive technology to their clients, the authors emphasize to limit making to physical adaptations where therapists tweak designs physically, using adaptable materials and quick fabrication methods. Slegers et al. [77] also investigated the attitudes of occupational therapists towards DIY assistive technology, specifcally using 3D printing technologies. In their studies, therapists saw benefts in DIY assistive technology to increase user satisfaction due to a better ft (both in functional and aesthetic way), and the potential of decreasing social stigma for their clients. Slegers et al. used a technology adoption framework (UTAUT) [83] to assess the potential of 3D printing technology to be accepted and used by occupational therapists. Interestingly, they found efort expectancy (i.e., perceived ease-of-use) and facilitating conditions (i.e., available infrastructure) to be lacking and restrain the potential of 3D printing technology. Therapists raised concerns regarding the required time to learn and produce 3D prints and emphasised the associated costs, which they thought would not be accepted by their employers. These concerns remained among therapists, also after having hands-on experiences with the technology. In order to make DIY assistive technology work, according to this study and from a therapist perspective, 3D printing professionals need to be involved in complement to therapists. This call for involving technology experts also aligns with the fndings of Norrie et al., who argue for the introduction of an 'assistive technologist' when introducing high-tech devices in schools for disabled children. [61] 2.1.3 DIY, assistive technology and the school environment. Studies that investigate the potential of DIY technologies in the context of schools for disabled children are still relatively sparse, the majority of maker studies and assistive technologies focus on physical rehabilitation [16,76] within a clinical realm [35,37]. However, in 2016, Bueler et al. explored the use of 3D printers in special education schools 2 [13]. They found there is interest in using 3D printing in special education, yet several barriers for adoption of 3D printing remain related to budgetting time for training, maintenance of the printer and ensuring equal access. More recently, M\u00e4kal\u00e4 and Vellonen did explore the use of DIY toolkits by educators in the context of special education schools [52]. The authors found that openness of the DIY toolkit (in this case Makey Makey [14]) to be an ambivalent factor, as educators were uncertain in how to make the best use of it. Educators struggled with ftting this creative, yet time-consuming, appropriation process into the reality of special education schools. In the past years, toolkits have come out for disabled children and their educators in a school environment, such as Sensebox [33], Tapeblock [20], or the SocialPlayToolkit [71]. These toolkits may resolve some of these issues related to the need for training and openness. This latter toolkit was designed through a three year situated co-design practice in a school environment to empower neurodiverse children. In relation to this this toolkit, the authors particularly highlight the importance of infrastructuring, in order words, the importance of considering socio-material aspects accompanying the toolkit, so that when leaving the feld, integration of the technology in practice is facilitated. Related to infrastructuring and education in low-resource settings, Rosner and Ames discuss processes of breakdown and repair [69] of the \"XO\" laptops of One Laptop Per Child in Paraguay [4]. The authors argue that breakdown and repair is tied to material realities. The political and social context of technology infrastructure, including manufacturing limitations and situational access to repair parts and expertise, is inherent to these processes of breakdown and repair, yet they cannot efectively be anticipated by designers. In response, authors promote 'negotiated endurance' among diferent actors, recognizing the importance of the local actors to facilitate ongoing use.  [56] to empower disabled people, pointed out that while DIY assistive technology is believed to be democratising design and manifacturing [80], the maker community does lack demographic diversity, and thus also diversity in who controls the design and production process. Moreover, they note that in the context of DIY assistive technology, it is seldomly the individual with a disability who is producing the technology. Instead, the design and creation of DIY assistive technology is still done by people with technical expertise, who have become part of an extended care network. This fnding is echoed by other researchers as well [12,87]; most of the makers are people without disabilities. In the words of Hofmann, do-it-yourself is still do-it-for others (DFO) [37]. These authors link DFO to non-use of assistive technology and strongly advocate for involving disabled people as active stakeholders in its production [56]. This apparent paradox between do-it-yourself and relying on others is also noted by Toombs et al. [81]. In an ethnographic study, the authors participated as members of a hackerspace, discussing the care ethos of making culture: its integral values of collaboration and community aspect, yet how this sits on top of its neoliberal ethos, celebrating self-determination and independence. The authors expand the notion of hacking from understanding how to reassemble physical and digital materials to citizens contributing to the social good, and 'making' community -or what the authors called 'hacker-care'.", "spans": "[{\"corpusId\": 123769357, \"span\": \"[37]\", \"start\": 200, \"end\": 204}, {\"corpusId\": 7092970, \"span\": \"[57]\", \"start\": 236, \"end\": 240}, {\"corpusId\": 218483361, \"span\": \"[77]\", \"start\": 1483, \"end\": 1487}, {\"corpusId\": 14435677, \"span\": \"[83]\", \"start\": 1908, \"end\": 1912}, {\"corpusId\": 248419480, \"span\": \"this study\", \"start\": 2574, \"end\": 2574}, {\"corpusId\": 59580282, \"span\": \"[16,\", \"start\": 3196, \"end\": 3200}, {\"corpusId\": 2427788, \"span\": \"76]\", \"start\": 3200, \"end\": 3203}, {\"corpusId\": 6415866, \"span\": \"[35,\", \"start\": 3228, \"end\": 3232}, {\"corpusId\": 123769357, \"span\": \"37]\", \"start\": 3232, \"end\": 3235}, {\"corpusId\": 6549568, \"span\": \"[13]\", \"start\": 3332, \"end\": 3336}, {\"corpusId\": 52074509, \"span\": \"[52]\", \"start\": 3689, \"end\": 3693}, {\"corpusId\": 207193309, \"span\": \"[14]\", \"start\": 3772, \"end\": 3776}, {\"corpusId\": 83458519, \"span\": \"[33]\", \"start\": 4131, \"end\": 4135}, {\"corpusId\": 233987118, \"span\": \"[20]\", \"start\": 4147, \"end\": 4151}, {\"corpusId\": 233986949, \"span\": \"[71]\", \"start\": 4178, \"end\": 4182}, {\"corpusId\": 2550533, \"span\": \"[69]\", \"start\": 4834, \"end\": 4838}, {\"corpusId\": 34447297, \"span\": \"[56]\", \"start\": 5390, \"end\": 5394}, {\"corpusId\": 234374624, \"span\": \"87]\", \"start\": 6028, \"end\": 6031}, {\"corpusId\": 123769357, \"span\": \"[37]\", \"start\": 6157, \"end\": 6161}, {\"corpusId\": 34447297, \"span\": \"[56]\", \"start\": 6314, \"end\": 6318}, {\"corpusId\": 15960480, \"span\": \"[81]\", \"start\": 6418, \"end\": 6422}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 18}, {"paragraphId": "82038", "title": "Maker Technology and the Promise of Empowerment in a Flemish School for Disabled Children", "sectionTitle": "Maker technologies, assistive technology and the school environment", "text": "2.1.5 The promise of maker culture. In sum, the diverse studies on maker technologies for assistive technology provide a mixed and nuanced view of their potential for disabled people, and when deployed in a school environment. While certain studies highlight benefts in terms of cost [41], accessibility [39], ft [39,77], and reducing stigma [16,77], other studies suggest that a making practice does not to align with a clinical practice [37], and still presents barriers for adoption, such as a lack of ease-of-use or physical infrastructure [77]. In a school environment, researchers additionally foreground the time-consuming process and the need for researchers to consider how to ensure uptake after researchers leave the feld [71]. Finally, several researchers stress the lack of diversity in DIY practices, leading to DFO instead [37]. Similar echos can be found when scrutinizing DIY practices in realms beyond AT; for example several authors have published critical refections on the promises of DIY maker technology used in a generic school environment [4, 75, e.g.]. Ames et al., also similar to Hofman and Meisner [37,56], question who is in control, who gets excluded, and what making could contribute to society [3]. Regarding inclusion, Marshall and Rode deconstruct the sociotechnical identity formation within maker culture through an ethnographic study of STEAM skill building activities [55]. The study found complex tensions regarding gender and (maker) technology excluding those who do not identify as male. Therefore, the question remains how maker technologies can be help to design assistive technologies that truly empower, helping \"people, organizations, and communities gain mastery over issues of concern to them\" [43] in a school environment. Regarding the use of DIY assistive technology in schools for disabled children, there is still not enough research that support the promises of empowerment in this specifc environment.", "spans": "[{\"corpusId\": 18998144, \"span\": \"[41]\", \"start\": 284, \"end\": 288}, {\"corpusId\": 9385528, \"span\": \"[39]\", \"start\": 304, \"end\": 308}, {\"corpusId\": 9385528, \"span\": \"[39,\", \"start\": 313, \"end\": 317}, {\"corpusId\": 218483361, \"span\": \"77]\", \"start\": 317, \"end\": 320}, {\"corpusId\": 59580282, \"span\": \"[16,\", \"start\": 342, \"end\": 346}, {\"corpusId\": 218483361, \"span\": \"77]\", \"start\": 346, \"end\": 349}, {\"corpusId\": 123769357, \"span\": \"[37]\", \"start\": 439, \"end\": 443}, {\"corpusId\": 218483361, \"span\": \"[77]\", \"start\": 544, \"end\": 548}, {\"corpusId\": 233986949, \"span\": \"[71]\", \"start\": 733, \"end\": 737}, {\"corpusId\": 123769357, \"span\": \"[37]\", \"start\": 838, \"end\": 842}, {\"corpusId\": 123769357, \"span\": \"[37,\", \"start\": 1127, \"end\": 1131}, {\"corpusId\": 34447297, \"span\": \"56]\", \"start\": 1131, \"end\": 1134}, {\"corpusId\": 20332255, \"span\": \"[3]\", \"start\": 1227, \"end\": 1230}, {\"corpusId\": 14009004, \"span\": \"[55]\", \"start\": 1407, \"end\": 1411}, {\"corpusId\": 14484174, \"span\": \"[43]\", \"start\": 1744, \"end\": 1748}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 10}, {"paragraphId": "82039", "title": "Maker Technology and the Promise of Empowerment in a Flemish School for Disabled Children", "sectionTitle": "Understanding empowerment in HCI and health care", "text": "Empowerment, implict or explicit, is a core warrant for research on disability and assistive technology in HCI [68]. However, as pointed out by Schneider et al. [72], the current discourse in HCI is characterized by a fuzzy understanding and delineation of what exactly is meant with empowerment. Schneider et al., building on the afore defnition of empowerment by Rappaport [43] highlight the many diferent conceptualizations of empowerment in HCI, distinguishing four dimensions in which empowerment can be understood: 1) envisioning empowerment either as power-to (i.e., the ability to act) or power-over (power in relation to others); 2) the psychological component of empowerment, distinguishing feeling, knowing and doing; 3) the persistence of empowerment, being either transient or persistent; and fnally 4) the design mindset, either expert-led or participatory. While the authors do not promote one conceptualization of empowerment over another, they point out that it is important for scholars to articulate their specifc stance and consequent decisions when investigating or designing for empowerment. When elaborating on the diferent dimensions of, and in particular the psychological component of empowerment, Schneider et al. also pointed to Zimmerman's Empowerment Theory [90]. This framework is geared towards rehabilitation sciences and healthcare, thus particularly suited for HCI studies that relate empowerment to disabled people and assistive technology. Zimmerman et al. distinguish three fundamental components of empowerment in rehabilitation: 1) control and access to resources; 2) participation with others; and 3) critical awareness of the sociopolitical environment. Interestingly, Zimmerman also points out that these three outcomes are to be infuenced at three interdependent levels of analysis: the individual, the organisational, and the community level (see Figure 1). For example, whereas a sense of control at the individual level is geared towards supporting an individual to gain mastery to act, at the community level this is geared towards organisations working together to exert control over policy decisions. Hence, Zimmerman emphasizes the interdependency between the diferent levels, these are not to be separated. Even on an individual level, i.e., psychological empowerment, is defned as the \"knowledge and skills necessary to take efective action within sociopolitical context\" [90]. Relating this back to the dimensions provided by Schneider, this implies that one cannot separate power-over from power-to, these are fundamentally interrelated. Zimmerman also observed that most research on empowerment is devoted to the individual level, yet the organizational and community levels are equally important and deserve equal attention. Moreover, a consequent premise of Zimmerman's framework is that we can only learn about how empowerment in rehabilitation, and by extension in a healthcare context such as a school for disabled children, by studying the specifc settings that provide opportunities as well as the broader socio-cultural context in which it takes place. Empowerment must be conceptualized \"differently for specifc contexts and populations\" [90, p. 4].", "spans": "[{\"corpusId\": 26921830, \"span\": \"[68]\", \"start\": 111, \"end\": 115}, {\"corpusId\": 5053761, \"span\": \"[72]\", \"start\": 161, \"end\": 165}, {\"corpusId\": 14484174, \"span\": \"[43]\", \"start\": 375, \"end\": 379}, {\"corpusId\": 145133810, \"span\": \"[90]\", \"start\": 1288, \"end\": 1292}, {\"corpusId\": 145133810, \"span\": \"[90]\", \"start\": 2425, \"end\": 2429}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "82040", "title": "Maker Technology and the Promise of Empowerment in a Flemish School for Disabled Children", "sectionTitle": "Understanding empowerment in HCI and health care", "text": "Following up on the call of Zimmerman, this work will therefore extend the recent, but still relatively modest body of work that addresses the use of DIY assistive technology in a school setting [34,38], also including how the larger socio-cultural environment contributes to its potential for empowerment. Figure 1: Visual representation of Zimmerman's Empowerment Theory [89] showing three processes of empowerment (being in control & access to resources; participation with others; and critical awareness of one's sociopolitical environment) and their outcomes. Each of these are to be analysed and interact with three levels of analysis: the individual, the organisation, and the community.", "spans": "[{\"corpusId\": 248419480, \"span\": \"this work\", \"start\": 48, \"end\": 48}, {\"corpusId\": 59221958, \"span\": \"[34,\", \"start\": 195, \"end\": 199}, {\"corpusId\": 14240542, \"span\": \"38]\", \"start\": 199, \"end\": 202}, {\"corpusId\": 241067586, \"span\": \"[89]\", \"start\": 373, \"end\": 377}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "82041", "title": "Maker Technology and the Promise of Empowerment in a Flemish School for Disabled Children", "sectionTitle": "Duration and data gathering", "text": "From September 2018 to June 2019, during a period of 42 weeks, the researcher was present on 29 days (including 3 school trips), organised 6 meetings with the school, and attended 4 additional (shorter) moments where the school asked for support, for example to support bus services. In the 42 weeks, 15 days were omitted due to holidays (8); by the school (2); or personal reasons such as illness or parental leave (5). We received ethical approval from the ethical board of our institution. We explained in detail how we approached the research ethically. We actively and continuously discussed consent with the research participants -students, teachers, and therapists in situ, adhering to the anthropological practice [7,88]. As students were sensitive to changes, note-taking while participating was deemed too obtrusive. Therefore, the researcher took notes and made sketches of observations after returning to the ofce. To support post-activity note taking and sketching, the frst author did use their phone camera to take pictures for later elicitation, with the consent of students, teachers, therapists, and the school. In respect to data protection, these photographs did not depict faces nor (recognizable) persons.", "spans": "[{\"corpusId\": 52936154, \"span\": \"(8)\", \"start\": 338, \"end\": 341}, {\"corpusId\": 73454817, \"span\": \"(5)\", \"start\": 416, \"end\": 419}, {\"corpusId\": 145446134, \"span\": \"[7,\", \"start\": 722, \"end\": 725}, {\"corpusId\": 166089256, \"span\": \"88]\", \"start\": 725, \"end\": 728}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "82042", "title": "Maker Technology and the Promise of Empowerment in a Flemish School for Disabled Children", "sectionTitle": "Daisy (preschool)", "text": "Luke is always smiling and does not easily give up. He uses sign language, communication aids, and a power wheelchair. Luke has limited and asymmetric hand function. Rose (8)(9)(10) Amy is quiet. She uses a power wheelchair and has verbal difculties. She is gradually losing hand function, and needs additional support during lunch. Jan is verbally present. He has endless imagination, and is often distracted. Jan needs additional support during lunch.", "spans": "[{\"corpusId\": 52936154, \"span\": \"(8)\", \"start\": 171, \"end\": 174}, {\"corpusId\": 2969974, \"span\": \"(9)\", \"start\": 174, \"end\": 177}, {\"corpusId\": 22124172, \"span\": \"(10)\", \"start\": 177, \"end\": 181}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "82043", "title": "Maker Technology and the Promise of Empowerment in a Flemish School for Disabled Children", "sectionTitle": "Refecting on technology in schools for disabled children through the lens of Empowerment Theory", "text": "5.1.1 Understanding technology in the context of interdependence between individuals, the organisation, and the wider community. Our work suggests that the potential of DIY assistive technology (and technology as such) to empower disabled students needs to be understood in the context of all interconnected levels of empowerment defned by Zimmerman and colleagues. Here, we want to draw attention to our observations that highlight how direct interactions with technology occur at the individual level (e.g., a student using a smart screen, or a teacher trying to set up a laptop), but are mediated by the environment (e.g., a student who uses a wheelchair being unable to reach the smart screen because the classroom is too small, or a teacher not managing to make peripheral devices work because of poorly serviced laptops) which is shaped by decisions taken by the wider organisation (e.g., the decision to no longer have therapists help teachers with transfers of students), which again is shaped by decisions in the broader community (e.g., the amount of funding available to the school leading to staf shortages, and housing the school in an inadequate building). Likewise, empowerment processes at the school were neither one of the individual student, nor one of the individual teacher or therapist, nor tied to one specifc time or location. We found that in the observed environment, therapy and teaching blended. Consequently, empowerment is interwoven and arises from the dynamic interactions, between the level of individual (the child, the teacher and the therapist) and the school as organisation, and the societal level. We hypothesize that because interactions with technology are primarily visible at the individual level, it is a natural consequence to focus research eforts on this clearly defned part, similar to how we originally articulated our research goal of leveraging maker technologies to support therapists and teachers at school, and to empower students, and likewise similar to previous HCI and accessibility research (e.g., see [2,57,76]). However, this individualistic perspective overlooks how students, teachers and therapists are afected by the organisations within which they operate, and which in turn are impacted on a societal level, thereby risking to undermine ongoing processes of empowerment.", "spans": "[{\"corpusId\": 248419480, \"span\": \"Our work\", \"start\": 137, \"end\": 137}, {\"corpusId\": 248419480, \"span\": \"our research\", \"start\": 1876, \"end\": 1876}, {\"corpusId\": 214639953, \"span\": \"[2,\", \"start\": 2061, \"end\": 2064}, {\"corpusId\": 7092970, \"span\": \"57,\", \"start\": 2064, \"end\": 2067}, {\"corpusId\": 2427788, \"span\": \"76]\", \"start\": 2067, \"end\": 2070}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "82044", "title": "Maker Technology and the Promise of Empowerment in a Flemish School for Disabled Children", "sectionTitle": "Component 3:", "text": "Critical awareness of the socio-political environment. The research presented here exposed the infrastructural challenges of the school, spanning stafng, equipment and the built environment, impacting the quality of provision for students. Here, design of technology needs to be done against the backdrop of this socio-cultural environment, a perspective that is widely acknowledged in HCI research [70]. Nevertheless, our work leaves us wondering whether the methods and approaches frequently used in HCI research, e.g., interviews, co-design workshops that are embedded in institutions as special, and often researcher-led events, or observations that may be limited to a small number of days, can achieve critical awareness. Instead, we hypothesize that short-term engagement at institutions that is so common in our research community may result in recording only front-stage behaviors [27], leading to fundamentally fawed assumptions about the role and potential of technology [22,53]. Moreover, there has been a call for applying infrastructuring, i.e., designing for the integration of new tools and technologies with existing people, materials and tools [46]. This approach emphasizes the need for temporal scaling [46] in an efort of \"sustaining and maintaining the results of HCI research and design projects, including technological artefacts, beyond the runtime of such projects and beyond the role that researchers played within the project context. \" [49] Researchers have also called for \"broken world thinking\" [45], focusing from the start of the design on how to support maintenance and repair [44]. In this vision, DIY approaches are considered particularly useful as they allow users without a technological background to leapfrog [68] and take on the maintenance and repair. However, other authors challenge the extent to which such processes of breakdown and repair can be anticipated [69], and point out that such an uncritical focus on independence of makers/repairers ignores the importance of a supportive maker community that, on an enduring basis, invests time in spreading understanding and support of how to reassemble physical and digital materials [81]. In other words, breakdown and repair is governed by the sociopolitical as well; by situational access to repair parts and availability of expertise, which in the context of this observed school for disabled children was problematic. Hence, our observations demonstrate how systematic underfunding can undercut such an aspiration. In a context where teachers and therapists are already overburdened, let alone given the time and space to tinker, and where basic ICT infrastructure to manage the dependencies is not guaranteed due to understafed ICT support and subsequent inadequate technological choices, DIY approaches are likely to complicate ongoing processes of empowerment, taking up precious time and resources.  [13,35,56,57]; the open availability and inherent adaptability of maker technologies serve the requirement for customization, while its hacker spirit results in afordable maintenance. Hence, upon a frst analysis through the perspective of Zimmerman, maker technology provides control over and access to important resources, highlighting its potential to contribute to empowerment. Yet, despite its promising ideology, the adoption of making technologies in the creation of successful assistive technology still has barriers [37,56,76], and non-use and abandonment of assistive technologies persist [39,50,59]. This paradox was at the heart of this paper, exploring the potential of DIY approaches in a school for disabled children.", "spans": "[{\"corpusId\": 2194116, \"span\": \"[70]\", \"start\": 399, \"end\": 403}, {\"corpusId\": 248419480, \"span\": \"our work\", \"start\": 427, \"end\": 427}, {\"corpusId\": 248419480, \"span\": \"Instead, we\", \"start\": 739, \"end\": 739}, {\"corpusId\": 248419480, \"span\": \"our research\", \"start\": 828, \"end\": 828}, {\"corpusId\": 14693101, \"span\": \"[22,\", \"start\": 982, \"end\": 986}, {\"corpusId\": 5539514, \"span\": \"53]\", \"start\": 986, \"end\": 989}, {\"corpusId\": 10511449, \"span\": \"[46]\", \"start\": 1162, \"end\": 1166}, {\"corpusId\": 248419480, \"span\": \"This approach\", \"start\": 1181, \"end\": 1181}, {\"corpusId\": 10511449, \"span\": \"[46]\", \"start\": 1223, \"end\": 1227}, {\"corpusId\": 233987452, \"span\": \"[49]\", \"start\": 1465, \"end\": 1469}, {\"corpusId\": 26921830, \"span\": \"[68]\", \"start\": 1751, \"end\": 1755}, {\"corpusId\": 2550533, \"span\": \"[69]\", \"start\": 1907, \"end\": 1911}, {\"corpusId\": 15960480, \"span\": \"[81]\", \"start\": 2180, \"end\": 2184}, {\"corpusId\": 6549568, \"span\": \"[13,\", \"start\": 2905, \"end\": 2909}, {\"corpusId\": 6415866, \"span\": \"35,\", \"start\": 2909, \"end\": 2912}, {\"corpusId\": 34447297, \"span\": \"56,\", \"start\": 2912, \"end\": 2915}, {\"corpusId\": 7092970, \"span\": \"57]\", \"start\": 2915, \"end\": 2918}, {\"corpusId\": 123769357, \"span\": \"[37,\", \"start\": 3429, \"end\": 3433}, {\"corpusId\": 34447297, \"span\": \"56,\", \"start\": 3433, \"end\": 3436}, {\"corpusId\": 2427788, \"span\": \"76]\", \"start\": 3436, \"end\": 3439}, {\"corpusId\": 9385528, \"span\": \"[39,\", \"start\": 3503, \"end\": 3507}, {\"corpusId\": 36942486, \"span\": \"50,\", \"start\": 3507, \"end\": 3510}, {\"corpusId\": 248419480, \"span\": \"this paper\", \"start\": 3558, \"end\": 3558}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 17}, {"paragraphId": "82045", "title": "Maker Technology and the Promise of Empowerment in a Flemish School for Disabled Children", "sectionTitle": "Maker technology as catalyst or inhibitor of empowerment", "text": "Hence, despite their promising characteristics, we assume that when designed and introduced without a deep level of participation and understanding of the diferent levels and complexities of empowerment in the socio-cultural deployment setting, maker technologies will in fact create additional barriers to empowerment. From earlier research on the use of and barriers to DIY technologies, we already learned about the challenges with respect to efort expectancy and the lack of facilitating conditions [77], the lack of alignment with clinical practice [37], the time-consuming process of confguration and adding content due to openness of DIY toolkits [52], and the lack of representation of end-users in the design [11], resulting in design for others [56]. Our fndings echo and reinforce these fndings, and further articulate the problems in institutional settings, injecting dependencies that cannot be met, and demanding resources from already overburdened staf. In this situation, expecting that actors engage in slow-paced technology exploration and tinkering is problematic; instead, our fndings regarding the use of velcro, masking tape, and magnets suggest that quick, nondigital, and iterative adaptation is preferred, echoing fndings by Hofmann et al. [37]. Such solutions would also facilitate adaptations in the periphery of user attention, while allowing teachers to maintain their active presence for the remainder of the class group. Considering our fndings on staf burden, the model of online communities sharing with and learning from each other to create DIY assistive technology, as pushed forward in earlier research [40,57] also seems less feasible. Likewise, practices of sharing through researchers, introducing or delivering time-limited support, should be examined through the lens of 'gifting', suggesting these actions may come at a cost: the school is no longer seen as a autonomous actor but becomes a recipient in need of help.", "spans": "[{\"corpusId\": 218483361, \"span\": \"[77]\", \"start\": 503, \"end\": 507}, {\"corpusId\": 123769357, \"span\": \"[37]\", \"start\": 554, \"end\": 558}, {\"corpusId\": 52074509, \"span\": \"[52]\", \"start\": 654, \"end\": 658}, {\"corpusId\": 30586716, \"span\": \"[11]\", \"start\": 718, \"end\": 722}, {\"corpusId\": 34447297, \"span\": \"[56]\", \"start\": 755, \"end\": 759}, {\"corpusId\": 123769357, \"span\": \"[37]\", \"start\": 1265, \"end\": 1269}, {\"corpusId\": 9385528, \"span\": \"[40,\", \"start\": 1640, \"end\": 1644}, {\"corpusId\": 7092970, \"span\": \"57]\", \"start\": 1644, \"end\": 1647}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "82046", "title": "Maker Technology and the Promise of Empowerment in a Flemish School for Disabled Children", "sectionTitle": "Generalisation of research.", "text": "Our observations rely on one year of participant observation, limited to one environment in a western, rich nation, yet characterized by an ongoing trend of efciency optimisation and savings in care for disabled people. Hence, we acknowledge that observations in this single-sited research may not be generalised across diferent (mainstream) schools where disabled students might have other needs, nor across diferent regions, cultures and educational systems, nor other low-resource settings. We have focused on richness of content, dissecting and unveiling how ongoing processes, including the design of technology can stymie processes of empowerment, in this manner aspiring to present an honest account of the actual environment, as an 'ultimate particular' [60,79] of activities in the school [84]. We acknowledge that in diferent regions, for example where schools are better funded, there may be a role for maker technology. However, the general observation of problematic uptake of DIY assistive technology suggests that in a lesser or greater extent, similar dynamics may be at play elsewhere.", "spans": "[{\"corpusId\": 59662567, \"span\": \"[60,\", \"start\": 762, \"end\": 766}, {\"corpusId\": 2573532, \"span\": \"79]\", \"start\": 766, \"end\": 769}, {\"corpusId\": 22245090, \"span\": \"[84]\", \"start\": 798, \"end\": 802}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "82047", "title": "Maker Technology and the Promise of Empowerment in a Flemish School for Disabled Children", "sectionTitle": "Revisiting our Positionality: Becoming activist.", "text": "In the process of participating in the school's activities and discussing experiences with participants, the initial focus on the need for specifc technological assistive artefacts and the potential of DIY technology, transformed to a broader focus on ongoing activities and use of nontechnological artefacts. The nuanced signals picked up along the way, transformed us and weakened our temptation for solutionist reasoning. Instead, the research turned out to be humbling, realising certain challenges are not to be resolved through technology alone. In the course of our analysis, this research also transformed us in to activists, recognizing how the structural underfunding refects social injustice and in fact can be regarded as structural violence against children with disabilities [28]. Because of the underfunding, at times, even basic services could not always be met (e.g., the bus service). During the course of this research, several articles appeared in popular press echoing the fndings in this school and across other nations. As researchers, to neglect this grim reality and design for a future that is unlikely to be come reality anytime soon, even when done with good intentions [78] is questionable. Such ignorance risks installing processes of disempowerement, further contributing to the social injustices we observed.", "spans": "[{\"corpusId\": 248419480, \"span\": \"this research\", \"start\": 596, \"end\": 596}, {\"corpusId\": 205575581, \"span\": \"[28]\", \"start\": 789, \"end\": 793}, {\"corpusId\": 248419480, \"span\": \"this research\", \"start\": 937, \"end\": 937}, {\"corpusId\": 231919408, \"span\": \"[78]\", \"start\": 1198, \"end\": 1202}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 15}
{"paperId": "4c934343f95950fe10894c35961783b72dc7a8e0", "title": "Neural Adaptation Layers for Cross-domain Named Entity Recognition", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2018, "citationCount": 95, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/D18-1226.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1810.06368, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2018-10-15", "authors": [{"authorId": "51583409", "name": "Bill Yuchen Lin"}, {"authorId": "143844110", "name": "Wei Lu"}], "abstract": "Recent research efforts have shown that neural architectures can be effective in conventional information extraction tasks such as named entity recognition, yielding state-of-the-art results on standard newswire datasets. However, despite significant resources required for training such models, the performance of a model trained on one domain typically degrades dramatically when applied to a different domain, yet extracting entities from new emerging domains such as social media can be of significant interest. In this paper, we empirically investigate effective methods for conveniently adapting an existing, well-trained neural NER model for a new domain. Unlike existing approaches, we propose lightweight yet effective methods for performing domain adaptation for neural models. Specifically, we introduce adaptation layers on top of existing neural architectures, where no re-training using the source domain data is required. We conduct extensive empirical studies and show that our approach significantly outperforms stateof-the-art methods.", "corpusId": "53083555", "paragraphs": [{"paragraphId": "41145", "title": "Neural Adaptation Layers for Cross-domain Named Entity Recognition", "sectionTitle": "Introduction", "text": "Named entity recognition (NER) focuses on extracting named entities in a given text while identifying their underlying semantic types. Most earlier approaches to NER are based on conventional structured prediction models such as conditional random fields (CRF) (Lafferty et al., 2001;Sarawagi and Cohen, 2004), relying on handcrafted features which can be designed based on domain-specific knowledge (Yang and Cardie, 2012;Passos et al., 2014;Luo et al., 2015). Recently, neural architectures have been shown effective in such a task, whereby minimal feature engineering is required (Lample et al., 2016;Ma and Hovy, 2016;Peters et al., 2017;Liu et al., 2018). Domain adaptation, as a special case for transfer learning, aims to exploit the abundant data of wellstudied source domains to improve the performance in target domains of interest (Pan and Yang, 2010;Weiss et al., 2016). There is a growing interest in investigating the transferability of neural models for NLP. Two notable approaches, namely INIT (parameter initialization) and MULT (multitask learning), have been proposed for studying the transferrability of neural networks under tasks such as sentence (pair) classification (Mou et al., 2016) and sequence labeling (Yang et al., 2017b). The INIT method first trains a model using labeled data from the source domain; next, it initializes a target model with the learned parameters; finally, it fine-tunes the initialized target model using labeled data from the target domain. The MULT method, on the other hand, simultaneously trains two models using both source and target data respectively, where some parameters are shared across the two models during the learning process. Figure 1 illustrates the two approaches based on the BLSTM-CRF (bidirectional LSTM augmented with a CRF layer) architecture for NER. While such approaches make intuitive senses, they also come with some limitations.", "spans": "[{\"corpusId\": 219683473, \"span\": \"(Lafferty et al., 2001;\", \"start\": 261, \"end\": 284}, {\"corpusId\": 14036493, \"span\": \"Sarawagi and Cohen, 2004)\", \"start\": 284, \"end\": 309}, {\"corpusId\": 11176977, \"span\": \"(Yang and Cardie, 2012;\", \"start\": 400, \"end\": 423}, {\"corpusId\": 12016540, \"span\": \"Luo et al., 2015)\", \"start\": 443, \"end\": 460}, {\"corpusId\": 6042994, \"span\": \"(Lample et al., 2016;\", \"start\": 583, \"end\": 604}, {\"corpusId\": 10489017, \"span\": \"Ma and Hovy, 2016;\", \"start\": 604, \"end\": 622}, {\"corpusId\": 7197241, \"span\": \"Peters et al., 2017;\", \"start\": 622, \"end\": 642}, {\"corpusId\": 19232497, \"span\": \"Liu et al., 2018)\", \"start\": 642, \"end\": 659}, {\"corpusId\": 740063, \"span\": \"Yang, 2010;\", \"start\": 851, \"end\": 862}, {\"corpusId\": 11866664, \"span\": \"(Mou et al., 2016)\", \"start\": 1191, \"end\": 1209}, {\"corpusId\": 17984798, \"span\": \"(Yang et al., 2017b)\", \"start\": 1232, \"end\": 1252}]", "conference": "emnlp", "year": 2018, "likelyRelatedWorkSection": false, "refCount": 11}, {"paragraphId": "41146", "title": "Neural Adaptation Layers for Cross-domain Named Entity Recognition", "sectionTitle": "Base Model", "text": "We briefly introduce the BLSTM-CRF architecture for NER, which serves as our base model throughout this paper. Our base model is the combination of two recently proposed popular works for named entity recognition by Lample et al. (2016) and Ma and Hovy (2016). Figure 2 illustrates the BLSTM-CRF architecture.", "spans": "[{\"corpusId\": 53083555, \"span\": \"this paper\", \"start\": 109, \"end\": 109}, {\"corpusId\": 6042994, \"span\": \"Lample et al. (2016)\", \"start\": 216, \"end\": 236}, {\"corpusId\": 10489017, \"span\": \"Ma and Hovy (2016)\", \"start\": 241, \"end\": 259}]", "conference": "emnlp", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "41147", "title": "Neural Adaptation Layers for Cross-domain Named Entity Recognition", "sectionTitle": "Base Model", "text": "This architecture is selected as our base model due to its generality and representativeness. We note that several recently proposed models (Peters et al., 2017;Liu et al., 2018) are built based on it. As our focus is on how to better transfer such architectures for NER, we include further discussions of the model and training details in our supplementary material.", "spans": "[{\"corpusId\": 7197241, \"span\": \"(Peters et al., 2017;\", \"start\": 140, \"end\": 161}, {\"corpusId\": 19232497, \"span\": \"Liu et al., 2018)\", \"start\": 161, \"end\": 178}, {\"corpusId\": 53083555, \"span\": \"our focus\", \"start\": 214, \"end\": 214}]", "conference": "emnlp", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "41148", "title": "Neural Adaptation Layers for Cross-domain Named Entity Recognition", "sectionTitle": "Projection Learning", "text": "We would like to highlight that, unlike many previous approaches to learning cross-domain word embeddings (Bollegala et al., 2015;Yang et al., 2017a), the learning of our word adaptation layer involves no modifications to the sourcedomain embedding spaces. It also requires no retraining of the embeddings based on the targetdomain data. Such a distinctive advantage of our approach comes with some important practical implications: it essentially enables the transfer learning process to work directly on top of a welltrained model by performing adaptation without involving significant re-training efforts. For example, the existing model could be one that has already gone through extensive training, tuning and testing for months based on large datasets with embeddings learned from a particular domain (which may be different from the target domain).", "spans": "[{\"corpusId\": 14116842, \"span\": \"(Bollegala et al., 2015;\", \"start\": 106, \"end\": 130}, {\"corpusId\": 28121799, \"span\": \"Yang et al., 2017a)\", \"start\": 130, \"end\": 149}, {\"corpusId\": 53083555, \"span\": \"our approach\", \"start\": 382, \"end\": 382}]", "conference": "emnlp", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "41149", "title": "Neural Adaptation Layers for Cross-domain Named Entity Recognition", "sectionTitle": "Source and Target Domains", "text": "\u2022 Challenging: Newswire is a well-studied domain for NER and existing neural models perform very well (around 90.0 F1-score (Ma and Hovy, 2016)). However, the performance drop dramatically in social media data (around 60.0 F-score (Strauss et al., 2016)). \u2022 Important: Social media is a rich soil for text mining (Petrovic et al., 2010;Rosenthal and McKeown, 2015;Wang and Yang, 2015), and NER is of significant importance for other information extraction tasks in social media (Ritter et al., 2011a;Peng and Dredze, 2016;Chou et al., 2016). \u2022 Representative: The noisy nature of user generated content as well as emerging entities with novel surface forms make the domain shift very salient (Finin et al., 2010;Han et al., 2016). Nevertheless, the techniques developed in this paper are domain independent and thus can be used for other learning tasks across any two domains so long as we have the necessary resources.", "spans": "[{\"corpusId\": 10489017, \"span\": \"(Ma and Hovy, 2016)\", \"start\": 124, \"end\": 143}, {\"corpusId\": 17389993, \"span\": \"(Strauss et al., 2016)\", \"start\": 231, \"end\": 253}, {\"corpusId\": 2146994, \"span\": \"(Petrovic et al., 2010;\", \"start\": 313, \"end\": 336}, {\"corpusId\": 3257353, \"span\": \"Wang and Yang, 2015)\", \"start\": 364, \"end\": 384}, {\"corpusId\": 12861120, \"span\": \"(Ritter et al., 2011a;\", \"start\": 478, \"end\": 500}, {\"corpusId\": 1862889, \"span\": \"Peng and Dredze, 2016;\", \"start\": 500, \"end\": 522}, {\"corpusId\": 9185099, \"span\": \"Chou et al., 2016)\", \"start\": 522, \"end\": 540}, {\"corpusId\": 8395279, \"span\": \"(Finin et al., 2010;\", \"start\": 692, \"end\": 712}, {\"corpusId\": 53083555, \"span\": \"this paper\", \"start\": 783, \"end\": 783}]", "conference": "emnlp", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "41150", "title": "Neural Adaptation Layers for Cross-domain Named Entity Recognition", "sectionTitle": "NER Datasets for Evaluation", "text": "For the source newswire domain, we use the following two datasets: OntoNotes-nw -the newswire section of OntoNotes 5.0 release dataset (ON) (Weischedel et al., 2013) that is publicly available 5 , as well as the CoNLL03 NER dataset (CO) (Sang and Meulder, 2003). For the first dataset, we randomly split the dataset into three sets: 80% for training, 15% for development and 5% for testing. For the second dataset, we follow their provided standard train-dev-test split. For the target domain, we consider the following two datasets: Ritter11 (RI) (Ritter et al., 2011b) and WNUT16 (WN) (Strauss et al., 2016), both of which are publicly available. The statistics of the four datasets we used in the paper are shown in Table 1.", "spans": "[{\"corpusId\": 2470716, \"span\": \"(Sang and Meulder, 2003)\", \"start\": 237, \"end\": 261}, {\"corpusId\": 12861120, \"span\": \"(Ritter et al., 2011b)\", \"start\": 548, \"end\": 570}, {\"corpusId\": 17389993, \"span\": \"(Strauss et al., 2016)\", \"start\": 587, \"end\": 609}]", "conference": "emnlp", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "41151", "title": "Neural Adaptation Layers for Cross-domain Named Entity Recognition", "sectionTitle": "Baseline Transfer Approaches", "text": "We present the baseline approaches, which were originally investigated by Mou Mou et al. (2016) and Yang et al. (2017b) follow Collobert and Weston (2008) and use a hyper-parameter as the probability of choosing an instance from D S instead of D T to optimize the model parameters. By selecting the hyper-parameter , the multi-task learning process tends to perform better in target domains. Note that this method needs re-training of the source model with D S every time we would like to build a new target model, which can be time-consuming especially when D S is large.", "spans": "[{\"corpusId\": 11866664, \"span\": \"Mou et al. (2016)\", \"start\": 78, \"end\": 95}, {\"corpusId\": 17984798, \"span\": \"Yang et al. (2017b)\", \"start\": 100, \"end\": 119}, {\"corpusId\": 2617020, \"span\": \"Collobert and Weston (2008)\", \"start\": 127, \"end\": 154}, {\"corpusId\": 53083555, \"span\": \"this method\", \"start\": 413, \"end\": 413}]", "conference": "emnlp", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "41152", "title": "Neural Adaptation Layers for Cross-domain Named Entity Recognition", "sectionTitle": "Related Work", "text": "Domain adaptation and transfer learning has been a popular topic that has been extensively studied in the past few years (Pan and Yang, 2010). For well-studied conventional feature-based models in NLP, there are various classic transfer approaches, such as EasyAdapt (Daum\u00e9, 2007), instance weighting (Jiang and Zhai, 2007) and structural correspondence learning (Blitzer et al., 2006). Fewer works have been focused on transfer approaches for neural models in NLP. Mou et al. (2016) use intuitive transfer methods (INIT and MULT) to study the transferability of neural network models for the sentence (pair) classification problem; Lee et al. (2017) utilize the INIT method on highly related datasets of electronic health records to study their specific deidentification problem. Yang et al. (2017b) use the MULT approach in sequence tagging tasks including named entity recognition. Following the MULT scheme, Wang et al. (2018) introduce a label-aware mechanism into maximum mean discrepancy (MMD) to explicitly reduce domain shift between the same labels across domains in medical data. Their approach requires the output space to be the same in both source and target domains. Note that the scenario in our paper is that the output spaces are different in two domains.", "spans": "[{\"corpusId\": 740063, \"span\": \"Yang, 2010)\", \"start\": 130, \"end\": 141}, {\"corpusId\": 5360764, \"span\": \"(Daum\\u00e9, 2007)\", \"start\": 267, \"end\": 280}, {\"corpusId\": 15036406, \"span\": \"(Jiang and Zhai, 2007)\", \"start\": 301, \"end\": 323}, {\"corpusId\": 15978939, \"span\": \"(Blitzer et al., 2006)\", \"start\": 363, \"end\": 385}, {\"corpusId\": 11866664, \"span\": \"Mou et al. (2016)\", \"start\": 466, \"end\": 483}, {\"corpusId\": 17984798, \"span\": \"Yang et al. (2017b)\", \"start\": 781, \"end\": 800}, {\"corpusId\": 13751762, \"span\": \"Wang et al. (2018)\", \"start\": 912, \"end\": 930}, {\"corpusId\": 53083555, \"span\": \"our paper\", \"start\": 1217, \"end\": 1217}]", "conference": "emnlp", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 8}, {"paragraphId": "41153", "title": "Neural Adaptation Layers for Cross-domain Named Entity Recognition", "sectionTitle": "Related Work", "text": "All these existing works do not use domainspecific embeddings for different domains and they use the same neural model for source and target models. However, with our word adaptation layer, it opens the opportunity to use domainspecific embeddings. Our approach also addresses the domain shift problem at both input and output level by re-constructing target models with our specifically designed adaptation layers. The hyper-parameter in our proposed methods and in MULT both control the knowledge transfer from source domain in the transfer learning process. While our method works on top of an existing pre-trained source model directly, MULT needs re-training with source domain data each time they train a target model. Fang and Cohn (2017) add an \"augmented layer\" before their final prediction layer for crosslingual POS tagging -which is a simple multilayer perceptron performing local adaptation for each token separately -ignoring contextual information. In contrast, we employ a BLSTM layer due to its ability in capturing contextual information, which was recently shown to be crucial for sequence labeling tasks such as NER (Ma and Hovy, 2016;Lample et al., 2016). We also notice that a similar idea to ours has been used in the recently proposed Deliberation Network (Xia et al., 2017) for the sequence generation task, where a second-pass decoder is added to a first-pass decoder to polish sequences generated by the latter.", "spans": "[{\"corpusId\": 53083555, \"span\": \"Our approach\", \"start\": 261, \"end\": 261}, {\"corpusId\": 53083555, \"span\": \"our proposed method\", \"start\": 458, \"end\": 458}, {\"corpusId\": 53083555, \"span\": \"our method\", \"start\": 577, \"end\": 577}, {\"corpusId\": 27747034, \"span\": \"Fang and Cohn (2017)\", \"start\": 725, \"end\": 745}, {\"corpusId\": 10489017, \"span\": \"(Ma and Hovy, 2016;\", \"start\": 1137, \"end\": 1156}, {\"corpusId\": 6042994, \"span\": \"Lample et al., 2016)\", \"start\": 1156, \"end\": 1176}, {\"corpusId\": 13481571, \"span\": \"(Xia et al., 2017)\", \"start\": 1281, \"end\": 1299}]", "conference": "emnlp", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "41154", "title": "Neural Adaptation Layers for Cross-domain Named Entity Recognition", "sectionTitle": "Related Work", "text": "We propose to learn the word adaptation layer in our task inspired by two prior studies. Fang and Cohn (2017) use the cross-lingual word embeddings to obtain distant supervision for target languages. Yang et al. (2017a) propose to re-train word embeddings on target domain by using regularization terms based on the sourcedomain embeddings, where some hyper-parameter tuning based on down-stream tasks is required. Our word adaptation layer serves as a lineartransformation (Mikolov et al., 2013), which is learned based on corpus level statistics. Although there are alternative methods that also learn a mapping between embeddings learned from different domains (Faruqui and Dyer, 2014;Artetxe et al., 2016;Smith et al., 2017), such methods usually involve modifying source domain embeddings, and thus re-training of the source model based on the modified source embeddings would be required for the subsequent transfer process.", "spans": "[{\"corpusId\": 53083555, \"span\": \"We propose\", \"start\": 10, \"end\": 10}, {\"corpusId\": 27747034, \"span\": \"Fang and Cohn (2017)\", \"start\": 89, \"end\": 109}, {\"corpusId\": 28121799, \"span\": \"Yang et al. (2017a)\", \"start\": 200, \"end\": 219}, {\"corpusId\": 3792324, \"span\": \"(Faruqui and Dyer, 2014;\", \"start\": 664, \"end\": 688}, {\"corpusId\": 1040556, \"span\": \"Artetxe et al., 2016;\", \"start\": 688, \"end\": 709}]", "conference": "emnlp", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 5}], "paragraphCount": 10}
{"paperId": "68a7ec5519c733757f87cb08d598c35fbcaff124", "title": "Harnessing Pre-Trained Neural Networks with Rules for Formality Style Transfer", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2019, "citationCount": 75, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/D19-1365.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://aclanthology.org/D19-1365, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2019-11-01", "authors": [{"authorId": "2107933959", "name": "Yunli Wang"}, {"authorId": "49176273", "name": "Yu Wu"}, {"authorId": "38956216", "name": "Lili Mou"}, {"authorId": "1707275", "name": "Zhoujun Li"}, {"authorId": "7277241", "name": "Wen-Han Chao"}], "abstract": "Formality text style transfer plays an important role in various NLP applications, such as non-native speaker assistants and child education. Early studies normalize informal sentences with rules, before statistical and neural models become a prevailing method in the field. While a rule-based system is still a common preprocessing step for formality style transfer in the neural era, it could introduce noise if we use the rules in a naive way such as data preprocessing. To mitigate this problem, we study how to harness rules into a state-of-the-art neural network that is typically pretrained on massive corpora. We propose three fine-tuning methods in this paper and achieve a new state-of-the-art on benchmark datasets", "corpusId": "202777169", "paragraphs": [{"paragraphId": "67824", "title": "Harnessing Pre-Trained Neural Networks with Rules for Formality Style Transfer", "sectionTitle": "Related Work", "text": "In the past few years, style-transfer generation has attracted increasing attention in NLP research. Early work transfers between modern English and the Shakespeare style with a phrase-based machine translation system (Xu et al., 2012). Recently, style transfer is more recognized as a controllable text generation problem (Hu et al., 2017), where the style may be designated as sentiment (Fu et al., 2018), tense (Hu et al., 2017), or even general syntax (Bao et al., 2019;. In the above approaches, the training sentences are labeled with style information, but no parallel data are given. Xu et al. (2019a) take one step further and capture the most salient style by detecting global variance in a purely unsupervised manner (i.e., style labels are unknown).", "spans": "[{\"corpusId\": 13050210, \"span\": \"(Xu et al., 2012)\", \"start\": 218, \"end\": 235}, {\"corpusId\": 20981275, \"span\": \"(Hu et al., 2017)\", \"start\": 323, \"end\": 340}, {\"corpusId\": 6484065, \"span\": \"(Fu et al., 2018)\", \"start\": 389, \"end\": 406}, {\"corpusId\": 20981275, \"span\": \"(Hu et al., 2017)\", \"start\": 414, \"end\": 431}, {\"corpusId\": 196176266, \"span\": \"(Bao et al., 2019;\", \"start\": 456, \"end\": 474}]", "conference": "emnlp", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "67825", "title": "Harnessing Pre-Trained Neural Networks with Rules for Formality Style Transfer", "sectionTitle": "Related Work", "text": "Formality style transfer is mostly driven by the GYAFC parallel corpus. Since a parallel corpus, albeit small, is available, formality style transfer usually takes a seq2seq-like approach (Rao and Tetreault, 2018;Niu et al., 2018a;Xu et al., 2019b). In particular, this paper focuses on harnessing pre-trained neural networks with rulebased systems.", "spans": "[{\"corpusId\": 4859003, \"span\": \"(Rao and Tetreault, 2018;\", \"start\": 188, \"end\": 213}, {\"corpusId\": 48364994, \"span\": \"Niu et al., 2018a;\", \"start\": 213, \"end\": 231}, {\"corpusId\": 202777169, \"span\": \"this paper\", \"start\": 275, \"end\": 275}]", "conference": "emnlp", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "67826", "title": "Harnessing Pre-Trained Neural Networks with Rules for Formality Style Transfer", "sectionTitle": "Evaluation Metrics", "text": "Overall: We evaluate the overall quality of formality-transferred sentences with BLEU (Papineni et al., 2002) and PINC (Chen and Dolan, 2011). BLEU evaluates the n-gram overlap, and PINC is an auxiliary metric indicating the dissimilarity between an output sentence and an input. A PINC score of 0 indicates that the input and output sentences are the same. According to Rao and Tetreault (2018), BLEU correlates with human annotation best.", "spans": "[{\"corpusId\": 11080756, \"span\": \"(Papineni et al., 2002)\", \"start\": 86, \"end\": 109}, {\"corpusId\": 215717103, \"span\": \"(Chen and Dolan, 2011)\", \"start\": 119, \"end\": 141}, {\"corpusId\": 4859003, \"span\": \"Rao and Tetreault (2018)\", \"start\": 371, \"end\": 395}]", "conference": "emnlp", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 3}
{"paperId": "2c11cb80ff697f81d2e67ee87fb4a0064ef48954", "title": "Efficient Sampling of Dependency Structure", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2021, "citationCount": 0, "openAccessPdf": {"url": "https://doi.org/10.18653/v1/2021.emnlp-main.824", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2109.06521, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2021-09-14", "authors": [{"authorId": "51044403", "name": "Ran Zmigrod"}, {"authorId": "2396787", "name": "Tim Vieira"}, {"authorId": "2295665129", "name": "Ryan Cotterell"}], "abstract": "Probabilistic distributions over spanning trees in directed graphs are a fundamental model of dependency structure in natural language processing, syntactic dependency trees. In NLP, dependency trees often have an additional root constraint: only one edge may emanate from the root. However, no sampling algorithm has been presented in the literature to account for this additional constraint. In this paper, we adapt two spanning tree sampling algorithms to faithfully sample dependency trees from a graph subject to the root constraint. Wilson (1996(\u2019s sampling algorithm has a running time of O(H) where H is the mean hitting time of the graph. Colbourn (1996)\u2019s sampling algorithm has a running time of O(N\u02c63), which is often greater than the mean hitting time of a directed graph. Additionally, we build upon Colbourn\u2019s algorithm and present a novel extension that can sample K trees without replacement in O(K N\u02c63 + K\u02c62 N) time. To the best of our knowledge, no algorithm has been given for sampling spanning trees without replacement from a directed graph.", "corpusId": "243865154", "paragraphs": [{"paragraphId": "21184", "title": "Efficient Sampling of Dependency Structure", "sectionTitle": "Introduction", "text": "Spanning trees in directed graphs 2 are fundamental combinatorial structures in natural language processing where they are used to represent dependency structures-especially syntactic dependency structure (K\u00fcbler et al., 2009). Additionally, probabilistic models over spanning trees are common in the NLP literature with applications primarily in non-projective dependency parsing (Pei et al., 2015;Wang and Chang, 2016;Dozat and Manning, 2017;Ma and Hovy, 2017), but also in recovering phylogenic structures (Andrews et al., 2012), and event extraction (McClosky et al., 2011).", "spans": "[{\"corpusId\": 2102270, \"span\": \"(Pei et al., 2015;\", \"start\": 381, \"end\": 399}, {\"corpusId\": 9289495, \"span\": \"Wang and Chang, 2016;\", \"start\": 399, \"end\": 420}, {\"corpusId\": 7942973, \"span\": \"Dozat and Manning, 2017;\", \"start\": 420, \"end\": 444}, {\"corpusId\": 6925721, \"span\": \"Ma and Hovy, 2017)\", \"start\": 444, \"end\": 462}, {\"corpusId\": 15188277, \"span\": \"(Andrews et al., 2012)\", \"start\": 509, \"end\": 531}, {\"corpusId\": 9821042, \"span\": \"(McClosky et al., 2011)\", \"start\": 554, \"end\": 577}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 6}, {"paragraphId": "21185", "title": "Efficient Sampling of Dependency Structure", "sectionTitle": "Introduction", "text": "Given the prevalence of such probabilistic models, efficient dependency tree sampling algorithms deserve study. Indeed, some work has been done in transition-based dependency parsing (Keith et al., 2018) as well as graph-based dependency parsing (Nakagawa, 2007;Mare\u010dek and \u017dabokrtsk\u00fd, 2011). Sampling has also been utilized in an abundance of NLP tasks, such as text generation (Clark et al., 2018;Fedus et al., 2018), co-reference resolution (Singh et al., 2012), and language modeling (Mnih and Hinton, 2007;Logan IV et al., 2020).", "spans": "[{\"corpusId\": 4934209, \"span\": \"(Keith et al., 2018)\", \"start\": 183, \"end\": 203}, {\"corpusId\": 9310605, \"span\": \"(Nakagawa, 2007;\", \"start\": 246, \"end\": 262}, {\"corpusId\": 1442456, \"span\": \"Mare\\u010dek and \\u017dabokrtsk\\u00fd, 2011)\", \"start\": 262, \"end\": 291}, {\"corpusId\": 52865081, \"span\": \"(Clark et al., 2018;\", \"start\": 379, \"end\": 399}, {\"corpusId\": 3655946, \"span\": \"Fedus et al., 2018)\", \"start\": 399, \"end\": 418}, {\"corpusId\": 2804797, \"span\": \"(Singh et al., 2012)\", \"start\": 444, \"end\": 464}, {\"corpusId\": 577005, \"span\": \"(Mnih and Hinton, 2007;\", \"start\": 488, \"end\": 511}, {\"corpusId\": 220045846, \"span\": \"Logan IV et al., 2020)\", \"start\": 511, \"end\": 533}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 8}, {"paragraphId": "21186", "title": "Efficient Sampling of Dependency Structure", "sectionTitle": "Introduction", "text": "The theoretical computer science literature has several efficient algorithms for sampling directed spanning trees. These algorithms come in two flavors. First, random walks through Markov chains have been used to sample spanning trees from both undirected (Broder, 1989;Aldous, 1990) and directed graphs (Wilson, 1996). The algorithm of Wilson (1996) is linear in the mean hitting time of the graph and is currently the fastest sampling algorithm for directed spanning trees. It has been used in dependency parsing inference by Zhang et al. (2014a,b). Second, several algorithms have leveraged the matrix-tree theorem (MTT; Kirchhoff, 1847;Tutte, 1984). The MTT has been frequently used to perform inference on non-projective graphbased dependency parsers (Koo et al., 2007;Mc-Donald and Satta, 2007;Smith and Smith, 2007;Zmigrod et al., 2021). This theorem was first used for sampling by Gu\u00e9noche (1983) who gave an O(N 5 ) algorithm which was then improved by Kulkarni (1990) and Colbourn et al. (1996). Colbourn et al. (1996) give an O(N 3 ) algorithm to sample spanning trees from an unweighted directed graph. We generalize their algorithm to the weighted case.", "spans": "[{\"corpusId\": 8057709, \"span\": \"(Broder, 1989;\", \"start\": 256, \"end\": 270}, {\"corpusId\": 6993062, \"span\": \"Aldous, 1990\", \"start\": 270, \"end\": 282}, {\"corpusId\": 207198080, \"span\": \"(Wilson, 1996)\", \"start\": 304, \"end\": 318}, {\"corpusId\": 207198080, \"span\": \"Wilson (1996)\", \"start\": 337, \"end\": 350}, {\"corpusId\": 122006791, \"span\": \"Kirchhoff, 1847;\", \"start\": 624, \"end\": 640}, {\"corpusId\": 11896512, \"span\": \"(Koo et al., 2007;\", \"start\": 756, \"end\": 774}, {\"corpusId\": 9230323, \"span\": \"Smith and Smith, 2007;\", \"start\": 800, \"end\": 822}, {\"corpusId\": 221376464, \"span\": \"Zmigrod et al., 2021)\", \"start\": 822, \"end\": 843}, {\"corpusId\": 20558728, \"span\": \"Gu\\u00e9noche (1983)\", \"start\": 889, \"end\": 904}, {\"corpusId\": 11361594, \"span\": \"Kulkarni (1990)\", \"start\": 962, \"end\": 977}, {\"corpusId\": 19505778, \"span\": \"Colbourn et al. (1996)\", \"start\": 982, \"end\": 1004}, {\"corpusId\": 19505778, \"span\": \"Colbourn et al. (1996)\", \"start\": 1006, \"end\": 1028}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 10}, {"paragraphId": "21187", "title": "Efficient Sampling of Dependency Structure", "sectionTitle": "Introduction", "text": "While directed spanning tree sampling algorithms exist, an important constraint of many dependency tree schemes, such as the Universal De-pendency (UD) scheme (Nivre et al., 2018), is that a dependency tree may only have one edge emanating from the designated root symbol. Algorithms exists for enforcing this constraint in decoding (Gabow and Tarjan, 1984;Zmigrod et al., 2020;Stanojevi\u0107 and Cohen, 2021) and inference (Koo et al., 2007;Zmigrod et al., 2021). However, to the best of our knowledge, no sampling algorithm exists which enforces the root constraint.", "spans": "[{\"corpusId\": 34028368, \"span\": \"(Gabow and Tarjan, 1984;\", \"start\": 333, \"end\": 357}, {\"corpusId\": 222141701, \"span\": \"Zmigrod et al., 2020;\", \"start\": 357, \"end\": 378}, {\"corpusId\": 243865119, \"span\": \"Stanojevi\\u0107 and Cohen, 2021)\", \"start\": 378, \"end\": 405}, {\"corpusId\": 11896512, \"span\": \"(Koo et al., 2007;\", \"start\": 420, \"end\": 438}, {\"corpusId\": 221376464, \"span\": \"Zmigrod et al., 2021)\", \"start\": 438, \"end\": 459}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "21188", "title": "Efficient Sampling of Dependency Structure", "sectionTitle": "Introduction", "text": "In this paper, we adapt the algorithms of Wilson (1996) and Colbourn et al. (1996) 3 to efficiently sample directed spanning trees subject to a root constraint while maintaining the runtime of the original algorithms. Additionally, we provide a further extension to Colbourn et al. (1996)'s algorithm that allows us to sample trees without replacement. Sampling without replacement (SWOR) algorithms are useful when distributions are skewed, which is often the case in a trained system. To the best of our knowledge, no SWOR algorithm has been presented in the literature for directed spanning trees, though Shi et al. (2020) provides a general framework that enables a SWOR algorithm to be adapted for particular kinds of sampling algorithms.", "spans": "[{\"corpusId\": 243865154, \"span\": \"this paper\", \"start\": 13, \"end\": 13}, {\"corpusId\": 207198080, \"span\": \"Wilson (1996)\", \"start\": 42, \"end\": 55}, {\"corpusId\": 19505778, \"span\": \"Colbourn et al. (1996)\", \"start\": 60, \"end\": 82}, {\"corpusId\": 19505778, \"span\": \"Colbourn et al. (1996)\", \"start\": 266, \"end\": 288}, {\"corpusId\": 211252488, \"span\": \"Shi et al. (2020)\", \"start\": 608, \"end\": 625}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "21189", "title": "Efficient Sampling of Dependency Structure", "sectionTitle": "Ancestral Sampling", "text": "In this section, we present an extension to the ancestral sampling algorithm of Colbourn et al. (1996) to the weighted graph case. This algorithm relies on the efficient computation of Z using the MTT (Kirchhoff, 1847;Tutte, 1984), allows us to compute Z in O(N 3 ) by taking the determinant of the Laplacian matrix, L \u2208 R N \u00d7N . We use Koo et al. (2007)'s adaptation of the MTT to dependency trees. 5", "spans": "[{\"corpusId\": 19505778, \"span\": \"Colbourn et al. (1996)\", \"start\": 80, \"end\": 102}, {\"corpusId\": 122006791, \"span\": \"(Kirchhoff, 1847;\", \"start\": 201, \"end\": 218}, {\"corpusId\": 11896512, \"span\": \"Koo et al. (2007)\", \"start\": 337, \"end\": 354}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "21190", "title": "Efficient Sampling of Dependency Structure", "sectionTitle": "Sampling Without Replacement", "text": "In this section, we present a novel extension to colbourn that can sample dependency trees without replacement. SWOR algorithms are useful when we must sample multiple trees from the same graph. Specifically, when the distribution of trees over the graph is skewed so that a normal sampling algorithm frequently samples the same trees. This is often the case when the edge weights have been learned using a neural model (Dozat and Manning, 2017;Ma and Hovy, 2017). The SWOR algorithm we present follows the scheme of Shi et al. (2020).", "spans": "[{\"corpusId\": 7942973, \"span\": \"(Dozat and Manning, 2017;\", \"start\": 420, \"end\": 445}, {\"corpusId\": 6925721, \"span\": \"Ma and Hovy, 2017)\", \"start\": 445, \"end\": 463}, {\"corpusId\": 211252488, \"span\": \"Shi et al. (2020)\", \"start\": 517, \"end\": 534}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "21191", "title": "Efficient Sampling of Dependency Structure", "sectionTitle": "Conclusion", "text": "We presented two efficient approaches to sample spanning trees subject to a root constraint, which were based on prior algorithms by Wilson (1996) and Colbourn et al. (1996). While Wilson (1996)'s O(H) algorithm was more rapid, Colbourn et al. (1996)'s O(N 3 ) algorithm is extendable to a novel sampling without replacement algorithm. To the best of our knowledge, not much work has been done in graph-based dependency parsing to sample dependency trees, and none has used sampling without replacement. We hope that this paper serves as a tutorial for how this can be done and encourages the use of sampling in future work.", "spans": "[{\"corpusId\": 207198080, \"span\": \"Wilson (1996)\", \"start\": 133, \"end\": 146}, {\"corpusId\": 19505778, \"span\": \"Colbourn et al. (1996)\", \"start\": 151, \"end\": 173}, {\"corpusId\": 243865154, \"span\": \"this paper\", \"start\": 527, \"end\": 527}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 8}
{"paperId": "66c87d70cd5e0981ad4c7ae85dff260b2c7e90d7", "title": "Digital Ventriloquism: Giving Voice to Everyday Objects", "venue": "International Conference on Human Factors in Computing Systems", "year": 2020, "citationCount": 20, "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3313831.3376503?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3313831.3376503, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2020-04-21", "authors": [{"authorId": "81800241", "name": "Yasha Iravantchi"}, {"authorId": "4646339", "name": "Mayank Goel"}, {"authorId": "145078227", "name": "Chris Harrison"}], "abstract": "Smart speakers with voice agents are becoming increasingly common. However, the agent's voice always emanates from the device, even when that information is contextually and spatially relevant elsewhere. Digital Ventriloquism allows smart speakers to render sound onto everyday objects, such that it appears they are speaking and are interactive. This can be achieved without any modification of objects or the environment. For this, we used a highly directional pan-tilt ultrasonic array. By modulating a 40 kHz ultrasonic signal, we can emit sound that is inaudible \"in flight\" and demodulates to audible frequencies when impacting a surface through acoustic parametric interaction. This makes it appear as though the sound originates from an object and not the speaker. We ran a study in which we projected speech onto five objects in three environments, and found that participants were able to correctly identify the source object 92% of the time and correctly repeat the spoken message 100% of the time, demonstrating our digital ventriloquy is both directional and intelligible.", "corpusId": "218482500", "paragraphs": [{"paragraphId": "37200", "title": "Digital Ventriloquism: Giving Voice to Everyday Objects", "sectionTitle": "Ultrasound in HCI", "text": "Ultrasound can be generated using low cost components: transducers can be found for as little as $0.25/pc [1], making ultrasound popular in many sensor-driven systems in the Human-Computer Interaction literature. For example, ultrasound is used as a rangefinder [16,4] and for Doppler sensing [13,32]. Beyond these two more common uses of ultrasound, interference effects [9] and beamforming [8] have been utilized for face and hand gesture recognition. Finally, the closest implementation of ultrasound to Digital Ventriloquism is for in-air haptics, which uses a similar array of coplanar transducers working in concert to create focused ultrasonic energy [3,12,19,41]. See [32] for a survey of uses of ultrasound in HCI.", "spans": "[{\"corpusId\": \"6437170\", \"span\": \"[16,\", \"start\": 262, \"end\": 266}, {\"corpusId\": \"3044352\", \"span\": \"4]\", \"start\": 266, \"end\": 268}, {\"corpusId\": \"2696021\", \"span\": \"[13,\", \"start\": 293, \"end\": 297}, {\"corpusId\": \"17080090\", \"span\": \"32]\", \"start\": 297, \"end\": 300}, {\"corpusId\": \"140224713\", \"span\": \"[9]\", \"start\": 372, \"end\": 375}, {\"corpusId\": \"140467925\", \"span\": \"[8]\", \"start\": 392, \"end\": 395}, {\"corpusId\": \"4892619\", \"span\": \"12,\", \"start\": 661, \"end\": 664}, {\"corpusId\": \"3467880\", \"span\": \"19,\", \"start\": 664, \"end\": 667}, {\"corpusId\": \"17098762\", \"span\": \"41]\", \"start\": 667, \"end\": 670}, {\"corpusId\": \"17080090\", \"span\": \"[32]\", \"start\": 676, \"end\": 680}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "37201", "title": "Digital Ventriloquism: Giving Voice to Everyday Objects", "sectionTitle": "Localized Audio", "text": "Sound localization plays a strong role in how users perceive their environment, especially in conjunction with visual input to generate immersive spatialized audio environments [26]. In applications where acoustics are tied to coordinated visual feedback, the directionality of the sound is attained through Interaural Time Difference (ITD) in which uses two speakers (often headphones) use phase shifts to give the perception of directionality. This is particularly important for 360\u00b0 videos [17], enhanced mobile apps [18], and interactions with augmented virtual objects [28].", "spans": "[{\"corpusId\": \"3342497\", \"span\": \"[26]\", \"start\": 177, \"end\": 181}, {\"corpusId\": \"18135217\", \"span\": \"[18]\", \"start\": 520, \"end\": 524}, {\"corpusId\": \"26148605\", \"span\": \"[28]\", \"start\": 574, \"end\": 578}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "37202", "title": "Digital Ventriloquism: Giving Voice to Everyday Objects", "sectionTitle": "Localized Audio", "text": "To create a soundscape for more than one observer, individual objects can be augmented with speakers to create a multitude of audio sources that multiple observers can experience [7]. In particular, there is significant work in creating audible overlays in museum environments [6,15,14,29]. Museums may embed paintings with transducers using the canvas as a diaphragm, allowing multiple viewers to experience sound emanating from the painting itself [2]. However, each painting would require instrumentation in order to \"speak\".", "spans": "[{\"corpusId\": \"15443565\", \"span\": \"[7]\", \"start\": 179, \"end\": 182}, {\"corpusId\": \"12717555\", \"span\": \"15,\", \"start\": 280, \"end\": 283}, {\"corpusId\": \"18342829\", \"span\": \"14,\", \"start\": 283, \"end\": 286}, {\"corpusId\": \"34239279\", \"span\": \"29]\", \"start\": 286, \"end\": 289}, {\"corpusId\": \"16017778\", \"span\": \"[2]\", \"start\": 450, \"end\": 453}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "37203", "title": "Digital Ventriloquism: Giving Voice to Everyday Objects", "sectionTitle": "Localized Audio", "text": "Another approach to localize audio is directional audio, which most commonly uses either a parabolic reflector or parabolic speaker array to produce a directed acoustic beam towards a chosen target [31]. Parabolic speakers do not significantly modify their input signal; the sound is completely audible in flight and have a useable listening range of a few meters [31].  Such directional speakers have been widely used in museum environments [15,14] and spherical loudspeakers have been used to reproduce the directivity of musical instruments [21]. With these types of speakers, users still localize the speaker itself as the origin of the sound, and not the targeted object.", "spans": "[{\"corpusId\": \"12717555\", \"span\": \"[15,\", \"start\": 442, \"end\": 446}, {\"corpusId\": \"18342829\", \"span\": \"14]\", \"start\": 446, \"end\": 449}, {\"corpusId\": \"8802026\", \"span\": \"[21]\", \"start\": 544, \"end\": 548}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "37204", "title": "Digital Ventriloquism: Giving Voice to Everyday Objects", "sectionTitle": "Parametric Interaction", "text": "These speakers have been used previously in HCI applications to render audio-enhanced spots through reverse ray tracing [28] and as a localized communication channel [38], including with handheld systems [27]. There is also significant commercial interest in taking advantage of parametric speakers for directional audio, though these systems (e.g., [20]) do not offer implementation details, nor physical or user studies to aid the HCI community. Finally, we note that prior research has explored using parametric speakers on pan-tilt platforms [11,10], exactly like our setup, but it is used to simply direct audio at listeners (i.e., directional audio) and does not explore the notion of ventriloquism, where other objects are given voice, nor using this ventriloquy to enabled distributed intelligence.", "spans": "[{\"corpusId\": \"26148605\", \"span\": \"[28]\", \"start\": 120, \"end\": 124}, {\"corpusId\": \"25413401\", \"span\": \"[38]\", \"start\": 166, \"end\": 170}, {\"corpusId\": \"14399520\", \"span\": \"[27]\", \"start\": 204, \"end\": 208}, {\"corpusId\": \"19000310\", \"span\": \"10]\", \"start\": 550, \"end\": 553}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 5}
{"paperId": "6757225d841451950a5cea245b73e5ff1af34ff1", "title": "Learning to Pronounce Chinese without a Pronunciation Dictionary", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2020, "citationCount": 1, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/2020.emnlp-main.458.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2010.04744, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2020-10-09", "authors": [{"authorId": "51480794", "name": "Christopher Chu"}, {"authorId": "80566426", "name": "Scot Fang"}, {"authorId": "152971314", "name": "Kevin Knight"}], "abstract": "We demonstrate a program that learns to pronounce Chinese text in Mandarin, without a pronunciation dictionary. From non-parallel streams of Chinese characters and Chinese pinyin syllables, it establishes a many-to-many mapping between characters and pronunciations. Using unsupervised methods, the program effectively deciphers writing into speech. Its token-level character-to-syllable accuracy is 89%, which significantly exceeds the 22% accuracy of prior work.", "corpusId": "222290872", "paragraphs": [{"paragraphId": "74514", "title": "Learning to Pronounce Chinese Without a Pronunciation Dictionary", "sectionTitle": "Unsupervised Vector Method", "text": "Borrowing from unsupervised machine translation, which learns mappings between words in different languages (Lample et al., 2018a;Artetxe et al., 2018), we attempt to learn a mapping between embeddings for characters and embeddings for pinyin symbols. We train fastText (Bojanowski et al., 2017) vectors of dimension 300 and default settings on each of our corpora and use the MUSE system 8 to learn the relationship between the two vector spaces (Lample et al., 2018b).", "spans": "[{\"corpusId\": \"3518190\", \"span\": \"(Lample et al., 2018a;\", \"start\": 108, \"end\": 130}, {\"corpusId\": \"52166727\", \"span\": \"Artetxe et al., 2018)\", \"start\": 130, \"end\": 151}, {\"corpusId\": \"207556454\", \"span\": \"(Bojanowski et al., 2017)\", \"start\": 270, \"end\": 295}, {\"corpusId\": \"3470398\", \"span\": \"(Lample et al., 2018b)\", \"start\": 447, \"end\": 469}]", "conference": "emnlp", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 1}
{"paperId": "dbb419268a467a0f42f737ab4386bf42ca6ecd65", "title": "CollaDroid: Automatic Augmentation of Android Application with Lightweight Interactive Collaboration", "venue": "Conference on Computer Supported Cooperative Work", "year": 2017, "citationCount": 11, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/2998181.2998278?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2998181.2998278, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2017-02-25", "authors": [{"authorId": "40282220", "name": "Jiahuan Zheng"}, {"authorId": "143621878", "name": "Xin Peng"}, {"authorId": "2368275262", "name": "Jiacheng Yang"}, {"authorId": "144703054", "name": "Huaqian Cai"}, {"authorId": "144513592", "name": "Gang Huang"}, {"authorId": "2153393191", "name": "Ying Zhang"}, {"authorId": "2636713", "name": "Wenyun Zhao"}], "abstract": null, "corpusId": "3474244", "paragraphs": [{"paragraphId": "71108", "title": "CollaDroid: Automatic Augmentation of Android Application with Lightweight Interactive Collaboration", "sectionTitle": "INTRODUCTION", "text": "With the widespread use of mobile devices (e.g., smartphones), collaborative work supported by mobile applications has become more and more popular. Users can use mobile applications to collaboratively create and edit various kinds of artifacts such as UML sketch [16], comic strip [10]. They can Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions@acm.org. also use mobile applications to leverage mobile crowdsourcing and participatory sensing for various purposes such as estimating individual exposure to environmental pollution [15], predicting bus arrival time [18], and obtaining map-based information [7].", "spans": "[{\"corpusId\": 17674460, \"span\": \"[16]\", \"start\": 264, \"end\": 268}, {\"corpusId\": 17250547, \"span\": \"[10]\", \"start\": 282, \"end\": 286}, {\"corpusId\": 3474244, \"span\": \"this work\", \"start\": 366, \"end\": 366}, {\"corpusId\": 3474244, \"span\": \"this work\", \"start\": 616, \"end\": 616}, {\"corpusId\": 17185671, \"span\": \"[15]\", \"start\": 1048, \"end\": 1052}, {\"corpusId\": 8822719, \"span\": \"[18]\", \"start\": 1082, \"end\": 1086}, {\"corpusId\": 40837157, \"span\": \"[7]\", \"start\": 1124, \"end\": 1127}]", "conference": "cscw", "year": 2017, "likelyRelatedWorkSection": false, "refCount": 6}, {"paragraphId": "71109", "title": "CollaDroid: Automatic Augmentation of Android Application with Lightweight Interactive Collaboration", "sectionTitle": "RELATED WORK", "text": "There have been researches on collaborative work on mobile devices. Ah Kun and Marsden [1] developed a mobile application that allows users to share photos with other co-present users by synchronizing the display on multiple mobile devices. BeThere [14] supports collaborative interactions involving 3D input. The 3D representation of the local environment at the requester side is captured by integrated depth sensors and displayed on the mobile screen of both sides. The collaborators 3D gesture thus can be captured and a virtual hand is formed on the screen of the requester device to instruct her to move the physical blocks in her environment. Gauglitz et al. [4] proposed a framework and implemented a prototype for mobile collaboration in the physical environment. Based on the framework, a requester and a collaborator can share real-time environment video captured by the filming equipment at the requester side and visual annotations labelled by the collaborator. MobiSurf [13] integrates an interactive surface into the interaction with people's own personal and mobile devices using existing interaction technologies and techniques It supports co-located collaboration through integrating mobile devices and interactive surfaces. Different from these works, CollaDroid supports interactive and remote collaboration on mobile applications.", "spans": "[{\"corpusId\": 13560089, \"span\": \"[1]\", \"start\": 87, \"end\": 90}, {\"corpusId\": 18760367, \"span\": \"[14]\", \"start\": 249, \"end\": 253}, {\"corpusId\": 1071756, \"span\": \"[4]\", \"start\": 666, \"end\": 669}, {\"corpusId\": 7820927, \"span\": \"[13]\", \"start\": 984, \"end\": 988}]", "conference": "cscw", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "71110", "title": "CollaDroid: Automatic Augmentation of Android Application with Lightweight Interactive Collaboration", "sectionTitle": "RELATED WORK", "text": "Most of the existing researches on program transformation of mobile applications focus on improving the performance and saving the energy of applications by refactoring. Zhang et al. [17] developed an automatic refactoring tool for Android applications which enables the applications to perform on-demand computation offloading at runtime to improve the performance and save energy. Lin et al. [9] developed an automatic refactoring tool which transfers incorrect An-droid async constructs into correct ones. The tool can extract long-running operations and encapsulate them in Async-Task for better performance. The application refactoring tool ASYNCDROID [8] helps Android developers to correct misused asynchronous programming constructs (AsyncTask) to IntentService, which uses a distributed communication instead of shared memory communication to prevent memory leak. Hao et al. [5] proposed a binary instrumentation framework for Android applications which can be used to specify instrumentation location compactly and precisely at different granularities. Lenin Ravindranath et al. [12] implemented an automatic fault detecting system for mobile applications by instrumenting the application binary to emulate various user, network and sensor behaviors to detect failures. Although these works also involve the analysis and transformation of Android applications, our work is targeted at a different specific goal, i.e., augmenting applications with lightweight interactive collaboration.", "spans": "[{\"corpusId\": 3484461, \"span\": \"[17]\", \"start\": 183, \"end\": 187}, {\"corpusId\": 5965262, \"span\": \"[9]\", \"start\": 394, \"end\": 397}, {\"corpusId\": 15647974, \"span\": \"[8]\", \"start\": 657, \"end\": 660}, {\"corpusId\": 7717345, \"span\": \"[5]\", \"start\": 884, \"end\": 887}, {\"corpusId\": 1274663, \"span\": \"[12]\", \"start\": 1089, \"end\": 1093}, {\"corpusId\": 3474244, \"span\": \"our work\", \"start\": 1379, \"end\": 1379}]", "conference": "cscw", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 6}], "paragraphCount": 3}
{"paperId": "133d4278069bd3eba627611c51a388879e9eae46", "title": "What Should I Ask? Using Conversationally Informative Rewards for Goal-oriented Visual Dialog.", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2019, "citationCount": 34, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/P19-1646.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1907.12021, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2019-07-01", "authors": [{"authorId": "9267940", "name": "Pushkar Shukla"}, {"authorId": "46185376", "name": "Carlos E. L. Elmadjian"}, {"authorId": "32883757", "name": "Richika Sharan"}, {"authorId": "144592382", "name": "Vivek Kulkarni"}, {"authorId": "2068762396", "name": "Matthew A. Turk"}, {"authorId": "1682479", "name": "William Yang Wang"}], "abstract": "The ability to engage in goal-oriented conversations has allowed humans to gain knowledge, reduce uncertainty, and perform tasks more efficiently. Artificial agents, however, are still far behind humans in having goal-driven conversations. In this work, we focus on the task of goal-oriented visual dialogue, aiming to automatically generate a series of questions about an image with a single objective. This task is challenging since these questions must not only be consistent with a strategy to achieve a goal, but also consider the contextual information in the image. We propose an end-to-end goal-oriented visual dialogue system, that combines reinforcement learning with regularized information gain. Unlike previous approaches that have been proposed for the task, our work is motivated by the Rational Speech Act framework, which models the process of human inquiry to reach a goal. We test the two versions of our model on the GuessWhat?! dataset, obtaining significant results that outperform the current state-of-the-art models in the task of generating questions to find an undisclosed object in an image.", "corpusId": "196180698", "paragraphs": [{"paragraphId": "27483", "title": "What Should I Ask? Using Conversationally Informative Rewards for Goal-oriented Visual Dialog.", "sectionTitle": "Table 3 :", "text": "With this challenge in mind, we directed our attention to contemporary works in the field of cognitive science, linguistics and psychology for modelling human inquiry (Groenendijk et al., 1984;Nelson, 2005;Van Rooy, 2003). More specifically, our focus lies on how humans come up with a series of questions in order to reach a particular goal. One popular theory suggests that humans try to maximize the expected regularized information gain while asking questions (Hawkins et al., 2015;Coenen et al., 2017). Motivated by that, we evaluate the utility of using information gain for goal-oriented visual question generation with a reinforcement learning paradigm. In this paper, we propose two different approaches for training an end-to-end architecture: first, a novel reward function that is a trade-off between the expected information gain of a question and the cost of asking it; and second, a loss function that uses regularized information gain with a step-based reward function. Our architecture is able to generate goal-oriented questions without using any prior templates. Our experiments are performed on the GuessWhat?! dataset , a standard dataset for goal-oriented visual dialogue that focuses on identifying an undisclosed object in the image through a series of questions. Thus, our contribution is threefold:", "spans": "[{\"corpusId\": \"8084012\", \"span\": \"Nelson, 2005;\", \"start\": 193, \"end\": 206}, {\"corpusId\": \"15173587\", \"span\": \"Van Rooy, 2003)\", \"start\": 206, \"end\": 221}, {\"corpusId\": 196180698, \"span\": \"our focus\", \"start\": 251, \"end\": 251}, {\"corpusId\": 196180698, \"span\": \"this paper\", \"start\": 675, \"end\": 675}, {\"corpusId\": 196180698, \"span\": \"we propose\", \"start\": 687, \"end\": 687}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "27484", "title": "What Should I Ask? Using Conversationally Informative Rewards for Goal-oriented Visual Dialog.", "sectionTitle": "Dialogue Generation and Visual Dialogue", "text": "Dialogue generation is an important research topic in NLP, thus many approaches have been proposed to address this task. Most earlier works made use of a predefined template (Lemon et al., 2006;Wang and Lemon, 2013) to generate dialogues. More recently, deep neural networks have been used for building end-to-end architectures capable of generating questions (Vinyals and Le, 2015;Sordoni et al., 2015) and also for the task of goal-oriented dialogue generation (Rajendran et al., 2018;Bordes et al., 2017). Visual dialogue focuses on having a conversation about an image with either one or both of the agents being a machine. Since its inception (Das et al., 2017), different approaches have been proposed to address this problem (Massiceti et al., 2018;Lu et al., 2017;Das et al., 2017). Goaloriented Visual Dialogue, on the other hand, is an area that has only been introduced fairly recently. De Vries et al.  proposed the GuessWhat?! dataset for goal-oriented visual dialogue while Strub et al.  developed a reinforcement learning approach for Figure 2: A block diagram of our model. The framework is trained on top of three individual models: the questioner (QGen), the guesser, and the oracle. The guesser returns an object distribution given a history of question-answer pairs that are generated by the questioner and the oracle respectively. These distributions are used for calculating the information gain of the question-answer pair. The information gain and distribution of probabilities given by the Guesser are used either as a reward or optimized as a loss function with global rewards for training the questioner.", "spans": "[{\"corpusId\": \"8004345\", \"span\": \"(Lemon et al., 2006;\", \"start\": 174, \"end\": 194}, {\"corpusId\": \"8109232\", \"span\": \"Wang and Lemon, 2013)\", \"start\": 194, \"end\": 215}, {\"corpusId\": \"52131263\", \"span\": \"(Rajendran et al., 2018;\", \"start\": 463, \"end\": 487}, {\"corpusId\": \"2129889\", \"span\": \"Bordes et al., 2017)\", \"start\": 487, \"end\": 507}, {\"corpusId\": \"35001335\", \"span\": \"Lu et al., 2017;\", \"start\": 756, \"end\": 772}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 5}], "paragraphCount": 2}
{"paperId": "c983102bb0c36b5e7e6ca15f4df2f7dc98b9a9a5", "title": "Combining Self-Training and Self-Supervised Learning for Unsupervised Disfluency Detection", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2020, "citationCount": 17, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/2020.emnlp-main.142.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2010.15360, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2020-10-29", "authors": [{"authorId": "38258535", "name": "Shaolei Wang"}, {"authorId": "2135394423", "name": "Zhongyuan Wang"}, {"authorId": "2256319", "name": "Wanxiang Che"}, {"authorId": "40282288", "name": "Ting Liu"}], "abstract": "Most existing approaches to disfluency detection heavily rely on human-annotated corpora, which is expensive to obtain in practice. There have been several proposals to alleviate this issue with, for instance, self-supervised learning techniques, but they still require human-annotated corpora. In this work, we explore the unsupervised learning paradigm which can potentially work with unlabeled text corpora that are cheaper and easier to obtain. Our model builds upon the recent work on Noisy Student Training, a semi-supervised learning approach that extends the idea of self-training. Experimental results on the commonly used English Switchboard test set show that our approach achieves competitive performance compared to the previous state-of-the-art supervised systems using contextualized word embeddings (e.g. BERT and ELECTRA).", "corpusId": "225102861", "paragraphs": [{"paragraphId": "85960", "title": "Combining Self-Training and Self-Supervised Learning for Unsupervised Disfluency Detection", "sectionTitle": "Settings", "text": "Dataset. English Switchboard (SWBD) (Godfrey et al., 1992) is the standard and largest (1.73 \u00d7 10 5 sentences for training ) corpus used for disfluency detection. We use English Switchboard as main data. Following the experiment settings in Charniak and Johnson (2001), we split the Switchboard corpus into train, dev and test set as follows: train data consists of all sw[23] * .dff files, dev data consists of all sw4[5-9] * .dff files and test data consists of all sw4[0-1] * .dff files. Following Honnibal and Johnson (2014), we lower-case the text and remove all punctuations and partial words. 2 We also discard the 'um' and 'uh' tokens and merge 'you know' and 'i mean' into single tokens.", "spans": "[{\"corpusId\": \"61412708\", \"span\": \"(Godfrey et al., 1992)\", \"start\": 36, \"end\": 58}, {\"corpusId\": \"5454540\", \"span\": \"Charniak and Johnson (2001)\", \"start\": 241, \"end\": 268}, {\"corpusId\": \"18046506\", \"span\": \"Honnibal and Johnson (2014)\", \"start\": 501, \"end\": 528}]", "conference": "emnlp", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "85961", "title": "Combining Self-Training and Self-Supervised Learning for Unsupervised Disfluency Detection", "sectionTitle": "Method P R F1", "text": "UBT (Wu et al., 2015) 90.3 80.5 85.1 Bi-LSTM (Zayats et al., 2016) 91.8 80.6 85.9 NCM (Lou and Johnson, 2017) --86.8 Transition-based (Wang et al., 2017) 91.1 84.1 87.5 Self-supervised  93.4 87.3 90.2 Self-training (Lou and Johnson, 2020) Table 4: Comparison with previous state-of-the-art methods on the Switchboard test set. The first part (from row 1 to row 4) is the methods without using contextualized word embeddings (e.g. ELMo (Peters et al., 2018) and ELECTRA), the second part (row 5 to 7) is the methods using contextualized word embeddings.", "spans": "[{\"corpusId\": \"11421759\", \"span\": \"(Wu et al., 2015)\", \"start\": 4, \"end\": 21}, {\"corpusId\": \"260001\", \"span\": \"(Lou and Johnson, 2017)\", \"start\": 86, \"end\": 109}, {\"corpusId\": \"31356274\", \"span\": \"(Wang et al., 2017)\", \"start\": 134, \"end\": 153}, {\"corpusId\": \"3626819\", \"span\": \"(Peters et al., 2018)\", \"start\": 435, \"end\": 456}]", "conference": "emnlp", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "85962", "title": "Combining Self-Training and Self-Supervised Learning for Unsupervised Disfluency Detection", "sectionTitle": "Related Work Disfluency Detection", "text": "Most work on disfluency detection focus on supervised learning methods, which mainly fall into three main categories: sequence tagging, noisy-channel, and parsing-based approaches. Sequence tagging approaches label words as fluent or disfluent using a variety of different techniques, including conditional random fields (CRF) (Georgila, 2009;Ostendorf and Hahn, 2013;Zayats et al., 2014), Max-Margin Markov Networks (M 3 N) (Qian and Liu, 2013), Semi-Markov CRF (Ferguson et al., 2015), and recurrent neural networks (Hough and Schlangen, 2015;Zayats et al., 2016;Wang et al., 2016). The main benefit of sequential models is the ability to capture longterm relationships between reparandum and repairs. Noisy channel models (Charniak and Johnson, 2001;Johnson and Charniak, 2004;Zwarts et al., 2010;Lou and Johnson, 2017) use the similarity between reparandum and repair as an indicator of disfluency. Parsing-based approaches (Rasooli and Tetreault, 2013;Honnibal and Johnson, 2014;Wu et al., 2015;Yoshikawa et al., 2016;Jamshid Lou et al., 2019) jointly perform parsing and disfluency detection. The joint models can capture long-range dependency of disfluencies as well as chunk-level information. However, training a parsing-based model requires large annotated tree-banks that contain both disfluencies and syntactic structures.", "spans": "[{\"corpusId\": \"14902521\", \"span\": \"(Georgila, 2009;\", \"start\": 327, \"end\": 343}, {\"corpusId\": \"13577557\", \"span\": \"Ostendorf and Hahn, 2013;\", \"start\": 343, \"end\": 368}, {\"corpusId\": \"2901186\", \"span\": \"Zayats et al., 2014)\", \"start\": 368, \"end\": 388}, {\"corpusId\": \"6193081\", \"span\": \"(Qian and Liu, 2013)\", \"start\": 425, \"end\": 445}, {\"corpusId\": \"16444685\", \"span\": \"(Ferguson et al., 2015)\", \"start\": 463, \"end\": 486}, {\"corpusId\": \"5696849\", \"span\": \"(Hough and Schlangen, 2015;\", \"start\": 518, \"end\": 545}, {\"corpusId\": \"16954494\", \"span\": \"Wang et al., 2016)\", \"start\": 565, \"end\": 583}, {\"corpusId\": \"5454540\", \"span\": \"(Charniak and Johnson, 2001;\", \"start\": 725, \"end\": 753}, {\"corpusId\": \"18837411\", \"span\": \"Johnson and Charniak, 2004;\", \"start\": 753, \"end\": 780}, {\"corpusId\": \"10557042\", \"span\": \"Zwarts et al., 2010;\", \"start\": 780, \"end\": 800}, {\"corpusId\": \"260001\", \"span\": \"Lou and Johnson, 2017)\", \"start\": 800, \"end\": 822}, {\"corpusId\": \"12672052\", \"span\": \"(Rasooli and Tetreault, 2013;\", \"start\": 928, \"end\": 957}, {\"corpusId\": \"18046506\", \"span\": \"Honnibal and Johnson, 2014;\", \"start\": 957, \"end\": 984}, {\"corpusId\": \"11421759\", \"span\": \"Wu et al., 2015;\", \"start\": 984, \"end\": 1000}, {\"corpusId\": \"17745836\", \"span\": \"Yoshikawa et al., 2016;\", \"start\": 1000, \"end\": 1023}]", "conference": "emnlp", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 15}, {"paragraphId": "85963", "title": "Combining Self-Training and Self-Supervised Learning for Unsupervised Disfluency Detection", "sectionTitle": "Self-Supervised Representation Learning", "text": "Self-supervised learning aims to train a network on an auxiliary task where ground-truth is obtained automatically. Over the last few years, many selfsupervised tasks have been introduced in image processing domain, which make use of non-visual signals, intrinsically correlated to the image, as a form to supervise visual feature learning (Agrawal et al., 2015;Wang and Gupta, 2015;Doersch et al., 2015).", "spans": "[{\"corpusId\": \"1637703\", \"span\": \"(Agrawal et al., 2015;\", \"start\": 340, \"end\": 362}, {\"corpusId\": \"2057504\", \"span\": \"Wang and Gupta, 2015;\", \"start\": 362, \"end\": 383}, {\"corpusId\": \"9062671\", \"span\": \"Doersch et al., 2015)\", \"start\": 383, \"end\": 404}]", "conference": "emnlp", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "85964", "title": "Combining Self-Training and Self-Supervised Learning for Unsupervised Disfluency Detection", "sectionTitle": "Self-Supervised Representation Learning", "text": "Language model pre-training (Bengio et al., 2003;Peters et al., 2018;Radford et al., 2018;Devlin et al., 2019) is another line of self-supervised learning task. A trained language model learns a function to predict the likelihood of occurrence of a word based on the surrounding sequence of words used in the text. There are mainly two existing strategies for applying pre-trained language rep-resentations to down-stream tasks: feature-based and fine-tuning. The feature-based approach, such as ELMo (Peters et al., 2018), uses task-specific architectures that include the pre-trained representations as additional features. The fine-tuning approach, such as the Generative Pre-trained Transformer (OpenAI GPT) (Radford et al., 2018) and BERT (Devlin et al., 2019), introduces minimal task-specific parameters and is trained on the downstream tasks by simply fine-tuning the pre-trained parameters.", "spans": "[{\"corpusId\": \"221275765\", \"span\": \"(Bengio et al., 2003;\", \"start\": 28, \"end\": 49}, {\"corpusId\": \"3626819\", \"span\": \"Peters et al., 2018;\", \"start\": 49, \"end\": 69}, {\"corpusId\": \"52967399\", \"span\": \"Devlin et al., 2019)\", \"start\": 90, \"end\": 110}, {\"corpusId\": \"3626819\", \"span\": \"(Peters et al., 2018)\", \"start\": 501, \"end\": 522}, {\"corpusId\": \"52967399\", \"span\": \"(Devlin et al., 2019)\", \"start\": 744, \"end\": 765}]", "conference": "emnlp", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "85965", "title": "Combining Self-Training and Self-Supervised Learning for Unsupervised Disfluency Detection", "sectionTitle": "Self-Training", "text": "Self-training (McClosky et al., 2006) first uses labeled data to train a good teacher model, then use the teacher model to label unlabeled data and finally use the labeled data and unlabeled data to jointly train a student model. Self-training has also been shown to work well for a variety of tasks including leveraging noisy data (Veit et al., 2017), semantic segmentation (Babakhin et al., 2019), text classification (Li et al., 2019). Xie et al. (2019) present Noisy Student Training, which extends the idea of self-training with the use of equal-or-larger student models and noise added to the student during learning.", "spans": "[{\"corpusId\": \"628455\", \"span\": \"(McClosky et al., 2006)\", \"start\": 14, \"end\": 37}, {\"corpusId\": \"52114281\", \"span\": \"\", \"start\": -25565, \"end\": -25540}, {\"corpusId\": \"164146\", \"span\": \"(Veit et al., 2017)\", \"start\": 332, \"end\": 351}, {\"corpusId\": \"104292091\", \"span\": \"(Babakhin et al., 2019)\", \"start\": 375, \"end\": 398}, {\"corpusId\": \"173990853\", \"span\": \"(Li et al., 2019)\", \"start\": 420, \"end\": 437}]", "conference": "emnlp", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 5}], "paragraphCount": 6}
{"paperId": "f48ae425e2567be2d993efcaaf74c2274fc9d7c5", "title": "COMET: Commonsense Transformers for Automatic Knowledge Graph Construction", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2019, "citationCount": 965, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/P19-1470.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1906.05317, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2019-06-12", "authors": [{"authorId": "2691021", "name": "Antoine Bosselut"}, {"authorId": "2516777", "name": "Hannah Rashkin"}, {"authorId": "2729164", "name": "Maarten Sap"}, {"authorId": "8805254", "name": "Chaitanya Malaviya"}, {"authorId": "1709797", "name": "Asli Celikyilmaz"}, {"authorId": "1699545", "name": "Yejin Choi"}], "abstract": "We present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et al., 2019) and ConceptNet (Speer et al., 2017). Contrary to many conventional KBs that store knowledge with canonical templates, commonsense KBs only store loosely structured open-text descriptions of knowledge. We posit that an important step toward automatic commonsense completion is the development of generative models of commonsense knowledge, and propose COMmonsEnse Transformers (COMET) that learn to generate rich and diverse commonsense descriptions in natural language. Despite the challenges of commonsense modeling, our investigation reveals promising results when implicit knowledge from deep pre-trained language models is transferred to generate explicit knowledge in commonsense knowledge graphs. Empirical results demonstrate that COMET is able to generate novel knowledge that humans rate as high quality, with up to 77.5% (ATOMIC) and 91.7% (ConceptNet) precision at top 1, which approaches human performance for these resources. Our findings suggest that using generative commonsense models for automatic commonsense KB completion could soon be a plausible alternative to extractive methods.", "corpusId": "189762527", "paragraphs": [{"paragraphId": "37465", "title": "COMET: Commonsense Transformers for Automatic Knowledge Graph Construction", "sectionTitle": "Introduction", "text": "When reading text, humans make commonsense inferences that frame their understanding of the narrative being presented. For machines to achieve this capability, they must be able to acquire relevant and correct commonsense for an unbounded set of situations. In this work, we cast commonsense acquisition as knowledge base construction and investigate whether large-scale language models can effectively learn to generate the knowledge  necessary to automatically construct a commonsense knowledge base (KB). Automatic KB construction is a long-standing goal of artificial intelligence research due to the difficulty of achieving high concept coverage in high-precision curated KBs (Lenat, 1995;Miller, 1995). Previous work has developed models capable of reading and extracting semi-structured text (Suchanek et al., 2007;Hoffart et al., 2013;Auer et al., 2007;Bollacker et al., 2008) and unstructured text (Dong et al., 2014;Carlson et al., 2010;Nakashole et al., 2011Nakashole et al., , 2012Niu, 2012) into relational schemas that can be queried for downstream applications. A common thread of these approaches, however, is the focus on encyclopedic knowledge, which lends itself to a well-defined space of entities and relations that can be modeled.", "spans": "[{\"corpusId\": 189762527, \"span\": \"this work\", \"start\": 270, \"end\": 270}, {\"corpusId\": 16147141, \"span\": \"(Lenat, 1995;\", \"start\": 681, \"end\": 694}, {\"corpusId\": 1671874, \"span\": \"Miller, 1995)\", \"start\": 694, \"end\": 707}, {\"corpusId\": 207163173, \"span\": \"(Suchanek et al., 2007;\", \"start\": 799, \"end\": 822}, {\"corpusId\": 6118799, \"span\": \"Hoffart et al., 2013;\", \"start\": 822, \"end\": 843}, {\"corpusId\": 207167677, \"span\": \"Bollacker et al., 2008)\", \"start\": 861, \"end\": 884}, {\"corpusId\": 4557963, \"span\": \"(Dong et al., 2014;\", \"start\": 907, \"end\": 926}, {\"corpusId\": 1064204, \"span\": \"Nakashole et al., 2011\", \"start\": 947, \"end\": 969}, {\"corpusId\": 2257688, \"span\": \"Nakashole et al., , 2012\", \"start\": 969, \"end\": 993}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 9}, {"paragraphId": "37466", "title": "COMET: Commonsense Transformers for Automatic Knowledge Graph Construction", "sectionTitle": "Introduction", "text": "to model \"entities\" as natural language phrases and relations as any concept that can link them (Li et al., 2016;Sap et al., 2019). OpenIE approaches display this property of open text entities and relations Mausam et al., 2012), but being extractive, they only capture knowledge that is explicitly mentioned in text, limiting their applicability for capturing commonsense knowledge, which is often implicit (Gordon and Van Durme, 2013).", "spans": "[{\"corpusId\": 1125916, \"span\": \"(Li et al., 2016;\", \"start\": 96, \"end\": 113}, {\"corpusId\": 53170360, \"span\": \"Sap et al., 2019)\", \"start\": 113, \"end\": 130}, {\"corpusId\": 74065, \"span\": \"Mausam et al., 2012)\", \"start\": 208, \"end\": 228}, {\"corpusId\": 16567195, \"span\": \"(Gordon and Van Durme, 2013)\", \"start\": 408, \"end\": 436}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "37467", "title": "COMET: Commonsense Transformers for Automatic Knowledge Graph Construction", "sectionTitle": "Setup", "text": "Baselines We report the performance of our method against the models trained in Sap et al. (2019) that use LSTM sequence-to-sequence models (Sutskever et al., 2014) to encode the input subject and relation and produce an output object.", "spans": "[{\"corpusId\": 189762527, \"span\": \"our method\", \"start\": 49, \"end\": 49}, {\"corpusId\": 53170360, \"span\": \"Sap et al. (2019)\", \"start\": 80, \"end\": 97}, {\"corpusId\": 7961699, \"span\": \"(Sutskever et al., 2014)\", \"start\": 140, \"end\": 164}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "37468", "title": "COMET: Commonsense Transformers for Automatic Knowledge Graph Construction", "sectionTitle": "ConceptNet Experiments", "text": "The ConceptNet dataset 8 , provided by Li et al. (2016), consists of tuples obtained from the Open Mind Common Sense (OMCS) entries in Concept-Net 5 (Speer et al., 2017). Tuples are in the standard sro form -(e.g., take a nap, Causes, have energy). The most confident 1200 tuples were used to create the test set, while the next 1200 tuples were used to create two development sets, which we combine in this work. The 100k version of the training set was used to train models, which contains 34 relation types.", "spans": "[{\"corpusId\": 1125916, \"span\": \"Li et al. (2016)\", \"start\": 39, \"end\": 55}, {\"corpusId\": 15206880, \"span\": \"(Speer et al., 2017)\", \"start\": 149, \"end\": 169}, {\"corpusId\": 189762527, \"span\": \"this work\", \"start\": 412, \"end\": 412}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "37469", "title": "COMET: Commonsense Transformers for Automatic Knowledge Graph Construction", "sectionTitle": "Related Work", "text": "Knowledge base construction Previous work has looked at constructing knowledge bases as relational schemas using expert knowledge (Lenat, 1995;Bodenreider, 2004;Miller, 1995), semistructured text extraction (Suchanek et al., 2007;Hoffart et al., 2013;Auer et al., 2007;Bollacker et al., 2008) and unstructured text extraction (Dong et al., 2014;Carlson et al., 2010;Nakashole et al., 2011Nakashole et al., , 2012Niu, 2012). In our work, we focus on construction of commonsense knowledge bases which require the use of open-text events rather than a well-defined relational schema structure. Other work in information extraction can also be applied to knowledge base construction with open-text entities (Soderland et al., 2010;Mausam et al., 2012;Fan et al., 2010;Cui et al., 2018), but these methods typically extract explicitly stated text relations. Conversely, our approach generates new knowledge that is often unstated in text, as commonsense information typically is (Gordon and Van Durme, 2013).", "spans": "[{\"corpusId\": 16147141, \"span\": \"(Lenat, 1995;\", \"start\": 130, \"end\": 143}, {\"corpusId\": 205228801, \"span\": \"Bodenreider, 2004;\", \"start\": 143, \"end\": 161}, {\"corpusId\": 1671874, \"span\": \"Miller, 1995)\", \"start\": 161, \"end\": 174}, {\"corpusId\": 207163173, \"span\": \"(Suchanek et al., 2007;\", \"start\": 207, \"end\": 230}, {\"corpusId\": 6118799, \"span\": \"Hoffart et al., 2013;\", \"start\": 230, \"end\": 251}, {\"corpusId\": 207167677, \"span\": \"Bollacker et al., 2008)\", \"start\": 269, \"end\": 292}, {\"corpusId\": 4557963, \"span\": \"(Dong et al., 2014;\", \"start\": 326, \"end\": 345}, {\"corpusId\": 1064204, \"span\": \"Nakashole et al., 2011\", \"start\": 366, \"end\": 388}, {\"corpusId\": 2257688, \"span\": \"Nakashole et al., , 2012\", \"start\": 388, \"end\": 412}, {\"corpusId\": 189762527, \"span\": \"our work\", \"start\": 435, \"end\": 435}, {\"corpusId\": 74065, \"span\": \"Mausam et al., 2012;\", \"start\": 727, \"end\": 747}, {\"corpusId\": 21668994, \"span\": \"Cui et al., 2018)\", \"start\": 764, \"end\": 781}, {\"corpusId\": 189762527, \"span\": \"our approach\", \"start\": 877, \"end\": 877}, {\"corpusId\": 16567195, \"span\": \"(Gordon and Van Durme, 2013)\", \"start\": 974, \"end\": 1002}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 13}, {"paragraphId": "37470", "title": "COMET: Commonsense Transformers for Automatic Knowledge Graph Construction", "sectionTitle": "Commonsense knowledge base completion", "text": "Existing work on generation of novel commonsense knowledge has also used ConceptNet and ATOMIC as underlying KBs. Specifically, Li et al. (2016) proposed a set of neural network models for scoring tuples in ConceptNet. Our work differs from this approach as their models evaluate full tuples rather than learning to generate the phrases to make new nodes in the knowledge graph. Saito et al. (2018) builds upon this work by proposing a joint model for completion and generation of commonsense tuples. Their work, however, focuses on using tuple generation to augment their KB completion model, rather than to increase coverage in commonsense KB construction. Finally, Sap et al. (2019) use LSTM encoder-decoder models to generate commonsense knowledge about social situations. We use transformers and investigate the effect of using pre-trained language representations (Radford et al., 2018) to initialize them.", "spans": "[{\"corpusId\": 1125916, \"span\": \"Li et al. (2016)\", \"start\": 128, \"end\": 144}, {\"corpusId\": 189762527, \"span\": \"Our work\", \"start\": 227, \"end\": 227}, {\"corpusId\": 189762527, \"span\": \"this approach\", \"start\": 254, \"end\": 254}, {\"corpusId\": 53106496, \"span\": \"Saito et al. (2018)\", \"start\": 379, \"end\": 398}, {\"corpusId\": 189762527, \"span\": \"this work\", \"start\": 420, \"end\": 420}, {\"corpusId\": 53170360, \"span\": \"Sap et al. (2019)\", \"start\": 668, \"end\": 685}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 6}
{"paperId": "817e8a03162adbb268f08b206a5f04c5bfa97b26", "title": "Adapting High-resource NMT Models to Translate Low-resource Related Languages without Parallel Data", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2021, "citationCount": 48, "openAccessPdf": {"url": "https://aclanthology.org/2021.acl-long.66.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2105.15071, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2021-05-31", "authors": [{"authorId": "3450591", "name": "Wei-Jen Ko"}, {"authorId": "1398503968", "name": "Ahmed El-Kishky"}, {"authorId": "2106411510", "name": "Adithya Renduchintala"}, {"authorId": "113810201", "name": "Vishrav Chaudhary"}, {"authorId": "39589154", "name": "Naman Goyal"}, {"authorId": "144204682", "name": "Francisco Guzm\u00e1n"}, {"authorId": "40539650", "name": "Pascale Fung"}, {"authorId": "49604675", "name": "Philipp Koehn"}, {"authorId": "1700007", "name": "Mona T. Diab"}], "abstract": "The scarcity of parallel data is a major obstacle for training high-quality machine translation systems for low-resource languages. Fortunately, some low-resource languages are linguistically related or similar to high-resource languages; these related languages may share many lexical or syntactic structures. In this work, we exploit this linguistic overlap to facilitate translating to and from a low-resource language with only monolingual data, in addition to any parallel data in the related high-resource language. Our method, NMT-Adapt, combines denoising autoencoding, back-translation and adversarial objectives to utilize monolingual data for low-resource adaptation. We experiment on 7 languages from three different language families and show that our technique significantly improves translation into low-resource language compared to other translation baselines.", "corpusId": "235253832", "paragraphs": [{"paragraphId": "41328", "title": "Adapting High-resource NMT Models to Translate Low-resource Related Languages without Parallel Data", "sectionTitle": "Related Work", "text": "Zero-shot translation Our work is closely related to that of zero-shot translation (Johnson et al., 2017;Al-Shedivat and Parikh, 2019). However, while zero-shot translation translates between a language pair with no parallel data, there is an assumption that both languages in the target pair have some parallel data with other languages. As such, the system can learn to process both languages. In one work, Currey and Heafield (2019) improved zero-shot translation using monolingual data on the pivot language. However, in our scenario, there is no parallel data between the low-resource language and any other language. In other work, Arivazhagan et al. (2019) showed that adding adversarial training to the encoder output could help zero shot training. We adopt a similar philosophy in our multi-task training to ensure our low-resource target is in the same latent space as the higher-resource language.", "spans": "[{\"corpusId\": 235253832, \"span\": \"Our work\", \"start\": 30, \"end\": 30}, {\"corpusId\": 6053988, \"span\": \"(Johnson et al., 2017;\", \"start\": 83, \"end\": 105}, {\"corpusId\": 102353391, \"span\": \"Al-Shedivat and Parikh, 2019)\", \"start\": 105, \"end\": 134}]", "conference": "acl", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "41329", "title": "Adapting High-resource NMT Models to Translate Low-resource Related Languages without Parallel Data", "sectionTitle": "Related Work", "text": "Unsupervised translation A related set of work is the family of unsupervised translation techniques; these approaches translate between language pairs with no parallel corpus of any kind. In work by Artetxe et al. (2018); Lample et al. (2018a), unsupervised translation is performed by training denoising autoencoding and backtranslation tasks concurrently. In these approaches, multiple pretraining methods were proposed to better initialize the model (Lample et al., 2018b;Lample and Conneau, 2019;Liu et al., 2020;Song et al., 2019). 2 https://github.com/wjko2/NMT-Adapt Different approaches were proposed that used parallel data between X-Y to improve unsupervised translation between X-Z (Garcia et al., 2020a;. This scenario differs from our setting as it does not assume that Y and Z are similar languages. These approaches leverage a cross-translation method on a multilingual NMT model where for a parallel data pair (S x ,S y ), they translate S x into language Z with the current model to get S z . Then use (S y ,S z ) as an additional synthesized data pair to further improve the model. Garcia et al. (2020b) experiment using multilingual cross-translation on low-resource languages with some success. While these approaches view the parallel data as auxiliary, to supplement unsupervised NMT, our work looks at the problem from a domain adaptation perspective. We attempt to use monolingual data in Z to make the supervised model trained on X-Y generalize to Z.", "spans": "[{\"corpusId\": 3515219, \"span\": \"Artetxe et al. (2018)\", \"start\": 199, \"end\": 220}, {\"corpusId\": 3518190, \"span\": \"Lample et al. (2018a)\", \"start\": 222, \"end\": 243}, {\"corpusId\": 5033497, \"span\": \"(Lample et al., 2018b;\", \"start\": 453, \"end\": 475}, {\"corpusId\": 210861178, \"span\": \"Liu et al., 2020;\", \"start\": 500, \"end\": 517}, {\"corpusId\": 146808476, \"span\": \"Song et al., 2019)\", \"start\": 517, \"end\": 535}, {\"corpusId\": 211066603, \"span\": \"(Garcia et al., 2020a;\", \"start\": 693, \"end\": 715}, {\"corpusId\": 235253832, \"span\": \"our work\", \"start\": 1315, \"end\": 1315}]", "conference": "acl", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "41330", "title": "Adapting High-resource NMT Models to Translate Low-resource Related Languages without Parallel Data", "sectionTitle": "Related Work", "text": "Leveraging High-resource Languages to Improve Low-resource Translation Several works have leveraged data in high-resource languages to improve the translation of similar low-resource languages. Neubig and Hu (2018) showed that it is beneficial to mix the limited parallel data pairs of low-resource languages with high-resource language data. Lakew et al. (2019) proposed selecting high-resource language data with lower perplexity in the low-resource language model. Xia et al. (2019) created synthetic sentence pairs by unsupervised machine translation, using the high-resource language as a pivot. However these previous approaches emphasize translating from the low-resource language to English, while the opposite direction is either unconsidered or shows poor translation performance. Siddhant et al. (2020) trained multilingual translation and denoising simultaneously, and showed that the model could translate languages without parallel data into English near the performance of supervised multilingual NMT.", "spans": "[{\"corpusId\": 51976920, \"span\": \"Neubig and Hu (2018)\", \"start\": 194, \"end\": 214}, {\"corpusId\": 204961341, \"span\": \"Lakew et al. (2019)\", \"start\": 343, \"end\": 362}, {\"corpusId\": 182952423, \"span\": \"Xia et al. (2019)\", \"start\": 468, \"end\": 485}, {\"corpusId\": 218580964, \"span\": \"Siddhant et al. (2020)\", \"start\": 791, \"end\": 813}]", "conference": "acl", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "41331", "title": "Adapting High-resource NMT Models to Translate Low-resource Related Languages without Parallel Data", "sectionTitle": "Related Work", "text": "Similar language translation Similar to our work, there have been methods proposed that leverage similar languages to improve translation. Hassan et al. (2017) generated synthetic English-dialect parallel data from English-main language corpus. However, this method assumes that the vocabulary in the main language could be mapped word by word into the dialect vocabulary, and they calculate the corresponding word for substitution using localized projection. This approach differs from our work in that it relies on the existence of a seed bilingual lexicon to the dialect/similar language. Additionally, the approach only considers translating from a dialect to English and not the reverse direction. Other work trains a massively multilingual many-to-many model and demonstrates that high-resource training data improves related lowresource language translation (Fan et al., 2020). In other work, Lakew et al. (2018) compared ways to model translations of different language varieties, in the setting that parallel data for both varieties is available, the variety for some pairs may not be labeled. Another line of work focus on translating between similar languages. In one such work, Pourdamghani and Knight (2017) learned a character-based cipher model. In other work, Wan et al. (2020) improved unsupervised translation between the main language and the dialect by separating the token embeddings into pivot and private parts while performing layer coordination.", "spans": "[{\"corpusId\": 235253832, \"span\": \"our work\", \"start\": 48, \"end\": 48}, {\"corpusId\": 7141401, \"span\": \"Hassan et al. (2017)\", \"start\": 139, \"end\": 159}, {\"corpusId\": 235253832, \"span\": \"this method\", \"start\": 265, \"end\": 265}, {\"corpusId\": 235253832, \"span\": \"This approach\", \"start\": 473, \"end\": 473}, {\"corpusId\": 235253832, \"span\": \"our work\", \"start\": 495, \"end\": 495}, {\"corpusId\": 53222270, \"span\": \"Lakew et al. (2018)\", \"start\": 900, \"end\": 919}, {\"corpusId\": 3329081, \"span\": \"Pourdamghani and Knight (2017)\", \"start\": 1190, \"end\": 1220}, {\"corpusId\": 209202196, \"span\": \"Wan et al. (2020)\", \"start\": 1276, \"end\": 1293}]", "conference": "acl", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "41332", "title": "Adapting High-resource NMT Models to Translate Low-resource Related Languages without Parallel Data", "sectionTitle": "Datasets", "text": "We describe the steps we took to obtain reliable dialectical Arabic monolingual data. As the CC-100 corpus does not distinguish between Modern Standard Arabic (MSA) and its dialectical variants, we train a finer-grained classifier that distinguishes between MSA and specific colloquial dialects. We base our language classifier on a BERT model pretrained for Arabic (Safaya et al., 2020) and finetune it for six-way classification: (i) Egyptian, (ii) Levantine, (iii) Gulf, (iv) Maghrebi, (v) Iraqi dialects as well as (vi) the literary Modern Standard Arabic (MSA). We use the data from (Bouamor et al., 2018) and (Zaidan and Callison-Burch, 2011) as training data, and the resulting classifier has an accuracy of 91% on a held-out set. We take our trained Arabic dialect classifier and further classify Arabic monolingual data from CC-100 and select MSA, Levantine and Egyptian sentences as Arabic monolingual data for our experiments.", "spans": "[{\"corpusId\": 220794027, \"span\": \"(Safaya et al., 2020)\", \"start\": 366, \"end\": 387}, {\"corpusId\": 21720875, \"span\": \"(Bouamor et al., 2018)\", \"start\": 588, \"end\": 610}, {\"corpusId\": 12678205, \"span\": \"(Zaidan and Callison-Burch, 2011)\", \"start\": 615, \"end\": 648}]", "conference": "acl", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "41333", "title": "Adapting High-resource NMT Models to Translate Low-resource Related Languages without Parallel Data", "sectionTitle": "Iterative Training", "text": "We compare our results with a baseline using the HRL language as a pivot. The baseline uses a fine tuned mBART (Liu et al., 2020) to perform supervised translation between English and the HRL, and uses MASS (Song et al., 2019) to perform unsupervised translation between the HRL and the LRL. The mBART is tuned on the same parallel data used in our method, and the MASS uses the same monolingual data as in our method. For all languages and directions, our method significantly outperforms the pivot baseline.", "spans": "[{\"corpusId\": 235253832, \"span\": \"our results\", \"start\": 22, \"end\": 22}, {\"corpusId\": 210861178, \"span\": \"(Liu et al., 2020)\", \"start\": 111, \"end\": 129}, {\"corpusId\": 146808476, \"span\": \"(Song et al., 2019)\", \"start\": 207, \"end\": 226}, {\"corpusId\": 235253832, \"span\": \"our method\", \"start\": 355, \"end\": 355}, {\"corpusId\": 235253832, \"span\": \"our method\", \"start\": 417, \"end\": 417}, {\"corpusId\": 235253832, \"span\": \"our method\", \"start\": 463, \"end\": 463}]", "conference": "acl", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 6}
{"paperId": "9893e9beec96c14f99ed0e06b0a189e11f0bbdcb", "title": "Synthesizing Stroke Gestures Across User Populations: A Case for Users with Visual Impairments", "venue": "International Conference on Human Factors in Computing Systems", "year": 2017, "citationCount": 26, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3025453.3025906?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3025453.3025906, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2017-05-02", "authors": [{"authorId": "145800450", "name": "Luis A. Leiva"}, {"authorId": "1403846047", "name": "Daniel Mart\u00edn-Albo"}, {"authorId": "1794666", "name": "Radu-Daniel Vatavu"}], "abstract": null, "corpusId": "33315489", "paragraphs": [{"paragraphId": "75336", "title": "Synthesizing Stroke Gestures Across User Populations: A Case for Users with Visual Impairments", "sectionTitle": "INTRODUCTION", "text": "The popularity of stroke gesture input for graphical user interfaces has vastly increased with the prevalence of touchscreen devices. Stroke gestures represent fast movements produced by one or more fingers in contact with a touch-sensitive surface that reports a temporal sequence of {x, y} coordinates mapped to a specific action in the user interface [26]. Compared to traditional interactions based on mouse and keyboard input, gestures have the potential to reduce users' cognitive load and visual attention [6,72] and to increase usability by replacing standard shortcuts with more accessible function triggers [27]. As touch interfaces become even more ubiquitous, it is crucial to provide equal access for people with all abilities, such as people with visual impairments, who face considerable challenges interacting with touchscreens that expose interfaces almost exclusively designed for visual input [7,22,23,44].", "spans": "[{\"corpusId\": 14557970, \"span\": \"[26]\", \"start\": 354, \"end\": 358}, {\"corpusId\": 13874494, \"span\": \"[6,\", \"start\": 513, \"end\": 516}, {\"corpusId\": 61743528, \"span\": \"72]\", \"start\": 516, \"end\": 519}, {\"corpusId\": 13982453, \"span\": \"[7,\", \"start\": 912, \"end\": 915}, {\"corpusId\": 1108352, \"span\": \"22,\", \"start\": 915, \"end\": 918}, {\"corpusId\": 1681652, \"span\": \"23,\", \"start\": 918, \"end\": 921}, {\"corpusId\": 9859306, \"span\": \"44]\", \"start\": 921, \"end\": 924}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": false, "refCount": 7}, {"paragraphId": "75337", "title": "Synthesizing Stroke Gestures Across User Populations: A Case for Users with Visual Impairments", "sectionTitle": "Techniques and tools for gesture articulation analysis", "text": "Users' stroke gesture articulations have been studied in the literature in terms of consistency between and within users [5], gesture preferences of various user populations [23,39,62,71], and the impact of gesture implementers, such as finger vs. pen input, or gesture articulation performance [5,60]. Finegrained analyses of users' gesture articulations are also possible to understand how users vary their gestures relative to each other and relative to recognizers' canonical template forms [65,66]. Also, gesture recognition algorithms have been using many gesture features, such as path length, articulation time, or average speed [8,52], that can be repurposed as gesture performance measures to evaluate users' gesture articulations [51,68]. However, most of these measures, although useful for gesture classification, lack descriptive power for gesture analysis because they focus on the global characteristics of a gesture as a whole. In contrast, the Gesture RElative Accuracy Toolkit (GREAT) [65], which we employ in this work, enables access to fine-grained measurements on the gesture path that reveal and help understand the subtleties of users' gesture articulations. More specifically, the GREAT measures describe the many ways in which gestures unfold in time, space, stroke structure, and appearance, characterizing gesture articulations in terms of their closeness to a reference form, analogous to MacKenzie et al.'s accuracy measures for pointing tasks [31].", "spans": "[{\"corpusId\": 14116301, \"span\": \"[5]\", \"start\": 121, \"end\": 124}, {\"corpusId\": 1681652, \"span\": \"[23,\", \"start\": 174, \"end\": 178}, {\"corpusId\": 2367798, \"span\": \"39,\", \"start\": 178, \"end\": 181}, {\"corpusId\": 17603338, \"span\": \"62,\", \"start\": 181, \"end\": 184}, {\"corpusId\": 1341945, \"span\": \"71]\", \"start\": 184, \"end\": 187}, {\"corpusId\": 14116301, \"span\": \"[5,\", \"start\": 295, \"end\": 298}, {\"corpusId\": 2904681, \"span\": \"60]\", \"start\": 298, \"end\": 301}, {\"corpusId\": 4675632, \"span\": \"[65,\", \"start\": 495, \"end\": 499}, {\"corpusId\": 4673301, \"span\": \"66]\", \"start\": 499, \"end\": 502}, {\"corpusId\": 16069978, \"span\": \"[8,\", \"start\": 637, \"end\": 640}, {\"corpusId\": 135419, \"span\": \"52]\", \"start\": 640, \"end\": 643}, {\"corpusId\": 1880085, \"span\": \"[51,\", \"start\": 741, \"end\": 745}, {\"corpusId\": 4674966, \"span\": \"68]\", \"start\": 745, \"end\": 748}, {\"corpusId\": 4675632, \"span\": \"[65]\", \"start\": 1004, \"end\": 1008}, {\"corpusId\": 33315489, \"span\": \"this work\", \"start\": 1038, \"end\": 1038}, {\"corpusId\": 16911942, \"span\": \"[31]\", \"start\": 1475, \"end\": 1479}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 14}, {"paragraphId": "75338", "title": "Synthesizing Stroke Gestures Across User Populations: A Case for Users with Visual Impairments", "sectionTitle": "Gesture interfaces for people with visual impairments", "text": "The literature on designing accessible touch interfaces for people with visual impairments has focused significantly on applications and interaction techniques [7,10,44], while studies on how people with visual impairments use touch input or articulate gestures have been scarce. Nevertheless, the studies that exist have reported valuable and useful data. For example, Kane et al. [23] showed that blind people prefer gestures that use an edge or a corner of the device and Buzzi et al. [11,12] reported preferences for round-shaped gestures, one-finger input, one-stroke gestures, and short trajectories. Detailed examination of gesture articulation paths [23] showed that blind people produce touch gestures that are different in size, speed, number of strokes, and gesture shape than the gestures produced by sighted people. Our work looks in more depth at the differences between gestures articulated by people with and without visual impairments by considering the new perspective of the velocity profiles of the hand producing touch gestures in the context of the formalism of the Kinematic Theory [46].", "spans": "[{\"corpusId\": 13982453, \"span\": \"[7,\", \"start\": 160, \"end\": 163}, {\"corpusId\": 6361435, \"span\": \"10,\", \"start\": 163, \"end\": 166}, {\"corpusId\": 9859306, \"span\": \"44]\", \"start\": 166, \"end\": 169}, {\"corpusId\": 1681652, \"span\": \"[23]\", \"start\": 382, \"end\": 386}, {\"corpusId\": 17370311, \"span\": \"[11,\", \"start\": 488, \"end\": 492}, {\"corpusId\": 1681652, \"span\": \"[23]\", \"start\": 658, \"end\": 662}, {\"corpusId\": 33315489, \"span\": \"Our work\", \"start\": 837, \"end\": 837}, {\"corpusId\": 19714577, \"span\": \"[46]\", \"start\": 1105, \"end\": 1109}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "75339", "title": "Synthesizing Stroke Gestures Across User Populations: A Case for Users with Visual Impairments", "sectionTitle": "Bootstrapping gestures by automatic synthesis", "text": "The amount and quality of training data are key factors for competitive gesture recognition. For example, the Freehand Formula Entry System [55] suggests 20-40 examples per symbol per user, and classifiers become more accurate when retrained with new samples [2,49]. Consequently, synthesizing new samples can improve recognition performance effectively.", "spans": "[{\"corpusId\": 16853059, \"span\": \"[55]\", \"start\": 140, \"end\": 144}, {\"corpusId\": 16069528, \"span\": \"[2,\", \"start\": 259, \"end\": 262}, {\"corpusId\": 11209895, \"span\": \"49]\", \"start\": 262, \"end\": 265}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "75340", "title": "Synthesizing Stroke Gestures Across User Populations: A Case for Users with Visual Impairments", "sectionTitle": "Bootstrapping gestures by automatic synthesis", "text": "Several techniques have been proposed in the literature to produce synthetic gestures with the goal to speed up development and to increase the accuracy of gesture recognizers. For example, Gesture Script [30] allows developers to describe the structure of a stroke gesture and, by using this information, the tool can synthesize new gesture samples by varying the relative scale and rotation of the gesture's components. Unfortunately, Gesture Script only works with unistroke gestures articulated in predefined ways. MAGIC Summoning [24] and Gesture Follower [13] are other tools that enable designers with means to generate synthetic gesture samples in 3D. MAGIC Summoning adds local perturbations to a gesture's resampled points, whereas Gesture Follower introduces variations into a gesture shape by using Viviani's 2/3 power law [69]. Both approaches are promising, although synthetic gestures might perform poorly for gesture recognition because of insufficient variation required for high-quality training [49]. However, this prior work has put forward the importance of increasing gesture recognition accuracy with large training datasets.", "spans": "[{\"corpusId\": 3892249, \"span\": \"[30]\", \"start\": 205, \"end\": 209}, {\"corpusId\": 8139201, \"span\": \"[24]\", \"start\": 535, \"end\": 539}, {\"corpusId\": 14419361, \"span\": \"[13]\", \"start\": 561, \"end\": 565}, {\"corpusId\": 17262069, \"span\": \"[69]\", \"start\": 835, \"end\": 839}, {\"corpusId\": 11209895, \"span\": \"[49]\", \"start\": 1014, \"end\": 1018}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "75341", "title": "Synthesizing Stroke Gestures Across User Populations: A Case for Users with Visual Impairments", "sectionTitle": "Bootstrapping gestures by automatic synthesis", "text": "Probably the most relevant prior work for our method are two compelling approaches to produce synthetic stroke gestures: GPSR [58] and G3 [27]. GPSR is strongly focused on rapid UI prototyping, is computationally efficient, and adds minimal coding overhead. However, GPSR does not synthesize timestamps, which precludes a fine-grained analysis of handwriting behavior [34]. In contrast, G3 relies on the Kinematic Theory and, consequently, takes a more generic approach to gesture synthesis. G3 creates a model of a user-provided gesture example to which it adds local and global perturbations. Although resulting gestures are human-like [28], G3 employs a set of generic \u03a3\u039bM parameters acquired from people without disabilities [18] and, consequently, it is unlikely that these variability ranges would also account for the actual variability attributed to people with various gesture articulation abilities.", "spans": "[{\"corpusId\": 33315489, \"span\": \"our method\", \"start\": 52, \"end\": 52}, {\"corpusId\": 16956611, \"span\": \"[58]\", \"start\": 126, \"end\": 130}, {\"corpusId\": 7803356, \"span\": \"[34]\", \"start\": 368, \"end\": 372}, {\"corpusId\": 31923045, \"span\": \"[28]\", \"start\": 638, \"end\": 642}, {\"corpusId\": 15991783, \"span\": \"[18]\", \"start\": 729, \"end\": 733}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "75342", "title": "Synthesizing Stroke Gestures Across User Populations: A Case for Users with Visual Impairments", "sectionTitle": "OVERVIEW OF THE KINEMATIC THEORY", "text": "Many models have been proposed to study human movement production, such as models relying on neural networks [9], behavioral models [59], and models exploiting minimization principles [16]. Among these, the Kinematic Theory [46] provides a solid and well-established framework to study human movement production [47] and previous work showed that it outperforms many other approaches [49]. \u03a3\u039bM is the latest instantiation of this framework [48], which was recently adopted for gesture synthesis and recognition. Leiva et al. [27] showed that synthesized gestures achieve similar recognition accuracy as their human counterparts and Plamondon et al. [48] showed that \u03a3\u039bM generalizes to any type of human movements, including wrist movements and eye saccades.", "spans": "[{\"corpusId\": 107715980, \"span\": \"[9]\", \"start\": 109, \"end\": 112}, {\"corpusId\": 18355250, \"span\": \"[16]\", \"start\": 184, \"end\": 188}, {\"corpusId\": 19714577, \"span\": \"[46]\", \"start\": 224, \"end\": 228}, {\"corpusId\": 2135817, \"span\": \"[47]\", \"start\": 312, \"end\": 316}, {\"corpusId\": 11209895, \"span\": \"[49]\", \"start\": 384, \"end\": 388}, {\"corpusId\": 12032553, \"span\": \"[48]\", \"start\": 440, \"end\": 444}, {\"corpusId\": 12032553, \"span\": \"[48]\", \"start\": 649, \"end\": 653}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "75343", "title": "Synthesizing Stroke Gestures Across User Populations: A Case for Users with Visual Impairments", "sectionTitle": "Human-like gesture synthesis", "text": "Previous work has demonstrated the connection between the distortion of the \u03a3\u039bM parameters and the intra-variability of human handwriting [14], which enables generation of realistic, human-like synthetic samples [28]. Once the gesture primitives have been extracted and modeled, perturbations can be introduced to the model's parameters [27,35]:", "spans": "[{\"corpusId\": 10495937, \"span\": \"[14]\", \"start\": 138, \"end\": 142}, {\"corpusId\": 31923045, \"span\": \"[28]\", \"start\": 212, \"end\": 216}, {\"corpusId\": 25085976, \"span\": \"35]\", \"start\": 341, \"end\": 344}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "75344", "title": "Synthesizing Stroke Gestures Across User Populations: A Case for Users with Visual Impairments", "sectionTitle": "Experiment 2: Gesture articulation", "text": "We used GREAT [65] to compute the geometric, kinematic, and articulation accuracy of the stroke gestures produced by our two groups of participants. GREAT computes twelve gesture descriptors relative to a reference template called the \"gesture task axis.\" In our experiments, we used the k-medoid as the reference gesture, i.e., the closest user-articulated sample to the median gesture. 2 The GREAT measures are grouped in the following categories: We refer the reader to Vatavu et al. [65] for a detailed description of these measures. All gestures were uniformly resampled into 32 points to speed up computation time without sacrificing accuracy [61]. We also generated synthetic gestures for participants with visual impairments by following the traditional synthesis approach; see 'Overview of the Kinematic Theory' and [27,28]. Figure 4 shows the results of this experiment.", "spans": "[{\"corpusId\": 4675632, \"span\": \"[65]\", \"start\": 14, \"end\": 18}, {\"corpusId\": 16069528, \"span\": \"2\", \"start\": 388, \"end\": 389}, {\"corpusId\": 4675632, \"span\": \"[65]\", \"start\": 487, \"end\": 491}, {\"corpusId\": 18797889, \"span\": \"[61]\", \"start\": 649, \"end\": 653}, {\"corpusId\": 31923045, \"span\": \"28]\", \"start\": 829, \"end\": 832}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "75345", "title": "Synthesizing Stroke Gestures Across User Populations: A Case for Users with Visual Impairments", "sectionTitle": "Experiment 2: Gesture articulation", "text": "To understand the differences between our three experimental conditions (i.e., gestures produced by people with visual impairments, gestures produced by people without visual impairments, and synthesized gestures for people with visual impairments), we ran a one-way ANOVA test (Greenhouse-Geisser corrected to control for deviations in sphericity), followed by pairwise comparisons (Bonferroni corrected) as post-hoc tests of significance, if applicable. We observed statistically significant differences for most of the GREAT measures, marked with an asterisk in Figure 4 F (2,177) >4, p<.001, \u03b7 2 p <0.2 . Post-hoc tests revealed that gestures produced by people with visual impairments were less accurate than those produced by people without visual impairments (p < .01). However, we found no significant difference between gestures produced by people with visual impairments and synthesized gestures (p > .05, n.s.). This result confirms previous findings that gestures synthesized with \u03a3\u039bM look similar to gestures produced by humans [18,27,28].", "spans": "[{\"corpusId\": 33315489, \"span\": \"This result\", \"start\": 934, \"end\": 934}, {\"corpusId\": 15991783, \"span\": \"[18,\", \"start\": 1041, \"end\": 1045}, {\"corpusId\": 31923045, \"span\": \"28]\", \"start\": 1048, \"end\": 1051}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "75346", "title": "Synthesizing Stroke Gestures Across User Populations: A Case for Users with Visual Impairments", "sectionTitle": "GESTURE SYNTHESIS ACROSS USER POPULATIONS", "text": "Informed by the results of our evaluation, we introduce a new method to estimate the human variability of \u03a3\u039bM values for different user populations. According to previous work [19,38], when a human produces a very rapid stroke, the trajectory is nearly straight and there might be up to two reversals in the direction of the motion (known as \"glitches\"), either at the beginning or at the end of the trajectory. Therefore, the velocity profile can have up to three primitives (each described with a lognormal), with one dominating the others in terms of amplitude. Moreover, when a user repeats the same rapid movement many times, some variability is expected and observed, although each individual trajectory still has a dominant primitive as long as there is no trembling or hesitation. These observations are key to our method.", "spans": "[{\"corpusId\": 33315489, \"span\": \"our evaluation\", \"start\": 41, \"end\": 41}, {\"corpusId\": 23370427, \"span\": \"[19,\", \"start\": 176, \"end\": 180}, {\"corpusId\": 17979972, \"span\": \"38]\", \"start\": 180, \"end\": 183}, {\"corpusId\": 33315489, \"span\": \"our method\", \"start\": 829, \"end\": 829}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "75347", "title": "Synthesizing Stroke Gestures Across User Populations: A Case for Users with Visual Impairments", "sectionTitle": "Designing gesture sets", "text": "The process of designing gesture sets is complex, as it involves many motor and cognitive aspects that the designer must consider, such as good discriminability with respect to other gestures in the set [1], ease of execution [43,68], ease of learning and memorability [42], good fit to application functions [39,71], etc. This process usually involves a lot of trial and error, where gestures go in and out of the gesture set while the designer optimizes the structure of the set with respect to the above criteria. Having fast access to actual gesture samples for new gestures that the designer might come up with during this process, without actually collecting them from the target user population, would have a positive effect on the designer's work, saving considerable time.", "spans": "[{\"corpusId\": 7605833, \"span\": \"[1]\", \"start\": 203, \"end\": 206}, {\"corpusId\": 8759604, \"span\": \"[43,\", \"start\": 226, \"end\": 230}, {\"corpusId\": 4674966, \"span\": \"68]\", \"start\": 230, \"end\": 233}, {\"corpusId\": 8505631, \"span\": \"[42]\", \"start\": 269, \"end\": 273}, {\"corpusId\": 2367798, \"span\": \"[39,\", \"start\": 309, \"end\": 313}, {\"corpusId\": 1341945, \"span\": \"71]\", \"start\": 313, \"end\": 316}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "75348", "title": "Synthesizing Stroke Gestures Across User Populations: A Case for Users with Visual Impairments", "sectionTitle": "Addressing other user populations", "text": "In this work, we focused specifically on people with visual impairments, for which touch interaction pose many challenges, because touchscreens rely almost exclusively on visual input [22,23,54]. However, we formalized our method in a way that is independent of the characteristics of the target population so that it would be easy to apply for synthesizing gesture sets for other user populations as well. For example, touch input remains largely inaccessible to people with motor impairments who need to adopt workaround strategies to be able to access content on touchscreen devices [4,37] and who need specific touch interaction techniques [40]. We also know from the literature of touch interaction for children that small children between 3 and 6 years old experience difficulties with touch and multitouch input [67] and that the touch gestures of children between 7 and 10 years old are recognized with lower accuracy rates than the same gestures produced by adults [3]. Because our method is able to transfer the articulation characteristics of gestures produced by a few users to a particular user population, we believe that addressing other user groups, such as those mentioned above, is viable and we leave these interesting exploration opportunities for future work.", "spans": "[{\"corpusId\": 33315489, \"span\": \"this work\", \"start\": 12, \"end\": 12}, {\"corpusId\": 1108352, \"span\": \"[22,\", \"start\": 184, \"end\": 188}, {\"corpusId\": 1681652, \"span\": \"23,\", \"start\": 188, \"end\": 191}, {\"corpusId\": 207165441, \"span\": \"54]\", \"start\": 191, \"end\": 194}, {\"corpusId\": 33315489, \"span\": \"our method\", \"start\": 229, \"end\": 229}, {\"corpusId\": 13470924, \"span\": \"[4,\", \"start\": 586, \"end\": 589}, {\"corpusId\": 21808388, \"span\": \"37]\", \"start\": 589, \"end\": 592}, {\"corpusId\": 489935, \"span\": \"[40]\", \"start\": 644, \"end\": 648}, {\"corpusId\": 1326851, \"span\": \"[67]\", \"start\": 819, \"end\": 823}, {\"corpusId\": 13187694, \"span\": \"[3]\", \"start\": 974, \"end\": 977}, {\"corpusId\": 33315489, \"span\": \"our method\", \"start\": 997, \"end\": 997}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "75349", "title": "Synthesizing Stroke Gestures Across User Populations: A Case for Users with Visual Impairments", "sectionTitle": "Further application areas", "text": "Interesting future work directions may look at the applicability of synthesizing data across user populations for mouse input [15,17,33], voice input [21,29], whole-body movement [53,62,63], and even EEG input [25,56]. While all these directions are definitely interesting, they are nevertheless challenging, but worth exploring in order to advance our theoretical and practical knowledge of simulating input data across different user populations toward better interface designs for users will all abilities. Looking forward, we believe that our work already forms a good demonstration of how simulation can be used to refine the gesture design process within HCI and accessibility research and we are eager to see how the community will pick up these ideas and use them for other application areas. CONCLUSION We presented a principled method to generate gesture samples for people with visual impairments using gestures collected from people without visual impairments. Our method is based on the foundations of the Kinematic Theory of Rapid Human Movements and its associated Sigma-Lognormal model. The software implementing our method is publicly available at https://g3.prhlt.upv.es, while the gestures dataset can be downloaded from http://www.eed.usv.ro/~vatavu.", "spans": "[{\"corpusId\": 5790314, \"span\": \"[15,\", \"start\": 126, \"end\": 130}, {\"corpusId\": 4626403, \"span\": \"17,\", \"start\": 130, \"end\": 133}, {\"corpusId\": 13362415, \"span\": \"33]\", \"start\": 133, \"end\": 136}, {\"corpusId\": 626332, \"span\": \"[21,\", \"start\": 150, \"end\": 154}, {\"corpusId\": 12820209, \"span\": \"29]\", \"start\": 154, \"end\": 157}, {\"corpusId\": 16247083, \"span\": \"[53,\", \"start\": 179, \"end\": 183}, {\"corpusId\": 17603338, \"span\": \"62,\", \"start\": 183, \"end\": 186}, {\"corpusId\": 4671662, \"span\": \"63]\", \"start\": 186, \"end\": 189}, {\"corpusId\": 6504989, \"span\": \"[25,\", \"start\": 210, \"end\": 214}, {\"corpusId\": 15585160, \"span\": \"56]\", \"start\": 214, \"end\": 217}, {\"corpusId\": 33315489, \"span\": \"our work\", \"start\": 551, \"end\": 551}, {\"corpusId\": 33315489, \"span\": \"Our method\", \"start\": 983, \"end\": 983}, {\"corpusId\": 33315489, \"span\": \"our method\", \"start\": 1139, \"end\": 1139}]", "conference": "chi", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 11}], "paragraphCount": 14}
{"paperId": "27f12cd65489a8e1e2e38b4ebe89e72c14598e9e", "title": "SynchroMouse: A Game of Improvised Joint Action", "venue": "CSCW Companion", "year": 2019, "citationCount": 2, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3311957.3359482?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3311957.3359482, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book"], "publicationDate": "2019-11-09", "authors": [{"authorId": "3089256", "name": "Valtteri Wikstr\u00f6m"}, {"authorId": "1404221977", "name": "M. Falcon"}, {"authorId": "4790655", "name": "Silja Martikainen"}, {"authorId": "4189120", "name": "K. Saarikivi"}], "abstract": "Joint improvised activity and synchrony of movement increases affiliation between people. The mirror game, where two people create joint motion in an improvised pattern, has been used to study different aspects of face-to-face collaboration and synchronization. To explore whether a similar game could be used to study computer-mediated interaction and as an ice-breaker activity to increase affiliation in remote collaboration, we developed a multiplayer online mouse coordination game inspired by the mirror game. The source code to the game is released as free open source software.", "corpusId": "207942109", "paragraphs": [{"paragraphId": "52493", "title": "SynchroMouse: A Game of Improvised Joint Action", "sectionTitle": "INTRODUCTION", "text": "We, as humans and as primates, tend to enjoy moving together and mimicking each other [2,7]. This is evidenced by activities such as dancing, playing music and marching. These kinds of activities can increase the sense of social cohesion within a group. Especially rhythmic, musical activity has been shown to increase social cohesion, cooperation and trust [6]. According to previous research, one key feature underlying this effect seems to be the interpersonal synchrony related to this type of activity. Specifically, synchronous behavior has been found to increase social ratings of affiliation [5] and closeness [9]. In addition to these types of findings, which are derived from subjective ratings, evidence suggests that synchronous activity can also enhance successful collaborative performance among pairs and groups. Performance in pair tasks that require detecting patterns and responding accordingly to the movements of the other person has been found to improve if preceded by synchronous movement [10]. Similarly, improvements have been found in group cooperation following synchronous movement and singing activities, compared to similar activities carried out asynchronously [11].", "spans": "[{\"corpusId\": 6915969, \"span\": \"[2,\", \"start\": 86, \"end\": 89}, {\"corpusId\": 44040325, \"span\": \"7]\", \"start\": 89, \"end\": 91}, {\"corpusId\": 29927, \"span\": \"[6]\", \"start\": 358, \"end\": 361}, {\"corpusId\": 26750358, \"span\": \"[5]\", \"start\": 600, \"end\": 603}, {\"corpusId\": 26869044, \"span\": \"[9]\", \"start\": 618, \"end\": 621}, {\"corpusId\": 145448287, \"span\": \"[10]\", \"start\": 1012, \"end\": 1016}, {\"corpusId\": 3170233, \"span\": \"[11]\", \"start\": 1192, \"end\": 1196}]", "conference": "cscw", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 7}, {"paragraphId": "52494", "title": "SynchroMouse: A Game of Improvised Joint Action", "sectionTitle": "INTRODUCTION", "text": "The mirror game is a widely used paradigm for studying joint improvised actions between two people. Its use originates from the context of dance, theater and sports, but the paradigm has more recently also been adapted for use in research of social interaction [1]. In its simplest form the mirror game consists of two people facing each other and mirroring each other's hand gestures. In one of the versions of the paradigm, used in a variety of studies [3,4,8], a device is used for measuring both participant's hand motions, as they are playing the game together, facing each other. The device has one handle for each participant, and both handles can be moved parallel on identical straight tracks. Commonly, the task for the participants is to create improvised motion together. This paradigm has been used, for instance, to study movement richness and synchrony [3], the effect of cooperative roles, such as leader-follower versus joint improvisation, on movement synchrony [8], and the effect of improvisation experience on cooperation during the task [4].", "spans": "[{\"corpusId\": 52066938, \"span\": \"[1]\", \"start\": 261, \"end\": 264}, {\"corpusId\": 20572225, \"span\": \"[3,\", \"start\": 455, \"end\": 458}, {\"corpusId\": 10382977, \"span\": \"4,\", \"start\": 458, \"end\": 460}, {\"corpusId\": 12753319, \"span\": \"8]\", \"start\": 460, \"end\": 462}, {\"corpusId\": 20572225, \"span\": \"[3]\", \"start\": 868, \"end\": 871}, {\"corpusId\": 12753319, \"span\": \"[8]\", \"start\": 980, \"end\": 983}, {\"corpusId\": 10382977, \"span\": \"[4]\", \"start\": 1059, \"end\": 1062}]", "conference": "cscw", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "52495", "title": "SynchroMouse: A Game of Improvised Joint Action", "sectionTitle": "DISCUSSION", "text": "Joint improvised action is an intriguing topic of human behavior, and it is not just limited to games or explicit activities. The tendency of humans to mirror each others behavior is an important social signal, used for showing affiliation and to guide the timing and tempo of social interaction. Intentionally increasing this kind of behavior has shown promise previously in improving social closeness and collaborative performance [5,10], and has been used in practice in the form of improvisational theatre and dance activities in workshops and therapy [1]. The game we have presented in this abstract is intended as a similar ice breaker activity for online communications. We intend to carry out research about the possible benefits playing SynchroMouse could have preceding cooperation, as well as whether play strategies and performance in the game can be used to predict the outcomes of such cooperative activities and the experience of team members. Additionally, since the task is released to the community as open source, we encourage others to use it and adapt it to their needs.", "spans": "[{\"corpusId\": 26750358, \"span\": \"[5,\", \"start\": 433, \"end\": 436}, {\"corpusId\": 145448287, \"span\": \"10]\", \"start\": 436, \"end\": 439}, {\"corpusId\": 52066938, \"span\": \"[1]\", \"start\": 556, \"end\": 559}]", "conference": "cscw", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 3}], "paragraphCount": 3}
{"paperId": "b51770fffaa319dc7d01d0c59406f8aab6d58c6a", "title": "Lying Through One\u2019s Teeth: A Study on Verbal Leakage Cues", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2021, "citationCount": 7, "openAccessPdf": {"url": "https://doi.org/10.18653/v1/2021.emnlp-main.370", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://aclanthology.org/2021.emnlp-main.370, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": null, "authors": [{"authorId": "2140738426", "name": "Min-Hsuan Yeh"}, {"authorId": "1746959", "name": "Lun-Wei Ku"}], "abstract": "Although many studies use the LIWC lexicon to show the existence of verbal leakage cues in lie detection datasets, none mention how verbal leakage cues are influenced by means of data collection, or the impact thereof on the performance of models. In this paper, we study verbal leakage cues to understand the effect of the data construction method on their significance, and examine the relationship between such cues and models\u2019 validity. The LIWC word-category dominance scores of seven lie detection datasets are used to show that audio statements and lie-based annotations indicate a greater number of strong verbal leakage cue categories. Moreover, we evaluate the validity of state-of-the-art lie detection models with cross- and in-dataset testing. Results show that in both types of testing, models trained on a dataset with more strong verbal leakage cue categories\u2014as opposed to only a greater number of strong cues\u2014yield superior results, suggesting that verbal leakage cues are a key factor for selecting lie detection datasets.", "corpusId": "243865628", "paragraphs": [{"paragraphId": "15841", "title": "Lying Through One\u2019s Teeth: A Study on Verbal Leakage Cues", "sectionTitle": "Introduction", "text": "One theory of lie detection is about cues to lying: Why and when do liars and truth-tellers display different behavior? Ekman and Friesen (1969) proposed two categories of cues: deception cues and leakage cues. Deception cues relate to the content of lies, such as an inconsistency in one's story; leakage cues appear because liars' emotions betray their true feeling, which can be further classified into non-verbal and verbal leakage cues. Zuckerman et al. (1981) reject the utility of focusing on liars' emotions but link such cues to cognitive load, supported by Vrij et al. (2008Vrij et al. ( , 2016Vrij et al. ( , 2017. DePaulo et al. (2003) analyzes 158 cues to deception, including non-verbal and verbal leakage cues, finding that verbal leakage cues are more reliable than others. Studies such as Adams (1996), Smith (2001), and Levitan (2019) show that verbal leak-age cues can be found through psycholinguistic dictionaries such as the LIWC lexicon (Pennebaker et al., 1999), LDI (Bachenko et al., 2008;Enos, 2009), and Harbingers (Niculae et al., 2015).", "spans": "[{\"corpusId\": 9955271, \"span\": \"Ekman and Friesen (1969)\", \"start\": 120, \"end\": 144}, {\"corpusId\": 145172823, \"span\": \"Vrij et al. (2008\", \"start\": 567, \"end\": 584}, {\"corpusId\": 145657197, \"span\": \"Vrij et al. ( , 2017\", \"start\": 604, \"end\": 624}, {\"corpusId\": 2628630, \"span\": \"DePaulo et al. (2003)\", \"start\": 626, \"end\": 647}, {\"corpusId\": 5805445, \"span\": \"(Bachenko et al., 2008;\", \"start\": 991, \"end\": 1014}, {\"corpusId\": 215824540, \"span\": \"(Niculae et al., 2015)\", \"start\": 1042, \"end\": 1064}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 6}], "paragraphCount": 1}
{"paperId": "6d06dbda28069c4aa86721d0f06b83ab1a30232e", "title": "Cross-Lingual Dependency Parsing Using Code-Mixed TreeBank", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2019, "citationCount": 40, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/D19-1092.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1909.02235, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2019-09-05", "authors": [{"authorId": "2678094", "name": "Meishan Zhang"}, {"authorId": "2096969631", "name": "Zhang Meishan"}, {"authorId": "2068672157", "name": "Zhang Yue"}, {"authorId": "31060997", "name": "Fu Guo-hong"}], "abstract": "Treebank translation is a promising method for cross-lingual transfer of syntactic dependency knowledge. The basic idea is to map dependency arcs from a source treebank to its target translation according to word alignments. This method, however, can suffer from imperfect alignment between source and target words. To address this problem, we investigate syntactic transfer by code mixing, translating only confident words in a source treebank. Cross-lingual word embeddings are leveraged for transferring syntactic knowledge to the target from the resulting code-mixed treebank. Experiments on University Dependency Treebanks show that code-mixed treebanks are more effective than translated treebanks, giving highly competitive performances among cross-lingual parsing methods.", "corpusId": "202541341", "paragraphs": [{"paragraphId": "4919", "title": "Cross-Lingual Dependency Parsing Using Code-Mixed TreeBank", "sectionTitle": "Introduction", "text": "Treebank translation (Tiedemann et al., 2014;Tiedemann, 2015;Tiedemann and Agi\u0107, 2016) has been considered as a method for cross-lingual syntactic transfer. Take dependency grammar for instance. Given a source treebank, machine translation is used to find target translations of its sentences. Then word alignment is used to find mappings between source and target words, so that source syntactic dependencies can be projected to the target translations. Following, a postprocessing step is applied by removing unaligned target words, in order to ensure that the resulting target syntax forms a valid dependency tree, The method has shown promising performance for unsupervised cross-lingual dependency parsing among transfer methods (McDonald et al., 2011;T\u00e4ckstr\u00f6m et al., 2012;Rasooli and Collins, 2015;Guo et al., 2016b). * Corresponding author.  The treebank translation method, however, suffers from various sources of noise. For example, machine translation errors directly affect the resulting treebank, by introducing ungrammatical word sequences. In addition, the alignments between source and target words may not be isomorphic due to inherent differences between languages or paraphrasing during translation. For example, in the case of Figure 1, the English words \"are\" and \"being\", and the Swedish word \"med\", do not have corresponding word-level translation. In addition, it can be perfect to express \"as soon as they can\" using \"very quickly\" in a translation, which looses word alignment information because of the longer span. Finally, errors in automatic word alignments can also bring noise. Such alignment errors can directly affect grammaticality of the resulting target treebank due to deletion of unaligned words during post-processing, or cause lost or mistaken dependency arcs.", "spans": "[{\"corpusId\": 14049482, \"span\": \"(Tiedemann et al., 2014;\", \"start\": 21, \"end\": 45}, {\"corpusId\": 14049482, \"span\": \"(Tiedemann et al., 2014;\", \"start\": 21, \"end\": 45}, {\"corpusId\": 6335141, \"span\": \"Tiedemann, 2015;\", \"start\": 45, \"end\": 61}, {\"corpusId\": 6335141, \"span\": \"Tiedemann, 2015;\", \"start\": 45, \"end\": 61}, {\"corpusId\": 7805664, \"span\": \"Tiedemann and Agi\\u0107, 2016)\", \"start\": 61, \"end\": 86}, {\"corpusId\": 7805664, \"span\": \"Tiedemann and Agi\\u0107, 2016)\", \"start\": 61, \"end\": 86}, {\"corpusId\": 6698104, \"span\": \"(McDonald et al., 2011;\", \"start\": 734, \"end\": 757}, {\"corpusId\": 6698104, \"span\": \"(McDonald et al., 2011;\", \"start\": 734, \"end\": 757}, {\"corpusId\": 891605, \"span\": \"T\\u00e4ckstr\\u00f6m et al., 2012;\", \"start\": 757, \"end\": 780}, {\"corpusId\": 891605, \"span\": \"T\\u00e4ckstr\\u00f6m et al., 2012;\", \"start\": 757, \"end\": 780}, {\"corpusId\": 2775235, \"span\": \"Rasooli and Collins, 2015;\", \"start\": 780, \"end\": 806}, {\"corpusId\": 2775235, \"span\": \"Rasooli and Collins, 2015;\", \"start\": 780, \"end\": 806}, {\"corpusId\": 2937031, \"span\": \"Guo et al., 2016b)\", \"start\": 806, \"end\": 824}, {\"corpusId\": 2937031, \"span\": \"Guo et al., 2016b)\", \"start\": 806, \"end\": 824}]", "conference": "emnlp", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 7}, {"paragraphId": "4920", "title": "Cross-Lingual Dependency Parsing Using Code-Mixed TreeBank", "sectionTitle": "Related Work", "text": "Existing work on cross-lingual transfer can be classified into two categories. The first aims to train a dependency parsing model on source treebanks (McDonald et al., 2011;Guo et al., 2016a,b), or their adapted versions (Zhao et al., 2009;Tiedemann et al., 2014;Wang et al., 2017) in the target language. The second category, 1 https://github.com/zhangmeishan/CodeMixedTreebank namely annotation projection, aims to produce a set of large-scale training instances full of automatic dependencies by parsing parallel sentences (Hwa et al., 2005;Rasooli and Collins, 2015). The two broad methods are orthogonal to each other, and can both make use of the lexicalized dependency models trained with cross-lingual word representations Collins, 2017, 2019).", "spans": "[{\"corpusId\": 6698104, \"span\": \"(McDonald et al., 2011;\", \"start\": 150, \"end\": 173}, {\"corpusId\": 6698104, \"span\": \"(McDonald et al., 2011;\", \"start\": 150, \"end\": 173}, {\"corpusId\": 15978883, \"span\": \"(Zhao et al., 2009;\", \"start\": 221, \"end\": 240}, {\"corpusId\": 15978883, \"span\": \"(Zhao et al., 2009;\", \"start\": 221, \"end\": 240}, {\"corpusId\": 14049482, \"span\": \"Tiedemann et al., 2014;\", \"start\": 240, \"end\": 263}, {\"corpusId\": 14049482, \"span\": \"Tiedemann et al., 2014;\", \"start\": 240, \"end\": 263}, {\"corpusId\": 10786404, \"span\": \"Wang et al., 2017)\", \"start\": 263, \"end\": 281}, {\"corpusId\": 10786404, \"span\": \"Wang et al., 2017)\", \"start\": 263, \"end\": 281}, {\"corpusId\": 157167, \"span\": \"(Hwa et al., 2005;\", \"start\": 526, \"end\": 544}, {\"corpusId\": 157167, \"span\": \"(Hwa et al., 2005;\", \"start\": 526, \"end\": 544}, {\"corpusId\": 2775235, \"span\": \"Rasooli and Collins, 2015)\", \"start\": 544, \"end\": 570}, {\"corpusId\": 2775235, \"span\": \"Rasooli and Collins, 2015)\", \"start\": 544, \"end\": 570}]", "conference": "emnlp", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "4921", "title": "Cross-Lingual Dependency Parsing Using Code-Mixed TreeBank", "sectionTitle": "Related Work", "text": "Source Treebank Adaption. There has been much work on unsupervised cross-lingual dependency parsing by direct source treebank transferring. Several researchers investigate delexicalized models where only non-lexical features are used in the models (Zeman and Resnik, 2008;Cohen et al., 2011;McDonald et al., 2011;Naseem et al., 2012;Rosa and Zabokrtsky, 2015). All the features in these models are language independent, and are consistent across languages and treebanks. Thus they can be applied into target languages directly.", "spans": "[{\"corpusId\": 10674977, \"span\": \"(Zeman and Resnik, 2008;\", \"start\": 248, \"end\": 272}, {\"corpusId\": 10674977, \"span\": \"(Zeman and Resnik, 2008;\", \"start\": 248, \"end\": 272}, {\"corpusId\": 14287962, \"span\": \"Cohen et al., 2011;\", \"start\": 272, \"end\": 291}, {\"corpusId\": 14287962, \"span\": \"Cohen et al., 2011;\", \"start\": 272, \"end\": 291}, {\"corpusId\": 6698104, \"span\": \"McDonald et al., 2011;\", \"start\": 291, \"end\": 313}, {\"corpusId\": 6698104, \"span\": \"McDonald et al., 2011;\", \"start\": 291, \"end\": 313}, {\"corpusId\": 3143538, \"span\": \"Naseem et al., 2012;\", \"start\": 313, \"end\": 333}, {\"corpusId\": 3143538, \"span\": \"Naseem et al., 2012;\", \"start\": 313, \"end\": 333}, {\"corpusId\": 9398597, \"span\": \"Rosa and Zabokrtsky, 2015)\", \"start\": 333, \"end\": 359}, {\"corpusId\": 9398597, \"span\": \"Rosa and Zabokrtsky, 2015)\", \"start\": 333, \"end\": 359}]", "conference": "emnlp", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "4922", "title": "Cross-Lingual Dependency Parsing Using Code-Mixed TreeBank", "sectionTitle": "Related Work", "text": "Subsequent research proposes to exploit lexicalized features to enhance the parsing models, by resorting to cross-lingual word representations (T\u00e4ckstr\u00f6m et al., 2012;Duong et al., 2015b,a;Zhang and Barzilay, 2015;Guo et al., 2016b;Ammar et al., 2016;Wick et al., 2016;de Lhoneux et al., 2018). Cross-lingual word clusters and cross-lingual word embeddings are two main sources of features for transferring knowledge between source and target language sentences. These studies enable us to train lexicalized models on code-mixed treebanks as well. Thus here we integrate the cross-lingual word representations as well, which gives more direct interaction between source and target words.", "spans": "[{\"corpusId\": 891605, \"span\": \"(T\\u00e4ckstr\\u00f6m et al., 2012;\", \"start\": 143, \"end\": 167}, {\"corpusId\": 891605, \"span\": \"(T\\u00e4ckstr\\u00f6m et al., 2012;\", \"start\": 143, \"end\": 167}, {\"corpusId\": 9555772, \"span\": \"Zhang and Barzilay, 2015;\", \"start\": 189, \"end\": 214}, {\"corpusId\": 9555772, \"span\": \"Zhang and Barzilay, 2015;\", \"start\": 189, \"end\": 214}, {\"corpusId\": 2937031, \"span\": \"Guo et al., 2016b;\", \"start\": 214, \"end\": 232}, {\"corpusId\": 2937031, \"span\": \"Guo et al., 2016b;\", \"start\": 214, \"end\": 232}, {\"corpusId\": 17617352, \"span\": \"Wick et al., 2016;\", \"start\": 251, \"end\": 269}, {\"corpusId\": 17617352, \"span\": \"Wick et al., 2016;\", \"start\": 251, \"end\": 269}, {\"corpusId\": 52111211, \"span\": \"de Lhoneux et al., 2018)\", \"start\": 269, \"end\": 293}, {\"corpusId\": 52111211, \"span\": \"de Lhoneux et al., 2018)\", \"start\": 269, \"end\": 293}]", "conference": "emnlp", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "4923", "title": "Cross-Lingual Dependency Parsing Using Code-Mixed TreeBank", "sectionTitle": "Related Work", "text": "Our work follows another mainstream method of this line of work, namely treebank translation (Tiedemann et al., 2014;Tiedemann, 2015;Tiedemann and Agi\u0107, 2016), which aims to adapt an annotated source treebank into the target language by machine translation. In addition, the targetside sentences are produced by machine translation. Previous work aims to build a well-formed tree (Tiedemann and Agi\u0107, 2016) from source dependencies, solving word alignment conflicts by heuristic rules. In contrast, we use partial translation instead to avoid unnecessary noise.", "spans": "[{\"corpusId\": 202541341, \"span\": \"Our work\", \"start\": 8, \"end\": 8}, {\"corpusId\": 14049482, \"span\": \"(Tiedemann et al., 2014;\", \"start\": 93, \"end\": 117}, {\"corpusId\": 14049482, \"span\": \"(Tiedemann et al., 2014;\", \"start\": 93, \"end\": 117}, {\"corpusId\": 6335141, \"span\": \"Tiedemann, 2015;\", \"start\": 117, \"end\": 133}, {\"corpusId\": 6335141, \"span\": \"Tiedemann, 2015;\", \"start\": 117, \"end\": 133}, {\"corpusId\": 7805664, \"span\": \"Tiedemann and Agi\\u0107, 2016)\", \"start\": 133, \"end\": 158}, {\"corpusId\": 7805664, \"span\": \"Tiedemann and Agi\\u0107, 2016)\", \"start\": 133, \"end\": 158}, {\"corpusId\": 7805664, \"span\": \"(Tiedemann and Agi\\u0107, 2016)\", \"start\": 380, \"end\": 406}, {\"corpusId\": 7805664, \"span\": \"(Tiedemann and Agi\\u0107, 2016)\", \"start\": 380, \"end\": 406}]", "conference": "emnlp", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "4924", "title": "Cross-Lingual Dependency Parsing Using Code-Mixed TreeBank", "sectionTitle": "Related Work", "text": "... ticular, a source parser trained on the source treebank is used to parse the source-side sentences of the parallel corpus. The source dependencies are then projected onto the target sentences according to word alignments. Different strategies can be applied for the dependency projection task (Ma and Xia, 2014;Rasooli and Collins, 2015;Xiao and Guo, 2015;Agi\u0107 et al., 2016;Schlichtkrull and S\u00f8gaard, 2017). For example, one can project only dependency arcs whose words are aligned to target-side words with high confidence (Lacroix et al., 2016). The resulting treebank can be highly noisy due to the auto-parsed source dependency trees. Recently Lacroix et al. (2016) and Rasooli and Collins (2017) propose to filter the results from the large-scale parallel corpus. Our work is different in that the source dependencies are from gold-standard treebanks.", "spans": "[{\"corpusId\": 15371205, \"span\": \"(Ma and Xia, 2014;\", \"start\": 297, \"end\": 315}, {\"corpusId\": 15371205, \"span\": \"(Ma and Xia, 2014;\", \"start\": 297, \"end\": 315}, {\"corpusId\": 2775235, \"span\": \"Rasooli and Collins, 2015;\", \"start\": 315, \"end\": 341}, {\"corpusId\": 2775235, \"span\": \"Rasooli and Collins, 2015;\", \"start\": 315, \"end\": 341}, {\"corpusId\": 35494, \"span\": \"Xiao and Guo, 2015;\", \"start\": 341, \"end\": 360}, {\"corpusId\": 35494, \"span\": \"Xiao and Guo, 2015;\", \"start\": 341, \"end\": 360}, {\"corpusId\": 7805664, \"span\": \"Agi\\u0107 et al., 2016;\", \"start\": 360, \"end\": 378}, {\"corpusId\": 7805664, \"span\": \"Agi\\u0107 et al., 2016;\", \"start\": 360, \"end\": 378}, {\"corpusId\": 1618800, \"span\": \"Schlichtkrull and S\\u00f8gaard, 2017)\", \"start\": 378, \"end\": 410}, {\"corpusId\": 1618800, \"span\": \"Schlichtkrull and S\\u00f8gaard, 2017)\", \"start\": 378, \"end\": 410}, {\"corpusId\": 16483916, \"span\": \"(Lacroix et al., 2016)\", \"start\": 528, \"end\": 550}, {\"corpusId\": 16483916, \"span\": \"(Lacroix et al., 2016)\", \"start\": 528, \"end\": 550}, {\"corpusId\": 16483916, \"span\": \"Lacroix et al. (2016)\", \"start\": 652, \"end\": 673}, {\"corpusId\": 16483916, \"span\": \"Lacroix et al. (2016)\", \"start\": 652, \"end\": 673}, {\"corpusId\": 2626026, \"span\": \"Rasooli and Collins (2017)\", \"start\": 678, \"end\": 704}, {\"corpusId\": 2626026, \"span\": \"Rasooli and Collins (2017)\", \"start\": 678, \"end\": 704}, {\"corpusId\": 202541341, \"span\": \"Our work\", \"start\": 781, \"end\": 781}]", "conference": "emnlp", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 8}, {"paragraphId": "4925", "title": "Cross-Lingual Dependency Parsing Using Code-Mixed TreeBank", "sectionTitle": "Code-Mixed Treebank Translation", "text": "We derive code-mixed trees from source dependency trees by partial translation, projecting words and the corresponding dependencies having highconfidence alignments with machine-translated target sentences. Our approach assumes that sentence level translations and alignment probabilities are available. The motivation is to reduce noise induced by problematic word alignments. We adopt the word-level alignment strategy, which has been demonstrated as effective as phrase-level alignment yet much simpler (Tiedemann et al., 2014;Tiedemann, 2015;Tiedemann and Agi\u0107, 2016). Give a source sentence e 1 \u00b7 \u00b7 \u00b7 e n and its target language translation f 1 \u00b7 \u00b7 \u00b7 f m , p(e i |f j ) denotes the probability of word f j being aligned with e i (0 \u2264 i \u2264 n and 0 < j \u2264 m), where e 0 denotes a null word, indicating the no alignment probability for one target word.", "spans": "[{\"corpusId\": 202541341, \"span\": \"Our approach\", \"start\": 219, \"end\": 219}, {\"corpusId\": 14049482, \"span\": \"(Tiedemann et al., 2014;\", \"start\": 506, \"end\": 530}, {\"corpusId\": 14049482, \"span\": \"(Tiedemann et al., 2014;\", \"start\": 506, \"end\": 530}, {\"corpusId\": 6335141, \"span\": \"Tiedemann, 2015;\", \"start\": 530, \"end\": 546}, {\"corpusId\": 6335141, \"span\": \"Tiedemann, 2015;\", \"start\": 530, \"end\": 546}, {\"corpusId\": 7805664, \"span\": \"Tiedemann and Agi\\u0107, 2016)\", \"start\": 546, \"end\": 571}, {\"corpusId\": 7805664, \"span\": \"Tiedemann and Agi\\u0107, 2016)\", \"start\": 546, \"end\": 571}]", "conference": "emnlp", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "4926", "title": "Cross-Lingual Dependency Parsing Using Code-Mixed TreeBank", "sectionTitle": "Settings", "text": "Our experiments are conducted on the Google Universal Dependency Treebanks (v2.0) Nivre et al., 2016), using English as the source language, and choosing six languages, including Spanish (ES), German (DE), French (FR), Italian (IT), Portuguese (PT) and Swedish (sv), as the target languages. Google Translate 3 is used to translate the sentences in the English training set into other languages. In order to generate high-quality word-level alignments, we merge the translated sentence pairs and the parallel data of EuroParl (Koehn, 2005) to obtain word alignments. We use the fastAlign tool (Dyer et al., 2013) to obtain word alignments.", "spans": "[{\"corpusId\": 17954486, \"span\": \"Nivre et al., 2016)\", \"start\": 82, \"end\": 101}, {\"corpusId\": 17954486, \"span\": \"Nivre et al., 2016)\", \"start\": 82, \"end\": 101}, {\"corpusId\": 38407095, \"span\": \"(Koehn, 2005)\", \"start\": 526, \"end\": 539}, {\"corpusId\": 38407095, \"span\": \"(Koehn, 2005)\", \"start\": 526, \"end\": 539}, {\"corpusId\": 8476273, \"span\": \"(Dyer et al., 2013)\", \"start\": 593, \"end\": 612}, {\"corpusId\": 8476273, \"span\": \"(Dyer et al., 2013)\", \"start\": 593, \"end\": 612}]", "conference": "emnlp", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "4927", "title": "Cross-Lingual Dependency Parsing Using Code-Mixed TreeBank", "sectionTitle": "Comparison with Previous Work", "text": "We compare our method with previous work in the literature.   Guo15 , Guo16 (Guo et al., 2016b) and TA16 (Tiedemann and Agi\u0107, 2016). Our model gives the best performance with one exception on the German language. One possible reason may be that TA16 has exploited multiple sources of treebanks besides English. The second block shows representative annotation projection models, including MX14 (Ma and Xia, 2014), RC15 (Rasooli and Collins, 2015), LA16. The models of annotation projection can be complementary with our work, since they build target training corpus from raw parallel texts. The best-performed results of the RC17 model (Rasooli and Collins, 2017) have demonstrated this point, which can be regarded as a combination of the dictionary-based treebank translation 4 (Zhao et al., 2009) and RC15.", "spans": "[{\"corpusId\": 202541341, \"span\": \"our method\", \"start\": 21, \"end\": 21}, {\"corpusId\": 2937031, \"span\": \"(Guo et al., 2016b)\", \"start\": 76, \"end\": 95}, {\"corpusId\": 2937031, \"span\": \"(Guo et al., 2016b)\", \"start\": 76, \"end\": 95}, {\"corpusId\": 7805664, \"span\": \"(Tiedemann and Agi\\u0107, 2016)\", \"start\": 105, \"end\": 131}, {\"corpusId\": 7805664, \"span\": \"(Tiedemann and Agi\\u0107, 2016)\", \"start\": 105, \"end\": 131}, {\"corpusId\": 15371205, \"span\": \"(Ma and Xia, 2014)\", \"start\": 394, \"end\": 412}, {\"corpusId\": 15371205, \"span\": \"(Ma and Xia, 2014)\", \"start\": 394, \"end\": 412}, {\"corpusId\": 202541341, \"span\": \"our work\", \"start\": 524, \"end\": 524}, {\"corpusId\": 2626026, \"span\": \"(Rasooli and Collins, 2017)\", \"start\": 636, \"end\": 663}, {\"corpusId\": 2626026, \"span\": \"(Rasooli and Collins, 2017)\", \"start\": 636, \"end\": 663}, {\"corpusId\": 15978883, \"span\": \"(Zhao et al., 2009)\", \"start\": 780, \"end\": 799}, {\"corpusId\": 15978883, \"span\": \"(Zhao et al., 2009)\", \"start\": 780, \"end\": 799}]", "conference": "emnlp", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 6}], "paragraphCount": 9}
{"paperId": "1c23a864a00ca1cc72f8b2ac74e6bd9e7e5ca3ed", "title": "Coding for Outdoor Play: a Coding Platform for Children to Invent and Enhance Outdoor Play Experiences", "venue": "International Conference on Human Factors in Computing Systems", "year": 2019, "citationCount": 18, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3290605.3300394?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3290605.3300394, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2019-05-02", "authors": [{"authorId": "40961082", "name": "Netta Ofer"}, {"authorId": "40545907", "name": "Idan David"}, {"authorId": "49983945", "name": "H. Erel"}, {"authorId": "1790753", "name": "Oren Zuckerman"}], "abstract": "Outdoor play is in decline, including its benefits to children's development. Coding, a typically indoor, screen-based activity, can potentially enrich outdoor play, serving as a rule-making medium. We present a coding platform that controls a programmable hardware device, enabling children to technologically-enhance their outdoor play experiences by inventing game ideas, coding them, and playing their games together with their friends. In the evaluation study, 24 children used the system to invent and play outdoor games. Results show children are able to bridge between the different domains of coding and outdoor play. They used the system to modify traditional games and invent new ones, enriching their outdoor experience. Children merged computational concepts with physical game elements, integrated physical outdoor properties as variables in their code, and were excited to see their code come to life. We conclude children can use coding to express their ideas by creating technologically-enhanced outdoor play experiences.", "corpusId": "140253939", "paragraphs": [{"paragraphId": "52638", "title": "Coding for Outdoor Play: a Coding Platform for Children to Invent and Enhance Outdoor Play Experiences", "sectionTitle": "Introduction", "text": "Compared with children in the 1970s, children today spend 50% less time in unstructured outdoor play [29]. This decline is attributed to several factors, including parents' safety concerns, lack of green spaces for play [30], and time spent using technology indoors [23]. Outdoor play is known to have positive effects on child development, including practicing problem-solving, creative thinking, and abstraction [1,11,16]. The open-ended, unstructured nature of outdoor activities [8,16], provide opportunities to acquire social skills [5,6,10,16] and fosters physical play [6,28,29,39].", "spans": "[{\"corpusId\": 202856681, \"span\": \"[30]\", \"start\": 220, \"end\": 224}, {\"corpusId\": 143186015, \"span\": \"[23]\", \"start\": 266, \"end\": 270}, {\"corpusId\": 144396348, \"span\": \"[1,\", \"start\": 414, \"end\": 417}, {\"corpusId\": 217174253, \"span\": \"11,\", \"start\": 417, \"end\": 420}, {\"corpusId\": 144879568, \"span\": \"16]\", \"start\": 420, \"end\": 423}, {\"corpusId\": 14988544, \"span\": \"[8,\", \"start\": 483, \"end\": 486}, {\"corpusId\": 144879568, \"span\": \"16]\", \"start\": 486, \"end\": 489}, {\"corpusId\": 12797819, \"span\": \"[5,\", \"start\": 538, \"end\": 541}, {\"corpusId\": 13213129, \"span\": \"6,\", \"start\": 541, \"end\": 543}, {\"corpusId\": 16052143, \"span\": \"10,\", \"start\": 543, \"end\": 546}, {\"corpusId\": 144879568, \"span\": \"16]\", \"start\": 546, \"end\": 549}, {\"corpusId\": 13213129, \"span\": \"[6,\", \"start\": 576, \"end\": 579}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 9}, {"paragraphId": "52639", "title": "Coding for Outdoor Play: a Coding Platform for Children to Invent and Enhance Outdoor Play Experiences", "sectionTitle": "Introduction", "text": "A key aspect of outdoor play, and the focus of this paper, is rule-making [2,21,27]. Rule-making is considered a basic feature of play as it provides structure to the play activity while preserving its open-ended nature. In outdoor play, children can define and change the rules however they desire [4,[8][9][10]33], contributing to physical play and social interaction [9].", "spans": "[{\"corpusId\": 140253939, \"span\": \"this paper\", \"start\": 57, \"end\": 57}, {\"corpusId\": 6584641, \"span\": \"[2,\", \"start\": 74, \"end\": 77}, {\"corpusId\": 26722971, \"span\": \"[4,\", \"start\": 299, \"end\": 302}, {\"corpusId\": 14988544, \"span\": \"[8]\", \"start\": 302, \"end\": 305}, {\"corpusId\": 22302529, \"span\": \"[9]\", \"start\": 305, \"end\": 308}, {\"corpusId\": 16052143, \"span\": \"[10]\", \"start\": 308, \"end\": 312}, {\"corpusId\": 4223074, \"span\": \"33]\", \"start\": 312, \"end\": 315}, {\"corpusId\": 22302529, \"span\": \"[9]\", \"start\": 370, \"end\": 373}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 7}, {"paragraphId": "52640", "title": "Coding for Outdoor Play: a Coding Platform for Children to Invent and Enhance Outdoor Play Experiences", "sectionTitle": "Introduction", "text": "Experience with coding from a young age is thought to extend children's ability to design, create, and invent [37,40,41]. Coding activities are considered to promote analytical thinking, abstraction abilities, [7,40,47,48], and computational literacy [20]. As coding becomes common in many schools, a wide range of approaches should be developed for introducing coding to diverse audiences. Outdoor play adds a unique nature to coding, and may appeal to children in ways that traditional coding activities do not, especially to children who are \"outdoor play-fluent\" [19].", "spans": "[{\"corpusId\": 9390203, \"span\": \"40,\", \"start\": 114, \"end\": 117}, {\"corpusId\": 207590899, \"span\": \"41]\", \"start\": 117, \"end\": 120}, {\"corpusId\": 207184749, \"span\": \"[7,\", \"start\": 210, \"end\": 213}, {\"corpusId\": 9390203, \"span\": \"40,\", \"start\": 213, \"end\": 216}, {\"corpusId\": 1693513, \"span\": \"47,\", \"start\": 216, \"end\": 219}, {\"corpusId\": 42358686, \"span\": \"[19]\", \"start\": 567, \"end\": 571}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "52641", "title": "Coding for Outdoor Play: a Coding Platform for Children to Invent and Enhance Outdoor Play Experiences", "sectionTitle": "Introduction", "text": "However, the integration of coding and outdoor play is not trivial. Outdoor play has known characteristics, namely social interaction and physical activity [11,16], as well as \"heads up\" play patterns [31,43]. Coding is typically a screenbased, \"heads down\" activity, and may compromise outdoor play characteristics. Careful consideration should be given to balance the advantages of coding with the disadvantages of adding technology to outdoor play [31].", "spans": "[{\"corpusId\": 217174253, \"span\": \"[11,\", \"start\": 156, \"end\": 160}, {\"corpusId\": 144879568, \"span\": \"16]\", \"start\": 160, \"end\": 163}, {\"corpusId\": 207157240, \"span\": \"[31,\", \"start\": 201, \"end\": 205}, {\"corpusId\": 6743688, \"span\": \"43]\", \"start\": 205, \"end\": 208}, {\"corpusId\": 207157240, \"span\": \"[31]\", \"start\": 451, \"end\": 455}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "52642", "title": "Coding for Outdoor Play: a Coding Platform for Children to Invent and Enhance Outdoor Play Experiences", "sectionTitle": "Pervasive Games", "text": "Pervasive games are designed to take gaming away from the computer screen and into the physical world, leveraging technology to merge the physical and digital game elements [31,35]. Sensing in Pervasive games integrates natural obstacles and challenges from the physical world into the game, and digital feedback brings game elements into outdoor play. This results in games that require physical effort and problem-solving in a real-world context [31]. Two notable examples are Pirates! and PacMap. In Pirates!, handheld computers and real-world properties such as locations are used as elements of the game, encouraging players to complete missions by exploring their digital-physical surrounding [12]. In PacMap, a location-based variant of the classic PacMan, players need to avoid enemies and collect rewards in real streets [15].", "spans": "[{\"corpusId\": 207157240, \"span\": \"[31,\", \"start\": 173, \"end\": 177}, {\"corpusId\": 140253939, \"span\": \"This results\", \"start\": 365, \"end\": 365}, {\"corpusId\": 207157240, \"span\": \"[31]\", \"start\": 448, \"end\": 452}, {\"corpusId\": 2531520, \"span\": \"[12]\", \"start\": 699, \"end\": 703}, {\"corpusId\": 14894807, \"span\": \"[15]\", \"start\": 830, \"end\": 834}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "52643", "title": "Coding for Outdoor Play: a Coding Platform for Children to Invent and Enhance Outdoor Play Experiences", "sectionTitle": "Head Up Games", "text": "Pervasive games commonly involve screens and hand-held devices that may interfere with natural outdoor play patterns [34], and may compromise the benefits of play [44]. To address these concerns, Markopoplus & Soute (2007), defined a sub-category of pervasive games coined Head Up Games (HUG) [43]. HUGs strive to promote outdoor social interaction with the support of digital devices while keeping players heads \"up\" to encourage natural social interaction. For example, \"Stop the Bomb\" prototype [25] is a belt with vibration motor and LEDs. Children are assigned to teams based on LED color, and vibration feedback is used to indicate which player holds the key. HeartBeat prototype [32] is a small portable device with heart rate sensing as input and a buzzer that beeps if the rate of the opponent's heart beat exceeds a preset value.", "spans": "[{\"corpusId\": 6204039, \"span\": \"[44]\", \"start\": 163, \"end\": 167}, {\"corpusId\": 6743688, \"span\": \"[43]\", \"start\": 293, \"end\": 297}, {\"corpusId\": 1276031, \"span\": \"[25]\", \"start\": 498, \"end\": 502}, {\"corpusId\": 10593017, \"span\": \"[32]\", \"start\": 686, \"end\": 690}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "52644", "title": "Coding for Outdoor Play: a Coding Platform for Children to Invent and Enhance Outdoor Play Experiences", "sectionTitle": "Discussion", "text": "Children's ability to program the device and use it as an integral part of their outdoor play experiences is not trivial. The essence of outdoor play is \"heads up\" social interaction and physical activity [11,16,31,43], which are not natural characteristics of coding activities. Moreover, adding screens to outdoor play (a coding platform running on a tablet device) is thought to interfere with natural play patterns [34] and compromise the benefits of natural play [44]. Nonetheless, the children successfully bridged this gap, using the \"heads down\" coding activity to create code that generates a \"heads up\" outdoor game experience. In addition, children played their games with their friends with no further adjustments to the code, indicating that they were able to program playable outdoor games. This may be attributed to the clear distinction between the coding platform and the digital device, that framed the coding platform as a tool for defining the game and the device as a tool for playing the game. Future work should test this assumption and compare the digital coding platform to a more tangible coding platform. While physical programming may preserve the \"heads up\" nature of outdoor play, it may also be perceived as part of the game instead of a mechanism for defining the game rules.", "spans": "[{\"corpusId\": 217174253, \"span\": \"[11,\", \"start\": 205, \"end\": 209}, {\"corpusId\": 144879568, \"span\": \"16,\", \"start\": 209, \"end\": 212}, {\"corpusId\": 207157240, \"span\": \"31,\", \"start\": 212, \"end\": 215}, {\"corpusId\": 6743688, \"span\": \"43]\", \"start\": 215, \"end\": 218}, {\"corpusId\": 6204039, \"span\": \"[44]\", \"start\": 468, \"end\": 472}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 5}], "paragraphCount": 7}
{"paperId": "bff8ae9e28323d217b9ad5a7321e58f79607f557", "title": "A Multi-Axis Annotation Scheme for Event Temporal Relations", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2018, "citationCount": 180, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/P18-1122.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1804.07828, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2018-04-01", "authors": [{"authorId": "3333257", "name": "Qiang Ning"}, {"authorId": "2119796958", "name": "Hao Wu"}, {"authorId": "144590225", "name": "D. Roth"}], "abstract": "Existing temporal relation (TempRel) annotation schemes often have low inter-annotator agreements (IAA) even between experts, suggesting that the current annotation task needs a better definition. This paper proposes a new multi-axis modeling to better capture the temporal structure of events. In addition, we identify that event end-points are a major source of confusion in annotation, so we also propose to annotate TempRels based on start-points only. A pilot expert annotation effort using the proposed scheme shows significant improvement in IAA from the conventional 60\u2019s to 80\u2019s (Cohen\u2019s Kappa). This better-defined annotation scheme further enables the use of crowdsourcing to alleviate the labor intensity for each annotator. We hope that this work can foster more interesting studies towards event understanding.", "corpusId": "5066019", "paragraphs": [{"paragraphId": "21936", "title": "A Multi-Axis Annotation Scheme for Event Temporal Relations", "sectionTitle": "Introduction", "text": "Temporal relation (TempRel) extraction is an important task for event understanding, and it has drawn much attention in the natural language processing (NLP) community recently (UzZaman et al., 2013;Llorens et al., 2015;Minard et al., 2015;Bethard et al., 2015Bethard et al., , 2016Bethard et al., , 2017Leeuwenberg and Moens, 2017;Ning et al., 2017Ning et al., , 2018a.", "spans": "[{\"corpusId\": 640783, \"span\": \"(UzZaman et al., 2013;\", \"start\": 177, \"end\": 199}, {\"corpusId\": 7849314, \"span\": \"Llorens et al., 2015;\", \"start\": 199, \"end\": 220}, {\"corpusId\": 209538, \"span\": \"Bethard et al., 2015\", \"start\": 240, \"end\": 260}, {\"corpusId\": 62948965, \"span\": \"Bethard et al., , 2016\", \"start\": 260, \"end\": 282}, {\"corpusId\": 8559209, \"span\": \"Bethard et al., , 2017\", \"start\": 282, \"end\": 304}, {\"corpusId\": 17894632, \"span\": \"Leeuwenberg and Moens, 2017;\", \"start\": 304, \"end\": 332}, {\"corpusId\": 28982109, \"span\": \"Ning et al., 2017\", \"start\": 332, \"end\": 349}, {\"corpusId\": 4957206, \"span\": \"Ning et al., , 2018a\", \"start\": 349, \"end\": 369}]", "conference": "acl", "year": 2018, "likelyRelatedWorkSection": false, "refCount": 8}, {"paragraphId": "21937", "title": "A Multi-Axis Annotation Scheme for Event Temporal Relations", "sectionTitle": "Introduction", "text": "Initiated by TimeBank (TB) (Pustejovsky et al., 2003b), a number of TempRel datasets have been collected, including but not limited to the verbclause augmentation to TB (Bethard et al., 2007), TempEval1-3 (Verhagen et al., 2007(Verhagen et al., , 2010UzZaman et al., 2013), TimeBank-Dense (TB-Dense) , EventTimeCorpus (Reimers et al., 2016), and datasets with both temporal and other types of relations (e.g., coreference and causality) such as CaTeRs (Mostafazadeh et al., 2016) and RED (O'Gorman et al., 2016). These datasets were annotated by experts, but most still suffered from low inter-annotator agreements (IAA). For instance, the IAAs of TB-Dense, RED and THYME-TimeML (Styler IV et al., 2014) were only below or near 60% (given that events are already annotated). Since a low IAA usually indicates that the task is difficult even for humans (see Examples 1-3), the community has been looking into ways to simplify the task, by reducing the label set, and by breaking up the overall, complex task into subtasks (e.g., getting agreement on which event pairs should have a relation, and then what that relation should be) (Mostafazadeh et al., 2016;O'Gorman et al., 2016). In contrast to other existing datasets, Bethard et al. (2007) achieved an agreement as high as 90%, but the scope of its annotation was narrowed down to a very special verb-clause structure.", "spans": "[{\"corpusId\": 16376903, \"span\": \"(Bethard et al., 2007)\", \"start\": 169, \"end\": 191}, {\"corpusId\": 39011, \"span\": \"(Verhagen et al., 2007\", \"start\": 205, \"end\": 227}, {\"corpusId\": 640783, \"span\": \"UzZaman et al., 2013)\", \"start\": 251, \"end\": 272}, {\"corpusId\": 6677927, \"span\": \"(Reimers et al., 2016)\", \"start\": 318, \"end\": 340}, {\"corpusId\": 8387007, \"span\": \"(Mostafazadeh et al., 2016)\", \"start\": 452, \"end\": 479}, {\"corpusId\": 15139323, \"span\": \"(O'Gorman et al., 2016)\", \"start\": 488, \"end\": 511}, {\"corpusId\": 10260215, \"span\": \"(Styler IV et al., 2014)\", \"start\": 679, \"end\": 703}, {\"corpusId\": 8387007, \"span\": \"(Mostafazadeh et al., 2016;\", \"start\": 1130, \"end\": 1157}, {\"corpusId\": 15139323, \"span\": \"O'Gorman et al., 2016)\", \"start\": 1157, \"end\": 1179}, {\"corpusId\": 16376903, \"span\": \"Bethard et al. (2007)\", \"start\": 1221, \"end\": 1242}]", "conference": "acl", "year": 2018, "likelyRelatedWorkSection": false, "refCount": 7}, {"paragraphId": "21938", "title": "A Multi-Axis Annotation Scheme for Event Temporal Relations", "sectionTitle": "Differences from Factuality", "text": "Event modality have been discussed in many existing event annotation schemes, e.g., Event Nugget (Mitamura et al., 2015), Rich ERE , and RED. Generally, an event is classified as Actual or Non-Actual, a.k.a. factuality (Saur\u00ed and Pustejovsky, 2009;Lee et al., 2015).", "spans": "[{\"corpusId\": 3137086, \"span\": \"(Mitamura et al., 2015)\", \"start\": 97, \"end\": 120}, {\"corpusId\": 34511131, \"span\": \"(Saur\\u00ed and Pustejovsky, 2009;\", \"start\": 219, \"end\": 248}, {\"corpusId\": 605188, \"span\": \"Lee et al., 2015)\", \"start\": 248, \"end\": 265}]", "conference": "acl", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "21939", "title": "A Multi-Axis Annotation Scheme for Event Temporal Relations", "sectionTitle": "Baseline System", "text": "(v) Whether the two verbs have a common synonym from their synsets in WordNet (Fellbaum, 1998). (vi) Whether the input event mentions have a common derivational form derived from WordNet. (vii) The head words of the preposition phrases that cover each event, respectively. And (viii) event properties such as Aspect, Modality, and Polarity that come with the TimeBank dataset and are commonly used as features. The proposed baseline system uses the averaged perceptron algorithm to classify the relation between each event pair into one of the four relation types. We adopted the same train/dev/test split of TB-Dense, where there are 22 documents in train, 5 in dev, and 9 in test. Parameters were tuned on the train-set to maximize its F 1 on the dev-set, after which the classifier was retrained on the union of train and dev. A detailed analysis of the baseline system is provided in Table 6. The performance on equal and vague is lower than on before and after, probably due to shortage in these labels in the training data and the inherent difficulty in event coreference and temporal vagueness. We can see, though, that the overall performance on MATRES is much better than those in the literature for TempRel extraction, which used to be in the low 50's Ning et al., 2017). The same system was also retrained and tested on the original annotations of TB-Dense (Line \"Original\"), which confirms the significant improvement if the proposed annotation scheme is used. Note that we do not mean to say that the proposed baseline system itself is better than other existing algorithms, but rather that the proposed annotation scheme and the resulting dataset lead to better defined machine learning tasks. In the future, more data can be collected and used with advanced techniques such as ILP (Do et al., 2012), structured learning (Ning et al., 2017) or multi-sieve .  Table 6: Performance of the proposed baseline system on MATRES. Line \"Original\" is the same system retrained on the original TB-Dense and tested on the same subset of event pairs. Due to the limited number of equal examples, the system did not make any equal predictions on the testset.", "spans": "[{\"corpusId\": 5066019, \"span\": \"proposed baseline system\", \"start\": 439, \"end\": 439}, {\"corpusId\": 28982109, \"span\": \"Ning et al., 2017)\", \"start\": 1262, \"end\": 1280}, {\"corpusId\": 5066019, \"span\": \"proposed baseline system\", \"start\": 1538, \"end\": 1538}, {\"corpusId\": 7359050, \"span\": \"(Do et al., 2012)\", \"start\": 1796, \"end\": 1813}, {\"corpusId\": 28982109, \"span\": \"(Ning et al., 2017)\", \"start\": 1835, \"end\": 1854}, {\"corpusId\": 5066019, \"span\": \"proposed baseline system\", \"start\": 1925, \"end\": 1925}]", "conference": "acl", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 4}
{"paperId": "ba6500dc69dc4f8630d9942e57c2852016596a2f", "title": "RePlay: Contextually Presenting Learning Videos Across Software Applications", "venue": "International Conference on Human Factors in Computing Systems", "year": 2019, "citationCount": 40, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3290605.3300527?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3290605.3300527, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2019-05-02", "authors": [{"authorId": "32200766", "name": "C. Fraser"}, {"authorId": "3720692", "name": "Tricia J. Ngoon"}, {"authorId": "2875493", "name": "Mira Dontcheva"}, {"authorId": "21520403", "name": "S. Klemmer"}], "abstract": "Complex activities often require people to work across multiple software applications. However, people frequently lack valuable knowledge about at least one application, especially as software changes and new software emerges. Existing help systems either lack contextual knowledge or are tightly-knit into a single application. We introduce an application-independent approach for contextually presenting video learning resources and demonstrate it through the RePlay system. RePlay uses accessibility APIs to gather context about the user's activity. It leverages an existing search engine to present relevant videos and highlights key segments within them using video captions. We report on a week-long field study (n=7) and a lab study (n=24) showing that contextual assistance helps people spend less time away from their task than web video search and replaces current video navigation strategies. Our findings highlight challenges with representing and using context across applications.", "corpusId": "140210876", "paragraphs": [{"paragraphId": "49182", "title": "RePlay: Contextually Presenting Learning Videos Across Software Applications", "sectionTitle": "INTRODUCTION", "text": "Presenting learning resources in-application [7,11,19,23,32,33] and augmenting search queries with contextual information [7,13] can offer a more fluid experience with lower cognitive load. However, existing solutions require deep integration with applications. And since today's applications are \"walled gardens\" with limited integration across software vendors [6], help resources typically focus on one application at a time. This leaves gaps when users want to move from one application to another (e.g., export an Adobe xd prototype to Zeplin) or interleave applications (e.g., coding a website in Sublime while debugging in Chrome and resizing graphics in gimp).", "spans": "[{\"corpusId\": 207178456, \"span\": \"[7,\", \"start\": 45, \"end\": 48}, {\"corpusId\": 9403648, \"span\": \"11,\", \"start\": 48, \"end\": 51}, {\"corpusId\": 15324700, \"span\": \"19,\", \"start\": 51, \"end\": 54}, {\"corpusId\": 1615395, \"span\": \"23,\", \"start\": 54, \"end\": 57}, {\"corpusId\": 17451313, \"span\": \"32,\", \"start\": 57, \"end\": 60}, {\"corpusId\": 2786582, \"span\": \"33]\", \"start\": 60, \"end\": 63}, {\"corpusId\": 207178456, \"span\": \"[7,\", \"start\": 122, \"end\": 125}, {\"corpusId\": 15325499, \"span\": \"13]\", \"start\": 125, \"end\": 128}, {\"corpusId\": 5093929, \"span\": \"[6]\", \"start\": 363, \"end\": 366}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 8}, {"paragraphId": "49183", "title": "RePlay: Contextually Presenting Learning Videos Across Software Applications", "sectionTitle": "INTRODUCTION", "text": "Web search results can of course include communitycreated resources that span applications. However, generic web search poses two problems. First, search is blind to relevant contextual information that could connect users to better resources [13,14,26]. Search engines place the burden on users to articulate an appropriate query, an almost paradoxical requirement for users who are there because they don't know the domain [44]. Second, search is divorced from the application UX, requiring users to bounce back and forth to connect the content [15]. These challenges are amplified when users work with multiple applications, each with its own terminology and conventions.", "spans": "[{\"corpusId\": 15325499, \"span\": \"[13,\", \"start\": 243, \"end\": 247}, {\"corpusId\": 12956853, \"span\": \"14,\", \"start\": 247, \"end\": 250}, {\"corpusId\": 11448775, \"span\": \"26]\", \"start\": 250, \"end\": 253}, {\"corpusId\": 152075392, \"span\": \"[44]\", \"start\": 425, \"end\": 429}, {\"corpusId\": 6239954, \"span\": \"[15]\", \"start\": 547, \"end\": 551}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "49184", "title": "RePlay: Contextually Presenting Learning Videos Across Software Applications", "sectionTitle": "INTRODUCTION", "text": "We introduce an application-independent approach for contextually presenting video learning resources. We embody this approach in the RePlay system, which enables users to search for learning videos based on their application usage. RePlay gathers application context using system accessibility apis. It extends online video search and cues videos to relevant segments based on their captions. We focus on video assistance because despite video's growing popularity (Cisco predicts that by 2021, 82% of all internet traffic will be video [2]), searching and browsing video remain cumbersome [25,39,40]. Video is popular for content creators as it is often easier to author than tutorials or diagrams (which require careful curation). Learners value video for its efficacy in communicating complex or continuous visual actions such as brushing or setting parameters [10]. However, interacting with videos remains difficult because they are harder to navigate and scan for steps than text [10].", "spans": "[{\"corpusId\": 140210876, \"span\": \"this approach\", \"start\": 126, \"end\": 126}, {\"corpusId\": 1470846, \"span\": \"[25,\", \"start\": 591, \"end\": 595}, {\"corpusId\": 5983643, \"span\": \"39,\", \"start\": 595, \"end\": 598}, {\"corpusId\": 207216566, \"span\": \"40]\", \"start\": 598, \"end\": 601}, {\"corpusId\": 94093, \"span\": \"[10]\", \"start\": 865, \"end\": 869}, {\"corpusId\": 94093, \"span\": \"[10]\", \"start\": 987, \"end\": 991}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "49185", "title": "RePlay: Contextually Presenting Learning Videos Across Software Applications", "sectionTitle": "RELATED WORK", "text": "Help systems for such applications tend to focus on their individual tasks rather than the transitions and interactions between them [37]. Implementing system-wide assistance that captures activity context is difficult, as every application has its own conventions and interface, and software interoperability tends to be limited [6]. Accessibility apis are one useful entry point for diverse system-wide extensibility, including visualizing user behavior [34], voice control [30,53], and modifying or enhancing existing user interfaces [9,12,47]. RePlay uses accessibility apis for detecting system-wide application context.", "spans": "[{\"corpusId\": 5093929, \"span\": \"[6]\", \"start\": 330, \"end\": 333}, {\"corpusId\": 8104600, \"span\": \"[34]\", \"start\": 456, \"end\": 460}, {\"corpusId\": 37321626, \"span\": \"[30,\", \"start\": 476, \"end\": 480}, {\"corpusId\": 12556369, \"span\": \"53]\", \"start\": 480, \"end\": 483}, {\"corpusId\": 12961084, \"span\": \"[9,\", \"start\": 537, \"end\": 540}, {\"corpusId\": 667695, \"span\": \"12,\", \"start\": 540, \"end\": 543}, {\"corpusId\": 7812663, \"span\": \"47]\", \"start\": 543, \"end\": 546}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "49186", "title": "RePlay: Contextually Presenting Learning Videos Across Software Applications", "sectionTitle": "Application context improves relevance and presentation of learning content", "text": "The most teachable moment for software tasks is often when the user is actively working... but stuck. In-task help for a specific goal is one of the biggest reasons people seek web [27] and video [4] tutorials. However, tutorials tend to show a full task from start to finish, much of which may not be relevant to the user's current goal. This leaves it to the user to both find a relevant tutorial and locate the segment(s) within it that contains the needed information. Effectively searching the Web is an acquired skill; coming up with the right keywords and search settings can be difficult, especially for novices [44]. In addition, web search environments lack context that human tutors use to proactively offer help and tailor feedback [45]. Adding contextual terms automatically to search queries (e.g., os version, application, recently-used tools) can help improve the relevance and utility of search results without requiring the user to know app-specific terminology [7,13,33]. RePlay augments queries with the current application name and uses context from both the current and recently-used applications to support cross-app activities when ranking search results.", "spans": "[{\"corpusId\": 1899999, \"span\": \"[27]\", \"start\": 181, \"end\": 185}, {\"corpusId\": 152075392, \"span\": \"[44]\", \"start\": 620, \"end\": 624}, {\"corpusId\": 207178456, \"span\": \"[7,\", \"start\": 980, \"end\": 983}, {\"corpusId\": 15325499, \"span\": \"13,\", \"start\": 983, \"end\": 986}, {\"corpusId\": 2786582, \"span\": \"33]\", \"start\": 986, \"end\": 989}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "49187", "title": "RePlay: Contextually Presenting Learning Videos Across Software Applications", "sectionTitle": "Application context improves relevance and presentation of learning content", "text": "Bringing learning resources directly into applications reduces the need for context switching. For example, proactively recommending content in-situ based on user context can lead users to resources they might not have even thought to search for [11,16,23,32,35]. In-app search also helps users stay focused on their task while learning [11,16,28]. RePlay brings these strategies into an application-independent system, functioning alongside the user's applications.", "spans": "[{\"corpusId\": 9403648, \"span\": \"[11,\", \"start\": 246, \"end\": 250}, {\"corpusId\": 1249595, \"span\": \"16,\", \"start\": 250, \"end\": 253}, {\"corpusId\": 1615395, \"span\": \"23,\", \"start\": 253, \"end\": 256}, {\"corpusId\": 17451313, \"span\": \"32,\", \"start\": 256, \"end\": 259}, {\"corpusId\": 16433405, \"span\": \"35]\", \"start\": 259, \"end\": 262}, {\"corpusId\": 9403648, \"span\": \"[11,\", \"start\": 337, \"end\": 341}, {\"corpusId\": 1249595, \"span\": \"16,\", \"start\": 341, \"end\": 344}, {\"corpusId\": 9002510, \"span\": \"28]\", \"start\": 344, \"end\": 347}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "49188", "title": "RePlay: Contextually Presenting Learning Videos Across Software Applications", "sectionTitle": "Application context improves relevance and presentation of learning content", "text": "Videos are helpful for learning but hard to navigate Videos are popular for many kinds of tasks, especially visual ones, because they show clear demonstrations that might be harder to explain or understand in text [10,41]. Videos are widely available and relatively easy to make. Software is always being updated, and new video demonstrations are constantly added to popular platforms by the user community to keep up with updates and current trends. However, while text-based documents are easy to skim and search, videos are not [25,39,40]. The predominant video search approach displays results as thumbnail images with a title and summary (e.g., YouTube, Vimeo). This presentation only provides a broad overview without cues about matching content; prior work has shown that people look for indications of how search results are relevant to their query [21]. Navigating within videos is typically limited to hovering across the timeline with a small visual preview.", "spans": "[{\"corpusId\": 94093, \"span\": \"[10,\", \"start\": 214, \"end\": 218}, {\"corpusId\": 16912989, \"span\": \"41]\", \"start\": 218, \"end\": 221}, {\"corpusId\": 1470846, \"span\": \"[25,\", \"start\": 531, \"end\": 535}, {\"corpusId\": 5983643, \"span\": \"39,\", \"start\": 535, \"end\": 538}, {\"corpusId\": 207216566, \"span\": \"40]\", \"start\": 538, \"end\": 541}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "49189", "title": "RePlay: Contextually Presenting Learning Videos Across Software Applications", "sectionTitle": "Application context improves relevance and presentation of learning content", "text": "Automatically dividing videos into conceptual chunks can improve peoples' ability to find useful information for their task [5,10,19,32,36,41]. RePlay uses captions to select relevant clips [17,39,40]. Automatic clip selection plays a limited but growing role in web search. Google displays a \"suggested video clip\" [48] as the automated summary for some searches, and Bing's \"smart motion preview\" feature [1] shows a 30-second preview for video search results. In contrast, RePlay focuses on searching with and presenting results within application context. Chi et al. [10] showed people benefit most from a mix of text and video; RePlay combines video and text instruction by presenting captions with videos for both navigational and learning assistance.", "spans": "[{\"corpusId\": 2144932, \"span\": \"[5,\", \"start\": 124, \"end\": 127}, {\"corpusId\": 94093, \"span\": \"10,\", \"start\": 127, \"end\": 130}, {\"corpusId\": 15324700, \"span\": \"19,\", \"start\": 130, \"end\": 133}, {\"corpusId\": 17451313, \"span\": \"32,\", \"start\": 133, \"end\": 136}, {\"corpusId\": 6168968, \"span\": \"36,\", \"start\": 136, \"end\": 139}, {\"corpusId\": 16912989, \"span\": \"41]\", \"start\": 139, \"end\": 142}, {\"corpusId\": 18451288, \"span\": \"[17,\", \"start\": 190, \"end\": 194}, {\"corpusId\": 5983643, \"span\": \"39,\", \"start\": 194, \"end\": 197}, {\"corpusId\": 207216566, \"span\": \"40]\", \"start\": 197, \"end\": 200}, {\"corpusId\": 94093, \"span\": \"[10]\", \"start\": 571, \"end\": 575}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "49190", "title": "RePlay: Contextually Presenting Learning Videos Across Software Applications", "sectionTitle": "Application context improves relevance and presentation of learning content", "text": "Methods for navigating between video segments include interactive timeline markers [5,20,24,25,32], thumbnail images [5,10,19,24,40,41], transcript text [24], and clickable elements overlaid on the video [36]. Like Ambient Help [32], ToolScape [25], and Chronicle [20], RePlay overlays markers on the timeline indicating command or tool use. We use timeline markers over other options as they take up little space and allow for pop-up text previews, which aid browsing. While prior work marks all instances of tool use or interface actions, RePlay marks only contextually-relevant moments (recently-used tools and words from the user's query) to reduce clutter and unnecessary detail in a small interface.", "spans": "[{\"corpusId\": 2144932, \"span\": \"[5,\", \"start\": 83, \"end\": 86}, {\"corpusId\": 9153636, \"span\": \"20,\", \"start\": 86, \"end\": 89}, {\"corpusId\": 2255938, \"span\": \"24,\", \"start\": 89, \"end\": 92}, {\"corpusId\": 1470846, \"span\": \"25,\", \"start\": 92, \"end\": 95}, {\"corpusId\": 17451313, \"span\": \"32]\", \"start\": 95, \"end\": 98}, {\"corpusId\": 2144932, \"span\": \"[5,\", \"start\": 117, \"end\": 120}, {\"corpusId\": 94093, \"span\": \"10,\", \"start\": 120, \"end\": 123}, {\"corpusId\": 15324700, \"span\": \"19,\", \"start\": 123, \"end\": 126}, {\"corpusId\": 2255938, \"span\": \"24,\", \"start\": 126, \"end\": 129}, {\"corpusId\": 207216566, \"span\": \"40,\", \"start\": 129, \"end\": 132}, {\"corpusId\": 16912989, \"span\": \"41]\", \"start\": 132, \"end\": 135}, {\"corpusId\": 2255938, \"span\": \"[24]\", \"start\": 153, \"end\": 157}, {\"corpusId\": 6168968, \"span\": \"[36]\", \"start\": 204, \"end\": 208}, {\"corpusId\": 17451313, \"span\": \"[32]\", \"start\": 228, \"end\": 232}, {\"corpusId\": 1470846, \"span\": \"[25]\", \"start\": 244, \"end\": 248}, {\"corpusId\": 9153636, \"span\": \"[20]\", \"start\": 264, \"end\": 268}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 10}, {"paragraphId": "49191", "title": "RePlay: Contextually Presenting Learning Videos Across Software Applications", "sectionTitle": "Video search & ranking", "text": "Finding clips and re-ranking videos. Several techniques automatically extract instructional video clips from screencasts of software use. The dominant approach leverages application usage [10,20,29,52], requiring that the video be recorded in an instrumented version of the software. Alternatively, computer vision can detect tool-selection events [32,41], even without prior knowledge about the specific software [5]. To be application-independent and embed online videos directly without waiting to download and process them, RePlay instead uses metadata and caption text to rank and segment videos.", "spans": "[{\"corpusId\": 94093, \"span\": \"[10,\", \"start\": 188, \"end\": 192}, {\"corpusId\": 9153636, \"span\": \"20,\", \"start\": 192, \"end\": 195}, {\"corpusId\": 15193243, \"span\": \"29,\", \"start\": 195, \"end\": 198}, {\"corpusId\": 5046225, \"span\": \"52]\", \"start\": 198, \"end\": 201}, {\"corpusId\": 17451313, \"span\": \"[32,\", \"start\": 348, \"end\": 352}, {\"corpusId\": 16912989, \"span\": \"41]\", \"start\": 352, \"end\": 355}, {\"corpusId\": 2144932, \"span\": \"[5]\", \"start\": 414, \"end\": 417}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "49192", "title": "RePlay: Contextually Presenting Learning Videos Across Software Applications", "sectionTitle": "What other domains might benefit?", "text": "RePlay's main insight is that given a source of user context, we can search, curate, and index into resources from a large corpus. RePlay demonstrates this approach using video; different activities (e.g., programming) may benefit from other types of content (e.g., text resources). RePlay could naturally be extended to any textual content (or content with textual metadata). Text results could be displayed as short summaries with clickable keywords to expand more detail [13]. For detecting context, RePlay used MacOS's accessibility api; other oss (e.g. Windows [34]) also have similar apis. Beyond software, RePlay's approach could extend to any domain for which online videos are abundant (e.g., physical building tasks). To detect activity context, one could augment physical tools with sensors [31,46] or track body poses with wearable sensors or computer vision. A challenge for future work is to convert sensor or vision data into text searches, or to index videos using the sensor or vision data directly.", "spans": "[{\"corpusId\": 140210876, \"span\": \"this approach\", \"start\": 164, \"end\": 164}, {\"corpusId\": 15325499, \"span\": \"[13]\", \"start\": 474, \"end\": 478}, {\"corpusId\": 8104600, \"span\": \"[34]\", \"start\": 566, \"end\": 570}, {\"corpusId\": 2189601, \"span\": \"46]\", \"start\": 806, \"end\": 809}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 11}
{"paperId": "2139c564a8fdc649727e5deb7f2ca468874c7bdd", "title": "We Need Numbers!: Heuristic Evaluation during Demonstrations (HED) for Measuring Usability in IT System Procurement", "venue": "International Conference on Human Factors in Computing Systems", "year": 2016, "citationCount": 7, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/2858036.2858570?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2858036.2858570, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2016-05-07", "authors": [{"authorId": "2447909", "name": "Mari Tyllinen"}, {"authorId": "34737337", "name": "J. Kaipio"}, {"authorId": "2682365", "name": "T. L\u00e4\u00e4veri"}, {"authorId": "143727260", "name": "M. Nieminen"}], "abstract": null, "corpusId": "2013923", "paragraphs": [{"paragraphId": "36340", "title": "We Need Numbers!: Heuristic Evaluation during Demonstrations (HED) for Measuring Usability in IT System Procurement", "sectionTitle": "INTRODUCTION", "text": "Heuristic evaluation (HE) [39] is an established method in user-centered system design [21]. It has been widely used in software development and evaluation especially in formative [13,18] development contexts in which it is possible to adjust or change the functionality of the software through technical development. In this paper, we describe accommodating the method to summative use.", "spans": "[{\"corpusId\": 17451097, \"span\": \"[39]\", \"start\": 26, \"end\": 30}, {\"corpusId\": 16692796, \"span\": \"[21]\", \"start\": 87, \"end\": 91}, {\"corpusId\": 7481465, \"span\": \"18]\", \"start\": 184, \"end\": 187}, {\"corpusId\": 2013923, \"span\": \"this paper\", \"start\": 331, \"end\": 331}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "36341", "title": "We Need Numbers!: Heuristic Evaluation during Demonstrations (HED) for Measuring Usability in IT System Procurement", "sectionTitle": "INTRODUCTION", "text": "From the research perspective, HE may be considered an outdated, even obsolete, method that fosters little academic contribution. Over the years, HE has been extended to accommodate different purposes and situations (e.g. [48]). The increasing demands in public IT system procurement [29] of packaged/COTS (commercial-off-the-shelf) software, introduce new summative-type uses for this wellestablished, widely applied method. Moreover, COTS procurement is an understudied systems context [36]. Current and emerging procurement surroundings pose challenging new requirements for fitting methods to the context and applying them properly. Legislation on public procurement permits only decisions that are based on relevant objective criteria for choosing economically the most advantageous tender. This applies on both EU [12] as well as on the national level in Finland [17].", "spans": "[{\"corpusId\": 13792769, \"span\": \"[48]\", \"start\": 222, \"end\": 226}, {\"corpusId\": 5664499, \"span\": \"[29]\", \"start\": 284, \"end\": 288}, {\"corpusId\": 1066731, \"span\": \"[36]\", \"start\": 488, \"end\": 492}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "36342", "title": "We Need Numbers!: Heuristic Evaluation during Demonstrations (HED) for Measuring Usability in IT System Procurement", "sectionTitle": "INTRODUCTION", "text": "Public IT systems have a large-scale impact on a significant number of people. Therefore understandably, usability problems appear as a constant topic in national discussion, especially in the area of healthcare IT systems [50]. The role of users and user needs have been left to the background during the product development of packaged software [25]. Moreover, usability has not appeared as an explicit requirement, or target of evaluation in public procurement [29]. We expect this to change along with the changing regulation. Therefore, we propose new applicable practices for assessing usability during public IT system procurement of packaged software.", "spans": "[{\"corpusId\": 36612394, \"span\": \"[50]\", \"start\": 223, \"end\": 227}, {\"corpusId\": 10801668, \"span\": \"[25]\", \"start\": 347, \"end\": 351}, {\"corpusId\": 5664499, \"span\": \"[29]\", \"start\": 464, \"end\": 468}, {\"corpusId\": 2013923, \"span\": \"we propose\", \"start\": 552, \"end\": 552}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "36343", "title": "We Need Numbers!: Heuristic Evaluation during Demonstrations (HED) for Measuring Usability in IT System Procurement", "sectionTitle": "RESEARCH BACKGROUND", "text": "Healthcare has been identified as a domain for complex information systems [35]. Researchers have pointed out that there is a lack of appropriate usability evaluation methods [8,42]. In the context of clinical information systems, usability evaluation methods have been applied to guide further development (e.g. [27,32,40,41]). However, the evaluation has focused on a limited set of functionalities or parts of the system. The role of usability design and evaluation has not been established in social welfare domain [26].", "spans": "[{\"corpusId\": 1454913, \"span\": \"[8,\", \"start\": 175, \"end\": 178}, {\"corpusId\": 64100497, \"span\": \"42]\", \"start\": 178, \"end\": 181}, {\"corpusId\": 205285547, \"span\": \"[27,\", \"start\": 313, \"end\": 317}, {\"corpusId\": 19559533, \"span\": \"32,\", \"start\": 317, \"end\": 320}, {\"corpusId\": 8091916, \"span\": \"40,\", \"start\": 320, \"end\": 323}, {\"corpusId\": 18811560, \"span\": \"41]\", \"start\": 323, \"end\": 326}, {\"corpusId\": 167204987, \"span\": \"[26]\", \"start\": 519, \"end\": 523}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "36344", "title": "We Need Numbers!: Heuristic Evaluation during Demonstrations (HED) for Measuring Usability in IT System Procurement", "sectionTitle": "RESEARCH BACKGROUND", "text": "Some researchers have argued that public organizations do not emphasize and include usability in IT system procurement because they are not prepared to take the responsibility for it [28]. In regard to electronic health record (EHR) systems, these organizations have assumed that the responsibility lies on the vendor [15]. However, the high configurability of these systems could be used to improve usability [37], hence the customer organization should also take responsibility for the usability in the EHR system implementation [15].", "spans": "[{\"corpusId\": 115013011, \"span\": \"[28]\", \"start\": 183, \"end\": 187}, {\"corpusId\": 35767511, \"span\": \"[15]\", \"start\": 318, \"end\": 322}, {\"corpusId\": 14818267, \"span\": \"[37]\", \"start\": 410, \"end\": 414}, {\"corpusId\": 35767511, \"span\": \"[15]\", \"start\": 531, \"end\": 535}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "36345", "title": "We Need Numbers!: Heuristic Evaluation during Demonstrations (HED) for Measuring Usability in IT System Procurement", "sectionTitle": "RESEARCH BACKGROUND", "text": "The importance of usability requirements [5] and understanding human factors [46] in IT system procurement were first highlighted two decades ago. Indeed, recent research proves that usability criteria can be used in public IT procurement [43,49] although this has not yet become a standard procedure [29]. There are examples of such procedures in the field of healthcare [31,33] and usability tests are recommended as the primary evaluation method when purchasing a healthcare IT system [31,45]. However, studies give only an overview of rankings, but the used evaluation criteria [31,33], formulation of numerical results or justification behind rankings have not been described in detail. Also, user testing requires significant resources: testing five tasks for two different user groups on two competing systems has taken one month of effort [43].", "spans": "[{\"corpusId\": 17700973, \"span\": \"[46]\", \"start\": 77, \"end\": 81}, {\"corpusId\": 46408321, \"span\": \"[43,\", \"start\": 239, \"end\": 243}, {\"corpusId\": 777343, \"span\": \"49]\", \"start\": 243, \"end\": 246}, {\"corpusId\": 5664499, \"span\": \"[29]\", \"start\": 301, \"end\": 305}, {\"corpusId\": 14276042, \"span\": \"[31,\", \"start\": 372, \"end\": 376}, {\"corpusId\": 110925741, \"span\": \"33]\", \"start\": 376, \"end\": 379}, {\"corpusId\": 14276042, \"span\": \"[31,\", \"start\": 488, \"end\": 492}, {\"corpusId\": 14276042, \"span\": \"[31,\", \"start\": 582, \"end\": 586}, {\"corpusId\": 110925741, \"span\": \"33]\", \"start\": 586, \"end\": 589}, {\"corpusId\": 46408321, \"span\": \"[43]\", \"start\": 847, \"end\": 851}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "36346", "title": "We Need Numbers!: Heuristic Evaluation during Demonstrations (HED) for Measuring Usability in IT System Procurement", "sectionTitle": "RESEARCH BACKGROUND", "text": "HE has been criticized for limited inclusion of use context, a very limited set of evaluated user interfaces that need to be selected before evaluation and not being able to reveal major missing functionalities in the evaluation [9,38]. While usability testing has been devised also for summative purposes, one could argue that inspection methods like HE have been designed for formative use because they provide mainly qualitative data on the usability problems [14]. The current practice on measuring usability indeed heavily relies on usability tests while inspection methods are not discussed [24]. Attempts to quantify HE have been presented [20] for evaluating the degree of usability of websites. In this model heuristics are divided into categories and problems are categorized accordingly resulting in a calculated usability score.", "spans": "[{\"corpusId\": 207722373, \"span\": \"[9,\", \"start\": 229, \"end\": 232}, {\"corpusId\": 2615818, \"span\": \"[24]\", \"start\": 597, \"end\": 601}, {\"corpusId\": 45418779, \"span\": \"[20]\", \"start\": 647, \"end\": 651}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "36347", "title": "We Need Numbers!: Heuristic Evaluation during Demonstrations (HED) for Measuring Usability in IT System Procurement", "sectionTitle": "User Questionnaires", "text": "Three different questionnaires were applied for evaluating perceived usability: two short questionnaires during the breaks (six statements each, total 12 statements) and a summative questionnaire at the end of each user scenario (10 statements). The questionnaires' design utilized the established usability questionnaires, such as SUMI (Software Usability Measurement Inventory) [30], SUS (System Usability Scale) [4], and QUIS (Questionnaire for User Interaction Satisfaction) [9], as well as a tailored usability questionnaire for EHR systems [50]. None of the established questionnaires were suitable as is, because the questions were not to be answered based on experience of using the system but based on seeing the system being demonstrated.", "spans": "[{\"corpusId\": 107686571, \"span\": \"[4]\", \"start\": 415, \"end\": 418}, {\"corpusId\": 207722373, \"span\": \"[9]\", \"start\": 479, \"end\": 482}, {\"corpusId\": 36612394, \"span\": \"[50]\", \"start\": 546, \"end\": 550}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "36348", "title": "We Need Numbers!: Heuristic Evaluation during Demonstrations (HED) for Measuring Usability in IT System Procurement", "sectionTitle": "Relation to Similar Studies", "text": "Evaluating usability during IT procurement has not become an established practice. Heuristic evaluation has been suggested as a suitable method for preliminary evaluation and ranking of candidates [7,31,45]. However, we are not aware of literature describing how this should be done in a numeric and comparable way. The research on measuring usability concentrates on usability testing [24]. To our knowledge, HED is the first such method reported for IT procurement that also addresses the criticized shortcomings [9,38] of traditional heuristic evaluation.", "spans": "[{\"corpusId\": 18606918, \"span\": \"[7,\", \"start\": 197, \"end\": 200}, {\"corpusId\": 14276042, \"span\": \"31,\", \"start\": 200, \"end\": 203}, {\"corpusId\": 2615818, \"span\": \"[24]\", \"start\": 386, \"end\": 390}, {\"corpusId\": 207722373, \"span\": \"[9,\", \"start\": 515, \"end\": 518}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 9}
{"paperId": "af4db070898b1f04df40f7e850500b6adb26c30e", "title": "Tracking and Reporting Asthma Data for Children", "venue": "CSCW Companion", "year": 2019, "citationCount": 8, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3311957.3359480?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3311957.3359480, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Psychology", "Computer Science"], "publicationTypes": ["Book", "JournalArticle"], "publicationDate": "2019-11-09", "authors": [{"authorId": "1404338904", "name": "Nikhila Nyapathy"}, {"authorId": "1752048", "name": "R. Arriaga"}], "abstract": "Asthma is a common childhood chronic disease. There are various metrics of asthma which are tracked and reported to healthcare providers. We investigated visualizations & concepts for tracking quantitative and qualitative asthma data for pediatric patients. We conducted a 3-part study with 14 participants where we (1) interviewed 2 parents and 6 children about their health tracking behavior (2) tested visualization alternatives with 6 children (3) designed concepts to track qualitative data for future testing. Our study shows that simple visualizations can be comprehended by children, so the use of these to report data to the healthcare provider is a powerful tool not just for the parents but also pediatric patients. We iterated the design of the visualizations based on qualitative feedback.", "corpusId": "207957714", "paragraphs": [{"paragraphId": "11924", "title": "Tracking and Reporting Asthma Data for Children", "sectionTitle": "INTRODUCTION", "text": "Asthma is a common chronic respiratory disease among children which affects 8.3% of children below 18 years in the US, according to the Centers for Disease Control and Prevention (CDC) [1,2]. Tracking asthma related metrics is a significant part of asthma self-management, and this is offered as the main functionality in 79% of 38 reviewed mHealth applications for asthma [6]. Lefco et al. developed an mHealth asthma application which has limited tracking functionality as shown in Fig. 1 [4]. We set our research goal broadly as understanding how to improve the continuity of care for children with asthma. More specifically, given the huge gaps between doctor visits, we look into ways to alleviate the problem of tracking the large amount of data generated and communicating the tracked data effectively to the healthcare provider. We look into the use of visualizations for this purpose specifically for pediatric patients -to investigate whether they can comprehend them, and if so what kind of visualizations are easily understood by them.", "spans": "[{\"corpusId\": \"32968328\", \"span\": \"[6]\", \"start\": 373, \"end\": 376}, {\"corpusId\": \"4497693\", \"span\": \"[4]\", \"start\": 491, \"end\": 494}, {\"corpusId\": 207957714, \"span\": \"our research\", \"start\": 515, \"end\": 515}]", "conference": "cscw", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "11925", "title": "Tracking and Reporting Asthma Data for Children", "sectionTitle": "RELATED WORK", "text": "A lot of work has been done with respect to continuity of care for asthma patients. In a 2005 study by Yoos et al., 65% of parents whose children's current symptoms indicated severe asthma reported \"good control\" [8]. Tinschert et al. performed a review of all publicly available asthma management applications on the market and found tracking to be the most common feature functionality offered (79% offered some type of tracking related to asthma) [6]. The same paper suggests the use of virtual coaches, like chatbots to increase long-term engagement with asthma applications. While tools like the Asthma Control Test (ACT) and the Asthma Therapy Assessment Questionnaire (ATAQ) have been found to be reliable surrogates in measuring asthma [3,5], there is some level of difference in how these tools evaluate the same symptoms [7].", "spans": "[{\"corpusId\": \"32968328\", \"span\": \"[6]\", \"start\": 450, \"end\": 453}, {\"corpusId\": \"2854296\", \"span\": \"[3,\", \"start\": 744, \"end\": 747}, {\"corpusId\": \"33724322\", \"span\": \"[7]\", \"start\": 831, \"end\": 834}]", "conference": "cscw", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 2}
{"paperId": "e6f52716129165ef1c97da9f08de1644bed04cb2", "title": "Touch+Finger: Extending Touch-based User Interface Capabilities with \"Idle\" Finger Gestures in the Air", "venue": "ACM Symposium on User Interface Software and Technology", "year": 2018, "citationCount": 21, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3242587.3242651?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3242587.3242651, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2018-10-11", "authors": [{"authorId": "2970583", "name": "Hyunchul Lim"}, {"authorId": "3492407", "name": "Jungmin Chung"}, {"authorId": "145343073", "name": "Changhoon Oh"}, {"authorId": "2107931450", "name": "Sohyun Park"}, {"authorId": "1959755", "name": "Joonhwan Lee"}, {"authorId": "3994427", "name": "B. Suh"}], "abstract": "In this paper, we present Touch+Finger, a new interaction technique that augments touch input with multi-finger gestures for rich and expressive interaction. The main idea is that while one finger is engaged in a touch event, a user can leverage the remaining fingers, the \"idle\" fingers, to perform a variety of hand poses or in-air gestures to extend touch-based user interface capabilities. To fully understand the use of these idle fingers, we constructed a design space based on conventional touch gestures (i.e., single- and multi-touch gestures) and inter- action period (i.e., before and during touch). Considering the design space, we investigated the possible movement of the idle fingers and developed a total of 20 Touch+Finger gestures. Using ring-like devices to track the motion of the idle fingers in the air, we evaluated the Touch+Finger gestures on both recognition accuracy and ease of use. They were classified with a recognition accuracy of over 99% and received positive and negative comments from 8 participants. We suggested 8 interaction techniques with Touch+Finger gestures that demonstrate extended touch-based user interface capabilities.", "corpusId": "52982198", "paragraphs": [{"paragraphId": "40846", "title": "Touch+Finger: Extending Touch-based User Interface Capabilities with \"Idle\" Finger Gestures in the Air", "sectionTitle": "INTRODUCTION", "text": "Human fingers are remarkably dexterous, making touch-based user interfaces an intuitive and effective mode of primary input. Researchers and interaction designers have utilized the fingers to provide diverse touch interaction techniques, for example using touch duration (e.g., long-press), multiple touch points (e.g., multi-touch gestures [7,32]), and/or different types of Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.  (Center) When one primary finger is engaged in touch interaction, the rest of the secondary \"idle\" fingers (blue) are still but are able to move. We utilize these idle fingers to perform various hand poses before a touch or in-air gestures during a touch to add modality and expressiveness to the primary touch event: (a) opening a file by tapping with a \"Basic\" hand pose, (b) opening a context menu of the file by tapping with a \"Spread All\" hand pose, (c) deleting the touched object with the index finger by flicking with the thumb and (d) drawing a line with the index finger while controlling the width of the brush stroke by swiping up/down with the thumb. finger input (e.g., thumb's contact size [2] and different parts of a finger [11]) for a richer touch input vocabulary. However, the limited interaction space provided by two-dimensional (2D) touch interfaces falls significantly short of the rich gestural capabilities of human fingers.", "spans": "[{\"corpusId\": 49145783, \"span\": \"32]\", \"start\": 344, \"end\": 347}, {\"corpusId\": 52982198, \"span\": \"this work\", \"start\": 445, \"end\": 445}, {\"corpusId\": 52982198, \"span\": \"this work\", \"start\": 695, \"end\": 695}, {\"corpusId\": 52805854, \"span\": \"[2]\", \"start\": 1658, \"end\": 1661}, {\"corpusId\": 1991780, \"span\": \"[11]\", \"start\": 1694, \"end\": 1698}]", "conference": "uist", "year": 2018, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "40847", "title": "Touch+Finger: Extending Touch-based User Interface Capabilities with \"Idle\" Finger Gestures in the Air", "sectionTitle": "INTRODUCTION", "text": "To address this limitation, researchers have proposed techniques for extending input space. Some researchers have investigated possible alternative interaction spaces above [1,22], around [3,35], and on the back [26,34] of the device. This extended space enables a variety of multi-finger gestures beyond the touchscreen, providing far richer user interactions. More recently, others have explored combining touch with hand gestures [18,23,27,33] to offer more expressive in-Session 7: Sensing in the Small Scale UIST 2018, October 14-17, 2018, Berlin, Germany put than either of them alone. For instance, Air+Touch [5] and Ringteraction [9] augment touch events with thumb-based gestures above the screen.", "spans": "[{\"corpusId\": 13343165, \"span\": \"[1,\", \"start\": 173, \"end\": 176}, {\"corpusId\": 8997012, \"span\": \"22]\", \"start\": 176, \"end\": 179}, {\"corpusId\": 13162216, \"span\": \"[3,\", \"start\": 188, \"end\": 191}, {\"corpusId\": 13059539, \"span\": \"35]\", \"start\": 191, \"end\": 194}, {\"corpusId\": 15401798, \"span\": \"[26,\", \"start\": 212, \"end\": 216}, {\"corpusId\": 14284361, \"span\": \"34]\", \"start\": 216, \"end\": 219}, {\"corpusId\": 8765406, \"span\": \"[18,\", \"start\": 433, \"end\": 437}, {\"corpusId\": 1888117, \"span\": \"23,\", \"start\": 437, \"end\": 440}, {\"corpusId\": 14749958, \"span\": \"27,\", \"start\": 440, \"end\": 443}, {\"corpusId\": 2143984, \"span\": \"33]\", \"start\": 443, \"end\": 446}, {\"corpusId\": 14474047, \"span\": \"[5]\", \"start\": 616, \"end\": 619}, {\"corpusId\": 13321507, \"span\": \"[9]\", \"start\": 638, \"end\": 641}]", "conference": "uist", "year": 2018, "likelyRelatedWorkSection": false, "refCount": 12}, {"paragraphId": "40848", "title": "Touch+Finger: Extending Touch-based User Interface Capabilities with \"Idle\" Finger Gestures in the Air", "sectionTitle": "2D Touch Interaction with Fingers", "text": "Previous works have proposed different methods for extending the input vocabulary on touchscreens to incorporate the full dexterity of the human hand. For instance, the input modality of a touch event can be enhanced by utilizing extra dimensions of a finger. Boring et al. [2] used the thumb's contact radius as additional input modality to switch between input modes. TapSense [11] employs the diverse anatomy of human hand (e.g., tip, knuckle, and pad) to provide different interaction modes. Finger orientations [29,30] have also been used as an additional input parameter for touch. Furthermore, there have been a number of research efforts to enhance touch interaction using multiple fingers. Westerman et. al. [32] proposed multitouch gestures on a 2D screen, allowing users to achieve fine levels of control. In recent years, multi-touch interaction techniques have been improved with recognition technologies such as individual finger identification [6,19,29] and whole-hand gesture recognition [8,21]. However, the limited interaction space of 2D touch user interfaces falls significantly short of the rich gestural capabilities of human fingers.", "spans": "[{\"corpusId\": 52982198, \"span\": \"proposed different method\", \"start\": 45, \"end\": 45}, {\"corpusId\": 52805854, \"span\": \"[2]\", \"start\": 274, \"end\": 277}, {\"corpusId\": 1991780, \"span\": \"[11]\", \"start\": 379, \"end\": 383}, {\"corpusId\": 3075638, \"span\": \"[29,\", \"start\": 516, \"end\": 520}, {\"corpusId\": 18483144, \"span\": \"30]\", \"start\": 520, \"end\": 523}, {\"corpusId\": 49145783, \"span\": \"[32]\", \"start\": 717, \"end\": 721}, {\"corpusId\": 5946577, \"span\": \"19,\", \"start\": 962, \"end\": 965}, {\"corpusId\": 3075638, \"span\": \"29]\", \"start\": 965, \"end\": 968}, {\"corpusId\": 14694800, \"span\": \"[8,\", \"start\": 1004, \"end\": 1007}, {\"corpusId\": 16464685, \"span\": \"21]\", \"start\": 1007, \"end\": 1010}]", "conference": "uist", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "40849", "title": "Touch+Finger: Extending Touch-based User Interface Capabilities with \"Idle\" Finger Gestures in the Air", "sectionTitle": "Beyond On-Screen Interaction", "text": "To address the limitations of the 2D touch interaction space, researchers have investigated possible alternative interaction space above, around, and on the back of the devices. SideSight [3] provides virtual, multi-touch interactions around the body of a small mobile device, using infrared (IR) proximity sensors. SideSwipe [35] also leverages the unmodified global system for mobile communication (GSM) signal to enable in-air hand gestures above and at the side of a mobile device. Arefin Shimon et. al., [1] explored hand gestures above a smartwatch in order to overcome the limited interaction space of the small screen. More recently, hovering interactions above the screen [12] have been found to allow for richer and more expressive interactions by identifying the user's intention before a touch event occurs. Much research Session 7: Sensing in the Small Scale UIST 2018, October 14-17, 2018, Berlin, Germany has been conducted on using the back of a mobile device [26] or handheld device [34] as a possible input space. This extended space enables a variety of multi-finger gestures beyond the touchscreen, providing far richer interactions. However, expanding the interaction space beyond the touchscreen may sacrifice some of the benefits of direct-touch interactions (e.g., increased time for selecting a target and better performance in pointing tasks [16]). Therefore, we seek to combine touch and in-air gestures to maximize the benefits of modality and expressivity.", "spans": "[{\"corpusId\": 13162216, \"span\": \"[3]\", \"start\": 188, \"end\": 191}, {\"corpusId\": 13059539, \"span\": \"[35]\", \"start\": 326, \"end\": 330}, {\"corpusId\": 13343165, \"span\": \"[1]\", \"start\": 509, \"end\": 512}, {\"corpusId\": 15482351, \"span\": \"[12]\", \"start\": 681, \"end\": 685}, {\"corpusId\": 15401798, \"span\": \"[26]\", \"start\": 976, \"end\": 980}, {\"corpusId\": 14284361, \"span\": \"[34]\", \"start\": 1000, \"end\": 1004}, {\"corpusId\": 39553054, \"span\": \"[16]\", \"start\": 1368, \"end\": 1372}]", "conference": "uist", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "40850", "title": "Touch+Finger: Extending Touch-based User Interface Capabilities with \"Idle\" Finger Gestures in the Air", "sectionTitle": "Combining Touch and Gestures", "text": "More recent works have addressed the combination of touch and gestures in order to provide more expressive interactions. Marguardt et al. [22] proposed a unification of touch and gestures called the \"continuous interaction space\" on a digital surface. Also, TouchID [23] led to novel and expressive tabletop interaction techniques by identifying which hand and which part of the hand was touching the surface, as well as what posture and what gesture was being enacted with the fiduciarytagged glove. Similarly, Finger-Aware Shortcuts [36] employed finger, hand, and posture identification for keyboards to provide shortcut availability and expressivity. In this system, a key press can have multiple command mappings depending on which fingers and postures were used to press a key. Jackson et. al. [15] also extend multi-touch interfaces by using a combination of multi-touch gestures and 3D movements of the hand(s) above the surface. Furthermore, Kim et al. [18] and Song et al. [27] augmented touch events on mobile devices with finger gestures by using both hands. One hand controls a touch device, while the other hand performs gestures as an additional input. Conversely, Hinckley et. al. [13] explored interaction techniques with one hand for hand-held devices that leverage the combination of touch and motion, suggesting hybrid touch+motion gestures. In addition, Expressy [33], using only one hand, employed the movement of the wrist to add expressiveness to touch-based interactions. Air+Touch [5] focused on in-air gestures performed only with the thumb to enhance touch interaction while the same hand grasped the phone. Also, by using thumb-based touch gestures on capacitive touch sensors in a ring-like device, Ringteraction [9] presented thumb-index touch interaction, which allowed for enhanced input modalities on handheld devices.", "spans": "[{\"corpusId\": 8997012, \"span\": \"[22]\", \"start\": 138, \"end\": 142}, {\"corpusId\": 1888117, \"span\": \"[23]\", \"start\": 266, \"end\": 270}, {\"corpusId\": 6940072, \"span\": \"[36]\", \"start\": 535, \"end\": 539}, {\"corpusId\": 52982198, \"span\": \"this system\", \"start\": 669, \"end\": 669}, {\"corpusId\": 10364718, \"span\": \"[15]\", \"start\": 800, \"end\": 804}, {\"corpusId\": 8765406, \"span\": \"[18]\", \"start\": 962, \"end\": 966}, {\"corpusId\": 14749958, \"span\": \"[27]\", \"start\": 983, \"end\": 987}, {\"corpusId\": 1548961, \"span\": \"[13]\", \"start\": 1197, \"end\": 1201}, {\"corpusId\": 2143984, \"span\": \"[33]\", \"start\": 1384, \"end\": 1388}, {\"corpusId\": 14474047, \"span\": \"[5]\", \"start\": 1507, \"end\": 1510}, {\"corpusId\": 13321507, \"span\": \"[9]\", \"start\": 1743, \"end\": 1746}]", "conference": "uist", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 11}, {"paragraphId": "40851", "title": "Touch+Finger: Extending Touch-based User Interface Capabilities with \"Idle\" Finger Gestures in the Air", "sectionTitle": "Combining Touch and Gestures", "text": "Our work relates closely to Finger-Aware Shortcuts [36], in that it also employed the rest of the \"idle\" fingers to increase the input space. Nonetheless, we focus on touch-based devices rather than the keyboard. To the best of our knowledge, we are unaware of any existing work that enhances primary touch interaction by making full use of these \"idle\" fingers. Unlike previous work [5,9], which only focused on thumb-based gesture interaction techniques, our work has focused on exploring different input capabilities of the rest of the fingers to perform hand poses or in-air gestures as additional input for primary touch interaction. Our main focus is to investigate a variety of hand poses and in-air gestures performed by all secondary fingers, and to allow them to extend touch-based user interface capabilities, providing users with a richer input vocabulary for novel interaction.", "spans": "[{\"corpusId\": 52982198, \"span\": \"Our work\", \"start\": 8, \"end\": 8}, {\"corpusId\": 6940072, \"span\": \"[36]\", \"start\": 51, \"end\": 55}, {\"corpusId\": 14474047, \"span\": \"[5,\", \"start\": 384, \"end\": 387}, {\"corpusId\": 13321507, \"span\": \"9]\", \"start\": 387, \"end\": 389}, {\"corpusId\": 52982198, \"span\": \"our work\", \"start\": 465, \"end\": 465}, {\"corpusId\": 52982198, \"span\": \"Our main focus\", \"start\": 653, \"end\": 653}]", "conference": "uist", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "40852", "title": "Touch+Finger: Extending Touch-based User Interface Capabilities with \"Idle\" Finger Gestures in the Air", "sectionTitle": "DESIGN SPACE", "text": "The fundamental idea of the design space is to allow idle fingers, in various ways, to enhance conventional touch interactions. Based on prior work on touch gesture techniques [7,32] and touch interaction periods [5,33], the two main factors we considered in our design space were touch gesture and interaction period.", "spans": "[{\"corpusId\": 49145783, \"span\": \"32]\", \"start\": 179, \"end\": 182}, {\"corpusId\": 14474047, \"span\": \"[5,\", \"start\": 213, \"end\": 216}, {\"corpusId\": 2143984, \"span\": \"33]\", \"start\": 216, \"end\": 219}]", "conference": "uist", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "40853", "title": "Touch+Finger: Extending Touch-based User Interface Capabilities with \"Idle\" Finger Gestures in the Air", "sectionTitle": "A TOUCH+FINGER PROTOTYPE", "text": "In order to implement Touch+Finger gestures as new interaction techniques, it is necessary to track the motions of fingers in the air. Therefore, we built a Touch+Finger prototype to detect touch and in-air gestures. While there are a number of sensing techniques to track finger movements in the air (e.g., vision-based techniques [5,8] and capacitive sensors [12]), our prototype utilized two finger-worn devices with IMU sensors attached [24], which was simple, robust, and reliable enough for an initial exploration of Touch+Finger gestures. This setup was used for the demonstration of several interaction techniques with the gestures, spanning the outlined design space and demonstrating the viability of this approach. Figure 3 shows the prototype, which consists of two ringlike devices with IMU sensors attached, a touch-based device (in this case, a Samsung Galaxy Note 10.1 tablet), and a PC for data processing. The IMU sensor board included 9-axis inertial motion sensors (i.e., an accelerometer, a gyroscope, and a magnetometer), providing the three-axis data from these sensors, as well as yaw, pitch, and roll (maximum 100Hz output rate). The tablet provided the touch input information, such as the number of touch points (e.g., single touch or twofinger touch). The external PC received IMU sensor data through a flexible USB connection for finger tracking, and then sent the finger information to the tablet via a wireless network. The tethered flexbile USB made the ring-like devices less bulky by eliminating the need for a battery and a Wi-Fi module, which minimized any inconvenience to finger movements. ", "spans": "[{\"corpusId\": 14474047, \"span\": \"[5,\", \"start\": 332, \"end\": 335}, {\"corpusId\": 14694800, \"span\": \"8]\", \"start\": 335, \"end\": 337}, {\"corpusId\": 15482351, \"span\": \"[12]\", \"start\": 361, \"end\": 365}, {\"corpusId\": 52982198, \"span\": \"this approach\", \"start\": 724, \"end\": 724}]", "conference": "uist", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "40854", "title": "Touch+Finger: Extending Touch-based User Interface Capabilities with \"Idle\" Finger Gestures in the Air", "sectionTitle": "Secondary Finger Tracking", "text": "To track the motion of secondary fingers in the air, the ring-like device prototypes were worn on the thumb and the index finger. We collected data continuously from each IMU sensor board at a sampling rate of 50Hz for all Touch+Finger gestures ( Figure  2). Since secondary gestures, i.e. hand poses and in-air gestures, take about 0.4s to 0.9s to perform, a one-second sliding window was used for performing statistical feature extraction. Inspired by [31], we calculated four statistical features from the sliding window: mean, standard deviation, maximum, and minimum. The same calculation was performed for each sensor value, i.e. three-axis accelerometer, three-axis gyroscope, pitch, and roll. The yaw value was excluded due to its unreliability and a calibration issue [33]. In general, roll and pitch are important for recognizing hand poses. Accelerometer and gyroscope features are useful in capturing amplitude differences of in-air gestures. In order to reduce false positive errors in recognizing Touch+Finger gestures, we defined a touch event to initiate when the recognition system was activated. We did not choose to collect pre-sensing data because various hand poses can be instantly detected when a touch occurs. Also, such data could result in erroneous results due to the considerable variation of user gesture performance [27]. Furthermore, starting the system when a touch occurs helps the secondary fingers to avoid collision with unintentional finger movements. This is because the secondary fingers tend to be still unless triggered by the user's intention while the primary finger is touching the screen. Taking all of the above into consideration, we designed the classifier to be activated while a touchscreen detects a touch event.", "spans": "[{\"corpusId\": 11243658, \"span\": \"[31]\", \"start\": 454, \"end\": 458}, {\"corpusId\": 2143984, \"span\": \"[33]\", \"start\": 777, \"end\": 781}, {\"corpusId\": 14749958, \"span\": \"[27]\", \"start\": 1346, \"end\": 1350}]", "conference": "uist", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "40855", "title": "Touch+Finger: Extending Touch-based User Interface Capabilities with \"Idle\" Finger Gestures in the Air", "sectionTitle": "Enhanced Single Tap", "text": "As demonstrated in prior work [5,11,13,23], our technique shows that the tap with a \"Spread\" hand pose can activate the touch for selecting a file, while the tap with a \"Spread All\"", "spans": "[{\"corpusId\": 14474047, \"span\": \"[5,\", \"start\": 30, \"end\": 33}, {\"corpusId\": 1991780, \"span\": \"11,\", \"start\": 33, \"end\": 36}, {\"corpusId\": 1548961, \"span\": \"13,\", \"start\": 36, \"end\": 39}, {\"corpusId\": 1888117, \"span\": \"23]\", \"start\": 39, \"end\": 42}]", "conference": "uist", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "40856", "title": "Touch+Finger: Extending Touch-based User Interface Capabilities with \"Idle\" Finger Gestures in the Air", "sectionTitle": "DISCUSSION", "text": "Although the current prototype was sufficient for an initial exploration and evaluation of Touch+Finger gestures, there is still room for improvement. Since the ring-like devices were wired to an external PC, a smaller, self-contained form of the ring device is desired. We believe that it is conceivable to further miniaturize the device until it is a standalone wearable ring device like commercial products [14,20]. Nonetheless, our techniques require wearing multiple rings to track the motions of secondary fingers, which may be somewhat impractical for some users. This could be addressed in the future by exploring alternatives such as a depth camera [5,18] or capacitive sensors [17] to detect multiple finger movements. For example, the hover-sensing techniques used in [17] can track fingers up to 35mm above the screen, which might be applicable to some of the Touch+Finger gestures.", "spans": "[{\"corpusId\": 14474047, \"span\": \"[5,\", \"start\": 658, \"end\": 661}, {\"corpusId\": 8765406, \"span\": \"18]\", \"start\": 661, \"end\": 664}, {\"corpusId\": 2805755, \"span\": \"[17]\", \"start\": 687, \"end\": 691}, {\"corpusId\": 2805755, \"span\": \"[17]\", \"start\": 779, \"end\": 783}]", "conference": "uist", "year": 2018, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "40857", "title": "Touch+Finger: Extending Touch-based User Interface Capabilities with \"Idle\" Finger Gestures in the Air", "sectionTitle": "DISCUSSION", "text": "Our work has focused on exploring Touch+Finger gestures using the thumb and/or the index finger as primary fingers. We believe that more extensive Touch+Finger gestures can be developed by using a finger other than the index finger as the primary finger. For example, if a user touches a screen with the middle finger as the primary finger, the secondary fingers are the thumb, the index, the ring, and the little finger. The thumb Session 7: Sensing in the Small Scale UIST 2018, October 14-17, 2018, Berlin, Germany and the index finger are more independently movable since they have their own muscles for stretching [4,25]. Hence, the thumb and index finger can together perform a variety hand poses or in-air gestures, which we will explore in future work.", "spans": "[{\"corpusId\": 52982198, \"span\": \"Our work\", \"start\": 8, \"end\": 8}, {\"corpusId\": 720598, \"span\": \"[4,\", \"start\": 619, \"end\": 622}, {\"corpusId\": 8759604, \"span\": \"25]\", \"start\": 622, \"end\": 625}]", "conference": "uist", "year": 2018, "likelyRelatedWorkSection": false, "refCount": 3}], "paragraphCount": 12}
{"paperId": "76a134e245367d2a1d0fc35801a549d47ec98d0a", "title": "Few-Shot Emotion Recognition in Conversation with Sequential Prototypical Networks", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2021, "citationCount": 37, "openAccessPdf": {"url": "https://aclanthology.org/2021.emnlp-main.549.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2109.09366, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference", "Review"], "publicationDate": "2021-09-20", "authors": [{"authorId": "10669236", "name": "Ga\u00ebl Guibon"}, {"authorId": "1888443", "name": "Matthieu Labeau"}, {"authorId": "2121385846", "name": "H\u00e9l\u00e8ne Flamein"}, {"authorId": "2093661892", "name": "Luce Lefeuvre"}, {"authorId": "2049106", "name": "C. Clavel"}], "abstract": "Several recent studies on dyadic human-human interactions have been done on conversations without specific business objectives. However, many companies might benefit from studies dedicated to more precise environments such as after sales services or customer satisfaction surveys. In this work, we place ourselves in the scope of a live chat customer service in which we want to detect emotions and their evolution in the conversation flow. This context leads to multiple challenges that range from exploiting restricted, small and mostly unlabeled datasets to finding and adapting methods for such context. We tackle these challenges by using Few-Shot Learning while making the hypothesis it can serve conversational emotion classification for different languages and sparse labels. We contribute by proposing a variation of Prototypical Networks for sequence labeling in conversation that we name ProtoSeq. We test this method on two datasets with different languages: daily conversations in English and customer service chat conversations in French. When applied to emotion classification in conversations, our method proved to be competitive even when compared to other ones.", "corpusId": "237571504", "paragraphs": [{"paragraphId": "50532", "title": "Few-Shot Emotion Recognition in Conversation with Sequential Prototypical Networks", "sectionTitle": "Introduction", "text": "There has been a recent surge in research focusing on analyzing dyadic human to human interactions. Many of these studies (Poria et al., 2017;Zadeh et al., 2018a,b; focus on emotion recognition in conversations (ERC) taking into account multiple data modalities. Moreover, most of the progress made in ERC has been done without factoring in constraints corresponding to specific but prominent industrial applications, like customer service. This is partly due to studies focusing on using artificial datasets (Li et al., 2017;Busso et al., 2008) made of mock-up conversations to facilitate result replication and comparison. A few existing studies address customer service applications (Mundra et al., 2017;Yom-Tov et al., 2018;Maslowski et al., 2017) and show the difficulties to deal with such in-the-wild and domain-specific data.", "spans": "[{\"corpusId\": 23583643, \"span\": \"(Poria et al., 2017;\", \"start\": 122, \"end\": 142}, {\"corpusId\": 12231974, \"span\": \"(Mundra et al., 2017;\", \"start\": 686, \"end\": 707}, {\"corpusId\": 20384983, \"span\": \"Maslowski et al., 2017)\", \"start\": 728, \"end\": 751}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "50533", "title": "Few-Shot Emotion Recognition in Conversation with Sequential Prototypical Networks", "sectionTitle": "Related Work", "text": "Emotion Recognition in Conversations In recent years, the widening scope of emotion detection tasks led to the rise of another sub-topic: detecting emotions in conversations. This research topic, commonly referred to as ERC, gained popularity when Poria et al. (2017) first applied recurrent neural networks (RNN) (Jordan, 1997) to multi-modal emotion recognition in conversations. This led to many improvements (Zadeh et al., 2018a,b;Hazarika et al., 2018;. Among those,  used 3 Gated Recurrent Units (GRU) (Cho et al., 2014) units, one for each context representation target (speaker, utterance, emotion). Studies on ERC applied to text followed, mainly built on an artificial conversation dataset named DailyDialog (Li et al., 2017). (Zhong et al., 2019) incorporated a knowledge base into the network using context-aware attention and hierarchical self-attention using Transformers (Vaswani et al., 2017). Ghosal et al. (2019) uses graph neural networks to deal with context propagation limitations. These approaches in ERC consider the conversational context surrounding the current utterance; on the other hand, some recent studies consider it as a sequence and tackled ERC through a sequence labeling task . We follow this last approach and consider the ERC task as a sequence labeling task. However, these supervised approaches are difficult to use, as it is hard to find a sufficient amount of conversations labeled with emotions. Hence, in this paper, we approach ERC as a few-shot learning problem. -Shot Learning FSL (Miller et al., 2000;Fei-Fei et al., 2006;Lake, 2015) is suitable to tackle this data limitation. It aims at generaliz-ing faster, leading to a lower dependency on data quantity. It is mainly set up through episodic composition (Ravi and Larochelle, 2016) which recreates the few-shot learning setting by working with small training episodes. Several learning methods are based on metric-learning: Siamese Networks, which share some weights, are used to learn a metric between examples (Koch et al., 2015). Matching Networks (Vinyals et al., 2017) use the training examples to find the weighted nearest neighbors (Vinyals et al., 2017). Prototypical Networks Snell et al. (2017) consider averaged class representations from the training examples and a cosine distance to compare the elements to these class representations. Relation networks replace the Euclidean by the deep neural network which aims at training a distance metric (Sung et al., 2018). In this work, we consider approaches based on Prototypical Networks. As Al-Shedivat et al. (2021) recently showed it, such approaches are the most efficient when working with a low amount of training samples. Many variants have been proposed, on different tasks and topics such as relation classification in text (Gao et al., 2019;Hui et al., 2020;Ren et al., 2020), sentiment classification in Amazon comments (Bao et al., 2020), named entity recognition (Fritzler et al., 2019;Hou et al., 2020;Perl et al., 2020;Safranchik et al., 2020), or even speech classification in conversation (Koluguri et al., 2020). This surge of interest on applying few-shot learning to these topics can be attributed to specific datasets, such as Few-Rel (Han et al., 2018) for relation classification. While ERC is mainly considered in a fully supervised learning setting, we intend to view it as a few-shot learning sequence labeling class. In this paper, we propose the first few-shot learning approach on ERC using sequence labeling through adapting Prototypical Networks. We compare our method to the original Prototypical Networks (Snell et al., 2017) and to a variant dedicated to named entity recognition (Fritzler et al., 2019) that is easily applicable to our task.", "spans": "[{\"corpusId\": 237571504, \"span\": \"This research\", \"start\": 188, \"end\": 188}, {\"corpusId\": 23583643, \"span\": \"Poria et al. (2017)\", \"start\": 248, \"end\": 267}, {\"corpusId\": 44164810, \"span\": \"Hazarika et al., 2018;\", \"start\": 435, \"end\": 457}, {\"corpusId\": 13756489, \"span\": \"(Vaswani et al., 2017)\", \"start\": 886, \"end\": 908}, {\"corpusId\": 201698197, \"span\": \"Ghosal et al. (2019)\", \"start\": 910, \"end\": 930}, {\"corpusId\": 237571504, \"span\": \"this last approach\", \"start\": 1243, \"end\": 1243}, {\"corpusId\": 237571504, \"span\": \"this paper\", \"start\": 1460, \"end\": 1460}, {\"corpusId\": 309759, \"span\": \"Snell et al. (2017)\", \"start\": 2188, \"end\": 2207}, {\"corpusId\": 4412459, \"span\": \"(Sung et al., 2018)\", \"start\": 2461, \"end\": 2480}, {\"corpusId\": 237571504, \"span\": \"this work\", \"start\": 2494, \"end\": 2494}, {\"corpusId\": 57398573, \"span\": \"(Gao et al., 2019;\", \"start\": 2795, \"end\": 2813}, {\"corpusId\": 219971238, \"span\": \"Hui et al., 2020;\", \"start\": 2813, \"end\": 2830}, {\"corpusId\": 227230475, \"span\": \"Ren et al., 2020)\", \"start\": 2830, \"end\": 2847}, {\"corpusId\": 201058594, \"span\": \"(Bao et al., 2020)\", \"start\": 2893, \"end\": 2911}, {\"corpusId\": 56482394, \"span\": \"(Fritzler et al., 2019;\", \"start\": 2938, \"end\": 2961}, {\"corpusId\": 220047102, \"span\": \"Perl et al., 2020;\", \"start\": 2978, \"end\": 2996}, {\"corpusId\": 211842725, \"span\": \"Safranchik et al., 2020)\", \"start\": 2996, \"end\": 3020}, {\"corpusId\": 237571504, \"span\": \"this paper\", \"start\": 3419, \"end\": 3419}, {\"corpusId\": 237571504, \"span\": \"we propose\", \"start\": 3431, \"end\": 3431}, {\"corpusId\": 237571504, \"span\": \"our method\", \"start\": 3561, \"end\": 3561}, {\"corpusId\": 309759, \"span\": \"(Snell et al., 2017)\", \"start\": 3600, \"end\": 3620}, {\"corpusId\": 56482394, \"span\": \"(Fritzler et al., 2019)\", \"start\": 3676, \"end\": 3699}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 14}, {"paragraphId": "50534", "title": "Few-Shot Emotion Recognition in Conversation with Sequential Prototypical Networks", "sectionTitle": "Results", "text": "Comparison to supervised learning DailyDialog is used to compare our FSL approach with recent supervised learning results on ERC. As expected, our best FSL model, ProtoSeq, yields lesser performance than supervised approaches. The latter presuppose the availability of a sufficiently large amount of annotated data and their performance thus represents the upper bound of the expected results. More precisely, we focus on the difference between ProtoSeq with a state-of-the-art supervised model, CESTa , which is computation-heavy. Indeed, CESTa is a contextualized emotion sequence tagging model which considers the fusion of a combination of a transformer and BiLSTM as the global context encoder with a recurrent individual context encoder before feeding a CRF layer. CESTa achieves 63% in micro F1-score in a fully supervised learning approach. ProtoSeq, much lighter, achieves a 31% micro F1 score, demonstrating the potential of FSL for sequence labeling when available data is scarce, especially when many supervised approaches obtained F1-scores around 50%. While using the Live Chat Customer Service dataset, we only change the initial embeddings from English to French, and apply the two best models according to 3: CESTa and KET (Zhong et al., 2019). The CESTa implementation yielded inconclusive results 6 , this is why we present the KET results on our specific corpus in Table 4. KET relies on ConceptNet (Speer et al., 2017), a multilingual knowledge base. Thus, we only switch from GloVe embeddings (Pennington et al., 2014) to French FastText ones in order to ensure comparison with our ProtoSeq model. As expected, performance is lower on the Live Chat Customer Service corpus.", "spans": "[{\"corpusId\": 237571504, \"span\": \"our FSL approach\", \"start\": 81, \"end\": 81}, {\"corpusId\": 15206880, \"span\": \"(Speer et al., 2017)\", \"start\": 1419, \"end\": 1439}, {\"corpusId\": 1957433, \"span\": \"(Pennington et al., 2014)\", \"start\": 1515, \"end\": 1540}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 3}
{"paperId": "02675c7581b1b919be4881f8ddf3855c46e8ead9", "title": "Examining and Enhancing the Illusory Touch Perception in Virtual Reality Using Non-Invasive Brain Stimulation", "venue": "International Conference on Human Factors in Computing Systems", "year": 2019, "citationCount": 17, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3290605.3300477?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3290605.3300477, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science", "Psychology"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2019-05-02", "authors": [{"authorId": "1928442", "name": "Filip \u0160kola"}, {"authorId": "1695331", "name": "F. Liarokapis"}], "abstract": "Virtual reality (VR) can be immersive to such a degree that users sometimes report feeling tactile sensations based on visualization of the touch, without any actual physical contact. This effect is not only interesting for studies of human perception, but can also be leveraged to improve the quality of VR by evoking tactile sensations without usage of specialized equipment. The aim of this paper is to study brain processing of the illusory touch and its enhancement for purposes of exploitation in VR scene design. To amplify the illusory touch, transcranial direct current stimulation (tDCS) was used. Participants attended two sessions with blinded stimulation and interacted with a virtual ball using tracked hands in VR. The effects were studied using electroencephalography (EEG), that allowed us to examine stimulation-induced changes in processing of the illusory touch in the brain, as well as to identify its neural correlates. Results confirm enhanced processing of the illusory touch after the stimulation, and some of these changes were correlated to subjective rating of its magnitude.", "corpusId": "140238432", "paragraphs": [{"paragraphId": "41179", "title": "Examining and Enhancing the Illusory Touch Perception in Virtual Reality Using Non-Invasive Brain Stimulation", "sectionTitle": "INTRODUCTION", "text": "Implementing touch into virtual reality (VR) is not always a straightforward task. VR scenes are mostly being perfected and examined in the visual domain, but engagement of other senses is also highly favorable for the design of immersive VR experiences. Classic approach to sense stimulation in VR consists of attaching a display to the relevant sensing organ [30]. Although this is effective for stimulation of vision and hearing (senses with relatively small sensing organs), it is much more difficult problem to stimulate the surface of the skin, the largest organ on the human body [8]. Recently, alternative approaches to haptic interfaces emerged, including electrical muscle stimulation [34,35]. This paper investigates non-invasive stimulation of central nervous system, the brain, to facilitate synthetic tactile experiences.", "spans": "[{\"corpusId\": 16783458, \"span\": \"[8]\", \"start\": 587, \"end\": 590}, {\"corpusId\": 17306724, \"span\": \"[34,\", \"start\": 695, \"end\": 699}, {\"corpusId\": 11531061, \"span\": \"35]\", \"start\": 699, \"end\": 702}, {\"corpusId\": 140238432, \"span\": \"This paper\", \"start\": 714, \"end\": 714}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "41180", "title": "Examining and Enhancing the Illusory Touch Perception in Virtual Reality Using Non-Invasive Brain Stimulation", "sectionTitle": "INTRODUCTION", "text": "One reason why this phenomenon occurs is the dominance of the visual perception over other senses -visual information can override the information coming from the other senses [23]. To a great degree, current VR systems, being predominantly visual, depend on this effect. The second reason for emergence of the illusory touch is the way how the human brain constructs bodily representation. Information from the senses are integrated in the brain to form plausible (internally consistent) representation of own body [24]. It has been revealed that the multisensory integration process can be manipulated to create altered perception of the self. One of the earliest experiments demonstrating malleability of the bodily representation is known as the rubber hand illusion [6]. In the rubber hand illusion, simultaneous haptic stimulation of a participant's hand (hidden behind a screen) and a rubber hand placed ahead of the participant (in a natural resting position) leads to rising of feelings that the rubber hand is actually part of the participant's body, and the tactile sensations seem to be originating in the rubber hand.", "spans": "[{\"corpusId\": 16730649, \"span\": \"[23]\", \"start\": 176, \"end\": 180}, {\"corpusId\": 141049077, \"span\": \"[24]\", \"start\": 516, \"end\": 520}, {\"corpusId\": 205024516, \"span\": \"[6]\", \"start\": 771, \"end\": 774}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "41181", "title": "Examining and Enhancing the Illusory Touch Perception in Virtual Reality Using Non-Invasive Brain Stimulation", "sectionTitle": "INTRODUCTION", "text": "VR is an ideal playground for the body ownership illusions (see, e.g., [7,51,55,61]). The current study leverages natural emergence of the sense of ownership and sense of agency in the virtual environments, i.e., feelings that the users own their virtual body or body parts and that they are the agents of actions of such virtual body. Using state-of-the-art VR (with a head-mounted display and accurate hand tracking), two VR scenes where participants experienced the illusory touch were created. In the active scene, participants actively touched a virtual object (ball) using their bare hands. On the contrary, the passive scene allowed participants to experience the illusory touch without actively moving their hands.", "spans": "[{\"corpusId\": 16927851, \"span\": \"[7,\", \"start\": 71, \"end\": 74}, {\"corpusId\": 9247470, \"span\": \"51,\", \"start\": 74, \"end\": 77}, {\"corpusId\": 6332619, \"span\": \"55,\", \"start\": 77, \"end\": 80}, {\"corpusId\": 16188885, \"span\": \"61]\", \"start\": 80, \"end\": 83}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "41182", "title": "Examining and Enhancing the Illusory Touch Perception in Virtual Reality Using Non-Invasive Brain Stimulation", "sectionTitle": "INTRODUCTION", "text": "Manipulation of the illusory touch was performed using transcranial direct current stimulation (tDCS). This noninvasive brain stimulation technique has been used for clinical purposes as well as by hobbyists, with the main goal being usually enhancements in cognition and learning [17]. In this study, we examined processing of the illusory touch by the brain using evaluation of event-related potentials (ERPs), evoked by seeing the hand colliding with the virtual object. ERP analysis is a standard technique for analysis of electroencephalography (EEG) data, examining electrical brain response to a sensory, cognitive, or motor events [3].", "spans": "[{\"corpusId\": 205063689, \"span\": \"[17]\", \"start\": 281, \"end\": 285}, {\"corpusId\": 140238432, \"span\": \"this study\", \"start\": 300, \"end\": 300}, {\"corpusId\": 29329322, \"span\": \"[3]\", \"start\": 639, \"end\": 642}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "41183", "title": "Examining and Enhancing the Illusory Touch Perception in Virtual Reality Using Non-Invasive Brain Stimulation", "sectionTitle": "Tactile consciousness and imagery", "text": "Conscious processing of a tactile stimulus is different from the conscious processing of other sensory modalities. In conclusion of their literature research on tactile consciousness, Gallace and Spence (2008) [18] claim that conscious perception of touch is inseparably dependent on the processing of more general (specifically, spatial) information in the brain. Tactile perception is largely dependent on the integration of information from multiple senses. This is in line with the study discovering that observing a video with a hand being touched during the reception of tactile stimuli on own hand enhances the sensory threshold [53]. Moreover, just observing touch on other human body can be 'felt'. In [28], it was found that touch observation activates the somatosensory areas in the brain. Indeed, humans posses such 'tactile empathy' that allows them to experience illusory tactile sensations while seeing other persons being touched. Interestingly, this ability can become over-active in some individuals, resulting in visually-induced tactile synaesthesia [4].", "spans": "[{\"corpusId\": 20909139, \"span\": \"Gallace and Spence (2008)\", \"start\": 184, \"end\": 209}, {\"corpusId\": 20909139, \"span\": \"[18]\", \"start\": 210, \"end\": 214}, {\"corpusId\": 13390769, \"span\": \"[53]\", \"start\": 636, \"end\": 640}, {\"corpusId\": 1414735, \"span\": \"[28]\", \"start\": 711, \"end\": 715}, {\"corpusId\": 3002731, \"span\": \"[4]\", \"start\": 1070, \"end\": 1073}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "41184", "title": "Examining and Enhancing the Illusory Touch Perception in Virtual Reality Using Non-Invasive Brain Stimulation", "sectionTitle": "Visually induced touch", "text": "The sensitivity to feel touch increases even after mere presentation of conflicting sensory cues -when the touch is seen, but no tactile stimulus is generated [49], thus in case coinciding with the experimental condition of this study. Finally, in the experiment with total of 220 participants, it was confirmed that a beam of laser light can be 'felt' on a fake hand [13]. This case was reported by 66% of 100 participants in the laser group -and not only tactile, but even thermal sensations were reported. Again, the rubber hand illusion set-up was exploited in this experiment.", "spans": "[{\"corpusId\": 21730724, \"span\": \"[49]\", \"start\": 159, \"end\": 163}, {\"corpusId\": 140238432, \"span\": \"this study\", \"start\": 234, \"end\": 234}, {\"corpusId\": 590798, \"span\": \"[13]\", \"start\": 368, \"end\": 372}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "41185", "title": "Examining and Enhancing the Illusory Touch Perception in Virtual Reality Using Non-Invasive Brain Stimulation", "sectionTitle": "Neural correlates of tactile imagery", "text": "As is the case in other sensory modalities, imagined touch produces significant neural correlates (in terms of neurophysiological signal in EEG and blood flow response in functional magnetic resonance imaging, fMRI). Tactile imagery was studied using EEG by Uhl et al. (1994) [58], who found the contralateral parietal cortex to be associated with processing of the tactile imagery. Their results were confirmed in another EEG study [16], examining the neural origins of imagery in visual, audial, and tactile domain. Finally, Yoo et al. (2003) [65] confirmed these findings using fMRI as well, observing mainly activations of contralateral somatosensory cortices during the tactile imagery, together with activations in the left parietal lobe.", "spans": "[{\"corpusId\": 4541031, \"span\": \"Uhl et al. (1994)\", \"start\": 258, \"end\": 275}, {\"corpusId\": 4541031, \"span\": \"[58]\", \"start\": 276, \"end\": 280}, {\"corpusId\": 12037610, \"span\": \"[16]\", \"start\": 433, \"end\": 437}, {\"corpusId\": 40971701, \"span\": \"Yoo et al. (2003)\", \"start\": 527, \"end\": 544}, {\"corpusId\": 40971701, \"span\": \"[65]\", \"start\": 545, \"end\": 549}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "41186", "title": "Examining and Enhancing the Illusory Touch Perception in Virtual Reality Using Non-Invasive Brain Stimulation", "sectionTitle": "NON-INVASIVE ELECTRICAL BRAIN", "text": "Two electrodes must be set up for tDCS. Correct positioning of the active and return electrode is crucial to achieve the desired effects. Nitsche and Paulus (2000) [44] experimented with various scalp locations for the active and return electrode for experiments including hand motor cortex. Optimal anode location was found to be over the hand motor cortex location (C3/C4 positions according to the international 10-20 EEG electrode placement system [27]) and the return electrode location should be placed over the contralateral supraorbital location (corresponds to the AF4/3 locations; see Figure 1). Evaluation using transcranial magnetic stimulation showed an increased cortical excitability by up to 40%. Later, the same authors studied relation of the stimulation length to the length of its effects [45]. Following 5-and 7minute long tDCS session, the increased motor responses returned to the baseline after couple of minutes; using 9-to 13-minute long stimulation, the effect lasted for up to 1.5 hours. Current of 1 mA was delivered during the stimulation in these studies, and 1-2 mA are typical currents in the studies using tDCS [64].", "spans": "[{\"corpusId\": 42370334, \"span\": \"Nitsche and Paulus (2000)\", \"start\": 138, \"end\": 163}, {\"corpusId\": 42370334, \"span\": \"[44]\", \"start\": 164, \"end\": 168}, {\"corpusId\": 12529212, \"span\": \"[27]\", \"start\": 452, \"end\": 456}, {\"corpusId\": 13431042, \"span\": \"[45]\", \"start\": 809, \"end\": 813}, {\"corpusId\": 3831514, \"span\": \"[64]\", \"start\": 1145, \"end\": 1149}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "41187", "title": "Examining and Enhancing the Illusory Touch Perception in Virtual Reality Using Non-Invasive Brain Stimulation", "sectionTitle": "NON-INVASIVE ELECTRICAL BRAIN", "text": "Both anodal and cathodal tDCS stimulation of the hand motor cortex was studied in the last two decades. Participants (N = 34) receiving anodal stimulation showed improved motor learning [46]. Increases in the motor function of the non-dominant hand after 20 minute anodal stimulation was achieved [5]. Interestingly, this effect was not reached in the dominant hands of the participants. Tactile perception abilities were decreased after cathodal tDCS stimulation (7minute, 1 mA) [50] (anodal stimulation did not increase the tactile perception in this study). Cathodal tDCS was studied even for acute pain perception [1]. Subjective pain rating scores and N100, N200, and P200 components were evaluated after acute painful stimulation of the hand. Contralateral N200 component and subjective pain perception showed to be decreased in the experiment, with no effect of anodal and sham conditions. Similar results were obtained later for cold detection threshold [21].", "spans": "[{\"corpusId\": 11640133, \"span\": \"[46]\", \"start\": 186, \"end\": 190}, {\"corpusId\": 2629773, \"span\": \"[5]\", \"start\": 297, \"end\": 300}, {\"corpusId\": 27566693, \"span\": \"[50]\", \"start\": 480, \"end\": 484}, {\"corpusId\": 140238432, \"span\": \"this study\", \"start\": 558, \"end\": 558}, {\"corpusId\": 11568887, \"span\": \"[1]\", \"start\": 618, \"end\": 621}, {\"corpusId\": 206354430, \"span\": \"[21]\", \"start\": 962, \"end\": 966}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "41188", "title": "Examining and Enhancing the Illusory Touch Perception in Virtual Reality Using Non-Invasive Brain Stimulation", "sectionTitle": "NON-INVASIVE ELECTRICAL BRAIN", "text": "SEPs elicited by electrical stimulation of the right median nerve (peripheral nerve stimulation was used to elicit SEPs rather than physical manipulation with the arm) significantly increased after anodal tDCS in the work of Matsunaga et al. (2004) [37]. Cathodal tDCS did not have an effect on SEPs. The effect lasted for 1 hour after 10-minute stimulation with 1 mA. Using fMRI, altered response to the tactile stimulation of foot after anodal tDCS was confirmed in terms of the hemodynamic response [62]. In 2014, a meta-analysis study on the sensory and pain perception changes following anodal tDCS was conducted [59], concluding that anodal tDCS of the primary motor cortex increases pain and sensory threshold in healthy individuals. However, the authors acknowledge the number of participants was low in some of the analyzed studies and warn the readers before interpreting the results. All the channels except for AF3 and AF4 were used for the EEG recording (white and semi-white background). For right hand stimulation, C3 was the anode and AF4 the return electrode (yellow). For left hand stimulation, C4 was the anode and AF3 the return electrode (green).", "spans": "[{\"corpusId\": 24630548, \"span\": \"Matsunaga et al. (2004)\", \"start\": 225, \"end\": 248}, {\"corpusId\": 24630548, \"span\": \"[37]\", \"start\": 249, \"end\": 253}, {\"corpusId\": 3029649, \"span\": \"[62]\", \"start\": 502, \"end\": 506}, {\"corpusId\": 353320, \"span\": \"[59]\", \"start\": 618, \"end\": 622}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "41189", "title": "Examining and Enhancing the Illusory Touch Perception in Virtual Reality Using Non-Invasive Brain Stimulation", "sectionTitle": "Stimulation", "text": "We used Neuroelectrics Starstim 8 [42] for the tDCS. Stimulation was performed using a pair of saline-soaked circular sponge electrodes with the area of 25 cm 2 . Anode was placed at the motor cortex of the dominant hand, at C3/C4 electrode (according to the 10-20 international system) contralateral to the dominant hand (the dominant hand was assessed using questionnaire). Cathode was placed on the forehead (AF7/8 position) ipsilateral to the dominant hand, contralateral to the anode (see Figure 1) 1 . Stimulation took 15 minutes with 3 seconds ramp-up and ramp-down (ramp-up and ramp-down denotes the time to reach the full stimulation power in the beginning of the process and vice versa), stimulating current was 1 mA. Parameters of the stimulation are based on previous studies [15,37,44,45,50], Section 3 provides more details. The sham protocol consisted of 3 seconds of rampup and ramp-down only, the rest of the set-up being the same as in the stimulation sessions, to not compromise the  blinding. In both sessions, electrodes for both dominant and non-dominant hand were positioned into the cap, so the participants could not make any deductions regarding the stimulation set-up.", "spans": "[{\"corpusId\": 43683810, \"span\": \"[15,\", \"start\": 788, \"end\": 792}, {\"corpusId\": 24630548, \"span\": \"37,\", \"start\": 792, \"end\": 795}, {\"corpusId\": 42370334, \"span\": \"44,\", \"start\": 795, \"end\": 798}, {\"corpusId\": 13431042, \"span\": \"45,\", \"start\": 798, \"end\": 801}, {\"corpusId\": 27566693, \"span\": \"50]\", \"start\": 801, \"end\": 804}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 5}], "paragraphCount": 11}
{"paperId": "667d4bedc542f69f06812bb68335c8d559064d44", "title": "Word and Document Embedding with vMF-Mixture Priors on Context Word Vectors", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2019, "citationCount": 5, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/P19-1321.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://aclanthology.org/P19-1321, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2019-07-01", "authors": [{"authorId": "38797620", "name": "Shoaib Jameel"}, {"authorId": "2265382", "name": "S. Schockaert"}], "abstract": "Word embedding models typically learn two types of vectors: target word vectors and context word vectors. These vectors are normally learned such that they are predictive of some word co-occurrence statistic, but they are otherwise unconstrained. However, the words from a given language can be organized in various natural groupings, such as syntactic word classes (e.g. nouns, adjectives, verbs) and semantic themes (e.g. sports, politics, sentiment). Our hypothesis in this paper is that embedding models can be improved by explicitly imposing a cluster structure on the set of context word vectors. To this end, our model relies on the assumption that context word vectors are drawn from a mixture of von Mises-Fisher (vMF) distributions, where the parameters of this mixture distribution are jointly optimized with the word vectors. We show that this results in word vectors which are qualitatively different from those obtained with existing word embedding models. We furthermore show that our embedding model can also be used to learn high-quality document representations.", "corpusId": "196187445", "paragraphs": [{"paragraphId": "60432", "title": "Word and Document Embedding with vMF-Mixture Priors on Context Word Vectors", "sectionTitle": "Introduction", "text": "Word embedding models are aimed at learning vector representations of word meaning (Mikolov et al., 2013b;Pennington et al., 2014;Bojanowski et al., 2017). These representations are primarily learned from co-occurrence statistics, where two words are represented by similar vectors if they tend to occur in similar linguistic contexts. Most models, such as Skip-gram (Mikolov et al., 2013b) and GloVe (Pennington et al., 2014) learn two different vector representations w andw for each word w, which we will refer to as the target word vector and the context word vector respectively. Apart from the constraint that w i \u00b7w j should reflect how often words w i and w j co-occur, these vectors are typically unconstrained.", "spans": "[{\"corpusId\": 16447573, \"span\": \"(Mikolov et al., 2013b;\", \"start\": 83, \"end\": 106}, {\"corpusId\": 1957433, \"span\": \"Pennington et al., 2014;\", \"start\": 106, \"end\": 130}, {\"corpusId\": 207556454, \"span\": \"Bojanowski et al., 2017)\", \"start\": 130, \"end\": 154}, {\"corpusId\": 16447573, \"span\": \"(Mikolov et al., 2013b)\", \"start\": 367, \"end\": 390}, {\"corpusId\": 1957433, \"span\": \"(Pennington et al., 2014)\", \"start\": 401, \"end\": 426}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "60433", "title": "Word and Document Embedding with vMF-Mixture Priors on Context Word Vectors", "sectionTitle": "Introduction", "text": "As was shown in (Mu et al., 2018), after performing a particular linear transformation, the angular distribution of the word vectors that are obtained by standard models is essentially uniform. This isotropy property is convenient for studying word embeddings from a theoretical point of view (Arora et al., 2016), but it sits at odds with fact that words can be organised in various natural groupings. For instance, we might perhaps expect that words from the same part-of-speech class should be clustered together in the word embedding. Similarly, we might expect that organising word vectors in clusters that represent semantic themes would also be beneficial. In fact, a number of approaches have already been proposed that use external knowledge for imposing such a cluster structure, capturing the intuition that words which belong to the same category should be represented by similar vectors (Xu et al., 2014;Guo et al., 2015;Hu et al., 2015;Li et al., 2016c) or be located in a low-dimensional subspace (Jameel and Schockaert, 2016). Such models tend to outperform standard word embedding models, but it is unclear whether this is only because they can take advantage of external knowledge, or whether imposing a cluster structure on the word vectors is itself also inherently useful.", "spans": "[{\"corpusId\": 3986339, \"span\": \"(Mu et al., 2018)\", \"start\": 16, \"end\": 33}, {\"corpusId\": 12744871, \"span\": \"(Arora et al., 2016)\", \"start\": 293, \"end\": 313}, {\"corpusId\": 2177534, \"span\": \"(Xu et al., 2014;\", \"start\": 900, \"end\": 917}, {\"corpusId\": 205692, \"span\": \"Guo et al., 2015;\", \"start\": 917, \"end\": 934}, {\"corpusId\": 10759252, \"span\": \"Hu et al., 2015;\", \"start\": 934, \"end\": 950}, {\"corpusId\": 1353980, \"span\": \"Li et al., 2016c)\", \"start\": 950, \"end\": 967}, {\"corpusId\": 16066021, \"span\": \"(Jameel and Schockaert, 2016)\", \"start\": 1012, \"end\": 1041}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 7}, {"paragraphId": "60434", "title": "Word and Document Embedding with vMF-Mixture Priors on Context Word Vectors", "sectionTitle": "Related Work", "text": "A large number of works have proposed techniques for improving word embeddings based on external lexical knowledge. Many of these approaches are focused on external knowledge about word similarity (Yu and Dredze, 2014;Faruqui et al., 2015;Mrksic et al., 2016), although some approaches for incorporating categorical knowledge have been studied as well, as already mentioned in the introduction. What is different about our approach is that we do not rely on any external knowledge. We essentially impose the constraint that some category structure has to exist, without specifying what these categories look like.", "spans": "[{\"corpusId\": 5628616, \"span\": \"(Yu and Dredze, 2014;\", \"start\": 197, \"end\": 218}, {\"corpusId\": 51838647, \"span\": \"Faruqui et al., 2015;\", \"start\": 218, \"end\": 239}, {\"corpusId\": 617993, \"span\": \"Mrksic et al., 2016)\", \"start\": 239, \"end\": 259}, {\"corpusId\": 196187445, \"span\": \"our approach\", \"start\": 431, \"end\": 431}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "60435", "title": "Word and Document Embedding with vMF-Mixture Priors on Context Word Vectors", "sectionTitle": "Related Work", "text": "In recent years, several approaches that combine the intuitions underlying topic models with word embeddings have been proposed. For example, in (Das et al., 2015) it was proposed to replace the usual representation of topics as multinomial distributions over words by Gaussian distributions over a pre-trained word embedding, while (Batmanghelich et al., 2016) and (Li et al., 2016b) used von Mises-Fisher distributions for this purpose. Note that documents are still modelled as multinomial distributions of topics in these models. In (He et al., 2017) the opposite approach is taken: documents and topics are represented as vectors, with the aim of modelling topic correlations in an efficient way, while each topic is represented as a multinomial distribution over words. In this paper, we take a different approach for learning document vectors, by not considering any documentspecific topic distribution. This allows us to represent document vectors and (context) word vectors in the same space and, as we will see, leads to improved empirical results.", "spans": "[{\"corpusId\": 14502960, \"span\": \"(Das et al., 2015)\", \"start\": 145, \"end\": 163}, {\"corpusId\": 6525455, \"span\": \"(Batmanghelich et al., 2016)\", \"start\": 333, \"end\": 361}, {\"corpusId\": 14435990, \"span\": \"(Li et al., 2016b)\", \"start\": 366, \"end\": 384}, {\"corpusId\": 12118784, \"span\": \"(He et al., 2017)\", \"start\": 537, \"end\": 554}, {\"corpusId\": 196187445, \"span\": \"this paper\", \"start\": 789, \"end\": 789}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "60436", "title": "Word and Document Embedding with vMF-Mixture Priors on Context Word Vectors", "sectionTitle": "Related Work", "text": "Apart from using pre-trained word embeddings for improving topic representations, a number of approaches have also been proposed that use topic models for learning word vectors. For example, (Liu et al., 2015b) first uses the standard LDA model to learn a latent topic assignment for each word occurrence. These assignments are then used to learn vector representations of words and topics. Some extensions of this model have been proposed which jointly learn the topic-specific word vectors and the latent topic assignment (Li et al., 2016a;Shi et al., 2017). The main motivation for these works is to learn topic-specific word representations. They are thus similar in spirit to multiprototype word embeddings, which aim to learn sense-specific word vectors (Neelakantan et al., 2014). Our method is clearly different from these works, as our focus is on learning standard word vectors (as well as document vectors).", "spans": "[{\"corpusId\": 12075649, \"span\": \"(Li et al., 2016a;\", \"start\": 524, \"end\": 542}, {\"corpusId\": 10980859, \"span\": \"Shi et al., 2017)\", \"start\": 542, \"end\": 559}, {\"corpusId\": 15251438, \"span\": \"(Neelakantan et al., 2014)\", \"start\": 760, \"end\": 786}, {\"corpusId\": 196187445, \"span\": \"Our method\", \"start\": 798, \"end\": 798}, {\"corpusId\": 196187445, \"span\": \"our focus\", \"start\": 850, \"end\": 850}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "60437", "title": "Word and Document Embedding with vMF-Mixture Priors on Context Word Vectors", "sectionTitle": "Model Description", "text": "Document embedding. The model described above can also be used to learn document embeddings. To this end, the target word vectors are simply replaced by document vectors and the counts x ij then reflect how often word j occurs in document i. Below we will experimentally compare this strategy with existing methods for learning document representations, focusing especially on approaches that are inspired by probabilistic topic models. Indeed, we can intuitively think of the vMF mixture components in our model as representing topics. While there have already been topic models that use vMF distributions in this way (Batmanghelich et al., 2016;Li et al., 2016b), our approach is different because we do not consider a document-level topic distribution, and because we do not rely on pre-trained word embeddings.", "spans": "[{\"corpusId\": 6525455, \"span\": \"(Batmanghelich et al., 2016;\", \"start\": 619, \"end\": 647}, {\"corpusId\": 14435990, \"span\": \"Li et al., 2016b)\", \"start\": 647, \"end\": 664}, {\"corpusId\": 196187445, \"span\": \"our approach\", \"start\": 678, \"end\": 678}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "60438", "title": "Word and Document Embedding with vMF-Mixture Priors on Context Word Vectors", "sectionTitle": "Word Embedding Results", "text": "In this section, we describe the word embedding results, where we directly compare our model with the following baselines: GloVe (Pennington et al., 2014), Skipgram (Mikolov et al., 2013b) (denoted as SG), Continuous Bag of Words (Mikolov et al., 2013b) (denoted as CBOW), and the recently proposed WeMAP model (Jameel et al., 2019). We have used the Wikipedia dataset which was shared by Jameel et al. (2019), using the same vocabulary and preprocessing strategy. We report results for 300-dimensional word vectors and we use K = 3000 mixture components for our model. As evaluation tasks, we use standard word analogy and similarity benchmarks.", "spans": "[{\"corpusId\": 1957433, \"span\": \"(Pennington et al., 2014)\", \"start\": 129, \"end\": 154}, {\"corpusId\": 16447573, \"span\": \"(Mikolov et al., 2013b\", \"start\": 165, \"end\": 187}, {\"corpusId\": 16447573, \"span\": \"(Mikolov et al., 2013b\", \"start\": 230, \"end\": 252}, {\"corpusId\": 53689705, \"span\": \"(Jameel et al., 2019)\", \"start\": 311, \"end\": 332}, {\"corpusId\": 53689705, \"span\": \"Jameel et al. (2019)\", \"start\": 389, \"end\": 409}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "60439", "title": "Word and Document Embedding with vMF-Mixture Priors on Context Word Vectors", "sectionTitle": "Document Embedding Results", "text": "To evaluate the document embeddings, we focus on two downstream applications: categorization and document retrieval. As an intrinsic evaluation, we also evaluate the semantic coherence of the topics identified by our model. Document Categorization. We have evaluated our document embeddings on four standard document classification benchmarks: 1) 20 Newsgroups (20NG) 5 , 2) OHSUMED-23 (OHS) 6 , 3) TechTC-300 (TechTC) 7 , and 4) Reuters-21578 (Reu) 8 . As baselines, we consider the following approaches: 1) TF-IDF weighted bag-ofwords representation, 2) LDA 9 , 3) HDP 10 , 4) the fastest india red attackers cession summer  Our  GloVe  Our  GloVe  Our  GloVe  Our  GloVe  Our  GloVe  Our  GloVe  slowest  fifth  pakistan  indian  blue  blue  assailants  assailants  ceding  ceding  winter  winter  quickest  second  lanka  mumbai  yellow white  attacker  besiegers  annexation  ceded  autumn  olympics  slower  sixth  nepal  pakistan  white yellow townspeople  pursuers  annexing  reaffirmation  spring  autumn  faster  slowest  indian  pradesh  black which  insurgents  fortunately  cede  abrogation  year  spring  fast  ever  bangladesh subcontinent green called  policemen  looters  expropriation  stipulating  fall  in  surpassing  quickest  asia  karnataka  pink  bright  retaliation  attacker  continuance  californios  months  beginning  next  third  delhi  bengal  gray  pink  rioters  accomplices  ceded  renegotiation  in  next  surpassed respectively  sri  bangalore  well  green  terrorists  captors  incorporation expropriation  also  months  best  tenth  thailand  asia  the  purple perpetrators strongpoints  ironically  zapatistas  time  during  slow  first  china  delhi  with  black  whereupon  whereupon  dismantling annexation beginning year     (sHDP) 1314 , 7) GloVe 15 (Pennington et al., 2014), 8) WeMAP (Jameel et al., 2019), 9) Skipgram (SG) and Continuous Bag-of-Words 16 (Mikolov et al., 2013b) models. In the case of the word embedding models, we create document vectors in the same way as we do for our model, by simply replacing the role of target word vectors with document word vectors. In all the datasets, we removed punctuation and non-ASCII characters. We then segmented the sentences using Perl. In all models, parameters were tuned based on a development dataset. To this end, we randomly split our dataset into 60% training, 20% development and 20% testing. We report the results in terms of F1 score on the test set, using the Perf tool 17 . The trained document vectors were used as input to a linear SVM classifier whose trade-off parameter C was tuned from a pool of {10, 50, 100}, which is a common setting in document classification tasks. Note that our experimental setup is inherently different from those setups where a word embedding model is evaluated on the text classification task using deep neural networks, as our focus is on methods that learn document vectors in an unsupervised way. We have therefore adopted a setting where document vectors are used as the input to an SVM classifier. In our model, we have set the number of word embeddings iterations to 50. The parameters of the vMF mixture model were re-computed after every 5 word embedding iterations. We tuned the dimensionality of the embedding from the pool {100, 150, 200} and the number of vMF mixture components from the pool {200, 500, 800}.", "spans": "[{\"corpusId\": 1957433, \"span\": \"(Pennington et al., 2014)\", \"start\": 1795, \"end\": 1820}, {\"corpusId\": 53689705, \"span\": \"(Jameel et al., 2019)\", \"start\": 1831, \"end\": 1852}, {\"corpusId\": 16447573, \"span\": \"(Mikolov et al., 2013b)\", \"start\": 1902, \"end\": 1925}, {\"corpusId\": 196187445, \"span\": \"our focus\", \"start\": 2878, \"end\": 2878}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "60440", "title": "Word and Document Embedding with vMF-Mixture Priors on Context Word Vectors", "sectionTitle": "Document Embedding Results", "text": "Document Retrieval. Next we describe our document retrieval experiments. Specifically, we consider this problem as a learning-to-rank (LTR) task and use standard information retrieval (IR) tools to present our evaluation results. We have used the following standard IR benchmark datasets: 1) WT2G 18 along with standard relevance assessments and topics (401 -450), 2) TREC HARD (denoted as HARD) 19 , 3) AQUAINT-2 (AQUT) 20 where we considered only the document-level relevance assessments, and 4) LETOR OHSUMED (OHS) 21 , which consists of 45 features along with query-document pairs with relevance judgments in five folds. We have obtained the raw documents and queries 22 of this dataset, from which we can learn the document representations. As baselines, we have considered the following methods: 1) TF-IDF, 2) LDA (Blei et al., 2003), 3) HDP (Teh et al., 2005), 4) movMF (Banerjee et al., 2005), 5) sHDP (Batmanghelich et al., 2016), 6) GloVe (Pennington et al., 2014), 7) WeMAP (Jameel et al., 2019), 8) Skip-gram, and 9) CBOW word embedding models (Mikolov et al., 2013b).", "spans": "[{\"corpusId\": 196187445, \"span\": \"our evaluation\", \"start\": 220, \"end\": 220}, {\"corpusId\": 3177797, \"span\": \"(Blei et al., 2003)\", \"start\": 820, \"end\": 839}, {\"corpusId\": 13156740, \"span\": \"(Teh et al., 2005)\", \"start\": 848, \"end\": 866}, {\"corpusId\": 7581749, \"span\": \"(Banerjee et al., 2005)\", \"start\": 877, \"end\": 900}, {\"corpusId\": 6525455, \"span\": \"(Batmanghelich et al., 2016)\", \"start\": 910, \"end\": 938}, {\"corpusId\": 1957433, \"span\": \"(Pennington et al., 2014)\", \"start\": 949, \"end\": 974}, {\"corpusId\": 53689705, \"span\": \"(Jameel et al., 2019)\", \"start\": 985, \"end\": 1006}, {\"corpusId\": 16447573, \"span\": \"(Mikolov et al., 2013b)\", \"start\": 1056, \"end\": 1079}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 8}, {"paragraphId": "60441", "title": "Word and Document Embedding with vMF-Mixture Priors on Context Word Vectors", "sectionTitle": "Document Embedding Results", "text": "We have adopted the same preprocessing strategy as for the categorization task, with the exception of OHSUMED, for which suitable LTR features are already given. For all other datasets we used the Terrier LTR framework 23 to generate the six standard LTR document features as described in (Jameel et al., 2015). The document vectors were then concatenated with these six features 24 . To perform the actual retrieval experiment, we used RankLib 25 with a listwise RankNet (Burges et al., 2005) model 26 . Our results are reported in terms of NDCG@10, which is a common evaluation metric for this setting.", "spans": "[{\"corpusId\": 10885618, \"span\": \"(Jameel et al., 2015)\", \"start\": 289, \"end\": 310}, {\"corpusId\": 11168734, \"span\": \"(Burges et al., 2005)\", \"start\": 472, \"end\": 493}, {\"corpusId\": 196187445, \"span\": \"Our results\", \"start\": 516, \"end\": 516}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "60442", "title": "Word and Document Embedding with vMF-Mixture Priors on Context Word Vectors", "sectionTitle": "Document Embedding Results", "text": "Our training strategy is mostly the same as for the document categorization experiments, although for some parameters, such as the number of topics and vMF mixture components, we used larger values, which is a reflection of the fact that the collections used in this experiment are substantially larger and tend to be more diverse (Wei and Croft, 2006). In particular, the word vector lengths were chosen from a pool of {150, 200, 300} and the vMF mixtures from a pool of {300, 1000, 3000}. In the LDA model, we selected the number of topics from a pool of {100, 150, 200}. For GLDA we have used the same pool for the number of topics. All our results are reported for five-fold cross validation, where the parameters of the LTR model were automatically tuned, which is a common LTR experimental setting (Liu et al., 2015a).", "spans": "[{\"corpusId\": 3343003, \"span\": \"(Wei and Croft, 2006)\", \"start\": 331, \"end\": 352}, {\"corpusId\": 196187445, \"span\": \"our results\", \"start\": 651, \"end\": 651}, {\"corpusId\": 9836122, \"span\": \"(Liu et al., 2015a)\", \"start\": 804, \"end\": 823}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "60443", "title": "Word and Document Embedding with vMF-Mixture Priors on Context Word Vectors", "sectionTitle": "Document Embedding Results", "text": "Word Coherence. In traditional topic models such as LDA, the topics are typically labelled by the k words that have the highest probability in the topic. These words tend to reflect semantically coherent themes, which is an important reason for the popularity of topic models. Accordingly, measuring the coherence of the top-k words that are identified by a given topic model, for each topic, is a common evaluation measure (Shi et al., 2017). Using the configurations that performed best on the tuning data in the document categorization task above, we used Gensim 27 (\u0158eh\u016f\u0159ek  and Sojka, 2010) to compute the coherence of the top-20 words using the c v metric (R\u00f6der et al., 2015). For our model, GDLA and sHDP, the mixture components that were learned were consided as topics for this experiment. For GloVe, WeMAP, SG, TF-IDF, and CBOW, we used the von Mises-Fisher (vMF) soft clustering model (Banerjee et al., 2005) to determine the cluster memberships of the context words. For the TF-IDF results, we instead used hard vMF clustering (Hornik and Gr\u00fcn, 2014), as the movMF results are based on TF-IDF features as well. We tuned the number of clusters using the tuning data. The top-20 words after applying the clustering model were then output based on the distance from the cluster centroid. The results are shown in Table 9, showing that the word clusters defined by our mixture components are more semantically coherent than the topics obtained by the other methods.", "spans": "[{\"corpusId\": 10980859, \"span\": \"(Shi et al., 2017)\", \"start\": 424, \"end\": 442}, {\"corpusId\": 7743332, \"span\": \"(R\\u00f6der et al., 2015)\", \"start\": 662, \"end\": 682}, {\"corpusId\": 7581749, \"span\": \"(Banerjee et al., 2005)\", \"start\": 897, \"end\": 920}, {\"corpusId\": 196187445, \"span\": \"we instead\", \"start\": 1014, \"end\": 1014}, {\"corpusId\": 13171102, \"span\": \"(Hornik and Gr\\u00fcn, 2014)\", \"start\": 1040, \"end\": 1063}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 5}], "paragraphCount": 12}
{"paperId": "eba6cf883f6a737cb54fe48458ee0fa1228791fc", "title": "Respecifying Phubbing: Video-Based Analysis of Smartphone Use in Co-Present Interactions", "venue": "International Conference on Human Factors in Computing Systems", "year": 2023, "citationCount": 6, "openAccessPdf": {"url": "https://dl.acm.org/doi/pdf/10.1145/3544548.3581052", "status": "BRONZE", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3544548.3581052?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3544548.3581052, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2023-04-19", "authors": [{"authorId": "2085552384", "name": "Iuliia Avgustis"}], "abstract": "The concept of phubbing (generally defined as a practice of ignoring co-present others by focusing on one's mobile device) is now widely used in studies aiming to understand the effects of smartphone use on co-present interactions. However, most of these studies are quantitative in nature and fail to grasp the interactional context of smartphone use. Drawing on video recordings and utilizing multimodal interaction analysis, the present study examines phubbing in naturally occurring interactions among young adults. Contrary to most previous research, the analysis reveals that disengagement often precedes self-initiated smartphone use rather than follows it. The study identifies factors that affect whether phubbing is reciprocated and whether it is oriented to as problematic. As a result of the analysis, an alternative conceptualization of phubbing is offered. By reflecting on participants\u2019 ways of managing phubbing and its consequences, we discuss design solutions for supporting them in this task.", "corpusId": "258216872", "paragraphs": [{"paragraphId": "14021", "title": "Respecifying Phubbing: Video-Based Analysis of Smartphone Use in Co-Present Interactions", "sectionTitle": "INTRODUCTION", "text": "Smartphones have become an integral part of people's daily lives in many countries around the world. Recent studies have shown that mobile technology use is embedded in various everyday activities [8,49,74,79]. Consequently, researchers have raised concerns about the negative efects of pervasive smartphone use on the quality of face-to-face interactions [2,20,80], hence the term phubbing (phone snubbing), which refers to situations when co-present others are overshadowed by smartphone use. So far, most of the existing studies on smartphone use have been based on surveys, interviews, or data collected in experimental settings. One problem with these approaches is that they often fail to take the interactional context of smartphone use into account. The generalizability of much-published research on this issue is also problematic, as the mainstream approaches do not consider when, how, and by whom smartphone use is initiated (i.e., its communicational motivation) and how co-present others then react to this. The necessity to analyze smartphone use in real-life contexts has been recently emphasized [15,37], but relatively few studies have focused on smartphone use in natural communication settings [21,53,71].", "spans": "[{\"corpusId\": 14609980, \"span\": \"[8,\", \"start\": 197, \"end\": 200}, {\"corpusId\": 53225176, \"span\": \"49,\", \"start\": 200, \"end\": 203}, {\"corpusId\": 14216676, \"span\": \"74,\", \"start\": 203, \"end\": 206}, {\"corpusId\": 169568360, \"span\": \"79]\", \"start\": 206, \"end\": 209}, {\"corpusId\": 58014825, \"span\": \"[2,\", \"start\": 356, \"end\": 359}, {\"corpusId\": 4788040, \"span\": \"20,\", \"start\": 359, \"end\": 362}, {\"corpusId\": 151587289, \"span\": \"80]\", \"start\": 362, \"end\": 365}, {\"corpusId\": 224942049, \"span\": \"[15,\", \"start\": 1113, \"end\": 1117}, {\"corpusId\": 229419724, \"span\": \"37]\", \"start\": 1117, \"end\": 1120}, {\"corpusId\": 233828718, \"span\": \"[21,\", \"start\": 1214, \"end\": 1218}, {\"corpusId\": 169609530, \"span\": \"53,\", \"start\": 1218, \"end\": 1221}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": false, "refCount": 11}, {"paragraphId": "14022", "title": "Respecifying Phubbing: Video-Based Analysis of Smartphone Use in Co-Present Interactions", "sectionTitle": "INTRODUCTION", "text": "While quantitative studies focus mostly on the negative side of smartphone use, prior qualitative research in HCI has investigated some of the positive aspects, specifcally in the context of collaborative technology use. These studies showed how smartphones could bring topical resources for local conversations [10], resolve conficts within conversations [74], and become sites for investigation and discussion [9]. Smartphones can also allow participants to produce joint content, such as selfes [88], and act as resources for ongoing joint activities [8]. The organization of individual smartphone use has received much less attention and has been addressed primarily in the context of transport situations [8,49]. The present study looks to fll this gap by exploring how this type of smartphone use is initiated, carried out, and terminated by participants in face-to-face encounters. Considering the increasing prevalence of smartphones in everyday interactions, it is important to understand how they are used in natural contexts. Therefore, the present study is based on the analysis of video-recorded naturally occurring interactions among young adults in cafes and restaurants. Instead of arguing about the positive or negative efects of smartphone use, we exploit the method of interaction analysis [29,46,60] to uncover how the nature of smartphone use is negotiated by young adults themselves.", "spans": "[{\"corpusId\": 254679915, \"span\": \"[10]\", \"start\": 312, \"end\": 316}, {\"corpusId\": 14216676, \"span\": \"[74]\", \"start\": 356, \"end\": 360}, {\"corpusId\": 32660425, \"span\": \"[9]\", \"start\": 412, \"end\": 415}, {\"corpusId\": 14609980, \"span\": \"[8]\", \"start\": 554, \"end\": 557}, {\"corpusId\": 14609980, \"span\": \"[8,\", \"start\": 710, \"end\": 713}, {\"corpusId\": 53225176, \"span\": \"49]\", \"start\": 713, \"end\": 716}, {\"corpusId\": 144068391, \"span\": \"[29,\", \"start\": 1309, \"end\": 1313}, {\"corpusId\": 62769362, \"span\": \"46,\", \"start\": 1313, \"end\": 1316}, {\"corpusId\": 55119215, \"span\": \"60]\", \"start\": 1316, \"end\": 1319}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": false, "refCount": 8}, {"paragraphId": "14023", "title": "Respecifying Phubbing: Video-Based Analysis of Smartphone Use in Co-Present Interactions", "sectionTitle": "INTRODUCTION", "text": "This study contributes to HCI by advancing our understanding and explicating some nuances of self-initiated individual smartphone use in co-present interactions. We show that the type of smartphone-based activity and the interactional context afect the way in which a particular instance of smartphone use is designed and oriented to by other participants. Instead of treating co-present others as victims of phubbing [1,2,7,87], we describe how the character of one's individual smartphone use is negotiated and collaboratively achieved by all co-present participants. Uncovering these nuances adds to the existing HCI research, which uses video data to describe systematic aspects of smartphone use in natural contexts [8-10, 49, 57, 74, 75]. By analyzing naturally occurring interactions, this study seeks to identify issues with existing defnitions of phubbing and ofers a new conceptualization for future research. As this study also investigates participants' practices of returning smartphone users back into conversations, we conclude the paper with design implications, aiming to support participants' practices for dealing with extended smartphone use.", "spans": "[{\"corpusId\": 258216872, \"span\": \"This study\", \"start\": 10, \"end\": 10}, {\"corpusId\": 2573626, \"span\": \"[1,\", \"start\": 418, \"end\": 421}, {\"corpusId\": 58014825, \"span\": \"2,\", \"start\": 421, \"end\": 423}, {\"corpusId\": 258216872, \"span\": \"this study\", \"start\": 802, \"end\": 802}, {\"corpusId\": 258216872, \"span\": \"this study\", \"start\": 933, \"end\": 933}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "14024", "title": "Respecifying Phubbing: Video-Based Analysis of Smartphone Use in Co-Present Interactions", "sectionTitle": "RELATED RESEARCH 2.1 Phubbing and its Impact on Social Interactions", "text": "The concept of phubbing is now widely used in studies aiming to understand how smartphone use afects face-to-face interactions [2,12,13,65,66,87]. Phubbing has been studied in a variety of different settings and types of relationships: professional settings [7], family interactions [7,42], and interactions with romantic partners [7,24,34,56], with friends and acquaintances [2], and even with virtual agents [68]. Despite the diferences in context, phubbing is defned quite similarly in these studies and usually consists of two parts: (1) ignoring co-present other(s) and (2) focusing on the mobile device instead. Prior studies have reported that smartphone-based multitasking (e.g., texting during face-to-face interactions) leads to lower romantic intimacy with partners [6], lower conversation intimacy [59,76,87], a decrease in the level of perceived quality of relationships [34,56], and a lower level of perceived interaction quality [13,86]. Phubbing is also associated with individuals experiencing a sense of social exclusion [17]. In light of the growing number of studies on this topic, several literature reviews have been conducted to summarize fndings about various phubbing practices and their predictors and impacts [5,11]. While some researchers claim that phubbing has become a social norm [12], other scholars argue that it has not yet become a normative practice despite being widespread [2]. It is also paradoxical that survey participants often admit to using technology in interactions with others, while also claiming that such behavior is ofensive and negatively impacts interpersonal interactions [2,7]. In part, these discrepancies can be attributed to the fact that most phubbing research uses quantitative methods, and the most frequent data collection instrument is a questionnaire [11], which often disregards the interactional context of device use. More recent studies underline the importance of studying phubbing in the context of participants' daily environments. It has been shown that phubbing behavior can be assessed diferently by the phubbee (the person receiving phubbing) depending on the context: phubbing does not damage relationships on its own, but the negative impact of phubbing is attributed to negative appraisals, which can vary across diferent situations [24]. There are, however, relatively few studies that analyze actual instances of solitary smartphone use in naturally occurring interactions [52,70]. In this study, we therefore attempt to understand phubbing as it unfolds in real-life situations. However, phubbing must frst be deconstructed and reinterpreted through the lens of interaction analysis, which is done in the next subsection.", "spans": "[{\"corpusId\": 58014825, \"span\": \"[2,\", \"start\": 127, \"end\": 130}, {\"corpusId\": 41269839, \"span\": \"12,\", \"start\": 130, \"end\": 133}, {\"corpusId\": 148993005, \"span\": \"13,\", \"start\": 133, \"end\": 136}, {\"corpusId\": 181859123, \"span\": \"65,\", \"start\": 136, \"end\": 139}, {\"corpusId\": 226948958, \"span\": \"66,\", \"start\": 139, \"end\": 142}, {\"corpusId\": 248002743, \"span\": \"42]\", \"start\": 286, \"end\": 289}, {\"corpusId\": 248620617, \"span\": \"24,\", \"start\": 334, \"end\": 337}, {\"corpusId\": 33612089, \"span\": \"34,\", \"start\": 337, \"end\": 340}, {\"corpusId\": 225758673, \"span\": \"56]\", \"start\": 340, \"end\": 343}, {\"corpusId\": 58014825, \"span\": \"[2]\", \"start\": 376, \"end\": 379}, {\"corpusId\": 243864755, \"span\": \"[68]\", \"start\": 410, \"end\": 414}, {\"corpusId\": 42079555, \"span\": \"[6]\", \"start\": 777, \"end\": 780}, {\"corpusId\": 13908852, \"span\": \"76,\", \"start\": 814, \"end\": 817}, {\"corpusId\": 33612089, \"span\": \"[34,\", \"start\": 884, \"end\": 888}, {\"corpusId\": 225758673, \"span\": \"56]\", \"start\": 888, \"end\": 891}, {\"corpusId\": 148993005, \"span\": \"[13,\", \"start\": 944, \"end\": 948}, {\"corpusId\": 152125918, \"span\": \"[17]\", \"start\": 1039, \"end\": 1043}, {\"corpusId\": 151226320, \"span\": \"[5,\", \"start\": 1236, \"end\": 1239}, {\"corpusId\": 41269839, \"span\": \"[12]\", \"start\": 1312, \"end\": 1316}, {\"corpusId\": 58014825, \"span\": \"[2]\", \"start\": 1412, \"end\": 1415}, {\"corpusId\": 58014825, \"span\": \"[2,\", \"start\": 1627, \"end\": 1630}, {\"corpusId\": 248620617, \"span\": \"[24]\", \"start\": 2312, \"end\": 2316}, {\"corpusId\": 248876805, \"span\": \"[52,\", \"start\": 2454, \"end\": 2458}, {\"corpusId\": 237251062, \"span\": \"70]\", \"start\": 2458, \"end\": 2461}, {\"corpusId\": 258216872, \"span\": \"this study\", \"start\": 2476, \"end\": 2476}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 17}, {"paragraphId": "14025", "title": "Respecifying Phubbing: Video-Based Analysis of Smartphone Use in Co-Present Interactions", "sectionTitle": "Understanding Phubbing through", "text": "Interaction Analysis 2.2.1 Managing Multiactivity in the Context of Smartphone Use. The frst part of the defnition of phubbing is \"focusing on a mobile device.\" A problem with this formulation is that it implies that people can focus exclusively either on their mobile devices or on their ongoing co-present interaction. However, studies relying on interaction analysis show that people can do multiple things simultaneously by dividing their attention between main and side involvements [27]. The topic of multiple engagements has already been addressed in studies analyzing how people interact with co-present others while driving [33,62], drinking [40], performing massage [67], and so on. In studies addressing multiactivity [32], researchers reveal practices participants employ to maintain several courses of action and make their multiple involvements recognizable for co-present others. Rather than assuming \"main\" and \"side\" characteristics of diferent simultaneously unfolding activities, they aim to understand how participants themselves collaboratively negotiate \"mainness\" and \"sideness\" [63] of diferent activities moment-by-moment [50]. This approach to understanding multiple involvements has also been used to study mobile device use in transport situations [33,49] and in face-to-face interactions [18,19,30]. Analysis of naturally occurring interactions revealed that \"the allocation of one's attention to engagement in one's smartphone and co-present others is not either-or; rather, it manifests in degrees through the allocation of interactive resources such as one's words, gaze, and corporal confgurations, in relation to the device and collocated others\" [52]. Therefore, in this study, instead of assuming that smartphone users ignore co-present others, we analyze how they accomplish smartphone use successively or concurrently with other activities, how they make their engagement recognizable and accountable to others, how the character of multiactivity is collaboratively achieved by all co-present participants, and how multiactivity is dissolved.", "spans": "[{\"corpusId\": 144671679, \"span\": \"[33,\", \"start\": 633, \"end\": 637}, {\"corpusId\": 55856386, \"span\": \"62]\", \"start\": 637, \"end\": 640}, {\"corpusId\": 150079455, \"span\": \"[40]\", \"start\": 651, \"end\": 655}, {\"corpusId\": 142896079, \"span\": \"[67]\", \"start\": 676, \"end\": 680}, {\"corpusId\": 74753556, \"span\": \"[63]\", \"start\": 1102, \"end\": 1106}, {\"corpusId\": 152184847, \"span\": \"[50]\", \"start\": 1147, \"end\": 1151}, {\"corpusId\": 258216872, \"span\": \"This approach\", \"start\": 1166, \"end\": 1166}, {\"corpusId\": 144671679, \"span\": \"[33,\", \"start\": 1276, \"end\": 1280}, {\"corpusId\": 53225176, \"span\": \"49]\", \"start\": 1280, \"end\": 1283}, {\"corpusId\": 149800175, \"span\": \"19,\", \"start\": 1321, \"end\": 1324}, {\"corpusId\": 151765118, \"span\": \"30]\", \"start\": 1324, \"end\": 1327}, {\"corpusId\": 248876805, \"span\": \"[52]\", \"start\": 1681, \"end\": 1685}, {\"corpusId\": 258216872, \"span\": \"this study\", \"start\": 1711, \"end\": 1711}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 11}, {"paragraphId": "14026", "title": "Respecifying Phubbing: Video-Based Analysis of Smartphone Use in Co-Present Interactions", "sectionTitle": "Understanding Phubbing through", "text": "2.2.2 Displays of (Dis)engagement. The second part of the defnition is \"ignoring co-present others.\" Although most studies on phubbing mention this aspect [11], a vast majority of them fail to defne what \"ignoring\" means. Other studies defne phubbing even broader: as the action of using a smartphone [87] or looking at it [4] during interactions with others. The focus of these studies is often on the frequency of glancing at or using smartphones, and \"ignoring co-present participants\" is presupposed. However, it has also been shown that smartphone use can be initiated and carried out as a parallel side activity [19], as a resource for co-present interaction [10,30,74,77], or in the context of a joint smartphone-based activity [9,38,75]. As a general principle, it is crucial to distinguish between convergent and divergent smartphone use [8]. Therefore, studying the role of smartphones in face-to-face interactions goes beyond observing how much and how frequently they are used by others. In order to understand smartphone use, it is necessary to consider its interactional context.", "spans": "[{\"corpusId\": 150011851, \"span\": \"[4]\", \"start\": 323, \"end\": 326}, {\"corpusId\": 149800175, \"span\": \"[19]\", \"start\": 618, \"end\": 622}, {\"corpusId\": 254679915, \"span\": \"[10,\", \"start\": 665, \"end\": 669}, {\"corpusId\": 151765118, \"span\": \"30,\", \"start\": 669, \"end\": 672}, {\"corpusId\": 14216676, \"span\": \"74,\", \"start\": 672, \"end\": 675}, {\"corpusId\": 24208612, \"span\": \"77]\", \"start\": 675, \"end\": 678}, {\"corpusId\": 32660425, \"span\": \"[9,\", \"start\": 735, \"end\": 738}, {\"corpusId\": 148636990, \"span\": \"38,\", \"start\": 738, \"end\": 741}, {\"corpusId\": 24973803, \"span\": \"75]\", \"start\": 741, \"end\": 744}, {\"corpusId\": 14609980, \"span\": \"[8]\", \"start\": 847, \"end\": 850}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 10}, {"paragraphId": "14027", "title": "Respecifying Phubbing: Video-Based Analysis of Smartphone Use in Co-Present Interactions", "sectionTitle": "Understanding Phubbing through", "text": "Previous studies have often utilized the concept of \"absent presence\" [25] to describe the efects of mobile device use on everyday social interactions. Despite being physically present, smartphone users exhibit delayed responses, mechanical intonations, and a limited range of body movements and face expressions [1]. Interaction analysis covers these aspects with the concept of disengagement. Even before smartphones were created, researchers showed that the degree of participants' engagement in face-to-face encounters is not stable [26], as well as talk-in-interaction is not continuous [84]. Although participants are constantly in co-presence, their form of co-presence changes [28]. Participants can display their engagement or disengagement, for example, by altering their gaze orientations or bodily positions and confgurations. However, even when displaying disengagement, participants do not ignore copresent others. Instead, they closely monitor others' actions, as the state of co-presence continuously proposes the relevance of a collaborative activity such as talk [28]. Therefore, in this study, instead of assuming that smartphone users focus exclusively on their mobile devices, we analyze how they initiate and carry out smartphone use while being in co-presence with others and how they display their (dis)engagement while accomplishing smartphone-related activities.", "spans": "[{\"corpusId\": 2573626, \"span\": \"[1]\", \"start\": 313, \"end\": 316}, {\"corpusId\": 145053042, \"span\": \"[26]\", \"start\": 537, \"end\": 541}, {\"corpusId\": 143778528, \"span\": \"[84]\", \"start\": 592, \"end\": 596}, {\"corpusId\": 258216872, \"span\": \"this study\", \"start\": 1111, \"end\": 1111}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "14028", "title": "Respecifying Phubbing: Video-Based Analysis of Smartphone Use in Co-Present Interactions", "sectionTitle": "Data Collection and Analysis", "text": "This study draws on multimodal interaction analysis [29,46,60] that aims to reveal and describe how (as opposed to how often) participants accomplish various social actions and activities. The reliability of this type of research is determined by the adequacy of recorded data (inclusiveness of relevant details and the size of the data set), the technical quality of recordings (the visibility of analyzed phenomenon), and the adequacy of transcripts (with respect to the video recordings) [35,73]. To ensure the adequacy and quality of recorded data, this study makes use of a multidimensional video recording setup: several cameras were used to capture the encounter as a whole, all participants were equipped with small wearable cameras for capturing participants' gestures and on-screen activities, and screen capture software was used for each mobile device whenever technically possible. The researcher set up the cameras at the beginning of the encounter and sat at a diferent table in the same restaurant/cafe throughout the recording process. Participants were not observed during their encounters. To ensure the adequacy of transcripts, video fragments and corresponding transcripts were discussed and analyzed with other practitioners of interaction analysis during data sessions. Data session is a standard practice in video-based interaction analysis research, which allows one to receive others' feedback not only on the quality of transcript but also on the validity of analytical claims [36,46]. For the purpose of analysis, talk was transcribed according to Jefersonian conventions [45], and bodily conduct (body positions, gestures, gaze orientations) was transcribed using Mondada's conventions [64]. However, as these transcripts are not easily accessible for researchers from other disciplines [73,82], the excerpts are presented as graphic transcripts [3,48,83], and the original talk in Russian is translated into English. The adequacy of the graphic transcripts and translations was assessed by several researchers in our research group.", "spans": "[{\"corpusId\": 258216872, \"span\": \"This study\", \"start\": 10, \"end\": 10}, {\"corpusId\": 144068391, \"span\": \"[29,\", \"start\": 52, \"end\": 56}, {\"corpusId\": 62769362, \"span\": \"46,\", \"start\": 56, \"end\": 59}, {\"corpusId\": 55119215, \"span\": \"60]\", \"start\": 59, \"end\": 62}, {\"corpusId\": 203204748, \"span\": \"73]\", \"start\": 495, \"end\": 498}, {\"corpusId\": 258216872, \"span\": \"this study\", \"start\": 563, \"end\": 563}, {\"corpusId\": 51841824, \"span\": \"[36,\", \"start\": 1504, \"end\": 1508}, {\"corpusId\": 62769362, \"span\": \"46]\", \"start\": 1508, \"end\": 1511}, {\"corpusId\": 147914712, \"span\": \"[45]\", \"start\": 1600, \"end\": 1604}, {\"corpusId\": 149575903, \"span\": \"[64]\", \"start\": 1715, \"end\": 1719}, {\"corpusId\": 203204748, \"span\": \"[73,\", \"start\": 1816, \"end\": 1820}, {\"corpusId\": 30981136, \"span\": \"82]\", \"start\": 1820, \"end\": 1823}, {\"corpusId\": 196164658, \"span\": \"[3,\", \"start\": 1875, \"end\": 1878}, {\"corpusId\": 60843624, \"span\": \"48,\", \"start\": 1878, \"end\": 1881}, {\"corpusId\": 258216872, \"span\": \"our research\", \"start\": 2055, \"end\": 2055}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 11}, {"paragraphId": "14029", "title": "Respecifying Phubbing: Video-Based Analysis of Smartphone Use in Co-Present Interactions", "sectionTitle": "Data Collection and Analysis", "text": "The validity of interaction analysis research is mostly achieved through the transparency of research claims [73]. Therefore, in line with previous HCI studies using a similar methodology [8,9,49,74,75], both data (as graphic transcripts) and detailed analysis are presented in the paper. For this study, a detailed examination of participants' verbal and bodily conduct (gaze, body positions, device manipulation, etc.) was carried out to understand how participants initiate smartphone use, how co-present others orient to it, and how the character of this individual activity is collaboratively achieved by all co-present participants. The presented analysis, therefore, makes the procedure transparent to the reader, which allows the reader to assess the presented analytical claims and replicate the study with a diferent group of participants.", "spans": "[{\"corpusId\": 203204748, \"span\": \"[73]\", \"start\": 109, \"end\": 113}, {\"corpusId\": 14609980, \"span\": \"[8,\", \"start\": 188, \"end\": 191}, {\"corpusId\": 32660425, \"span\": \"9,\", \"start\": 191, \"end\": 193}, {\"corpusId\": 53225176, \"span\": \"49,\", \"start\": 193, \"end\": 196}, {\"corpusId\": 14216676, \"span\": \"74,\", \"start\": 196, \"end\": 199}, {\"corpusId\": 24973803, \"span\": \"75]\", \"start\": 199, \"end\": 202}, {\"corpusId\": 258216872, \"span\": \"this study\", \"start\": 303, \"end\": 303}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "14030", "title": "Respecifying Phubbing: Video-Based Analysis of Smartphone Use in Co-Present Interactions", "sectionTitle": "Reciprocating Phubbing", "text": "As the previous subsection demonstrated, smartphone use is not always problematized. Moreover, as past research suggests, phone use is socially contagious [22]. Phubbing can be reciprocated by copresent others as a response to a discontented action [12], as a way to save face [58], or as a way to re-establish a certain symmetry [39]. Multimodal interaction analysis can provide additional insights into reciprocal phubbing. In this subsection, we demonstrate that the reasons for reciprocating phubbing are often very similar to the reasons for initiating smartphone use in general. Participants often initiate their individual smartphone-based activities when the joint activity is fnished or suspended (because of one's smartphone use or other activity not related to technology use) or when there are no engaged participants left.", "spans": "[{\"corpusId\": 143071202, \"span\": \"[22]\", \"start\": 155, \"end\": 159}, {\"corpusId\": 41269839, \"span\": \"[12]\", \"start\": 249, \"end\": 253}, {\"corpusId\": 151823873, \"span\": \"[58]\", \"start\": 277, \"end\": 281}, {\"corpusId\": 225163137, \"span\": \"[39]\", \"start\": 330, \"end\": 334}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "14031", "title": "Respecifying Phubbing: Video-Based Analysis of Smartphone Use in Co-Present Interactions", "sectionTitle": "Reciprocating Phubbing", "text": "Even though Maria can guess the type of activity (typing) based on Ekaterina's embodied conduct, she is not aware of its phase, and therefore, the possible completion of the activity cannot be foreseen. This feature of interactions involving smartphone use was previously addressed as \"bystander ignorance\" [54,78]. Despite a long period of silence, Maria does not reciprocate phubbing immediately but monitors Ekaterina's involvement, as the continuation of the story is expected. Orienting to the absence of talk, Maria then utters \"so?\" to facilitate its continuation (panel 6), and Ekaterina immediately responds (panel 7). By saying \"a moment\" she indicates that the story is not abandoned, but merely suspended, and its resumption will follow later [47]. She then provides an account for the suspension (\"I'll answer to Misha\"), which, while being short, is enough for Maria, as participants have previously discussed the possibility of meeting the mentioned person.", "spans": "[{\"corpusId\": 211548440, \"span\": \"[54,\", \"start\": 307, \"end\": 311}, {\"corpusId\": 149892062, \"span\": \"78]\", \"start\": 311, \"end\": 314}, {\"corpusId\": 168240018, \"span\": \"[47]\", \"start\": 755, \"end\": 759}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "14032", "title": "Respecifying Phubbing: Video-Based Analysis of Smartphone Use in Co-Present Interactions", "sectionTitle": "Organizational Aspects of Self-Initiated Smartphone Use", "text": "There is growing concern that smartphone use negatively afects the quality of co-present interactions [13,20,34,86]. Most existing studies in this area use quantitative methods that do not take interactional context into account [11], and it has been recently suggested that smartphone use should be analyzed in the context of participants' daily environments [24,52,87]. While prior HCI studies have elucidated many important aspects of collaborative smartphone use [8-10, 74, 75], self-initiated individual smartphone use has received much less attention. This study contributes to the body of HCI literature by uncovering and describing common patterns of individual smartphone use in everyday co-present interactions. Our fndings demonstrate when and how young adults themselves initiate, carry out, and terminate individual smartphone use when interacting with others. Below, we summarize the key fndings, situate them within previous research and present implications for HCI. We discuss the role of context in the way smartphone use is initiated, factors afecting whether smartphone use is carried out as a temporarily prioritized or as a parallel activity, reasons for reciprocating one's smartphone use and participants' strategies for managing extended smartphone use. The analysis of naturally occurring interactions also allows us to respecify phubbing and suggest guidelines for further research. Drawing on participants' practices of managing extended smartphone use, we propose how the design of mobile technologies can better facilitate social interactions. Finally, we discuss limitations of this study and directions for future research.", "spans": "[{\"corpusId\": 148993005, \"span\": \"[13,\", \"start\": 102, \"end\": 106}, {\"corpusId\": 4788040, \"span\": \"20,\", \"start\": 106, \"end\": 109}, {\"corpusId\": 33612089, \"span\": \"34,\", \"start\": 109, \"end\": 112}, {\"corpusId\": 248620617, \"span\": \"[24,\", \"start\": 360, \"end\": 364}, {\"corpusId\": 248876805, \"span\": \"52,\", \"start\": 364, \"end\": 367}, {\"corpusId\": 258216872, \"span\": \"This study\", \"start\": 568, \"end\": 568}, {\"corpusId\": 258216872, \"span\": \"we propose\", \"start\": 1492, \"end\": 1492}, {\"corpusId\": 258216872, \"span\": \"this study\", \"start\": 1619, \"end\": 1619}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "14033", "title": "Respecifying Phubbing: Video-Based Analysis of Smartphone Use in Co-Present Interactions", "sectionTitle": "Organizational Aspects of Self-Initiated Smartphone Use", "text": "5.1.1 Initiating Smartphone Use: The Role of Context. Many psychological predictors of phubbing were previously identifed, such as Internet and smartphone addictions, fear of missing out, and lack of self-control [4,12,16]. This study adds to this line of research by revealing situational and interactional factors that can act as predictors of self-initiated smartphone use. Participants often initiate smartphone use after some signs of disengagement are already visible, for example, the absence of talk and/or lack of mutual gaze orientation. Smartphone use can also be initiated as a \"now-relevant\" or a \"now-or-never\" activity, or specifcally with the purpose of suspending/abandoning ongoing interaction in order to avoid conficts or awkward moments. While audible notifcations and phone calls can have a disruptive efect on co-present interactions due to their unpredictability [85], in the current data set, participants rarely attended to a summons at the moment of its occurrence. Individual smartphone-based activities were usually delayed until an appropriate sequential slot presented itself. If the goal is to understand the predictors and consequences of phubbing in real-life situations, it is imperative to take these situational and interactional factors into account, along with psychological factors.", "spans": "[{\"corpusId\": 150011851, \"span\": \"[4,\", \"start\": 213, \"end\": 216}, {\"corpusId\": 41269839, \"span\": \"12,\", \"start\": 216, \"end\": 219}, {\"corpusId\": 2643149, \"span\": \"16]\", \"start\": 219, \"end\": 222}, {\"corpusId\": 258216872, \"span\": \"This study\", \"start\": 234, \"end\": 234}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "14034", "title": "Respecifying Phubbing: Video-Based Analysis of Smartphone Use in Co-Present Interactions", "sectionTitle": "Reciprocating Smartphone use: Smartphone", "text": "Breaks. The current study enhances our understanding of what has been called contagious phone use [22] or reciprocal phubbing [12,39,58]. This phenomenon was previously interpreted as a response to a discontented action [12], as part of face-saving work [58], or as a way of establishing symmetry in interaction [39]. Although we do not reject these earlier fndings, we do demonstrate one more possible explanation for reciprocal smartphone use. In fact, the reasons and contexts for reciprocated smartphone use can be quite similar to those of initial self-initiated smartphone use (e.g., disengagement). During dyadic interactions, for instance, if the other person is using their smartphone and displays disengagement, the device can serve as a time-passing tool (Example 3). \"Smartphone breaks, \" that is, situations in which all co-present participants are temporarily engaged in their own smartphone-based activities, also emerge in the context of prior mutual disengagement (Example 4).", "spans": "[{\"corpusId\": 143071202, \"span\": \"[22]\", \"start\": 98, \"end\": 102}, {\"corpusId\": 41269839, \"span\": \"[12,\", \"start\": 126, \"end\": 130}, {\"corpusId\": 225163137, \"span\": \"39,\", \"start\": 130, \"end\": 133}, {\"corpusId\": 151823873, \"span\": \"58]\", \"start\": 133, \"end\": 136}, {\"corpusId\": 41269839, \"span\": \"[12]\", \"start\": 220, \"end\": 224}, {\"corpusId\": 151823873, \"span\": \"[58]\", \"start\": 254, \"end\": 258}, {\"corpusId\": 225163137, \"span\": \"[39]\", \"start\": 312, \"end\": 316}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "14035", "title": "Respecifying Phubbing: Video-Based Analysis of Smartphone Use in Co-Present Interactions", "sectionTitle": "Terminating Smartphone Use and Dissolving Smartphone", "text": "Breaks. While previous studies argue that young adults need guidance to control smartphone use and phubbing [16], the current study demonstrates that participants in interactions are capable of managing smartphone use and its possible negative efects on the interaction. Generally, smartphone users return to the ongoing conversation themselves, while co-present others continue talking without problematizing their smartphone use (Example 1). Smartphone users can also be brought back to the ongoing interaction by co-present other(s), who can, for example, introduce a new topic or ask the smartphone user about the type of on-screen activity. However, they rarely problematize one's smartphone use and usually do it in a humorous way, as shown in previous studies [39] and confrmed in this study (Example 2). One important fnding that video-based analysis of phubbing reveals is that smartphone use per se is rarely problematized or oriented to as problematic by participants themselves. However, depending on the interactional context and the type of the user's on-screen activity, smartphone users' disengagement can be problematized with reference to smartphone use. Smartphone breaks can be dissolved diferently based on the interactional context that preceded them. If there is a person who is expected to talk prior to the emergence of a \"smartphone break, \" they are usually held responsible for resuming joint interaction (Example 3). However, if \"smartphone breaks\" follow disengagement, smartphone users are left with no ongoing interaction to which they can return (Example 4). In these cases, smartphones are often used as resources for introducing new topics or activities and, therefore, for restoring a common interactional space.", "spans": "[{\"corpusId\": 2643149, \"span\": \"[16]\", \"start\": 108, \"end\": 112}, {\"corpusId\": 225163137, \"span\": \"[39]\", \"start\": 767, \"end\": 771}, {\"corpusId\": 258216872, \"span\": \"this study\", \"start\": 798, \"end\": 798}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "14036", "title": "Respecifying Phubbing: Video-Based Analysis of Smartphone Use in Co-Present Interactions", "sectionTitle": "Design Implications", "text": "There is growing interest in the design of mobile technologies that can encourage users to engage in face-to-face interactions [43] and enhance social interactions [23,72]. Previous solutions include designing technologies that ofer meaningful shared experiences [14], create a shared locus of attention [51], or send reminders to technology-abusing users [42]. Studies also showed that smartphone use can be encouraged in situations when it enriches the ongoing activity, for example, taking pictures and videos, sharing memes, and putting on music [51]. As smartphones can both constrain and enable co-present interactions, we should design solutions that would not limit participants' opportunities to use technology as a resource for interaction. In addition, we should consider designing technology that supports participants' own strategies for managing smartphone use and its potential negative efects on co-present interactions.", "spans": "[{\"corpusId\": 24293372, \"span\": \"[43]\", \"start\": 127, \"end\": 131}, {\"corpusId\": 3087159, \"span\": \"[23,\", \"start\": 164, \"end\": 168}, {\"corpusId\": 61808706, \"span\": \"72]\", \"start\": 168, \"end\": 171}, {\"corpusId\": 174802067, \"span\": \"[14]\", \"start\": 263, \"end\": 267}, {\"corpusId\": 246485554, \"span\": \"[51]\", \"start\": 304, \"end\": 308}, {\"corpusId\": 248002743, \"span\": \"[42]\", \"start\": 356, \"end\": 360}, {\"corpusId\": 246485554, \"span\": \"[51]\", \"start\": 550, \"end\": 554}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "14037", "title": "Respecifying Phubbing: Video-Based Analysis of Smartphone Use in Co-Present Interactions", "sectionTitle": "Making Smartphone Use Accountable for Co-Present Others.", "text": "Making the type and phase of smartphone-based activities more accountable for co-present others is one of the solutions that can help young adults to manage their and others' smartphone use. Previous studies showed that co-present others react more negatively to smartphone use (than, e.g., to reading a magazine) since they cannot directly understand the nature and the goal of the on-screen activity [55,69]. An example of a design solution for this problem is \"social displays,\" additional displays attached to the backside of the mobile device and revealing the user's current application [44]. The current study supports these previous fndings and design solutions by showing some of the ways in which co-present others return smartphone users back into interactions, for example, by commenting on the on-screen activity or by enquiring the smartphone user about the type of activity. As smartphones' screens are of low visibility due to their size, additional audio or video cues can be a good solution for increasing activity awareness for co-present others.", "spans": "[{\"corpusId\": 238743398, \"span\": \"[55,\", \"start\": 402, \"end\": 406}, {\"corpusId\": 25378027, \"span\": \"69]\", \"start\": 406, \"end\": 409}, {\"corpusId\": 18126913, \"span\": \"[44]\", \"start\": 593, \"end\": 597}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 17}
{"paperId": "4c1c2ed537d18ffc87112ca315f3596775a44284", "title": "Acustico: Surface Tap Detection and Localization using Wrist-based Acoustic TDOA Sensing", "venue": "ACM Symposium on User Interface Software and Technology", "year": 2020, "citationCount": 31, "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3379337.3415901?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3379337.3415901, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2020-10-20", "authors": [{"authorId": "1574549639", "name": "Jun Gong"}, {"authorId": "2020345", "name": "Aakar Gupta"}, {"authorId": "2704133", "name": "Hrvoje Benko"}], "abstract": "In this paper, we present Acustico, a passive acoustic sensing approach that enables tap detection and 2D tap localization on uninstrumented surfaces using a wrist-worn device. Our technique uses a novel application of acoustic time differences of arrival (TDOA) analysis. We adopt a sensor fusion approach by taking both 'surface waves' (i.e., vibrations through surface) and 'sound waves' (i.e., vibrations through air) into analysis to improve sensing resolution. We carefully design a sensor configuration to meet the constraints of a wristband form factor. We built a wristband prototype with four acoustic sensors, two accelerometers and two microphones. Through a 20-participant study, we evaluated the performance of our proposed sensing technique for tap detection and localization. Results show that our system reliably detects taps with an F1-score of 0.9987 across different environmental noises and yields high localization accuracies with root-mean-square-errors of 7.6mm (X-axis) and 4.6mm (Y-axis) across different surfaces and tapping techniques.", "corpusId": "222805626", "paragraphs": [{"paragraphId": "75550", "title": "Acustico: Surface Tap Detection and Localization using Wrist-based Acoustic TDOA Sensing", "sectionTitle": "INTRODUCTION", "text": "We assume the distance between Sensor A and B to be 4 cm (a common wrist length), the distance between Sensor A and Tap D to be 18cm (a common hand size), the distance between the two taps (C and D, E and F) to be 4cm, and the speed of sound to be 340m/s. Populating the equations with these numbers, we get the differences of two TDOAs along X axis and Y axis as 25.8\u00b5s and 3.6\u00b5s respectively. This is why X axis localization is easier than Y axis. A similar conclusion can also be found in Toffee [48] and SoundCraft [17] since both solutions only work in angular estimation (similar to X-axis) instead of distance interpolation (similar to Y-axis).", "spans": "[{\"corpusId\": \"52871305\", \"span\": \"\", \"start\": -14731, \"end\": -14727}, {\"corpusId\": \"10170946\", \"span\": \"[48]\", \"start\": 499, \"end\": 503}, {\"corpusId\": \"23408697\", \"span\": \"[17]\", \"start\": 519, \"end\": 523}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "75551", "title": "Acustico: Surface Tap Detection and Localization using Wrist-based Acoustic TDOA Sensing", "sectionTitle": "Feature Extraction and Machine Learning", "text": "Based on the findings from previous work [36,48] and our initial tests, we use four different methods to estimate the TDOA between two signals in 0.1s tap windows: (1) time displacement when the cross-correlation (i.e., similarity of two signals as a function of the displacement of one relative to the other) reaches maximum; (2) time difference of the first peaks; (3) time difference of the maximum peaks; (4) time difference of minimum. In total, we feed a 24-feature vector (4 estimate methods \u00d7 6 pairs of sensors) into the machine learning model for localization.", "spans": "[{\"corpusId\": \"14867846\", \"span\": \"\", \"start\": -19751, \"end\": -19748}, {\"corpusId\": \"25382751\", \"span\": \"\", \"start\": -19748, \"end\": -19746}, {\"corpusId\": \"3965577\", \"span\": \"\", \"start\": -19746, \"end\": -19743}, {\"corpusId\": \"14957135\", \"span\": \"\", \"start\": -19722, \"end\": -19718}, {\"corpusId\": \"3933114\", \"span\": \"\", \"start\": -19718, \"end\": -19715}, {\"corpusId\": \"4430840\", \"span\": \"[36,\", \"start\": 41, \"end\": 45}, {\"corpusId\": \"10170946\", \"span\": \"48]\", \"start\": 45, \"end\": 48}, {\"corpusId\": 222805626, \"span\": \"our different method\", \"start\": 100, \"end\": 100}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 8}, {"paragraphId": "75552", "title": "Acustico: Surface Tap Detection and Localization using Wrist-based Acoustic TDOA Sensing", "sectionTitle": "Participants", "text": "Twenty right-handed participants (11 males, 9 females; 23-59 years old, average age: 39.2) were recruited to participate in this study from our organization. The participants were compensated for their time.", "spans": "[{\"corpusId\": \"17032627\", \"span\": \"\", \"start\": -20696, \"end\": -20693}, {\"corpusId\": \"9794660\", \"span\": \"\", \"start\": -20693, \"end\": -20690}, {\"corpusId\": 222805626, \"span\": \"this study\", \"start\": 134, \"end\": 134}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "75553", "title": "Acustico: Surface Tap Detection and Localization using Wrist-based Acoustic TDOA Sensing", "sectionTitle": "Study Procedure -Tap Localization", "text": "To ensure we could collect all eighteen taps in each session for localization, if a tap was not detected, participants were instructed to tap at the same location again until it was registered. The experimenter recorded all false detections manually for later analysis. A one-minute break was given between repetition sessions where participants were asked to take off the wristband, leave the desk and walk around in the room [14,28,56]. Note that the calibration was only performed before the first session on each surface. The whole study took about 90 minutes to complete.", "spans": "[{\"corpusId\": \"35563511\", \"span\": \"[14,\", \"start\": 427, \"end\": 431}, {\"corpusId\": \"3717304\", \"span\": \"28,\", \"start\": 431, \"end\": 434}, {\"corpusId\": \"7189519\", \"span\": \"56]\", \"start\": 434, \"end\": 437}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "75554", "title": "Acustico: Surface Tap Detection and Localization using Wrist-based Acoustic TDOA Sensing", "sectionTitle": "Touch Input on Surfaces", "text": "Touch Input on Instrumented Surfaces. Plenty of existing work supports touch sensing by instrumenting or modifying the surface with capacitive [29,43,59], optical [16,32], electrical impedance [51,55,58] and acoustic sensors [36,37]. For example, Wall++ [59] uses conductive paint for patterning large electrodes onto a wall, turning ordinary walls into smart infrastructure supporting capacitive touch tracking. TouchLight [45] presents a touch screen display system on a sheet of acrylic plastic by instrumenting two video cameras behind the semi-transparent plane. Electrick [58] is a low-cost electrical impedance sensing technique enabling touch input on a surface painted with conductive coating. Since the surfaces always need to be instrumented or modified before sensing touch, these are not always practical.", "spans": "[{\"corpusId\": \"1196331\", \"span\": \"[29,\", \"start\": 143, \"end\": 147}, {\"corpusId\": \"40455284\", \"span\": \"43,\", \"start\": 147, \"end\": 150}, {\"corpusId\": \"5050052\", \"span\": \"59]\", \"start\": 150, \"end\": 153}, {\"corpusId\": \"18908925\", \"span\": \"[16,\", \"start\": 163, \"end\": 167}, {\"corpusId\": \"18188221\", \"span\": \"32]\", \"start\": 167, \"end\": 170}, {\"corpusId\": \"21834017\", \"span\": \"[51,\", \"start\": 193, \"end\": 197}, {\"corpusId\": \"5041442\", \"span\": \"55,\", \"start\": 197, \"end\": 200}, {\"corpusId\": \"20979362\", \"span\": \"58]\", \"start\": 200, \"end\": 203}, {\"corpusId\": \"4430840\", \"span\": \"[36,\", \"start\": 225, \"end\": 229}, {\"corpusId\": \"18173927\", \"span\": \"37]\", \"start\": 229, \"end\": 232}, {\"corpusId\": \"5050052\", \"span\": \"[59]\", \"start\": 254, \"end\": 258}, {\"corpusId\": \"10910243\", \"span\": \"[45]\", \"start\": 424, \"end\": 428}, {\"corpusId\": \"20979362\", \"span\": \"[58]\", \"start\": 578, \"end\": 582}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 11}, {"paragraphId": "75555", "title": "Acustico: Surface Tap Detection and Localization using Wrist-based Acoustic TDOA Sensing", "sectionTitle": "Touch Input on Surfaces", "text": "Touch Input on Uninstrumented Surfaces. Cameras in the environment or worn on user's body allow sensing touch without instrumenting or modifying the surfaces. There are many existing optical schemes for touch sensing in the literature, including RGB cameras [2,7,25,30], infrared cameras [1] and thermal cameras [39]. However, these approaches still require fixing the cameras in the environment or using wearable cameras [19,47], which are expensive, power consuming and might introduce privacy issues [3,22]. Aside from cameras, work has also been done to exploit a ring with IMU and light proximity sensor to sense touch [15] or track fingertip movements on uninstrumented surfaces [26]. None of the existing work uses wrist-based sensing. With the growing popularity of smartwatches, combined with their small touchscreen input space, enabling such surface input via wrist-based sensing holds a high potential for impact.", "spans": "[{\"corpusId\": \"14867846\", \"span\": \"[2,\", \"start\": 258, \"end\": 261}, {\"corpusId\": \"25382751\", \"span\": \"7,\", \"start\": 261, \"end\": 263}, {\"corpusId\": \"310246\", \"span\": \"25,\", \"start\": 263, \"end\": 266}, {\"corpusId\": \"3965577\", \"span\": \"30]\", \"start\": 266, \"end\": 269}, {\"corpusId\": \"6647203\", \"span\": \"[1]\", \"start\": 288, \"end\": 291}, {\"corpusId\": \"15219811\", \"span\": \"[39]\", \"start\": 312, \"end\": 316}, {\"corpusId\": \"14957135\", \"span\": \"[19,\", \"start\": 422, \"end\": 426}, {\"corpusId\": \"3933114\", \"span\": \"47]\", \"start\": 426, \"end\": 429}, {\"corpusId\": \"17032627\", \"span\": \"[3,\", \"start\": 503, \"end\": 506}, {\"corpusId\": \"9794660\", \"span\": \"22]\", \"start\": 506, \"end\": 509}, {\"corpusId\": \"204811954\", \"span\": \"[15]\", \"start\": 624, \"end\": 628}, {\"corpusId\": \"9758399\", \"span\": \"[26]\", \"start\": 685, \"end\": 689}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 12}, {"paragraphId": "75556", "title": "Acustico: Surface Tap Detection and Localization using Wrist-based Acoustic TDOA Sensing", "sectionTitle": "Gesture Sensing using a Wristband / Smartwatch", "text": "Another body of related research focuses on sensing finger gestures (e.g., pinch) [14,31,40,44] and hand gestures (e.g., fist) [9,11,23,33,38,42,56] using the sensors on a wristband or a smartwatch. For example, GestureWrist [38] uses capacitive sensors to detect the changes in forearm shape to infer hand postures. CapBand [42] uses a similar ultra-low power capacitive sensing technique but achieves significant improvements on accuracy and gesture quantity. WristFlex [9] and Tomo [56] use force resistors or electrical impedance tomography (EIT) sensors to identify different hand postures. WristWhirl [13] supports 2D continuous input from wrist whirling using infrared proximity sensors on the wristband.", "spans": "[{\"corpusId\": \"35563511\", \"span\": \"[14,\", \"start\": 82, \"end\": 86}, {\"corpusId\": \"6601027\", \"span\": \"31,\", \"start\": 86, \"end\": 89}, {\"corpusId\": \"9079288\", \"span\": \"40,\", \"start\": 89, \"end\": 92}, {\"corpusId\": \"11243658\", \"span\": \"44]\", \"start\": 92, \"end\": 95}, {\"corpusId\": \"9335893\", \"span\": \"[9,\", \"start\": 127, \"end\": 130}, {\"corpusId\": \"5918199\", \"span\": \"11,\", \"start\": 130, \"end\": 133}, {\"corpusId\": \"140224713\", \"span\": \"23,\", \"start\": 133, \"end\": 136}, {\"corpusId\": \"21341435\", \"span\": \"33,\", \"start\": 136, \"end\": 139}, {\"corpusId\": \"4843637\", \"span\": \"38,\", \"start\": 139, \"end\": 142}, {\"corpusId\": \"53106551\", \"span\": \"42,\", \"start\": 142, \"end\": 145}, {\"corpusId\": \"7189519\", \"span\": \"56]\", \"start\": 145, \"end\": 148}, {\"corpusId\": \"4843637\", \"span\": \"[38]\", \"start\": 225, \"end\": 229}, {\"corpusId\": \"53106551\", \"span\": \"[42]\", \"start\": 325, \"end\": 329}, {\"corpusId\": \"9335893\", \"span\": \"[9]\", \"start\": 472, \"end\": 475}, {\"corpusId\": \"7189519\", \"span\": \"[56]\", \"start\": 485, \"end\": 489}, {\"corpusId\": \"1363231\", \"span\": \"[13]\", \"start\": 607, \"end\": 611}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 12}, {"paragraphId": "75557", "title": "Acustico: Surface Tap Detection and Localization using Wrist-based Acoustic TDOA Sensing", "sectionTitle": "Localization using Active Sensing", "text": "Previous work has also shown the possibility to detect or localize a finger/finger-tap using active sensing methods, which use infrared [4], electrical [57,60], magnetic [8] or acoustic signals [35,54]. These approaches typically involve active transmission of a signal from a transmitter node and then analyzing the reception of that signal at the receiver node. FingerIO [35], for example, transforms the device into an active sonar system that transmits inaudible sound signals and tracks the echoes of the finger at its microphones. We investigated an active sensing approach, but there are fundamental constraints in the physics of this approach (detailed later in Discussion).", "spans": "[{\"corpusId\": \"13162216\", \"span\": \"[4]\", \"start\": 136, \"end\": 139}, {\"corpusId\": \"204811986\", \"span\": \"[57,\", \"start\": 152, \"end\": 156}, {\"corpusId\": \"16964785\", \"span\": \"60]\", \"start\": 156, \"end\": 159}, {\"corpusId\": \"2044436\", \"span\": \"[8]\", \"start\": 170, \"end\": 173}, {\"corpusId\": \"14629673\", \"span\": \"[35,\", \"start\": 194, \"end\": 198}, {\"corpusId\": \"22884915\", \"span\": \"54]\", \"start\": 198, \"end\": 201}, {\"corpusId\": \"14629673\", \"span\": \"[35]\", \"start\": 373, \"end\": 377}, {\"corpusId\": 222805626, \"span\": \"this approach\", \"start\": 650, \"end\": 650}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "75558", "title": "Acustico: Surface Tap Detection and Localization using Wrist-based Acoustic TDOA Sensing", "sectionTitle": "Gesture Input and Localization with Passive Acoustics", "text": "Many passive acoustic approaches have been employed to detect gestures [12,20,21,52] and localize signals [17,24,36,37,48,49]. For gesture inputs, SurfaceLink [12] exploits a combination of accelerometers and microphones to sense gestures and uses them to control information transfer among devices. ScratchInput [20] relies on the unique sound produced when a fingernail is dragged over different surfaces to identify six scratch gestures.", "spans": "[{\"corpusId\": \"10130094\", \"span\": \"[12,\", \"start\": 71, \"end\": 75}, {\"corpusId\": \"16403904\", \"span\": \"20,\", \"start\": 75, \"end\": 78}, {\"corpusId\": \"1632852\", \"span\": \"21,\", \"start\": 78, \"end\": 81}, {\"corpusId\": \"16853563\", \"span\": \"52]\", \"start\": 81, \"end\": 84}, {\"corpusId\": \"23408697\", \"span\": \"[17,\", \"start\": 106, \"end\": 110}, {\"corpusId\": \"11784714\", \"span\": \"24,\", \"start\": 110, \"end\": 113}, {\"corpusId\": \"4430840\", \"span\": \"36,\", \"start\": 113, \"end\": 116}, {\"corpusId\": \"18173927\", \"span\": \"37,\", \"start\": 116, \"end\": 119}, {\"corpusId\": \"10170946\", \"span\": \"48,\", \"start\": 119, \"end\": 122}, {\"corpusId\": \"27431433\", \"span\": \"49]\", \"start\": 122, \"end\": 125}, {\"corpusId\": \"10130094\", \"span\": \"[12]\", \"start\": 159, \"end\": 163}, {\"corpusId\": \"16403904\", \"span\": \"[20]\", \"start\": 313, \"end\": 317}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 10}, {"paragraphId": "75559", "title": "Acustico: Surface Tap Detection and Localization using Wrist-based Acoustic TDOA Sensing", "sectionTitle": "Gesture Input and Localization with Passive Acoustics", "text": "The TDOA approach. For localizing the acoustic signal, the most prevalent approach, which we also use in this work, is time difference of arrival (TDOA) analysis [10,24,36,37,48,49]. For example, PingPongPlus [24] instruments four contact microphones located at the outermost corners of the desired interactive region. When a Ping-Pong ball falls inside of this region, the signal arrives to the four sensors at different times, enabling a hyperbolic intersection localization. Likewise, SurfaceVibe [36] also uses four geophones in a similar setup to enable two interaction types, tap and swipe, on multiple types of surfaces. Instead of instrumenting the surfaces, Toffee [48] augments the mobile devices and laptops with four piezo sensors and demonstrates accurate resolution of the bearings of touch events around the devices, although the evaluation considers only a single user. Besides TDOA analysis, SoundCraft [17] instead uses a target signal subspace method, by adopting the basic idea of Multiple Signal Classification technique, which can localize acoustic signals even in noisy environment.", "spans": "[{\"corpusId\": 222805626, \"span\": \"this work\", \"start\": 114, \"end\": 114}, {\"corpusId\": \"11784714\", \"span\": \"24,\", \"start\": 166, \"end\": 169}, {\"corpusId\": \"4430840\", \"span\": \"36,\", \"start\": 169, \"end\": 172}, {\"corpusId\": \"18173927\", \"span\": \"37,\", \"start\": 172, \"end\": 175}, {\"corpusId\": \"10170946\", \"span\": \"48,\", \"start\": 175, \"end\": 178}, {\"corpusId\": \"27431433\", \"span\": \"49]\", \"start\": 178, \"end\": 181}, {\"corpusId\": \"11784714\", \"span\": \"[24]\", \"start\": 209, \"end\": 213}, {\"corpusId\": \"4430840\", \"span\": \"[36]\", \"start\": 500, \"end\": 504}, {\"corpusId\": \"10170946\", \"span\": \"[48]\", \"start\": 674, \"end\": 678}, {\"corpusId\": \"23408697\", \"span\": \"[17]\", \"start\": 920, \"end\": 924}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 7}], "paragraphCount": 10}
{"paperId": "80df46dbcb20deaaad29089dd970212fc6a23de4", "title": "Insights and Opportunities for HCI Research into Hurricane Risk Communication", "venue": "International Conference on Human Factors in Computing Systems", "year": 2022, "citationCount": 11, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3491102.3502101?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3491102.3502101, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference", "Review"], "publicationDate": "2022-04-29", "authors": [{"authorId": "49391193", "name": "R. Soden"}, {"authorId": "1912259", "name": "Lydia B. Chilton"}, {"authorId": "30049584", "name": "S. Miles"}, {"authorId": "113703979", "name": "R. Bicksler"}, {"authorId": "90712232", "name": "K. Villanueva"}, {"authorId": "2580633", "name": "Melissa Bica"}], "abstract": "Communicating risk to the public in the lead-up to tropical storms has the potential to significantly reduce the impacts on both livelihood and property. While significant research has been conducted in the storm risk community on how people receive, seek, and utilize risk information, given the importance of computing technologies and social media in these activities, human-centered design stands to make important contributions to this area. Drawing on an extensive literature review and 48 interviews with hurricane experts and members of the public, this paper makes three contributions. First, we provide a broad overview of hurricane risk communication. We then offer a set of guiding insights to inform HCI research work in this domain. Finally, we identify 6 opportunities that future human centered design work might pursue. In sum, this paper offers an invitation and a starting point for HCI to take up the problem of hurricane risk communication.", "corpusId": "248318531", "paragraphs": [{"paragraphId": "34696", "title": "Insights and Opportunities for HCI Research into Hurricane Risk Communication", "sectionTitle": "INTRODUCTION", "text": "Despite signifcant progress, there are a number of persistent challenges in regard to efective communication of expert knowledge about storm risk to the public. For example, research has shown that graphics are more efective at communicating risk than text products, yet members of the public often have trouble interpreting commonly used graphics used to describe hurricane projections [26] [96] [105]. In addition, ofcial information created and disseminated by hurricane experts at NOAA or local emergency management ofces is increasingly competing for the public's attention with other sources of information including mainstream and social media and information received from neighbors, friends, and family-members. Another challenge is that many contextual factors, including prior experience with storms, socioeconomic status, and behaviors of an individual's social networks, infuence people's decisions to prepare, evacuate, or take other protective actions prior to storms [15] [32]. Prior work in HCI has highlighted the importance of further in vivo studies through contextual inquiry or other methods in order to address the wide variety of contexts in which the public accesses and interprets risk information [11].", "spans": "[{\"corpusId\": 14063253, \"span\": \"[26]\", \"start\": 387, \"end\": 391}, {\"corpusId\": 3566598, \"span\": \"[96]\", \"start\": 392, \"end\": 396}, {\"corpusId\": 109048644, \"span\": \"[105]\", \"start\": 397, \"end\": 402}, {\"corpusId\": 140227467, \"span\": \"[11]\", \"start\": 1224, \"end\": 1228}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "34697", "title": "Insights and Opportunities for HCI Research into Hurricane Risk Communication", "sectionTitle": "RELATED WORK 2.1 Weather risk communication", "text": "Research in tropical storm risk communication has found that there are several components of efective public messaging. Communicating risk efectively requires consistent, clear, and concise messaging that is not fear-based [23] [31] [79] [82] [84]. Trust, whether in an organization, government agency, or spokesperson, is a major factor for risk reduction and protective action in weather-related hazards [81] [130]. This trusted authority should be working with a variety of institutions, scientists, and public ofcials to communicate accurate messages with 'one voice' [36]. Risk communication may be unidirectional, top-down communication from authorities to the public, which is often the case during a hazard event; however, there is growing evidence that two-way dialogue between the message creators and message receivers is more efective, in both crisis situations and in disaster mitigation [4] [35].", "spans": "[{\"corpusId\": 19838063, \"span\": \"[79]\", \"start\": 233, \"end\": 237}, {\"corpusId\": 123027525, \"span\": \"[81]\", \"start\": 406, \"end\": 410}, {\"corpusId\": 205734618, \"span\": \"[130]\", \"start\": 411, \"end\": 416}, {\"corpusId\": 154397925, \"span\": \"[36]\", \"start\": 572, \"end\": 576}, {\"corpusId\": 143477909, \"span\": \"[4]\", \"start\": 901, \"end\": 904}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "34698", "title": "Insights and Opportunities for HCI Research into Hurricane Risk Communication", "sectionTitle": "Crisis informatics", "text": "Crisis informatics is an area of research and design within HCI that focuses on how digital technologies shape information seeking and sharing behavior related to disaster [99] [118]. Drawing upon classic scholarship in disaster studies, crisis informatics has highlighted the important ways in which members of the public play important roles in circulating and reinterpreting ofcial disaster information [125]. This research has also discussed the public's use of technologies in coordinating informal, emergent citizen response to disasters [132]. As with risk communications, crisis informatics has documented the vital role of journalists in interpreting and broadcasting expert information about disaster [28]. While the feld is best known for its contributions to understand the role of social media during moments of crisis [100] [107], other work in the area has looked at a wider range of technologies and temporalities relevant to hurricane risk including research into disaster risk models [116], post-disaster impact assessments [116], and the design of smartphone applications for creating and sharing disaster information [59].", "spans": "[{\"corpusId\": 206651216, \"span\": \"[99]\", \"start\": 172, \"end\": 176}, {\"corpusId\": 13438430, \"span\": \"[125]\", \"start\": 406, \"end\": 411}, {\"corpusId\": 248318531, \"span\": \"This research\", \"start\": 426, \"end\": 426}, {\"corpusId\": 32690732, \"span\": \"[132]\", \"start\": 544, \"end\": 549}, {\"corpusId\": 8823436, \"span\": \"[28]\", \"start\": 711, \"end\": 715}, {\"corpusId\": 158858065, \"span\": \"[100]\", \"start\": 832, \"end\": 837}, {\"corpusId\": 3899671, \"span\": \"[107]\", \"start\": 838, \"end\": 843}, {\"corpusId\": 7947115, \"span\": \"[116]\", \"start\": 1002, \"end\": 1007}, {\"corpusId\": 7947115, \"span\": \"[116]\", \"start\": 1042, \"end\": 1047}, {\"corpusId\": 219449832, \"span\": \"[59]\", \"start\": 1137, \"end\": 1141}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "34699", "title": "Insights and Opportunities for HCI Research into Hurricane Risk Communication", "sectionTitle": "Crisis informatics", "text": "Crisis informatics research has only recently begun to examine risk communication. With regards to tropical storm risk, crisis informatics and social computing research has utilized digital traces on social media as a means to understand people's online and ofine behaviors during hurricane events. For example, by using social media data from people directly impacted by hurricanes, Metaxa-Kakavouli et al. [77] found that evacuation behavior is associated with social capital, i.e. the breadth of one's extended social network. In other work, Bica et al. [11] classifed hurricane risk images shared by authorities on social media throughout the 2017 Atlantic hurricane season and described their prevalence, difusion, and reception by the public. Their study supports prior risk communication research that suggests that emphasizing, rather than obscuring, uncertainty or alternative outcomes in visualizations may support better decision-making by viewers [45] [48].", "spans": "[{\"corpusId\": 53245560, \"span\": \"[77]\", \"start\": 408, \"end\": 412}, {\"corpusId\": 140227467, \"span\": \"[11]\", \"start\": 557, \"end\": 561}, {\"corpusId\": 5051169, \"span\": \"[45]\", \"start\": 959, \"end\": 963}, {\"corpusId\": 140233909, \"span\": \"[48]\", \"start\": 964, \"end\": 968}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "34700", "title": "Insights and Opportunities for HCI Research into Hurricane Risk Communication", "sectionTitle": "Crisis informatics", "text": "HCI research has also examined online risk communication as it relates to public health crisis events. For example, Pine et al found that ofcial risk communication about COVID-19 in the United States was too often contradictory, complex, or changing, so that the public often turned to their own social networks in the absence of clear signals from ofcials [103]. A study of online conversations during the Zika epidemic highlighted the challenges citizens faced with authoritative risk information and the countermeasures they took to fnd trustworthy guidance for their decision-making [46]. The extreme uncertainty of the Zika epidemic gave rise to multidimensional and speculative risk perceptions, highlighting the need for a more participatory approach to risk communication that engages laypeople/members of the public along with experts [47]. Such fndings demonstrate the opportunity for HCI to contribute to the improvement of risk communication during hurricane events, both on-and ofine.", "spans": "[{\"corpusId\": 233987830, \"span\": \"[103]\", \"start\": 357, \"end\": 362}, {\"corpusId\": 20564132, \"span\": \"[46]\", \"start\": 587, \"end\": 591}, {\"corpusId\": 5056466, \"span\": \"[47]\", \"start\": 844, \"end\": 848}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "34701", "title": "Insights and Opportunities for HCI Research into Hurricane Risk Communication", "sectionTitle": "Human-centered design", "text": "Human-centered design (HCD) is an area of research and practice that is being taken up in multiple domains as a means of understanding the distinct needs, capacities, and contexts of use for a range of technologies. For example, within the HCI community, health researchers use HCD to discover needs beyond curing diseases, such as empowering patients to \"gain greater control over decisions and actions afecting their health\" [74], helping patients support each other and learn from each other using online health communities [24], and using visualizations to better communicate risks to patients [112]. Other domains where human centered design approaches have made contributions include education [64], sustainability [65], personal informatics [38], mental health [34], and accessibility [8]. Through taking a broader perspective of problems and focusing on the experiences of people most impacted by the problem, HCD can open avenues for multiple kinds of insights and solutions into complex design challenges. In this paper we bring this lens to a similarly difcult set of questions, those raised by eforts to communicate information about tropical storm risk to the public.", "spans": "[{\"corpusId\": 13571618, \"span\": \"[74]\", \"start\": 427, \"end\": 431}, {\"corpusId\": 1809763, \"span\": \"[24]\", \"start\": 527, \"end\": 531}, {\"corpusId\": 6360552, \"span\": \"[112]\", \"start\": 598, \"end\": 603}, {\"corpusId\": 14622348, \"span\": \"[64]\", \"start\": 700, \"end\": 704}, {\"corpusId\": 17437613, \"span\": \"[65]\", \"start\": 721, \"end\": 725}, {\"corpusId\": 12449176, \"span\": \"[38]\", \"start\": 748, \"end\": 752}, {\"corpusId\": 10486226, \"span\": \"[34]\", \"start\": 768, \"end\": 772}, {\"corpusId\": 140445039, \"span\": \"[8]\", \"start\": 792, \"end\": 795}, {\"corpusId\": 248318531, \"span\": \"this paper\", \"start\": 1029, \"end\": 1029}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "34702", "title": "Insights and Opportunities for HCI Research into Hurricane Risk Communication", "sectionTitle": "METHODS", "text": "Finally, we interviewed 36 members of the public from four hurricane-prone states in the United States: New York, Texas, Louisiana, and North Carolina. These states were chosen to refect a range of storm type and frequency profles. Participants were recruited through professional networks of our research team and social media channels. Though we did not formally screen participants, we note that a wide diversity of racial, gender, language, and personal experiences with disasters were represented across the interviews. The interviews lasted on average around 35 minutes and focused on detailed understanding of individuals' experiences with hurricanes over the last decade. We asked questions about where participants sought information, how they evaluated between competing forecasts, key decisions such as whether to evacuate or prepare in other ways, what factors infuenced these decisions. Prior research in risk communication has conducted systematic, quantitative research into some of these questions [5] [18] [29] [52]. Here, drawing on design research practice, our priority was to gather detailed stories from the target audience of risk communications to understand the breadth and complexity of the design space.", "spans": "[{\"corpusId\": 248318531, \"span\": \"our research\", \"start\": 305, \"end\": 305}, {\"corpusId\": 111190274, \"span\": \"[5]\", \"start\": 1014, \"end\": 1017}, {\"corpusId\": 147294063, \"span\": \"[52]\", \"start\": 1028, \"end\": 1032}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "34703", "title": "Insights and Opportunities for HCI Research into Hurricane Risk Communication", "sectionTitle": "The Public's Mental Models of Risk Difer from Those of Experts", "text": "Many of the central challenges of tropical storm risk communication stem from the gulf of understanding between expert knowledge about storms and popular mental models surrounding risk and uncertainty [15]. Bridging that gulf requires, at minimum, greater understanding of the public's knowledge and beliefs about these topics and may require thinking diferently about how risk models are currently constructed. A standard expert view about forecasts is the notion that a good or efective model is one that is a good predictor -where model outputs accurately match an empirical dataset [110]. However, the usefulness of a weather model for decision-making, is not guaranteed by a good empirical match [7] [66] [78] [95]. On this point Norton [93] argues that models used for decision support must help policymakers and the public to formulate and measure goals efectively, as well as propose and implement plans and policies to reach these goals. Even accurate model predictions may be miscommunicated or misused, resulting in undesirable outcomes [51]. Similarly, the output of a forecast can be efectively communicated, but may not be of a form useful to stakeholders within their specifc decision context. The diferences between expert understanding and the public's needs for hurricane risk information thus creates signifcant challenges for communicating storm risk. The cone of uncertainty, one of the more common hurricane information products [15], exemplifes some of the challenges of risk communication. Pictured in Figure 1, the cone graphic shows the probable path of the storm center over time. The cone in the image delineates the boundaries enclosing two-thirds of modeled tracks based on historical data; thus, there is estimated a 66% chance that the center for the storm will be within the cone during the projected time frame [87]. The cone shape depicts a narrow range of possible storm track boundaries in the more immediate forecast, which expands into a greater range due to increased uncertainty of the track forecast further into the future. Prior work in risk communications has found that the public frequently misinterprets these images in a number of ways, including believing the size of the cone to represent hurricane intensity or that areas outside of the cone were out of the danger area [19] [109]. An alternative to the cone, the so-called \"spaghetti plot\", or ensemble graphic ( Figure  2), shows individual tracks of selected models, but also struggles to efectively communicate uncertainty. The distinct tracks tend to be read as overly deterministic, especially when they coincide with signifcant landmarks [96]. Interpreting spaghetti plots can also be more cognitively taxing than for other visual hurricane forecast representations [26]. We return to the question of the cone in Section 5.1.", "spans": "[{\"corpusId\": 62678555, \"span\": \"[7]\", \"start\": 701, \"end\": 704}, {\"corpusId\": 230250652, \"span\": \"[93]\", \"start\": 742, \"end\": 746}, {\"corpusId\": 6483768, \"span\": \"[19]\", \"start\": 2322, \"end\": 2326}, {\"corpusId\": 7832525, \"span\": \"[109]\", \"start\": 2327, \"end\": 2332}, {\"corpusId\": 3566598, \"span\": \"[96]\", \"start\": 2647, \"end\": 2651}, {\"corpusId\": 14063253, \"span\": \"[26]\", \"start\": 2775, \"end\": 2779}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "34704", "title": "Insights and Opportunities for HCI Research into Hurricane Risk Communication", "sectionTitle": "Protective action can be difcult or", "text": "expensive; trust is therefore essential Activities such as evacuation, boarding up storefronts and windows, and others that risk communication experts refer to as protective decision-making can be difcult or expensive undertakings, thus it is crucial that the public trust the information they are receiving. Many of our interviewees described situations such as lacking funds for gas or hotel-rooms, not owning a car, or having family members that weren't physically able to evacuate that made evacuation challenging. This research fnds that \"before deciding to take a disruptive and often expensive action such as evacuation, people must understand the forecast; believe it applies to them; and, most important, feel that they and/or their loved ones are at risk\" [81] [6] [127]. Best practices in risk communication thus emphasize that risk warnings need to be clear and come from a trusted source [88]. While it is necessary to convey the serious nature of storm threat, it is critical to not overstate risks. Multiple interviewees told us that their trust in information sources had been negatively afected based on their perception, whether true or not, that the risk of previous hurricanes had been exaggerated. For example, one told us:", "spans": "[{\"corpusId\": 248318531, \"span\": \"our interviewees\", \"start\": 333, \"end\": 333}, {\"corpusId\": 248318531, \"span\": \"This research\", \"start\": 532, \"end\": 532}, {\"corpusId\": 123027525, \"span\": \"[81]\", \"start\": 766, \"end\": 770}, {\"corpusId\": 67767876, \"span\": \"[127]\", \"start\": 775, \"end\": 780}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "34705", "title": "Insights and Opportunities for HCI Research into Hurricane Risk Communication", "sectionTitle": "Efective risk communication requires many forms of knowledge and expertise", "text": "The signifcant amount of expertise that is utilized by forecasters to model and project hurricane threat and impacts can create the impression that the information they produce is somehow neutral or merely technical in nature. Indeed, prior work has demonstrated that risk information can \"hide the basic normative questions essential to ... decision-making in the mystique of statistics\" [39]. One efect of this is to create a counterproductive hierarchy between experts and the local knowledge and lived experiences of at-risk communities [2] [58] [75]. However, any efort to quantify complex phenomena such as the potential impact of storms on local communities will necessarily involve judgment calls and value-laden decisions [118]. These concerns align with work in HCI and critical data studies that seek to unpack and mitigate the various ways in which data standards, algorithms, and other socio-technical processes contain biases and assumptions that refect the interest and worldviews of those who create them, simultaneously excluding and marginalizing other perspectives [9] [43] [62] [63] [94]. Risk communication is often conceived of as a process whereby experts, such as forecasters and meteorologists, transfer knowledge about potential threats to the public for their response [4] [30]. This one-way communication, referred to variously as the broadcast, defcit, or transmission model, has come under scrutiny from various directions, but is still largely characteristic of many risk communication processes [30] [114]. Critiques of these approaches argue that science and risk-intensive protective action design problems are inherently interdisciplinary and require more knowledge than any single person or discipline possesses [3] and that knowledge relevant to hurricane risk is distributed among residents of afected areas as much as scientists and other experts. New insights, ideas, and methods for communicating and activating hurricane risk information will arise by bringing diferent, even contested, points of view together to create a shared or at least collective understanding among those participants of a hurricane decision-making process. Risk-informed decision-making should be conceived of as a series of personal interactions with information tools and artifacts mediated by familiar groups of people and knowledge communities [3]. New technologies, artifacts, workfows, and participatory processes should aford those exposed to hurricane risk to contribute to the framing and resolving the complex problem of risk communication and protective action.", "spans": "[{\"corpusId\": 199442539, \"span\": \"[9]\", \"start\": 1084, \"end\": 1087}, {\"corpusId\": 218483077, \"span\": \"[94]\", \"start\": 1103, \"end\": 1107}, {\"corpusId\": 143477909, \"span\": \"[4]\", \"start\": 1296, \"end\": 1299}, {\"corpusId\": 154728348, \"span\": \"[30]\", \"start\": 1527, \"end\": 1531}, {\"corpusId\": 39760445, \"span\": \"[114]\", \"start\": 1532, \"end\": 1537}, {\"corpusId\": 45842, \"span\": \"[3]\", \"start\": 1748, \"end\": 1751}, {\"corpusId\": 45842, \"span\": \"[3]\", \"start\": 2365, \"end\": 2368}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "34706", "title": "Insights and Opportunities for HCI Research into Hurricane Risk Communication", "sectionTitle": "Future work.", "text": "Second, HCI scholars have developed an active area of research in the areas of visualizing uncertainty. This work may be relevant to developing alternative ways of accomplishing the risk communication goals of the cone graphic and spaghetti models [44] [54] [60]. One study has even explored how certain forms of graphical interaction may support science education goals by helping users learn to improve their ability to evaluate uncertainty in other contexts [53]. Research in the feld of risk communication has argued for almost two decades that providing users with information about the degree and source of uncertainty in forecast models improves their trust in information sources and supports decision-making [88]. Yet more work remains to be done to develop approaches to doing so that inform rather than confuse users. ", "spans": "[{\"corpusId\": 248318531, \"span\": \"This work\", \"start\": 113, \"end\": 113}, {\"corpusId\": 7851900, \"span\": \"[44]\", \"start\": 248, \"end\": 252}, {\"corpusId\": 9377480, \"span\": \"[60]\", \"start\": 258, \"end\": 262}, {\"corpusId\": 409606, \"span\": \"[53]\", \"start\": 461, \"end\": 465}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "34707", "title": "Insights and Opportunities for HCI Research into Hurricane Risk Communication", "sectionTitle": "Future work.", "text": "HCI has already contributed important fndings to understanding how people share visual imagery of storm impacts on social media, including the importance of contextualization to one's local area and of representing uncertainty [11]. These fndings may be built upon further through augmented or virtual reality techniques that have been experimented with in science education and visualizations about climate change and disaster [10]. The Weather Channel has also used these tools to communicate disaster risk to the public [56]. AR/VR tools have also been used by HCI research into science education [106]. Such approaches ofer the potential to deliver contextualized risk information to the public in ways that includes familiar local landmarks and settings, which is thought to improve user understanding and trust. Finally, including information about vulnerable communities or public resources is another tactic that may be useful. Communication of vulnerability ahead of storm arrival could provide additional information to users about potential impacts of the storm in ways that support decision-making or improved understanding of hurricane risk.", "spans": "[{\"corpusId\": 140227467, \"span\": \"[11]\", \"start\": 227, \"end\": 231}, {\"corpusId\": 182213723, \"span\": \"[10]\", \"start\": 428, \"end\": 432}, {\"corpusId\": 140261723, \"span\": \"[106]\", \"start\": 600, \"end\": 605}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "34708", "title": "Insights and Opportunities for HCI Research into Hurricane Risk Communication", "sectionTitle": "Future work.", "text": "Top-down approaches to addressing this issue include working to craft or amplify messaging from ofcial sources in ways that ensure reliable information is more visible or resonant with target audiences than other sources. For example, work in crisis informatics has recommended useful practices for sharing ofcial information over social media, in particular how the inclusion of details such as geo-location, location-referencing information, and situational update categories may, if judiciously employed, help afected communities to establish situational awareness [121] [122] [134]. An example of a conscientiously constructed tweet that applies a combination of geo-location and situational update information: \"Fire Warning for Love Co. People east of Oswalt rd near/ Mariette to evacuate to the east\" [121]. Journalists, and in particular broadcast meteorologists, also play an important role in coping with the volume of information, in providing context and explanation for ofcial information. They also engage with information on social media and can help to combat misinformation and rumors [123]. Further work in applying these insights to the hurricane risk communication space could substantially help ensure lifesaving information reaches the public during storms.", "spans": "[{\"corpusId\": 107320743, \"span\": \"[121]\", \"start\": 568, \"end\": 573}, {\"corpusId\": 53227924, \"span\": \"[134]\", \"start\": 580, \"end\": 585}, {\"corpusId\": 107320743, \"span\": \"[121]\", \"start\": 808, \"end\": 813}, {\"corpusId\": 5046314, \"span\": \"[123]\", \"start\": 1102, \"end\": 1107}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "34709", "title": "Insights and Opportunities for HCI Research into Hurricane Risk Communication", "sectionTitle": "Embracing uncertainty", "text": "Much of the discussion about uncertainty in science and risk communication treats uncertainty as problematic, or as a challenge to be overcome [119]. Hence there is intense focus on identifying and reducing sources of uncertainty in risk models and developing efective means of communicating the remainder. While such eforts are no doubt essential, there are several strands of work in HCI that explore the benefts of engaging with uncertainty. Research in the area of ambiguous design, for example, has argued that purposeful inclusion of ambiguity can support deeper appropriation of complex technologies by users [42]. Game design rests on careful use of uncertainty to create tension, challenge, and engagement from participants [25]. Prior crisis informatics research in food risk visualization has explored the role of serious games and deliberative risk communication strategies to support deeper understanding of complex information about disaster [116]. Such approaches also show promise in the context of tropical storm risk communication [12].", "spans": "[{\"corpusId\": 218483602, \"span\": \"[119]\", \"start\": 143, \"end\": 148}, {\"corpusId\": 928018, \"span\": \"[42]\", \"start\": 616, \"end\": 620}, {\"corpusId\": 7947115, \"span\": \"[116]\", \"start\": 956, \"end\": 961}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "34710", "title": "Insights and Opportunities for HCI Research into Hurricane Risk Communication", "sectionTitle": "Future work.", "text": "When considering uncertainty in the context of hurricane risk communication, several approaches can be adopted from HCI. First, many hurricane risk graphics tend to highlight the certainty of forecasts rather than the uncertainty. For example the cone and spaghetti plots are among the most common visualizations of hurricane track forecasts. Yet the representations of uncertainty they provide, if any, are often difculty to assess. The ofcial NHC track forecast cone graphics (typically) include a text disclaimer at the top that reads: \"Note: The cone contains the probable path of the storm center but does not show the size of the storm. Hazardous conditions can occur outside of the cone. \" Yet, most other depictions of the cone by news and media organizations do not include the disclaimer, nor any alternative. Spaghetti plots are non-standardized and unregulated by government organizations, and in many media representations do not even ofer the model names corresponding to each forecast track, much less associated probabilities or uncertainties. Thus, there is much opportunity for HCI and information visualization research to continue studying efective methods for uncertainty visualization approaches for hurricane forecasts [20] [105] [109] [113] [133].", "spans": "[{\"corpusId\": 65445057, \"span\": \"[20]\", \"start\": 1242, \"end\": 1246}, {\"corpusId\": 7832525, \"span\": \"[109]\", \"start\": 1253, \"end\": 1258}, {\"corpusId\": 12061004, \"span\": \"[133]\", \"start\": 1265, \"end\": 1270}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "34711", "title": "Insights and Opportunities for HCI Research into Hurricane Risk Communication", "sectionTitle": "Participatory design of risk information products", "text": "5.5.2 Future work. Some members of the public we spoke to about their information-seeking behavior described developing a range of intricate and intentional hurricane risk information processes specifc for their decision needs, risk tolerance, and possible protective actions. This was particularly true for those who had lived in the same area for a signifcant period of time and experienced multiple major storm events. Indeed, despite stereotypes of the public being irrational, uninformed, or helpless victims during emergencies, decades of research have shown that people are likely to behave rationally, according to available information, during crises [40]. The complex approaches developed by some members of the public typically entailed networks of hyper-local knowledge communities, social cues, employer protocols, national and local news media, social media, weather apps, and government alert subscriptions. Engaging such \"leading users\" in participatory processes around the evaluation and improvement of risk information tools could lead to novel insights and improved design. In addition, participatory design processes may help shift design processes away from scientifc proof, technical feasibility, and institutional viability that experts focus on, and toward more practical information needs of the public during storms [97]. Participatory design of hurricane risk information products would allow participants to deliberate about issues of hurricane risk that directly afect them, their relations, or their sources of livelihood. Involving those considered \"non-experts\" in hurricane risk information design processes is therefore a strategy for ensuring that concern for the public good is placed ahead of the success and reputation of experts or their organizations [39]. Evidence from related felds suggest that this may further legitimize the development and implementation of hurricane risk information, tools, policies, and plans [66] [129]. The co-construction of knowledge that can occur when experts and at-risk communities collaborate around issues characterized by deep uncertainty has the potential to rebalance priorities and power relationships between these groups in favor of more productive partnerships and increased public safety [116] [131]. 5.6 Designing for diferent audiences 5.6.1 Background. As discussed in Section 4.4, people's information needs as well as how they seek out and interpret storm information vary widely. Our interviews with people who had experienced hurricanes further reinforced the fnding that \"the public\" is a diverse set of groups with distinct needs [82] [83]. These needs aren't often aligned with the original design goals of an existing information product or those of other users, particularly experts in the weather forecast community or emergency response. Our interviews with staf of the National Hurricane Center found that while some efort is made to provide specialized information to some groups, such as mariners, there is signifcant opportunity to further develop products that more specifcally target particular user groups' needs. Such needs may be determined by residential or work location, economic status, technology use, and disability status. Further research into hurricane risk information, along with standard human-centered design techniques such as persona development and user-journey tracking, may assist in determining how to meaningfully segment \"the public\" into user groups to inform the efective design of hurricane risk information for diverse audiences.", "spans": "[{\"corpusId\": 145653495, \"span\": \"[40]\", \"start\": 660, \"end\": 664}, {\"corpusId\": 26089407, \"span\": \"[66]\", \"start\": 1960, \"end\": 1964}, {\"corpusId\": 84447022, \"span\": \"[129]\", \"start\": 1965, \"end\": 1970}, {\"corpusId\": 7947115, \"span\": \"[116]\", \"start\": 2273, \"end\": 2278}, {\"corpusId\": 248318531, \"span\": \"Our interviews\", \"start\": 2485, \"end\": 2485}, {\"corpusId\": 54539705, \"span\": \"[83]\", \"start\": 2629, \"end\": 2633}, {\"corpusId\": 248318531, \"span\": \"Our interviews\", \"start\": 2851, \"end\": 2851}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "34712", "title": "Insights and Opportunities for HCI Research into Hurricane Risk Communication", "sectionTitle": "Participatory design of risk information products", "text": "Here we demonstrate the potential through examination of two user groups. 5.6.2 Future work. First, research in disaster risk communication has identifed important diferences in information-seeking behavior needs between disabled and non-disabled user groups [120]. For example, one study has found that hearing-impaired persons rely most on friends and family for hurricane risk information, while non-hearing-impaired persons with disabilities rely on television sources more than internet sources [72]. At present, most risk information sources available to the public are not geared towards people with disabilities [101], which can result in a lack of targeted services and assistance to these users [128]. HCI has a strong tradition of research in the area of accessibility that stands to contribute to developing a more robust understanding of how hurricane risk information design can better meet the needs of people with disabilities. Recent work in this feld suggests that such investigations would be best accomplished through extended and iterative collaboration with people with disabilities [8].", "spans": "[{\"corpusId\": 7196725, \"span\": \"[120]\", \"start\": 259, \"end\": 264}, {\"corpusId\": 201359875, \"span\": \"[101]\", \"start\": 620, \"end\": 625}, {\"corpusId\": 109503102, \"span\": \"[128]\", \"start\": 705, \"end\": 710}, {\"corpusId\": 140445039, \"span\": \"[8]\", \"start\": 1105, \"end\": 1108}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "34713", "title": "Insights and Opportunities for HCI Research into Hurricane Risk Communication", "sectionTitle": "Participatory design of risk information products", "text": "Second, hurricane risk has an inherently spatial character. Risk information is therefore most actionable when it is specifc to users' locations [70]. Our interviews with both staf of the National Hurricane Center and members of the public raised the opportunity for hurricane risk information products to be further localized in order to assist the public in locating the hazards and potential impacts that are relevant to where they live and work [52] [71]. What is geographically relevant is infuenced by user-specifc factors, such as risk perception, the infuence of neighbors, residence construction, access to transportation, awareness of evacuation zones, and media reference to local landmarks [124]. Many of our interviewees noted the difculty in accessing localized forecasts and protective action recommendations from government information products and social media posts, highlighting that ofcial hurricane risk maps are typically at the regional or national scale. HCI work in areas such as geo-visualization [41] [49] thus stands to support users by developing products and interfaces that deliver localized information.", "spans": "[{\"corpusId\": 144747708, \"span\": \"[70]\", \"start\": 145, \"end\": 149}, {\"corpusId\": 248318531, \"span\": \"Our interviews\", \"start\": 165, \"end\": 165}, {\"corpusId\": 147294063, \"span\": \"[52]\", \"start\": 449, \"end\": 453}, {\"corpusId\": 5184129, \"span\": \"[71]\", \"start\": 454, \"end\": 458}, {\"corpusId\": 26088027, \"span\": \"[124]\", \"start\": 702, \"end\": 707}, {\"corpusId\": 248318531, \"span\": \"our interviewees\", \"start\": 733, \"end\": 733}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "34714", "title": "Insights and Opportunities for HCI Research into Hurricane Risk Communication", "sectionTitle": "CONCLUSION", "text": "Over the past fve decades tropical cyclones have, on average, killed 10,000 people and caused $15 billion dollars in damage a year [37]. These impacts are only predicted to increase as a result of anthropogenic climate change and continued population growth and urban development in storm prone areas [55] [67]. Improving the ways in which science can help at-risk communities understand, prepare for, and mitigate the impacts of major storm events is thus a critical task, and one to which HCI can make important contributions. In this paper we provide an overview of an initial research agenda for HCI that focuses on communicating risk information to the public during the predictive phase of storms. As HCI research in this space continues to develop, we anticipate that further opportunities will develop and that we may also take on related questions, such as risk communications focused primarily in urban and regional planning decisions aimed at mitigating storm risk, rather than taking protective action in the lead-up period. Inasmuch as we argue that HCI can support this agenda, we also believe that our feld would be enriched through focus on these issues. Questions of representation of uncertainty, trust in information, and the human relationship to the environment are critical areas of work across HCI that research into tropical storm risk communication may inform.", "spans": "[{\"corpusId\": 79204966, \"span\": \"[55]\", \"start\": 301, \"end\": 305}, {\"corpusId\": 218688448, \"span\": \"[67]\", \"start\": 306, \"end\": 310}, {\"corpusId\": 248318531, \"span\": \"this paper\", \"start\": 542, \"end\": 542}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 19}
{"paperId": "679c780127ce31f2602c3cb5bb4c3ab93ff0eab8", "title": "InfoNice: Easy Creation of Information Graphics", "venue": "International Conference on Human Factors in Computing Systems", "year": 2018, "citationCount": 55, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3173574.3173909?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3173574.3173909, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2018-04-21", "authors": [{"authorId": "2118375601", "name": "Yun Wang"}, {"authorId": "46702036", "name": "Haidong Zhang"}, {"authorId": "2115528552", "name": "He Huang"}, {"authorId": "2145308192", "name": "Xi Chen"}, {"authorId": "3272273", "name": "Q. Yin"}, {"authorId": "2068251464", "name": "Zhitao Hou"}, {"authorId": "46334641", "name": "D. Zhang"}, {"authorId": "153889459", "name": "Qiong Luo"}, {"authorId": "2300486168", "name": "Huamin Qu"}], "abstract": null, "corpusId": "5077303", "paragraphs": [{"paragraphId": "72195", "title": "InfoNice: Easy Creation of Information Graphics", "sectionTitle": "INTRODUCTION", "text": "Compared with traditional visualizations, information graphics (also known as infographics) [16] are specifically designed to serve a presentation purpose rather than data exploration and analysis [22]. In order to enhance data communication, infographics often utilize embellished versions of common chart types [21,36]. The visual embellishments usually include pictographic elements [15], textual annotations [30], and elaborately designed figures and imageries [1,9,20]. When incorporating appropriate embellishments, infographics can effectively convey messages, present insights, and tell stories about data in an aesthetically pleasing, memorable, and engaging style [1,15,17,22,23]. As a result, infographics have become increasingly popular in a variety of fields. The demands for crafting infographics have gone beyond graphic designers and visualization experts. Nowadays, non-experts also have a strong desire to add impressive infographic visualizations to data reports, business dashboards, or news articles.", "spans": "[{\"corpusId\": 8738875, \"span\": \"[22]\", \"start\": 197, \"end\": 201}, {\"corpusId\": 10207500, \"span\": \"[21,\", \"start\": 313, \"end\": 317}, {\"corpusId\": 51951717, \"span\": \"36]\", \"start\": 317, \"end\": 320}, {\"corpusId\": 5657755, \"span\": \"[15]\", \"start\": 386, \"end\": 390}, {\"corpusId\": 17645166, \"span\": \"[30]\", \"start\": 412, \"end\": 416}, {\"corpusId\": 195346232, \"span\": \"[1,\", \"start\": 465, \"end\": 468}, {\"corpusId\": 15218177, \"span\": \"9,\", \"start\": 468, \"end\": 470}, {\"corpusId\": 195346232, \"span\": \"[1,\", \"start\": 674, \"end\": 677}, {\"corpusId\": 5657755, \"span\": \"15,\", \"start\": 677, \"end\": 680}, {\"corpusId\": 8585458, \"span\": \"17,\", \"start\": 680, \"end\": 683}, {\"corpusId\": 8738875, \"span\": \"22,\", \"start\": 683, \"end\": 686}, {\"corpusId\": 8545110, \"span\": \"23]\", \"start\": 686, \"end\": 689}]", "conference": "chi", "year": 2018, "likelyRelatedWorkSection": false, "refCount": 9}, {"paragraphId": "72196", "title": "InfoNice: Easy Creation of Information Graphics", "sectionTitle": "INTRODUCTION", "text": "In recent years, advanced visualization authoring systems, such as Lyra [34], iVisDesigner [31], iVoLVER [28], and DDG [21], have been developed to facilitate the creation of data-driven infographics. To enable highly expressive and customized designs, these systems usually provide a flexible, but complicated design environment. Consequently, although such authoring environments are familiar to graphic designers or visualization experts, they are much more difficult to use for general users without strong design background.", "spans": "[{\"corpusId\": 32370368, \"span\": \"[34]\", \"start\": 72, \"end\": 76}, {\"corpusId\": 12627199, \"span\": \"[31]\", \"start\": 91, \"end\": 95}, {\"corpusId\": 6429508, \"span\": \"[28]\", \"start\": 105, \"end\": 109}, {\"corpusId\": 10207500, \"span\": \"[21]\", \"start\": 119, \"end\": 123}]", "conference": "chi", "year": 2018, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "72197", "title": "InfoNice: Easy Creation of Information Graphics", "sectionTitle": "Information Graphics", "text": "Information graphics convey messages behind data engagingly [9]. While the forms of infographics greatly diverge, we focus on one of the most common categories, variations of common data visualizations with visual embellishments. Traditionally, visual embellishments are considered harmful [38]. Visualizations are usually kept plain for the effectiveness of data analysis. Recently, researchers have started to reveal the value of visual embellishments in data communication. For example, Bateman et al. [1] find the recall of embellished charts is significantly higher than plain charts. Haroz et al. [15] learn that ISOTYPE charts are equal to plain charts in terms of reading speed and accuracy, and the added visual information makes them more memorable. Others [5,6,7,35,36] also conclude that appropriate embellishments, such as color and the inclusion of recognizable objects, can increase memorability of visualizations. Besides, Byrne et al. find that figurative elements can effectively provide context, show content, and label data [9]. While these studies answer the question of why we need custom infographics, we aim to solve the problem of how to enable general users to easily create data-driven infographics to enhance data presentation and communication.", "spans": "[{\"corpusId\": 15218177, \"span\": \"[9]\", \"start\": 60, \"end\": 63}, {\"corpusId\": 5225463, \"span\": \"[38]\", \"start\": 290, \"end\": 294}, {\"corpusId\": 195346232, \"span\": \"[1]\", \"start\": 505, \"end\": 508}, {\"corpusId\": 5657755, \"span\": \"[15]\", \"start\": 603, \"end\": 607}, {\"corpusId\": 17643653, \"span\": \"[5,\", \"start\": 767, \"end\": 770}, {\"corpusId\": 15911191, \"span\": \"6,\", \"start\": 770, \"end\": 772}, {\"corpusId\": 2936091, \"span\": \"7,\", \"start\": 772, \"end\": 774}, {\"corpusId\": 5821481, \"span\": \"35,\", \"start\": 774, \"end\": 777}, {\"corpusId\": 51951717, \"span\": \"36]\", \"start\": 777, \"end\": 780}, {\"corpusId\": 15218177, \"span\": \"[9]\", \"start\": 1044, \"end\": 1047}]", "conference": "chi", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "72198", "title": "InfoNice: Easy Creation of Information Graphics", "sectionTitle": "Design Process Paradigms", "text": "The typical design process of creating visualizations usually includes multiple steps, namely data analysis, filtering, encoding or mapping, and rendering [2,10,11,12,32]. Among them, data mapping is a key part. To understand the mapping process, Mendez et al. proposed bottom-up and top-down paradigms to categorize common visualization tools [27]. The bottomup paradigm describes the process of creating visualization by manipulating individual data points and attributes, while the top-down one focuses on the overall mapping. Through the user study comparing the use of Tableau Desktop and iVoLVER [28] as representatives of the two paradigms, the authors find that the top-down paradigm enables speedy exploration of visualization solutions that users are acquainted with, while the bottom-up one requires initial thinking about the intended visualization and facilitates creative and critical thinking [27]. Our mark customization approach follows a hybrid paradigm to achieve a balance between design speed and flexibility. From the top down, users can initiate from a plain chart quickly instead of authoring from scratch; from the bottom up, during mark customization, we enable users to design data mapping and construct marks with visual elements without changing the chart layout to achieve flexible and expressive infographic designs.", "spans": "[{\"corpusId\": 612198, \"span\": \"[2,\", \"start\": 155, \"end\": 158}, {\"corpusId\": 5319048, \"span\": \"11,\", \"start\": 161, \"end\": 164}, {\"corpusId\": 206372769, \"span\": \"12,\", \"start\": 164, \"end\": 167}, {\"corpusId\": 206805304, \"span\": \"32]\", \"start\": 167, \"end\": 170}, {\"corpusId\": 22039331, \"span\": \"[27]\", \"start\": 344, \"end\": 348}, {\"corpusId\": 6429508, \"span\": \"[28]\", \"start\": 602, \"end\": 606}, {\"corpusId\": 22039331, \"span\": \"[27]\", \"start\": 908, \"end\": 912}]", "conference": "chi", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "72199", "title": "InfoNice: Easy Creation of Information Graphics", "sectionTitle": "Data Visualization Tools", "text": "Visualization authoring systems and tools have been developed to facilitate the creation of data visualization. For example, Polaris [37], Tableau [26], and Many Eyes [40] can help users to encode data with different visualization forms. These tools enable general users to create visualizations quickly without specialized programming knowledge, but tend to be less flexible and less expressive than code-generated visualization with programming languages such as D3 [8] and Processing [4].", "spans": "[{\"corpusId\": 221311948, \"span\": \"[37]\", \"start\": 133, \"end\": 137}, {\"corpusId\": 13457388, \"span\": \"[26]\", \"start\": 147, \"end\": 151}, {\"corpusId\": 2656946, \"span\": \"[40]\", \"start\": 167, \"end\": 171}, {\"corpusId\": 14970263, \"span\": \"[8]\", \"start\": 468, \"end\": 471}]", "conference": "chi", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "72200", "title": "InfoNice: Easy Creation of Information Graphics", "sectionTitle": "Data Visualization Tools", "text": "SageBrush [33] is a pioneering tool for creating customized visualizations by performing simple drag-and-drop operations. More advanced techniques, including Lyra [34] and iVisDesigner [31], enable more expressive custom visualization designs without writing any code. These tools are based on graphical specifications [41] or a declarative model [18]. However, users can only change a small set of style parameters, such as color, fonts, scales, and layouts. The ability to create novel infographic design is still limited. Kim et al. develop Data-Driven Guides (DDG), a technique that allows users to create infographics by freeform drawing and bind data with self-created shapes to achieve complex and expressive infographic designs [21]. However, targeting professional graphical designers, it adopts a graphical design interface similar to Adobe Illustrator, which increases the difficulty of creating infographics for general users. In addition, the system is separated from data exploration and analysis, which requires much effort to process the data to the specific data structure to conduct creative designs.", "spans": "[{\"corpusId\": 6115404, \"span\": \"[33]\", \"start\": 10, \"end\": 14}, {\"corpusId\": 32370368, \"span\": \"[34]\", \"start\": 163, \"end\": 167}, {\"corpusId\": 12627199, \"span\": \"[31]\", \"start\": 185, \"end\": 189}, {\"corpusId\": 15117994, \"span\": \"[18]\", \"start\": 347, \"end\": 351}, {\"corpusId\": 10207500, \"span\": \"[21]\", \"start\": 736, \"end\": 740}]", "conference": "chi", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 5}], "paragraphCount": 6}
{"paperId": "8382ff3a2db6ce15e0650498162ec47b9c89a47b", "title": "Philosophers Living with the Tilting Bowl", "venue": "International Conference on Human Factors in Computing Systems", "year": 2018, "citationCount": 99, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3173574.3173668?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3173574.3173668, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Sociology", "Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2018-04-19", "authors": [{"authorId": "1783186", "name": "Ron Wakkary"}, {"authorId": "2566792", "name": "Doenja Oogjes"}, {"authorId": "2116203550", "name": "Henry W. J. Lin"}, {"authorId": "3904836", "name": "Sabrina Hauser"}], "abstract": null, "corpusId": "5041159", "paragraphs": [{"paragraphId": "40914", "title": "Philosophers Living with the Tilting Bowl", "sectionTitle": "INTRODUCTION", "text": "In addition to our material speculation approach, we recruited trained philosophers who have the competencies (e.g. critical thinking, ethical training, philosophical vocabulary, etc.) to help us speculate, reveal, and describe human-technology relations with the Tilting Bowl. We believe speculation of this nature requires the bringing together of lived-with experiences and philosophical work. We refer to this additional methodological approach as cospeculation. Co-speculation is the recruiting and participation of study participants who are well positioned to actively and knowingly speculate with us in our inquiry in ways that we cannot alone. This approach aligns with increasing interest to involve study participants in shared speculations in design research (e.g. [5,8,42]).", "spans": "[{\"corpusId\": 5041159, \"span\": \"this additional method\", \"start\": 431, \"end\": 431}, {\"corpusId\": 5041159, \"span\": \"This approach\", \"start\": 666, \"end\": 666}, {\"corpusId\": 9958991, \"span\": \"8,\", \"start\": 780, \"end\": 782}, {\"corpusId\": 28077713, \"span\": \"42]\", \"start\": 782, \"end\": 785}]", "conference": "chi", "year": 2018, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "40915", "title": "Philosophers Living with the Tilting Bowl", "sectionTitle": "Philosophies of technology and HCI", "text": "Drawing on the philosophies of technology such as those of Ihde, Verbeek, Borgmann, and Latour [1,15,18,36] is not new to HCI research (see for example [9]). Postphenomenology specifically has been used mostly as an analytical lens such as Fallman's argument for new values in HCI [10]. Research like Odom et al. [20] describes attachment as a key factor in human-technology relations for future design implementations. Wiltse and Stolterman [44] use a postphenomenological framework to analyze the interaction architectures of instant messaging and file sharing revealing how these interactive spaces mediate human activity. Pierce and Paulos [26][27][28] aim to describe the materializing of technologies and its implications from the material awareness of everyday things to embodied relations within technologies. Furthermore, concepts like personal informatics [24] have been analytically reexamined through the utilization of a postphenomenological framework to discuss the changing agency of users. More broadly, Tromp et al. [33], reflect on the social consequences of mediated relations and argue that designers should make more informed decisions to design for socially responsible behavior.", "spans": "[{\"corpusId\": 141895782, \"span\": \"18,\", \"start\": 101, \"end\": 104}, {\"corpusId\": 20277755, \"span\": \"[9]\", \"start\": 152, \"end\": 155}, {\"corpusId\": 21408057, \"span\": \"[44]\", \"start\": 442, \"end\": 446}, {\"corpusId\": 12095554, \"span\": \"[27]\", \"start\": 648, \"end\": 652}, {\"corpusId\": 16641522, \"span\": \"[28]\", \"start\": 652, \"end\": 656}, {\"corpusId\": 11522727, \"span\": \"[24]\", \"start\": 866, \"end\": 870}, {\"corpusId\": 12984918, \"span\": \"[33]\", \"start\": 1033, \"end\": 1037}]", "conference": "chi", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "40916", "title": "Philosophers Living with the Tilting Bowl", "sectionTitle": "Philosophies of technology and HCI", "text": "In previous work, we have drawn on postphenomenology and investigated the ontological gap between humans and things in thing-oriented inquiries [42], social practices [39], and the representation of things from a postphenomenological perspective [25]. Our investigation in this paper shares similar concerns and starting points as those discussed above however dramatically take a different turn by framing the inquiry as a design driven philosophical inquiry.", "spans": "[{\"corpusId\": 28077713, \"span\": \"[42]\", \"start\": 144, \"end\": 148}, {\"corpusId\": 21642936, \"span\": \"[25]\", \"start\": 246, \"end\": 250}, {\"corpusId\": 5041159, \"span\": \"Our investigation\", \"start\": 269, \"end\": 269}, {\"corpusId\": 5041159, \"span\": \"this paper\", \"start\": 283, \"end\": 283}]", "conference": "chi", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "40917", "title": "Philosophers Living with the Tilting Bowl", "sectionTitle": "THE TILTING BOWL", "text": "We were motivated in the design of the Tilting Bowl for it to be a vastly familiar and mundane object like a bowl, that unquestionably is part of everyday life. At the same time, we aimed through digital technologies to make the bowl unfamiliar, challenging expectations and assumed roles, however in such a way as not to overshadow its familiarity. This approach to defamiliarizing was with the intention of making it simultaneously familiar and strange, and therefore best open to reflection and analysis of the particularities of non-normative perceptions of humantechnology relations and qualities of experience. To support these aims and in keeping with a counterfactual artifact [41] and research product [23], we crafted the Tilting Bowl with a great deal of purpose and quality so it would fit with and be robust enough for everyday settings over time. Additionally, we drew on ideas of unawareness [22], and unselfconscious interaction [38] to guide the design in which the artifact required no human attention nor user interface to function, and the Tilting Bowl suggested more incremental engagements or intersections rather than explicit interaction. Furthermore, it could easily become a part of ad hoc and changing configurations in a home with other objects in what is referred to as ensembles [22,38]. In these respects, the Tilting Bowl was designed specifically to inquire through lived-with experience into the types and qualities of relationships beyond use and functionality that may emerge.", "spans": "[{\"corpusId\": 5041159, \"span\": \"This approach\", \"start\": 363, \"end\": 363}, {\"corpusId\": 53638579, \"span\": \"[41]\", \"start\": 685, \"end\": 689}, {\"corpusId\": 14113629, \"span\": \"[23]\", \"start\": 711, \"end\": 715}, {\"corpusId\": 14795815, \"span\": \"[22]\", \"start\": 907, \"end\": 911}, {\"corpusId\": 4642113, \"span\": \"[38]\", \"start\": 945, \"end\": 949}, {\"corpusId\": 14795815, \"span\": \"[22,\", \"start\": 1309, \"end\": 1313}, {\"corpusId\": 4642113, \"span\": \"38]\", \"start\": 1313, \"end\": 1316}]", "conference": "chi", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "40918", "title": "Philosophers Living with the Tilting Bowl", "sectionTitle": "Background and commitments", "text": "There is no one postphenomenological approach rather it can be seen as an ongoing and related discourse and theoretical articulations that share much in common [16,32,36]. Further, these varying positions draw on phenomenology's prioritizing of the concreteness of human experience yet postphenomenology differs fundamentally from phenomenology in how it conceptualizes the role of technology. Postphenomenology also draws on and is related to a range of philosophies and studies of technology including Winner [45], Ihde [15], Borgmann [1], Feenberg [11] and Latour [18]. In this context, a critical position of postphenomenology is its critique of either separating humans from or conflating with technology [16,31,34].", "spans": "[{\"corpusId\": 15660866, \"span\": \"[45]\", \"start\": 511, \"end\": 515}, {\"corpusId\": 141895782, \"span\": \"[18]\", \"start\": 567, \"end\": 571}, {\"corpusId\": 60815965, \"span\": \"31,\", \"start\": 714, \"end\": 717}]", "conference": "chi", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "40919", "title": "Philosophers Living with the Tilting Bowl", "sectionTitle": "Methodological considerations for future work", "text": "Postphenomenological studies always include empirical work as a basis for philosophical reflection: Our study is clearly empirical however as stated earlier, we extend this commitment from postphenomenology by designing a new artifact tailored to the philosophical inquiry that moves from the retrospective to the generative. Relatedly, our material speculation and counterfactual artifact approach [41] addresses the avoidance of normative frameworks as a starting point for postphenomenological inquiries, and lastly our use of co-speculation offers a new empirical approach for postphenomenology (and interaction design). HCI offers a plethora of innovative and design oriented empirical approaches that we believe can readily be adapted to postphenomenology concerns from well-known methods like cultural probes [12] and experience prototyping [2] to more recent approaches like speculative enactments [8].", "spans": "[{\"corpusId\": 5041159, \"span\": \"Our study\", \"start\": 109, \"end\": 109}, {\"corpusId\": 53638579, \"span\": \"[41]\", \"start\": 399, \"end\": 403}, {\"corpusId\": 6481095, \"span\": \"[2]\", \"start\": 848, \"end\": 851}, {\"corpusId\": 9958991, \"span\": \"[8]\", \"start\": 906, \"end\": 909}]", "conference": "chi", "year": 2018, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "40920", "title": "Philosophers Living with the Tilting Bowl", "sectionTitle": "Methodological considerations for future work", "text": "Postphenomenological studies analyze the roles that technologies play in the relations between humans and world (human-technology relations: embodiment, alterity, hermeneutic, and background). This is the central concern of any postphenomenological inquiry. In our study, novel and rich descriptions emerged with respect to alterity and background relations in particular. As we discussed earlier, there is an emerging body of work that considers humantechnology relations in HCI [9,10,20,[24][25][26][27][28]33,42,44]. Additionally, much like our Tilting Bowl, design resarch has a history of making reflective artifacts that imply if not directly engage philsophical concerns like key earlier work such as Gaver et al's Drift Table [13] or Redstr\u00f6m et al's Chatterbox [30] and more recent research products like Odom et al's Photobox [21] and Pierce and Paulos' Obscura 1C Digital Camera [29].", "spans": "[{\"corpusId\": 5041159, \"span\": \"our study\", \"start\": 270, \"end\": 270}, {\"corpusId\": 20277755, \"span\": \"[9,\", \"start\": 480, \"end\": 483}, {\"corpusId\": 11522727, \"span\": \"[24]\", \"start\": 489, \"end\": 493}, {\"corpusId\": 21642936, \"span\": \"[25]\", \"start\": 493, \"end\": 497}, {\"corpusId\": 12095554, \"span\": \"[27]\", \"start\": 501, \"end\": 505}, {\"corpusId\": 16641522, \"span\": \"[28]\", \"start\": 505, \"end\": 509}, {\"corpusId\": 12984918, \"span\": \"33,\", \"start\": 509, \"end\": 512}, {\"corpusId\": 28077713, \"span\": \"42,\", \"start\": 512, \"end\": 515}, {\"corpusId\": 21408057, \"span\": \"44]\", \"start\": 515, \"end\": 518}, {\"corpusId\": 2037843, \"span\": \"[13]\", \"start\": 734, \"end\": 738}, {\"corpusId\": 10748061, \"span\": \"[30]\", \"start\": 770, \"end\": 774}, {\"corpusId\": 15251677, \"span\": \"[21]\", \"start\": 836, \"end\": 840}, {\"corpusId\": 16565196, \"span\": \"[29]\", \"start\": 890, \"end\": 894}]", "conference": "chi", "year": 2018, "likelyRelatedWorkSection": false, "refCount": 13}, {"paragraphId": "40921", "title": "Philosophers Living with the Tilting Bowl", "sectionTitle": "Methodological considerations for future work", "text": "Postphenomenological studies typically investigate how, in the relations that arise around a technology, a specific \"world\" is constituted, as well as a specific \"subject.\" This characteristic rests on the concept of relational ontology, asserting the hybrid nature of the inseparability of humans and technology. In our case, any understanding of the Tilting Bowl cannot be separated from the particular philosopher and their contexts and vice versa (their \"specific world\"). Additionally, given the concept of multistability, we expected variant interpretations of these hybrid relations that can be as contradictory as they are diverse, yet always represent their \"specific world\". We previously cited broader philosophical framings of HCI [2,5,14,37] that introduce notions of subject-object relations and embodiment. Recent work has investigated how designoriented practice can ground and further inform these notions, particularly embodiment relations, including somaesthetics [14] embodied practice [43] and more closely related investigations of relativistic investigations of wearables [6]. Such efforts hold value and insights for postphenomenological concerns.", "spans": "[{\"corpusId\": 6481095, \"span\": \"[2,\", \"start\": 743, \"end\": 746}, {\"corpusId\": 4228410, \"span\": \"14,\", \"start\": 748, \"end\": 751}, {\"corpusId\": 4228410, \"span\": \"[14]\", \"start\": 983, \"end\": 987}, {\"corpusId\": 9002198, \"span\": \"[43]\", \"start\": 1006, \"end\": 1010}]", "conference": "chi", "year": 2018, "likelyRelatedWorkSection": false, "refCount": 3}], "paragraphCount": 8}
{"paperId": "48bf1d216339ee13ed8e518eb67bf5fef9b001df", "title": "Enlivening Redundant Heads in Multi-head Self-attention for Machine Translation", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2021, "citationCount": 14, "openAccessPdf": {"url": "https://doi.org/10.18653/v1/2021.emnlp-main.260", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://aclanthology.org/2021.emnlp-main.260, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": null, "authors": [{"authorId": "2146333431", "name": "Tianfu Zhang"}, {"authorId": "4590286", "name": "Heyan Huang"}, {"authorId": "144579978", "name": "Chong Feng"}, {"authorId": "2148761004", "name": "Longbing Cao"}], "abstract": "Multi-head self-attention recently attracts enormous interest owing to its specialized functions, significant parallelizable computation, and flexible extensibility. However, very recent empirical studies show that some self-attention heads make little contribution and can be pruned as redundant heads. This work takes a novel perspective of identifying and then vitalizing redundant heads. We propose a redundant head enlivening (RHE) method to precisely identify redundant heads, and then vitalize their potential by learning syntactic relations and prior knowledge in the text without sacrificing the roles of important heads. Two novel syntax-enhanced attention (SEA) mechanisms: a dependency mask bias and a relative local-phrasal position bias, are introduced to revise self-attention distributions for syntactic enhancement in machine translation. The importance of individual heads is dynamically evaluated during the redundant heads identification, on which we apply SEA to vitalize redundant heads while maintaining the strength of important heads. Experimental results on widely adopted WMT14 and WMT16 English to German and English to Czech language machine translation validate the RHE effectiveness.", "corpusId": "243865417", "paragraphs": [{"paragraphId": "60240", "title": "Enlivening Redundant Heads in Multi-head Self-attention for Machine Translation", "sectionTitle": "Introduction", "text": "Recently, self-attention network (SAN) (Lin et al., 2017) has been applied to various natural language processing tasks. Instead of drawing distanceaware dependencies like recurrent neural network (Hochreiter and Schmidhuber, 1997) and convolutional neural network (Kim, 2014), SAN captures short-and long-range relations between elements. SAN involves all signals with a weighted averaging operation, which may incorporate too many unrelated elements to concentrates on specific relations. Recent work has modified SAN to enhance specific relation learning. For example, in (Shen et al., 2018), a directional self-attention network (DiSAN) uses one to multiple positional masks to model the asymmetric attention between two elements and capture context-aware relations for all tokens.  modeled the local information by revising the attention distribution with a learnable Gaussian bias to focus on neighboring relations. (Shaw et al., 2018) extended SAN to efficiently consider distinct representations of the relative linear position relations between sequence elements. However, the above approaches consider the multi-head SAN as a whole but ignore unbalanced contribution distributions between heads.", "spans": "[{\"corpusId\": 15280949, \"span\": \"(Lin et al., 2017)\", \"start\": 39, \"end\": 57}, {\"corpusId\": 1915014, \"span\": \"(Hochreiter and Schmidhuber, 1997)\", \"start\": 197, \"end\": 231}, {\"corpusId\": 9672033, \"span\": \"(Kim, 2014)\", \"start\": 265, \"end\": 276}, {\"corpusId\": 3725815, \"span\": \"(Shaw et al., 2018)\", \"start\": 922, \"end\": 941}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "60241", "title": "Enlivening Redundant Heads in Multi-head Self-attention for Machine Translation", "sectionTitle": "Related Work", "text": "One popular extension to the SAN is to revise attention distribution by static and dynamic biases. Different dimensions of biases have been considered, including directional relation (Shen et al., 2018) and localness (Sperber et al., 2018;Zhang et al., 2018a;. (Shen et al., 2018) improves SAN with directional masks and multidimensional features by explicitly revising attention distribution. In this paper, we focus on the explicit syntactic biases by proposing dependencyenhanced attention and local-phrase-enhanced attention. Several papers show that explicitly modeling dependency (Bastings et al., 2017;Nadejde et al., 2017) or phrase (Wang et al., 2017;Huang et al., 2018;Zhang et al., 2018bZhang et al., , 2020 is useful for tasks such as NMT. Related to our work, (Strubell et al., 2018) and (Hao et al., 2019) also modify parts of self-attention heads with syntactic information. However, they randomly assign heads instead of analysing the importance and function of each head in advance. (Sperber et al., 2018) restricts SAN with the neighboring elements and performs better for longer sequences in acoustic modeling and natural language inference tasks.  leverages Gaussian bias predicted by the query vector to dynamically model the localness for SAN.", "spans": "[{\"corpusId\": 19152001, \"span\": \"(Shen et al., 2018)\", \"start\": 183, \"end\": 202}, {\"corpusId\": 4427800, \"span\": \"(Sperber et al., 2018;\", \"start\": 217, \"end\": 239}, {\"corpusId\": 19152001, \"span\": \"(Shen et al., 2018)\", \"start\": 261, \"end\": 280}, {\"corpusId\": 243865417, \"span\": \"this paper\", \"start\": 407, \"end\": 407}, {\"corpusId\": 6206777, \"span\": \"(Bastings et al., 2017;\", \"start\": 586, \"end\": 609}, {\"corpusId\": 462553, \"span\": \"(Wang et al., 2017;\", \"start\": 641, \"end\": 660}, {\"corpusId\": 1437370, \"span\": \"Huang et al., 2018;\", \"start\": 660, \"end\": 679}, {\"corpusId\": 243865417, \"span\": \"our work\", \"start\": 771, \"end\": 771}, {\"corpusId\": 5068376, \"span\": \"(Strubell et al., 2018)\", \"start\": 773, \"end\": 796}, {\"corpusId\": 202539179, \"span\": \"(Hao et al., 2019)\", \"start\": 801, \"end\": 819}, {\"corpusId\": 4427800, \"span\": \"(Sperber et al., 2018)\", \"start\": 1000, \"end\": 1022}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 8}, {"paragraphId": "60242", "title": "Enlivening Redundant Heads in Multi-head Self-attention for Machine Translation", "sectionTitle": "Related Work", "text": "Other work analyzes the attention weights of different NMT models (Ghader and Monz, 2017;Voita et al., 2018;Tang et al., 2018;Raganato and Tiedemann, 2018). (Voita et al., 2019) considers how different heads correspond to specific relations and proves that redundant heads can be pruned without greatly decreasing translation performance. However, they disregard the full potential of redundant heads as in our SEA. (Li et al., 2018) realizes the diversity of multiple attention heads and introduces a disagreement regularization to explicitly encourage the diversity. Nevertheless, they do not realize that only partial individual heads are redundant, which is a prerequisite for optimizing multi-head diversity.", "spans": "[{\"corpusId\": 44062236, \"span\": \"Voita et al., 2018;\", \"start\": 89, \"end\": 108}, {\"corpusId\": 52984984, \"span\": \"Tang et al., 2018;\", \"start\": 108, \"end\": 126}, {\"corpusId\": 53596423, \"span\": \"Raganato and Tiedemann, 2018)\", \"start\": 126, \"end\": 155}, {\"corpusId\": 162183964, \"span\": \"(Voita et al., 2019)\", \"start\": 157, \"end\": 177}, {\"corpusId\": 53081097, \"span\": \"(Li et al., 2018)\", \"start\": 416, \"end\": 433}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "60243", "title": "Enlivening Redundant Heads in Multi-head Self-attention for Machine Translation", "sectionTitle": "Multi-head Self-attention", "text": "Multi-head SAN (Vaswani et al., 2017;Shaw et al., 2018;Shen et al., 2018; projects the input sequence to multiple subspaces (h attention heads), applies the scaled dot-product attention to the hidden states in each head, and then concatenates the output. For each self-attention head head i (1 \u2264 i \u2264 h) in the multi-head SAN for NMT, given an input sequence x = {x 1 , ..., x n }, each hidden state in the l-layer is constructed by attending to the states in the (l \u2212 1)-th layer. Specifically, the hidden states of (l \u2212 1)-th layer H l\u22121 \u2208 R n\u00d7d h are firstly transformed into the queries Q \u2208 R n\u00d7d h , the keys K \u2208 R n\u00d7d h , and the values V \u2208 R n\u00d7d h with three separate weight matrices, where d h represents the dimensionality of each head.", "spans": "[{\"corpusId\": 13756489, \"span\": \"(Vaswani et al., 2017;\", \"start\": 15, \"end\": 37}, {\"corpusId\": 3725815, \"span\": \"Shaw et al., 2018;\", \"start\": 37, \"end\": 55}, {\"corpusId\": 19152001, \"span\": \"Shen et al., 2018;\", \"start\": 55, \"end\": 73}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "60244", "title": "Enlivening Redundant Heads in Multi-head Self-attention for Machine Translation", "sectionTitle": "Enlivening Redundant Heads", "text": "After differing redundant heads from those important ones in the multi-head self-attention, we further enliven the redundant heads with a syntactic bias per Eq. (4) or Eq. (6) without interfering with the important head functions. (Voita et al., 2019) shows that redundant heads are mostly distributed in the lower encoder layers, meanwhile (Hao et al., 2019; shows that the bottom layer in the encoder, which directly takes word embedding as input, benefits more from modeling local relations. We evaluate the performance of applying our method on the low-and high-level encoder layers in the next section, and obtain the best performance when applying on the first encoder layer.  (Collins et al., 2005). The byte-pair encoding (BPE) toolkit 2 (Sennrich et al., 2016) is used with 32K merge operations. The 4-gram NIST BLEU score (Papineni et al., 2002) is used as the evaluation metric. We implement the proposed RHE and all the baselines on top of Transformer model (Vaswani et al., 2017) by using open-source toolkit OpenNMT (Klein et al., 2017). Please refer to the Appendix for more details of dataset and parameter setting . Table 1 shows the ablation study results of the Transformer enabled by the two proposed SEA mechanisms DEA and LPEA and the RHE approach. First, the Rows of \"+DEA\" and \"+LPE\" represent the models with all heads of the first encoder layer, including original important heads, are replaced by the syntax-enhanced attention networks DEA and LPEA respectively. Second, the RHE approach (containing the Rows of \"+DEA+RHE\" and \"+LPEA+RHE\" ) significantly lifts both DEA and LPEA mechanisms across all small and large language pairs. This tests the effectiveness of identifying and modifying redundant heads without interfering important head functions. RHE lifts the LPEA, which together i.e. LPEA+RHE substantially outperforms Transformer by +1.0 BLEU points on En\u2192De (WMT16), +0.96 BLEU points on En\u2192De (WMT14), and +0.81 BLEU points on En\u2192Cs (WMT16). These results demonstrate the efficacy and applicability of both SEA and RHE designs.", "spans": "[{\"corpusId\": 162183964, \"span\": \"(Voita et al., 2019)\", \"start\": 231, \"end\": 251}, {\"corpusId\": 202539179, \"span\": \"(Hao et al., 2019;\", \"start\": 341, \"end\": 359}, {\"corpusId\": 243865417, \"span\": \"our method\", \"start\": 545, \"end\": 545}, {\"corpusId\": 11142668, \"span\": \"(Collins et al., 2005)\", \"start\": 683, \"end\": 705}, {\"corpusId\": 1114678, \"span\": \"(Sennrich et al., 2016)\", \"start\": 746, \"end\": 769}, {\"corpusId\": 11080756, \"span\": \"(Papineni et al., 2002)\", \"start\": 832, \"end\": 855}, {\"corpusId\": 13756489, \"span\": \"(Vaswani et al., 2017)\", \"start\": 970, \"end\": 992}, {\"corpusId\": 16538528, \"span\": \"(Klein et al., 2017)\", \"start\": 1030, \"end\": 1050}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 8}, {"paragraphId": "60245", "title": "Enlivening Redundant Heads in Multi-head Self-attention for Machine Translation", "sectionTitle": "A.3 Effect of Syntax Parsing Quality", "text": "We compare the effect of two classical constituency tree parser tools, PCFGs-based Parser (Petrov and Klein, 2007) and Neural-based Parser (Kitaev and Klein, 2018), on the performance of the LPEA+RHE mechanism. Table A3 shows the reported parsing performance (F1 score) on the Penn Treebank WSJ test set (for English) and its corresponding translation BLEU score in this work.", "spans": "[{\"corpusId\": 1123594, \"span\": \"(Petrov and Klein, 2007)\", \"start\": 90, \"end\": 114}, {\"corpusId\": 19206893, \"span\": \"(Kitaev and Klein, 2018)\", \"start\": 139, \"end\": 163}, {\"corpusId\": 243865417, \"span\": \"this work\", \"start\": 375, \"end\": 375}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 6}
{"paperId": "73e851e42286030d7c511e3e74a01fbb0fb0c3b9", "title": "monoQA: Multi-Task Learning of Reranking and Answer Extraction for Open-Retrieval Conversational Question Answering", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2022, "citationCount": 9, "openAccessPdf": {"url": "https://aclanthology.org/2022.emnlp-main.485.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://aclanthology.org/2022.emnlp-main.485, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": null, "authors": [{"authorId": "2533998", "name": "S. Kongyoung"}, {"authorId": "145434248", "name": "Craig Macdonald"}, {"authorId": "1698205", "name": "I. Ounis"}], "abstract": "To address the Conversational Question Answering (ORConvQA) task, previous work has considered an effective three-stage architecture, consisting of a retriever, a reranker, and a reader to extract the answers. In order to effectively answer the users\u2019 questions, a number of existing approaches have applied multi-task learning, such that the same model is shared between the reranker and the reader. Such approaches also typically tackle reranking and reading as classification tasks. On the other hand, recent text generation models, such as monoT5 and UnifiedQA, have been shown to respectively yield impressive performances in passage reranking and reading. However, no prior work has combined monoT5 and UnifiedQA to share a single text generation model that directly extracts the answers for the users instead of predicting the start/end positions in a retrieved passage. In this paper, we investigate the use of Multi-Task Learning (MTL) to improve performance on the ORConvQA task by sharing the reranker and reader\u2019s learned structure in a generative model. In particular, we propose monoQA, which uses a text generation model with multi-task learning for both the reranker and reader. Our model, which is based on the T5 text generation model, is fine-tuned simultaneously for both reranking (in order to improve the precision of the top retrieved passages) and extracting the answer. Our results on the OR-QuAC and OR-CoQA datasets demonstrate the effectiveness of our proposed model, which significantly outperforms existing strong baselines with improvements ranging from +12.31% to +19.51% in MAP and from +5.70% to +23.34% in F1 on all used test sets.", "corpusId": "256461415", "paragraphs": [{"paragraphId": "35332", "title": "monoQA: Multi-Task Learning of Reranking and Answer Extraction for Open-Retrieval Conversational Question Answering", "sectionTitle": "Introduction", "text": "Research in Conversational Search and Conversational Question Answering (ConvQA) is of increasing interest. The ConvQA task (Choi et al., 2018;Reddy et al., 2019) consists in understanding the question based on a given conversational history, and extracting an answer from a given passage. This task is an extractive type of QA, meaning that the answer takes the form of a span in the provided passage, and can be successfully tackled by employing an extractive or generative reader. Extractive reader models (Qu et al., 2019a,b;Yeh and Chen, 2019) are typically employed, where the goal is to classify the start and end positions of the answer span in the given passage. In contrast, generative readers (Raffel et al., 2020;Khashabi et al., 2020; have demonstrated impressive results on the extractive QA tasks, where the goal is to generate tokens that are a subset of a passage. Recently, there has been more focus on retrieval as part of the ConvQA pipeline, known as Open-Retrieval Conversational Question Answering (ORConvQA). In this setting, the ORConvQA system needs to apply the ConvQA model upon passages retrieved from a large collection, given a question, before actually extracting the answer.", "spans": "[{\"corpusId\": 52057510, \"span\": \"(Choi et al., 2018;\", \"start\": 124, \"end\": 143}, {\"corpusId\": 52055325, \"span\": \"Reddy et al., 2019)\", \"start\": 143, \"end\": 162}, {\"corpusId\": 199577753, \"span\": \"Yeh and Chen, 2019)\", \"start\": 529, \"end\": 548}, {\"corpusId\": 204838007, \"span\": \"(Raffel et al., 2020;\", \"start\": 704, \"end\": 725}, {\"corpusId\": 218487109, \"span\": \"Khashabi et al., 2020;\", \"start\": 725, \"end\": 747}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "35333", "title": "monoQA: Multi-Task Learning of Reranking and Answer Extraction for Open-Retrieval Conversational Question Answering", "sectionTitle": "Introduction", "text": "To address the ORConvQA task, prior works (Qu et al., 2020(Qu et al., , 2021Liang et al., 2022) have adopted a three-stage architecture, including a retriever, a reranker, and a reader to extract the answers. First, the retriever retrieves the top K relevant passages from the collection based on a question and its conversation history. The reranker and the reader then respectively rerank and identify an answer in the top K passages. We also adopt this threestage architecture in our proposed model. However, in order to investigate the effectiveness of the cross-encoder reranker, we consider a two-stage pipeline including a retriever and a reader, as a baseline for comparison with our system. For the retriever, existing works (Qu et al., 2020(Qu et al., , 2021Liang et al., 2022;Yu et al., 2021) have focused on using bi-encoder dense retrieval (a question encoder and a passage encoder), which applies neural contextual language models, such as ALBERT or BERT, for encoding the question and passage into low-dimensional vectors and computing their relevance scores. For example, Yu et al. (2021) proposed ConvDR, which encodes the question and its history in a dense vector learned with a teacher-student model to mimic a dense representation of the manually rewritten question. ConvDR has also been shown to outperform other retriever models for conversational search such as sparse BM25, and bi-encoders using ALBERT (Qu et al., 2020) or BERT . Due to the good effectiveness of bi-encoder dense retrievers for passage retrieval, we adapt this type of retrieval model as our retriever. We also consider other recent existing bi-encoder passage retrievers such as TCT-ColBERT (Lin et al., 2021b, 2020a and CQE (Lin et al., 2021a) as baseline passage retrievers.", "spans": "[{\"corpusId\": 218869571, \"span\": \"(Qu et al., 2020\", \"start\": 42, \"end\": 58}, {\"corpusId\": 231717690, \"span\": \"(Qu et al., , 2021\", \"start\": 58, \"end\": 76}, {\"corpusId\": 256461415, \"span\": \"our system\", \"start\": 698, \"end\": 698}, {\"corpusId\": 218869571, \"span\": \"(Qu et al., 2020\", \"start\": 734, \"end\": 750}, {\"corpusId\": 231717690, \"span\": \"(Qu et al., , 2021\", \"start\": 750, \"end\": 768}, {\"corpusId\": 234343311, \"span\": \"Yu et al., 2021)\", \"start\": 787, \"end\": 803}, {\"corpusId\": 234343311, \"span\": \"Yu et al. (2021)\", \"start\": 1088, \"end\": 1104}, {\"corpusId\": 218869571, \"span\": \"(Qu et al., 2020)\", \"start\": 1428, \"end\": 1445}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "35334", "title": "monoQA: Multi-Task Learning of Reranking and Answer Extraction for Open-Retrieval Conversational Question Answering", "sectionTitle": "Introduction", "text": "Recently, Multi-Task Learning (MTL), which is a method of learning multiple different but related tasks at the same time, has become a popular approach for tackling several tasks using a uniform model (Qu et al., 2019b). For instance, MTL has been employed in order to efficiently answer the questions posed by the users (Qu et al., 2020(Qu et al., , 2021. In this manner, the network structure is shared between the reranker and the reader. Doing this, existing works (Qu et al., 2020(Qu et al., , 2021 also typically approach reranking and extractive reading as classification tasks, with two fully-connected layers (one for the reranker and reader, respectively) added to find an answer span for the retrieved passages (start/end positions) as well as to predict the relevance score of the question to the passage as shown in Figure 1(a). In this paper, we use the multi-task learning of the reranker and the extractive reader as our strongest baseline.", "spans": "[{\"corpusId\": 201669002, \"span\": \"(Qu et al., 2019b)\", \"start\": 201, \"end\": 219}, {\"corpusId\": 218869571, \"span\": \"(Qu et al., 2020\", \"start\": 321, \"end\": 337}, {\"corpusId\": 231717690, \"span\": \"(Qu et al., , 2021\", \"start\": 337, \"end\": 355}, {\"corpusId\": 218869571, \"span\": \"(Qu et al., 2020\", \"start\": 469, \"end\": 485}, {\"corpusId\": 231717690, \"span\": \"(Qu et al., , 2021\", \"start\": 485, \"end\": 503}, {\"corpusId\": 256461415, \"span\": \"this paper\", \"start\": 855, \"end\": 855}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "35335", "title": "monoQA: Multi-Task Learning of Reranking and Answer Extraction for Open-Retrieval Conversational Question Answering", "sectionTitle": "Introduction", "text": "On the other hand, Nogueira et al. (2020) proposed monoT5, a text generation model, which was fine-tuned to generate the tokens \"true\" or \"false\" depending on whether the document is relevant or not to the query. Indeed, the monoT5 model has been shown to outperform BERT-based models in passage reranking (Nogueira et al., 2020). In addition, many studies (Raffel et al., 2020;Khashabi et al., 2020; have focused on developing a generative reader which is fine-tuned as a text generation model to extract the answer from the passage. In particular, Khashabi et al. (2020) introduced the UnifiedQA model, which has been shown to yield impressive performances on many extractive QA datasets. However, we show that compared to using monoT5 and UnifiedQA separately, a joint learning can enhance the learning efficiency and prediction accuracy of a model for the ORConvQA task, since by sharing the learning model the reranker and reader can simultaneously predict the answer and reranking score. Indeed, a joint learning by sharing a single model trained using MTL reduces the memory needs and speeds up inference (Sun et al., 2020;Standley et al., 2020). In addition, we combine the effective monoT5 (to rerank the retrieved passages) and UnifiedQA (to extract the answer from the highest scored passage) models into a strong baseline. To the best of our knowledge, no prior work has combined monoT5 and UnifiedQA by sharing a single text generation model, in order to directly extract the answers instead of predicting the start/end positions in a retrieved passage.", "spans": "[{\"corpusId\": 212725651, \"span\": \"Nogueira et al. (2020)\", \"start\": 19, \"end\": 41}, {\"corpusId\": 212725651, \"span\": \"(Nogueira et al., 2020)\", \"start\": 306, \"end\": 329}, {\"corpusId\": 204838007, \"span\": \"(Raffel et al., 2020;\", \"start\": 357, \"end\": 378}, {\"corpusId\": 218487109, \"span\": \"Khashabi et al., 2020;\", \"start\": 378, \"end\": 400}, {\"corpusId\": 218487109, \"span\": \"Khashabi et al. (2020)\", \"start\": 550, \"end\": 572}, {\"corpusId\": 208513386, \"span\": \"(Sun et al., 2020;\", \"start\": 1112, \"end\": 1130}, {\"corpusId\": 159040666, \"span\": \"Standley et al., 2020)\", \"start\": 1130, \"end\": 1152}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "35336", "title": "monoQA: Multi-Task Learning of Reranking and Answer Extraction for Open-Retrieval Conversational Question Answering", "sectionTitle": "Introduction", "text": "In summary, in this work, we investigate the use of Multi-Task Learning (MTL) to improve performance on the ORConvQA task by sharing the reranker and reader's learned structure. We propose monoQA, which uses a text generation model with multi-task learning for both the reranker and reader. Our model, which is based on the T5 (Raffel et al., 2020) text generation model, is fine-tuned simultaneously for both reranking (in order to improve the precision of the top retrieved passages) and extracting the answer. Unlike previous work, monoQA makes predictions by generating the first token for the passage reranking task, followed by the other tokens for the answer extraction task, as illustrated in Figure 1(b). Our contributions are summarised as follows: (1) we leverage Multi-Task Learning with a text generation model by sharing the reranker and reader's learned structure to effectively addresses the ORConvQA task; (2) using two different ORConvQA datasets, we compare our model to two strong baselines from the literature, and show that our MTL reranker and generative reader approach yields the best F1, Recall, MRR, Figure 2: An example dialog and relevant passages from the ORConvQA dataset (Qu et al., 2020). and MAP performance improvements over the strongest baseline with statistically significant improvements ranging from +5.70% to +23.34%; (3) the proposed MTL model combining the reranker and generative reader significantly outperforms and is twice as fast for inference than the individual application of the monoT5 and UnifiedQA models for reranking and extracting the answer.", "spans": "[{\"corpusId\": 256461415, \"span\": \"this work\", \"start\": 24, \"end\": 24}, {\"corpusId\": 256461415, \"span\": \"We propose\", \"start\": 188, \"end\": 188}, {\"corpusId\": 204838007, \"span\": \"(Raffel et al., 2020)\", \"start\": 327, \"end\": 348}, {\"corpusId\": 218869571, \"span\": \"(Qu et al., 2020)\", \"start\": 1203, \"end\": 1220}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "35337", "title": "monoQA: Multi-Task Learning of Reranking and Answer Extraction for Open-Retrieval Conversational Question Answering", "sectionTitle": "monoQA: Reranker & Generative Reader", "text": "The right part of Figure 3 presents our proposed model, which uses T5, a large pre-trained language models designed for text generation. In particular, text generation approaches can be trained to generate a meaningful textual response based on some input text. Moreover, like BERT (Devlin et al., 2019), the pre-trained BART (Lewis et al., 2019) and T5 (Raffel et al., 2020) text generation models can be fine-tuned to perform a variety of downstream tasks. To adopt an MTL approach to a text generation model for jointly learning from both passage reranking and answer extraction, the MTL model makes predictions by generating the first token for the passage reranking task and the follow-up tokens for the answer extraction task. In particular, when fine-tuning the T5 model for a downstream task, we use Prompt Learning, which is a method to modify the model by using a taskspecific prompt together with the input . We deploy a T5 model to capture the relation between the rewritten question q r of the current question q c and the passage p as shown in the right part of Figure 3. In particular, we define a monoQA transformation function as monoQA(\u00b7) by taking the input sequence as follows:", "spans": "[{\"corpusId\": 52967399, \"span\": \"(Devlin et al., 2019)\", \"start\": 282, \"end\": 303}, {\"corpusId\": 204960716, \"span\": \"(Lewis et al., 2019)\", \"start\": 326, \"end\": 346}, {\"corpusId\": 204838007, \"span\": \"(Raffel et al., 2020)\", \"start\": 354, \"end\": 375}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "35338", "title": "monoQA: Multi-Task Learning of Reranking and Answer Extraction for Open-Retrieval Conversational Question Answering", "sectionTitle": "monoQA Training", "text": "where M is the number of tokens in the ground truth answer a, a i is the i th token in a, and a 0 is the beginning of sequence token (<s>). We also consider relevance accuracy and wordlevel F1 scores for selecting the best training model checkpoint during the evaluation step with the development set of the OR-QuAC dataset. Relevance accuracy is defined as the percentage of correct predictions for the first token generated from the model. The target token is \"true\" (the passage is indeed relevant) or \"false\" (a non-relevant passage). Following Qu et al. (2020), the word-level F1 is calculated by first removing stopwords and then considering the overlapping portion of the words in the prediction and ground truth answer. Prompt: Recently, Prompt Learning, which is a method to tailor pre-trained language models to downstream tasks by using a task-specific prompt together with the input, has recently become a popular approach for tackling several tasks using a uniform model . To fine-tune the monoQA model for passage reranking and answer extraction, we use Prompt Learning to modify the model input. By doing this, we investigate several prompts in previous works (Nogueira et al., 2020;Khashabi et al., 2020), and for completeness we evaluate all of them in order to choose the most effective. Details of the Prompt Learning and their corresponding experiments and results are provided in Appendix A.2. We do not investigate Prompt Learning for question reformulation since our main contribution focuses on leveraging the output of a generative model for re-ranking and reading. Positive and negative passages: Selecting positive and negative passages is a crucial step for training monoQA. For instance, passages relevant to a question are provided in the ORConvQA task. All other passages in the collection, which are unjudged, can be viewed as non-relevant by default. To cope with this issue, following Yu et al. (2021), we employ a hard negative sampling technique by randomly selecting the negative passage p \u2212 for the question q from the top K retrieved passages by ConvDR. For training monoQA, the output sequence for the positive passage p + begins with the token \"true\" followed by the ground truth answer; the output sequence for the negative passage p \u2212 begins with the token \"false\" followed by \"CANNOTANSWER\". Model initialisation: We consider the use of different models to initialisation monoQA during training, since we propose to combine monoT5 and UnifiedQA to share a single text generation model. Moreover, both monoT5 and UnifiedQA are fine-tuned based on the t5-base model. Therefore, we investigate which of monoT5, UnifiedQA, and t5-base, are suitable for initialising monoQA (see details in Section 4.1).", "spans": "[{\"corpusId\": 218869571, \"span\": \"Qu et al. (2020)\", \"start\": 549, \"end\": 565}, {\"corpusId\": 212725651, \"span\": \"(Nogueira et al., 2020;\", \"start\": 1175, \"end\": 1198}, {\"corpusId\": 218487109, \"span\": \"Khashabi et al., 2020)\", \"start\": 1198, \"end\": 1220}, {\"corpusId\": 234343311, \"span\": \"Yu et al. (2021)\", \"start\": 1919, \"end\": 1935}, {\"corpusId\": 256461415, \"span\": \"we propose\", \"start\": 2456, \"end\": 2456}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "35339", "title": "monoQA: Multi-Task Learning of Reranking and Answer Extraction for Open-Retrieval Conversational Question Answering", "sectionTitle": "Datasets", "text": "To conduct our evaluation of monoQA, we choose the OR-QuAC (Qu et al., 2020) and OR-CoQA (Qu et al., 2021) datasets, which are extractive Question Answering (QA) datasets. However, the OR-CoQA dataset can be also considered as a generative QA dataset because it contains both span and freeform answers. Indeed, in this paper, we focus on extractive QA only since we train our monoQA only on the OR-QuAC training set. In addition, following (Qu et al., 2021), we remove unanswerable questions from both datasets. OR-QuAC: This dataset has been introduced by Qu et al. (2020), adapting the well-known QuAC (Choi et al., 2018) dataset to an openretrieval setting. This dataset is an aggregation of three existing datasets consisting of (1) the QuAC (Choi et al., 2018) dataset, which is an information seeking dataset, (2) the CA-NARD (Elgohary et al., 2019) dataset, which contains questions that humans have re-written from questions in the QuAC dataset, and (3) the Wikipedia corpus, a large collection of over 11 million passages, which are used as the knowledge source for actually answering a given question. OR-CoQA: Qu et al. (2021) introduced this dataset by aggregating the CoQA (Reddy et al., 2019) dataset with the Wikipedia corpus from the OR-QuAC dataset. In contrast to OR-QuAC, the gold passages for each question are not included in the OR-CoQA dataset. Moreover, unlike OR-QuAC, there are no manually rewritten questions in the OR-CoQA dataset. As a result, we do not use OR-CoQA for training monoQA.", "spans": "[{\"corpusId\": 256461415, \"span\": \"our evaluation\", \"start\": 25, \"end\": 25}, {\"corpusId\": 218869571, \"span\": \"(Qu et al., 2020)\", \"start\": 59, \"end\": 76}, {\"corpusId\": 231717690, \"span\": \"(Qu et al., 2021)\", \"start\": 89, \"end\": 106}, {\"corpusId\": 256461415, \"span\": \"this paper\", \"start\": 324, \"end\": 324}, {\"corpusId\": 231717690, \"span\": \"(Qu et al., 2021)\", \"start\": 440, \"end\": 457}, {\"corpusId\": 218869571, \"span\": \"Qu et al. (2020)\", \"start\": 557, \"end\": 573}, {\"corpusId\": 52057510, \"span\": \"(Choi et al., 2018)\", \"start\": 604, \"end\": 623}, {\"corpusId\": 52057510, \"span\": \"(Choi et al., 2018)\", \"start\": 746, \"end\": 765}, {\"corpusId\": 202771124, \"span\": \"(Elgohary et al., 2019)\", \"start\": 832, \"end\": 855}, {\"corpusId\": 231717690, \"span\": \"Qu et al. (2021)\", \"start\": 1121, \"end\": 1137}, {\"corpusId\": 52055325, \"span\": \"(Reddy et al., 2019)\", \"start\": 1186, \"end\": 1206}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "35340", "title": "monoQA: Multi-Task Learning of Reranking and Answer Extraction for Open-Retrieval Conversational Question Answering", "sectionTitle": "Baselines and Implementation Details", "text": "Three-stage pipelines: (a) The first ORCon-vQA system has been proposed by Qu et al. (2020). It adopts a duo-ALBERT encoder as the retriever and an MTL of the reranker and reader by sharing a BERT encoder. We make use of the code provided by Qu et al. (2020); (b) This baseline is adapted from (a) by replacing the duo-ALBERT encoder passage retriever with ConvDR (Yu et al., 2021) in a similar manner to our proposed ORConvQA system (consisting of ConvDR and monoQA). This is a crucial baseline to compare with our monoQA model in order to evaluate the reranker and reader performances. We reproduce the MTL of the reranker and reader models and its evaluation results provided by Qu et al. (2020); (c) This baseline uses ConvDR as the passage retriever similarly to our ORConvQA system, monoT5 (Nogueira et al., 2020) as the passage reranker, and UnifiedQA (Khashabi et al., 2020) as the passage reader. It is deployed by using three models in the pipeline for comparison with our ORConvQA system, which employs a MTL of the reranker and reader. This comparison is done in order to evaluate the performance of using monoT5 and UnifiedQA separately in comparison with the joint learning of the reranker and reader. ", "spans": "[{\"corpusId\": 218869571, \"span\": \"Qu et al. (2020)\", \"start\": 75, \"end\": 91}, {\"corpusId\": 218869571, \"span\": \"Qu et al. (2020)\", \"start\": 242, \"end\": 258}, {\"corpusId\": 234343311, \"span\": \"(Yu et al., 2021)\", \"start\": 364, \"end\": 381}, {\"corpusId\": 256461415, \"span\": \"proposed ORConvQA system\", \"start\": 433, \"end\": 433}, {\"corpusId\": 218869571, \"span\": \"Qu et al. (2020)\", \"start\": 682, \"end\": 698}, {\"corpusId\": 256461415, \"span\": \"our ORConvQA system\", \"start\": 787, \"end\": 787}, {\"corpusId\": 212725651, \"span\": \"(Nogueira et al., 2020)\", \"start\": 796, \"end\": 819}, {\"corpusId\": 218487109, \"span\": \"(Khashabi et al., 2020)\", \"start\": 859, \"end\": 882}, {\"corpusId\": 256461415, \"span\": \"our ORConvQA system\", \"start\": 998, \"end\": 998}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "35341", "title": "monoQA: Multi-Task Learning of Reranking and Answer Extraction for Open-Retrieval Conversational Question Answering", "sectionTitle": "Hyperparameter settings:", "text": "Evaluation metrics: Since we are using the OR-QuAC dataset, we naturally adopt the two evaluation metrics, namely the word-level F1, and the human equivalence score (HEQ). Word-level F1, commonly used in the Machine Comprehension and ConvQA tasks (Rajpurkar et al., 2016(Rajpurkar et al., , 2018Choi et al., 2018), evaluates the word overlap between the system's prediction and the ground truth answer span. Meanwhile, the HEQ metric is used to evaluate the percentage of examples for which the deployed model's F1 is equivalent to or higher than the human F1. Given n references (ground-truth answers) for each question, human F1 is calculated by averaging the maximum F1 from each n\u22121 subset with respect to the heldout reference (Choi et al., 2018). This metric is composed of HEQ-Q, computed at the question level, and HEQ-D, computed at the dialogue (conversation) level. To evaluate the ", "spans": "[{\"corpusId\": 11816014, \"span\": \"(Rajpurkar et al., 2016\", \"start\": 247, \"end\": 270}, {\"corpusId\": 47018994, \"span\": \"(Rajpurkar et al., , 2018\", \"start\": 270, \"end\": 295}, {\"corpusId\": 52057510, \"span\": \"Choi et al., 2018)\", \"start\": 295, \"end\": 313}, {\"corpusId\": 52057510, \"span\": \"(Choi et al., 2018)\", \"start\": 732, \"end\": 751}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "35342", "title": "monoQA: Multi-Task Learning of Reranking and Answer Extraction for Open-Retrieval Conversational Question Answering", "sectionTitle": "Related Work", "text": "In the following, we discuss related work and position our contribution in relation to Conversational Question Answering and Multi-Task Learning. Conversational Question Answering: This is a conversational search task, where the system needs to correctly interpret a question in the context of an ongoing conversation. Most research on conversational QA focuses on conversational response ranking tasks (Dalton et al., 2019(Dalton et al., , 2020(Dalton et al., , 2021 and extractive QA tasks (Choi et al., 2018;Reddy et al., 2019;Qu et al., 2019b;Yeh and Chen, 2019). Qu et al. (2020) were first to define the task of Open-Retrieval Conversational Question Answering (OR-ConvQA), where the system is required to learn to retrieve top relevant passages from a large collection before extracting answers from the passages. To address the ORConvQA task, Qu et al. (2020) proposed a three-stage pipeline: (1) a retriever, (2) a reranker, and (3) a reader. Later, Qu et al. (2021) introduced a learned weakly-supervised training approach to address the problem of accessing gold passages during the training of the model on the OR-CoQA dataset in (Qu et al., 2020). One particular problem is coarse ranking, where the reranker of Qu et al. (2020) only takes the top-ranked passages as input. This makes the whole pipeline suffers from this coarse ranking, especially for situations when the golden passages are not retrieved in the top-ranked passages. Liang et al. (2022) addressed this issue by adding a post-ranker module that can push more relevant passages to the reader. However, these works typically approach reranking and reading as classification tasks to find an answer span for retrieved passages (start/end positions). Instead, we use a text generation model with multi-task learning for both the reranker and reader in order to directly extract the answers for the users instead of predicting the start/end positions in a retrieved passage.", "spans": "[{\"corpusId\": 214713838, \"span\": \"(Dalton et al., 2019\", \"start\": 403, \"end\": 423}, {\"corpusId\": 214735659, \"span\": \"(Dalton et al., , 2020\", \"start\": 423, \"end\": 445}, {\"corpusId\": 214735659, \"span\": \"(Dalton et al., , 2021\", \"start\": 445, \"end\": 467}, {\"corpusId\": 52057510, \"span\": \"(Choi et al., 2018;\", \"start\": 492, \"end\": 511}, {\"corpusId\": 52055325, \"span\": \"Reddy et al., 2019;\", \"start\": 511, \"end\": 530}, {\"corpusId\": 201669002, \"span\": \"Qu et al., 2019b;\", \"start\": 530, \"end\": 547}, {\"corpusId\": 199577753, \"span\": \"Yeh and Chen, 2019)\", \"start\": 547, \"end\": 566}, {\"corpusId\": 218869571, \"span\": \"Qu et al. (2020)\", \"start\": 568, \"end\": 584}, {\"corpusId\": 218869571, \"span\": \"Qu et al. (2020)\", \"start\": 851, \"end\": 867}, {\"corpusId\": 231717690, \"span\": \"Qu et al. (2021)\", \"start\": 959, \"end\": 975}, {\"corpusId\": 218869571, \"span\": \"(Qu et al., 2020)\", \"start\": 1142, \"end\": 1159}, {\"corpusId\": 218869571, \"span\": \"Qu et al. (2020)\", \"start\": 1225, \"end\": 1241}, {\"corpusId\": 256461415, \"span\": \"Instead, we\", \"start\": 1738, \"end\": 1738}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "35343", "title": "monoQA: Multi-Task Learning of Reranking and Answer Extraction for Open-Retrieval Conversational Question Answering", "sectionTitle": "Related Work", "text": "Multi-Task Learning (MTL) in Conversational QA: MTL methods have recently been effectively implemented in existing Conversational QA works (Kongyoung et al., 2020;Qu et al., 2019b;Xu et al., 2019;Yeh and Chen, 2019;Qu et al., 2020Qu et al., , 2021. However, all of the tasks in these works leverage MTL by sharing the network structure between an extractive reader and its auxiliary tasks, which are typically classification tasks, such as a yes/no question prediction or a follow-up question prediction. For example, some existing works (Qu et al., 2020(Qu et al., , 2021 have applied MTL on reranking and answer reading by adding two fully-connected layers (one for the reranker and reader, respectively) to find an answer span for the retrieved passages (start/end positions). Instead, in this paper, we leverage MTL on reranking and answer extraction by sharing a single text generation model in order to directly extract the answers instead of predicting the start/end positions in a retrieved passage. On the other hand, Ide and Kawahara (2021) recently adopted an MTL approach that involves both classification and text generation tasks. However, they addressed a completely different use case, consisting in detecting a user's emotion-aware response, rather than conversational QA.", "spans": "[{\"corpusId\": 226283691, \"span\": \"(Kongyoung et al., 2020;\", \"start\": 139, \"end\": 163}, {\"corpusId\": 201669002, \"span\": \"Qu et al., 2019b;\", \"start\": 163, \"end\": 180}, {\"corpusId\": 84846285, \"span\": \"Xu et al., 2019;\", \"start\": 180, \"end\": 196}, {\"corpusId\": 199577753, \"span\": \"Yeh and Chen, 2019;\", \"start\": 196, \"end\": 215}, {\"corpusId\": 218869571, \"span\": \"Qu et al., 2020\", \"start\": 215, \"end\": 230}, {\"corpusId\": 231717690, \"span\": \"Qu et al., , 2021\", \"start\": 230, \"end\": 247}, {\"corpusId\": 218869571, \"span\": \"(Qu et al., 2020\", \"start\": 538, \"end\": 554}, {\"corpusId\": 231717690, \"span\": \"(Qu et al., , 2021\", \"start\": 554, \"end\": 572}, {\"corpusId\": 256461415, \"span\": \"this paper\", \"start\": 802, \"end\": 802}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "35344", "title": "monoQA: Multi-Task Learning of Reranking and Answer Extraction for Open-Retrieval Conversational Question Answering", "sectionTitle": "A.2 Prompt Learning", "text": "Recently, Prompt Learning, which is a method to modify pre-trained language models to downstream tasks by using a task-specific prompt together with the input, has increasingly become a popular approach for tackling several tasks in a uniform model . To fine-tune the monoQA model for passage reranking and answer extraction, we adopt Prompt Learning to modify the model input. We have observed that several prompts have previously been used in previous work (Nogueira et al., 2020;Khashabi et al., 2020). Below we list the templates f prompt () that we consider in this study: \u2022 monoT5 prompt: We adapt the monoT5's template by replacing the prefix word from \"Query:\" to \"Question:\", the separator token from \"Document:\" to \"Passage:\", without using the word \"Relevant:\":", "spans": "[{\"corpusId\": 212725651, \"span\": \"(Nogueira et al., 2020;\", \"start\": 459, \"end\": 482}, {\"corpusId\": 218487109, \"span\": \"Khashabi et al., 2020)\", \"start\": 482, \"end\": 504}, {\"corpusId\": 256461415, \"span\": \"this study\", \"start\": 576, \"end\": 576}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 13}
{"paperId": "bc9ad2654b273fbad5dec0a119c97e5d5d6ff84e", "title": "How to get away with cyberattacks: An argumentative approach to cyberattacks\u2019 legitimization by common users", "venue": "International Conference on Human Factors in Computing Systems", "year": 2022, "citationCount": 1, "openAccessPdf": {"url": "https://dl.acm.org/doi/pdf/10.1145/3491102.3517444", "status": "GREEN", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3491102.3517444?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3491102.3517444, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2022-04-27", "authors": [{"authorId": "3308203", "name": "A. Spagnolli"}, {"authorId": "1395810186", "name": "Mariavittoria Masotina"}, {"authorId": "2163708534", "name": "Annalorena Scarcia"}, {"authorId": "2089292474", "name": "Beatrice Zuffi"}, {"authorId": "1699447", "name": "L. Gamberini"}], "abstract": "The possibility that common users are successfully recruited in cyberattacks represents a considerable vulnerability because it implies that citizens can legitimize cyberattacks instead of condemning them. We propose to adopt an argumentative approach to identify which premises allow such legitimization. To showcase this approach, we created four short narratives describing cyberattacks involving generic users and covering different motives for the attacks: profit, recreation, revenge, and ideology. A sample of 16 participants read the four narratives and was afterward interviewed to express their position on the attacks described. All interview transcripts were then analyzed with an argumentative approach, and 15 premises were found to account for the different positions taken. We describe the premises, their distribution across the four narratives, and discuss the implications of this approach for cybersecurity.", "corpusId": "248419681", "paragraphs": [{"paragraphId": "70511", "title": "How to Get Away with Cyberattacks: An Argumentative Approach to Cyberattacks\u2019 Legitimization by Common Users", "sectionTitle": "INTRODUCTION", "text": "In sociology, Sykes and Matza [53] proposed the notion of neutralization; according to them, criminals do not belong to a deviant subculture that inverts the values of the 'respectable' society [53]. Instead, criminals keep some commitments to the dominant values of society and use some techniques to conciliate them with their criminal acts. Sykes and Matza identifed fve such techniques: denying the responsibility, denying the negativity of the efects, turning the victim or the condemners into culprits, or appealing to higher values [53]. Their ideas have been extensively used in the study of criminal behavior, included within various theoretical frameworks [33], and re-elaborated by Scott and Lyman's theory of accounts [49]. They have also been applied to the study of cybercrime, and evidence of recourse to all fve types of neutralization techniques has been found so far in research on hackers [24]. When it comes to understanding lay citizens' participation in cyberattacks, which is the topic of this paper, Sykes and Mazda's theory suggests that the distinction between a community of criminals and the community of law-abiding citizens is culturally more blurred than one might assume. One does not need to give up all values of the dominant society to legitimize their illegal behaviors. Indeed, Chua et al [9] as well as Morris et al [38] surveyed college students and found such neutralization techniques. Morris et al., in particular, investigated common forms of computer hacking, such as accessing somebody else's device or guessing somebody else's password [38].", "spans": "[{\"corpusId\": 144973138, \"span\": \"[53]\", \"start\": 30, \"end\": 34}, {\"corpusId\": 144973138, \"span\": \"[53]\", \"start\": 30, \"end\": 34}, {\"corpusId\": 144973138, \"span\": \"[53]\", \"start\": 194, \"end\": 198}, {\"corpusId\": 144973138, \"span\": \"[53]\", \"start\": 194, \"end\": 198}, {\"corpusId\": 144973138, \"span\": \"[53]\", \"start\": 539, \"end\": 543}, {\"corpusId\": 144973138, \"span\": \"[53]\", \"start\": 539, \"end\": 543}, {\"corpusId\": 147877325, \"span\": \"[24]\", \"start\": 908, \"end\": 912}, {\"corpusId\": 147877325, \"span\": \"[24]\", \"start\": 908, \"end\": 912}, {\"corpusId\": 248419681, \"span\": \"this paper\", \"start\": 1022, \"end\": 1022}, {\"corpusId\": 146519638, \"span\": \"[9]\", \"start\": 1326, \"end\": 1329}, {\"corpusId\": 146519638, \"span\": \"[9]\", \"start\": 1326, \"end\": 1329}, {\"corpusId\": 63337757, \"span\": \"[38]\", \"start\": 1354, \"end\": 1358}, {\"corpusId\": 63337757, \"span\": \"[38]\", \"start\": 1354, \"end\": 1358}, {\"corpusId\": 63337757, \"span\": \"[38]\", \"start\": 1582, \"end\": 1586}, {\"corpusId\": 63337757, \"span\": \"[38]\", \"start\": 1582, \"end\": 1586}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "70512", "title": "How to Get Away with Cyberattacks: An Argumentative Approach to Cyberattacks\u2019 Legitimization by Common Users", "sectionTitle": "INTRODUCTION", "text": "We propose that legitimization of cyberattacks is made possible by the argumentative nature of position-taking. Assigning someone the status of the victim or the ofender is the result of an interpretive, interactional process [23] [56]. identifying the premises on which favorable argumentation rests would help to understand how lay citizens could legitimize (or condemn) cyberattacks. (We prefer to use the term legitimized over neutralized or justifed/excused because the former term assumes a cognitive model that is not necessary to our purpose; the terms justifed or excused only refer to a subset of neutralization techniques, and are then not adequate to refer to all techniques in general [49].) To showcase this argumentative approach to legitimization, we study the position on cyberattacks of a small sample of university students, who represent a typical participant in the literature on cybercrime [5]. The investigation uses a refexive thematic analysis [6] [7], which is open to the arguments spontaneously used by the participants. The purpose is not to map the entire argumentative space used by university students to make sense of cyberattacks, but to illustrate an argumentative approach and draw some cybersecurity implications from the results. We will start by briefy explaining what we mean by \"argumentative\".", "spans": "[{\"corpusId\": 248419681, \"span\": \"We propose\", \"start\": 10, \"end\": 10}, {\"corpusId\": 145810633, \"span\": \"[23]\", \"start\": 226, \"end\": 230}, {\"corpusId\": 145810633, \"span\": \"[23]\", \"start\": 226, \"end\": 230}, {\"corpusId\": 248419681, \"span\": \"this argumentative approach\", \"start\": 744, \"end\": 744}, {\"corpusId\": 210686030, \"span\": \"[5]\", \"start\": 912, \"end\": 915}, {\"corpusId\": 210686030, \"span\": \"[5]\", \"start\": 912, \"end\": 915}, {\"corpusId\": 10075179, \"span\": \"[6]\", \"start\": 969, \"end\": 972}, {\"corpusId\": 10075179, \"span\": \"[6]\", \"start\": 969, \"end\": 972}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "70513", "title": "How to Get Away with Cyberattacks: An Argumentative Approach to Cyberattacks\u2019 Legitimization by Common Users", "sectionTitle": "AN ARGUMENTATIVE APPROACH", "text": "The clearest theorization of attitudes as positions in an argumentative space is due to the discursive psychologist Michael Billig, according to whom culture ofers a set of shared and accepted commonplaces [3] both in favor and against a given controversial behavior [3]. An example is provided by the debate on Facebook's policy on users' personal data: their policy was justifed in the name of the free, valuable service it provided but also criticized in the name of transparency [41]. Far from being possessed in advance, positions emerge from the very process of trying diferent arguments and testing their suitability and implications; this process, as in dialectic philosophy [16], generates the knowledge needed to come to terms with a given controversy. A controversy is an issue that can inspire opposite positions and can be framed within opposite categories [3], [21], [29], [57]. In our case, the cyberattack represents the controversy, i.e., a behavior that can be framed either favorably or unfavorably.", "spans": "[{\"corpusId\": 10248049, \"span\": \"[3]\", \"start\": 206, \"end\": 209}, {\"corpusId\": 10248049, \"span\": \"[3]\", \"start\": 206, \"end\": 209}, {\"corpusId\": 10248049, \"span\": \"[3]\", \"start\": 267, \"end\": 270}, {\"corpusId\": 10248049, \"span\": \"[3]\", \"start\": 267, \"end\": 270}, {\"corpusId\": 124330185, \"span\": \"[41]\", \"start\": 483, \"end\": 487}, {\"corpusId\": 124330185, \"span\": \"[41]\", \"start\": 483, \"end\": 487}, {\"corpusId\": 10248049, \"span\": \"[3]\", \"start\": 870, \"end\": 873}, {\"corpusId\": 10248049, \"span\": \"[3]\", \"start\": 870, \"end\": 873}, {\"corpusId\": 146031496, \"span\": \"[29]\", \"start\": 881, \"end\": 885}, {\"corpusId\": 146031496, \"span\": \"[29]\", \"start\": 881, \"end\": 885}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "70514", "title": "How to Get Away with Cyberattacks: An Argumentative Approach to Cyberattacks\u2019 Legitimization by Common Users", "sectionTitle": "AN ARGUMENTATIVE APPROACH", "text": "To convert this conceptual approach to position-taking into an investigation methodology means to capture the premises mobilized when taking a favorable about a controversial behavior. Consistently, in our study, the participants did not rate pre-formulated arguments (as in [29] or [38]) but worked their way to a position during open answers to interviews. This allowed them to use the arguments that spontaneously occurred while answering and to take articulated and ambivalent positions as they were considering various sides of the attack. What we valued were the arguments that backed such positions, not the positions themselves. An argumentative method also needs to consider various scenarios in which a controversial behavior can appear. Our study used four diferent cyberattack scenarios inspired by common motives for cyberattacks reported in the literature and applicable to general users.", "spans": "[{\"corpusId\": 248419681, \"span\": \"this conceptual approach\", \"start\": 35, \"end\": 35}, {\"corpusId\": 248419681, \"span\": \"our study\", \"start\": 211, \"end\": 211}, {\"corpusId\": 146031496, \"span\": \"[29]\", \"start\": 275, \"end\": 279}, {\"corpusId\": 146031496, \"span\": \"[29]\", \"start\": 275, \"end\": 279}, {\"corpusId\": 63337757, \"span\": \"[38]\", \"start\": 283, \"end\": 287}, {\"corpusId\": 63337757, \"span\": \"[38]\", \"start\": 283, \"end\": 287}, {\"corpusId\": 248419681, \"span\": \"Our study\", \"start\": 757, \"end\": 757}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "70515", "title": "How to Get Away with Cyberattacks: An Argumentative Approach to Cyberattacks\u2019 Legitimization by Common Users", "sectionTitle": "METHOD", "text": "We carried out semi-structured interviews with the participants. Semi-structured interviews allow participants a spontaneous choice of terms [7], [32], and the production of articulated answers that are not forced into pre-defned categories. The interviews gravitated around four cases of cyberattacks, to set the questions in a vivid and realistic context and allow participants to form an idea [7], [25], [29]. The process through which we analyzed the participants' answers was a refexive thematic analysis [6], in which the premises supporting the interviewees' positions represented the themes. In the rest of this section, we will describe the method in more detail.", "spans": "[{\"corpusId\": 146358257, \"span\": \"[25]\", \"start\": 401, \"end\": 405}, {\"corpusId\": 146358257, \"span\": \"[25]\", \"start\": 401, \"end\": 405}, {\"corpusId\": 146031496, \"span\": \"[29]\", \"start\": 407, \"end\": 411}, {\"corpusId\": 146031496, \"span\": \"[29]\", \"start\": 407, \"end\": 411}, {\"corpusId\": 10075179, \"span\": \"[6]\", \"start\": 510, \"end\": 513}, {\"corpusId\": 10075179, \"span\": \"[6]\", \"start\": 510, \"end\": 513}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "70516", "title": "How to Get Away with Cyberattacks: An Argumentative Approach to Cyberattacks\u2019 Legitimization by Common Users", "sectionTitle": "Narratives", "text": "The cyberattack scenarios we created varied in their motives. The early taxonomies published in the literature distinguish between four motives, i.e., curiosity, proft, notoriety, and revenge [20], [45]. Curiosity is the pursuit of the excitement connected to intellectual challenges. Proft refers to actions driven by greed or personal fnancial gain\" ( [45], p.100). Notoriety, also called prestige, consists of pursuing \"media attention, bragging, and the quest for fame\" ( [45], p. 100). Revenge is the search for compensating a tort sufered by the attacker. We excluded notoriety and curiosity from this original set of four motives because they did not ft our purposes: we were interested in cases involving lay people in the attack and not in a single attacker wanting to gain popularity or test their talent. We then added recreation or fun [17] and ideology, which refers to ideological and societal motives [50]. Our fnal set of motives then included: proft, revenge, recreation, and ideology.", "spans": "[{\"corpusId\": 34026034, \"span\": \"[20]\", \"start\": 192, \"end\": 196}, {\"corpusId\": 34026034, \"span\": \"[20]\", \"start\": 192, \"end\": 196}, {\"corpusId\": 35162077, \"span\": \"[45]\", \"start\": 198, \"end\": 202}, {\"corpusId\": 35162077, \"span\": \"[45]\", \"start\": 198, \"end\": 202}, {\"corpusId\": 35162077, \"span\": \"[45]\", \"start\": 354, \"end\": 358}, {\"corpusId\": 35162077, \"span\": \"[45]\", \"start\": 354, \"end\": 358}, {\"corpusId\": 35162077, \"span\": \"[45]\", \"start\": 476, \"end\": 480}, {\"corpusId\": 35162077, \"span\": \"[45]\", \"start\": 476, \"end\": 480}, {\"corpusId\": 204491530, \"span\": \"[17]\", \"start\": 848, \"end\": 852}, {\"corpusId\": 204491530, \"span\": \"[17]\", \"start\": 848, \"end\": 852}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "70517", "title": "How to Get Away with Cyberattacks: An Argumentative Approach to Cyberattacks\u2019 Legitimization by Common Users", "sectionTitle": "Argumentation and cybersecurity", "text": "Addressing the human vulnerabilities of a system, allowing users to recognize and prevent potential threats, including deception and manipulation [12] [31] is increasingly recognized as more efective than only addressing the technical factors [14] [61]. Alongside structural interventions that are long-term and need the mobilization of various stakeholders and policymakers, cybersecurity can use brief interventions in the form of seminars.", "spans": "[{\"corpusId\": 70178926, \"span\": \"[12]\", \"start\": 146, \"end\": 150}, {\"corpusId\": 70178926, \"span\": \"[12]\", \"start\": 146, \"end\": 150}, {\"corpusId\": 209442973, \"span\": \"[14]\", \"start\": 243, \"end\": 247}, {\"corpusId\": 209442973, \"span\": \"[14]\", \"start\": 243, \"end\": 247}, {\"corpusId\": 144382697, \"span\": \"[61]\", \"start\": 248, \"end\": 252}, {\"corpusId\": 144382697, \"span\": \"[61]\", \"start\": 248, \"end\": 252}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 7}
{"paperId": "1aba2e7139161fc277e54265e8543539b3c2ca75", "title": "Deep Neural Model Inspection and Comparison via Functional Neuron Pathways", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2019, "citationCount": 12, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/P19-1575.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://aclanthology.org/P19-1575, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2019-07-01", "authors": [{"authorId": "2366489566", "name": "James Fiacco"}, {"authorId": "22177625", "name": "Samridhi Choudhary"}, {"authorId": "35959897", "name": "C. Ros\u00e9"}], "abstract": "We introduce a general method for the interpretation and comparison of neural models. The method is used to factor a complex neural model into its functional components, which are comprised of sets of co-firing neurons that cut across layers of the network architecture, and which we call neural pathways. The function of these pathways can be understood by identifying correlated task level and linguistic heuristics in such a way that this knowledge acts as a lens for approximating what the network has learned to apply to its intended task. As a case study for investigating the utility of these pathways, we present an examination of pathways identified in models trained for two standard tasks, namely Named Entity Recognition and Recognizing Textual Entailment.", "corpusId": "196211427", "paragraphs": [{"paragraphId": "48839", "title": "Deep Neural Model Inspection and Comparison via Functional Neuron Pathways", "sectionTitle": "Introduction", "text": "This method, which can be applied simply in a purely post-hoc analysis, independent of the training process, can enable both understanding of individual models and comparison across models. The interpretation process enables investigation of which identified functional groups correspond to linguistic or task level heuristics that may be employed in well understood non-neural methods for performing the task. Furthermore, it enables comparison across very different architectures in terms of the extent and the manner in which each architecture has approximated use of such knowledge. In so doing, the method can also be used to formulate explanations for differences in performance between models based on relevant linguistic or task knowledge that is identified as learned or not learned by the models. This approach builds on and extends prior work using linguistic and task knowledge to understand the behavior and the results of modern neural models (Shi et al., 2016b;Adi et al., 2016;Conneau et al., 2018).", "spans": "[{\"corpusId\": 196211427, \"span\": \"This method\", \"start\": 11, \"end\": 11}, {\"corpusId\": 196211427, \"span\": \"This approach\", \"start\": 820, \"end\": 820}, {\"corpusId\": 7197724, \"span\": \"(Shi et al., 2016b;\", \"start\": 957, \"end\": 976}, {\"corpusId\": 24461982, \"span\": \"Conneau et al., 2018)\", \"start\": 993, \"end\": 1014}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "48840", "title": "Deep Neural Model Inspection and Comparison via Functional Neuron Pathways", "sectionTitle": "Related Work", "text": "Our work falls under the broad topic of neural network interpretation. Recently, in this area of research a wide variety of models have been the target of investigation, including additive classifiers (Poulin et al., 2006), kernel-based classifiers (Baehrens et al., 2010), hierarchical networks (Landecker et al., 2013), and many others that are too numerous to list. As our work focuses on interpretation, we are not presenting new state-of-theart performance on a given task, but rather a new method to understand and compare neural models. Our evaluation is a demonstration that focuses on models trained for the Named Entity Recognition and Recognizing Textual Entailment tasks. The specific goal of our evaluation will be to demonstrate the broad applicability of the approach, and position it as building on and extending the existing body of work exploring interpretability of previously defined neural models (Glockner et al., 2018;Mudrakarta et al., 2018).", "spans": "[{\"corpusId\": 196211427, \"span\": \"Our work\", \"start\": 8, \"end\": 8}, {\"corpusId\": 107463, \"span\": \"(Poulin et al., 2006)\", \"start\": 201, \"end\": 222}, {\"corpusId\": 14664111, \"span\": \"(Baehrens et al., 2010)\", \"start\": 249, \"end\": 272}, {\"corpusId\": 2878997, \"span\": \"(Landecker et al., 2013)\", \"start\": 296, \"end\": 320}, {\"corpusId\": 196211427, \"span\": \"our work\", \"start\": 380, \"end\": 380}, {\"corpusId\": 196211427, \"span\": \"Our evaluation\", \"start\": 558, \"end\": 558}, {\"corpusId\": 196211427, \"span\": \"our evaluation\", \"start\": 719, \"end\": 719}, {\"corpusId\": 19204066, \"span\": \"(Glockner et al., 2018;\", \"start\": 918, \"end\": 941}, {\"corpusId\": 21673814, \"span\": \"Mudrakarta et al., 2018)\", \"start\": 941, \"end\": 965}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "48841", "title": "Deep Neural Model Inspection and Comparison via Functional Neuron Pathways", "sectionTitle": "Related Work", "text": "We observe that neural interpretation approaches fall within several broad categories: visualizations and heatmaps (Karpathy et al., 2015;Strobelt et al., 2016), gradient-based analyses (Potapenko et al., 2017;Samek et al., 2017b;Bach et al., 2015;Arras et al., 2017), learning disentangled representations during training (Whitney, 2016;Siddharth et al., 2017;Esmaeili et al., 2018), and model probes (Shi et al., 2016a;Adi et al., 2016;Conneau et al., 2018;Zhu et al., 2018;Kuncoro et al., 2018;Khandelwal et al., 2018). Our work uses linear probes as a method to identify the function of groups of neurons that are correlated with linguistic and tasklevel features, rather than for interpretation of individual neurons. Through correlation with the pathway analysis, we can furthermore reason about the role that those linguistic and task-level features have in the network's predictions.", "spans": "[{\"corpusId\": 8743497, \"span\": \"(Potapenko et al., 2017;\", \"start\": 186, \"end\": 210}, {\"corpusId\": 9327892, \"span\": \"Bach et al., 2015;\", \"start\": 230, \"end\": 248}, {\"corpusId\": 2479906, \"span\": \"Arras et al., 2017)\", \"start\": 248, \"end\": 267}, {\"corpusId\": 5024767, \"span\": \"Siddharth et al., 2017;\", \"start\": 338, \"end\": 361}, {\"corpusId\": 34975990, \"span\": \"(Shi et al., 2016a;\", \"start\": 402, \"end\": 421}, {\"corpusId\": 24461982, \"span\": \"Conneau et al., 2018;\", \"start\": 438, \"end\": 459}, {\"corpusId\": 51874490, \"span\": \"Zhu et al., 2018;\", \"start\": 459, \"end\": 476}, {\"corpusId\": 51873108, \"span\": \"Kuncoro et al., 2018;\", \"start\": 476, \"end\": 497}, {\"corpusId\": 196211427, \"span\": \"Our work\", \"start\": 531, \"end\": 531}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "48842", "title": "Deep Neural Model Inspection and Comparison via Functional Neuron Pathways", "sectionTitle": "Related Work", "text": "More recently,  published a detailed tutorial on the recent approaches and techniques of interpreting deep neural networks. They identified cross-cutting techniques that have been applied to explain the behavior of a wide range of models. A notable contribution of this tutorial is an approach for sensitivity analysis capable of identifying important input features to a network. The technique observes the magnitude of the gradient for each input feature for each data point, giving relevance scores per data point for each feature. Analogous methods for accomplishing similar goals include layer-wise relevance propagation (Bach et al., 2015) and its derivatives (Samek et al., 2017a;Arras et al., 2017).", "spans": "[{\"corpusId\": 9327892, \"span\": \"(Bach et al., 2015)\", \"start\": 626, \"end\": 645}, {\"corpusId\": 7689122, \"span\": \"(Samek et al., 2017a;\", \"start\": 666, \"end\": 687}, {\"corpusId\": 2479906, \"span\": \"Arras et al., 2017)\", \"start\": 687, \"end\": 706}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "48843", "title": "Deep Neural Model Inspection and Comparison via Functional Neuron Pathways", "sectionTitle": "Methodology", "text": "Many previous approaches have analyzed individual neurons or architectures of specific neural networks with gradient methods (Karpathy et al., 2015;Bach et al., 2015;Arras et al., 2017). However, we propose an approach that enables abstraction above the surface structure of a network architecture, enabling a relaxation of the assumption of an direct link between structure and function. To accomplish this abstraction, we employ a simple approach to identify what we conceptualize as emergent neural pathways, which are specific sets of co-firing neurons that work together as the model makes predictions on the data. To understand the specifics of the function performed by the functional group, we align activation patterns through the group per instance with patterns of relevance for task and linguistic knowledge.", "spans": "[{\"corpusId\": 9327892, \"span\": \"Bach et al., 2015;\", \"start\": 148, \"end\": 166}, {\"corpusId\": 2479906, \"span\": \"Arras et al., 2017)\", \"start\": 166, \"end\": 185}, {\"corpusId\": 196211427, \"span\": \"we propose\", \"start\": 206, \"end\": 206}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "48844", "title": "Deep Neural Model Inspection and Comparison via Functional Neuron Pathways", "sectionTitle": "Experiments", "text": "To evaluate our interpretation technique on real world data, we applied our method on four trained models over two tasks: recognizing textual entailment using the Multi-genre Natural Language Inference corpus (Williams et al., 2018) and named entity recognition using the CoNLL 2003 data (Sang and Meulder, 2003) for English NER. The analysis was implemented using Scikit-Learn (Pedregosa et al., 2011) and SciPy (Jones et al., 2001-) and unless otherwise noted used default hyperparameters.", "spans": "[{\"corpusId\": 196211427, \"span\": \"our method\", \"start\": 82, \"end\": 82}, {\"corpusId\": 3432876, \"span\": \"(Williams et al., 2018)\", \"start\": 209, \"end\": 232}, {\"corpusId\": 2470716, \"span\": \"(Sang and Meulder, 2003)\", \"start\": 288, \"end\": 312}, {\"corpusId\": 10659969, \"span\": \"(Pedregosa et al., 2011)\", \"start\": 378, \"end\": 402}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "48845", "title": "Deep Neural Model Inspection and Comparison via Functional Neuron Pathways", "sectionTitle": "Interpretation", "text": "For the entailment models, the experiment was designed to explore the predictive behavior of each model for the task. The linear probes indicate that the information about what type of reasoning is required for a task, which is hypothesized to be encoded in the models, was distinctly encoded in each model, but to a greater extent in the decomposable attention model. The connection between the pathways and the linear probes was less strong, however. This indicates that despite the models having an encoding of the knowledge observed by the probe, it is likely a byproduct of a different function that is being approximated by the neural network. The pathways were created by analyzing which neurons behave cohesively, indicating a subprocess within the network. However, these subprocesses do not correspond strongly to any of the tested features. Consequences of this finding could be an indication that the model is 'cheating' on the task and has some inductive bias that is beneficial to the task independent from the task as envisioned by the creators. Otherwise, if many models demonstrate this behavior, the task or dataset may be insufficient to induce the desired learning behavior in neural models. This is consistent with recent highly domain specific analyses of this task (Gururangan et al., 2018;Glockner et al., 2018;Poliak et al., 2018).", "spans": "[{\"corpusId\": 196211427, \"span\": \"this finding\", \"start\": 880, \"end\": 880}, {\"corpusId\": 4537113, \"span\": \"(Gururangan et al., 2018;\", \"start\": 1288, \"end\": 1313}, {\"corpusId\": 19204066, \"span\": \"Glockner et al., 2018;\", \"start\": 1313, \"end\": 1335}, {\"corpusId\": 21382535, \"span\": \"Poliak et al., 2018\", \"start\": 1335, \"end\": 1354}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 7}
{"paperId": "07696855918fd575504b7072b42bf5c863082d2a", "title": "SLM: Learning a Discourse Language Representation with Sentence Unshuffling", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2020, "citationCount": 53, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/2020.emnlp-main.120.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2010.16249, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2020-10-30", "authors": [{"authorId": "2110308676", "name": "Haejun Lee"}, {"authorId": "152951058", "name": "Drew A. Hudson"}, {"authorId": "2115495251", "name": "Kangwook Lee"}, {"authorId": "144783904", "name": "Christopher D. Manning"}], "abstract": "We introduce Sentence-level Language Modeling, a new pre-training objective for learning a discourse language representation in a fully self-supervised manner. Recent pre-training methods in NLP focus on learning either bottom or top-level language representations: contextualized word representations derived from language model objectives at one extreme and a whole sequence representation learned by order classification of two given textual segments at the other. However, these models are not directly encouraged to capture representations of intermediate-size structures that exist in natural languages such as sentences and the relationships among them. To that end, we propose a new approach to encourage learning of a contextualized sentence-level representation by shuffling the sequence of input sentences and training a hierarchical transformer model to reconstruct the original ordering. Through experiments on downstream tasks such as GLUE, SQuAD, and DiscoEval, we show that this feature of our model improves the performance of the original BERT by large margins.", "corpusId": "226222033", "paragraphs": [{"paragraphId": "84049", "title": "SLM: Learning a Discourse Language Representation with Sentence Unshuffling", "sectionTitle": "Introduction", "text": "Inspired by prior works about sentence-based representations for recurrent networks Hill et al., 2016;Gan et al., 2017;Jernite et al., 2017;Logeswaran et al., 2018;Gong et al., 2016;, we seek to incorporate a more explicit hierarchy into the transformer by extending it with the capacity to learn contextualized sentence-level representations. Equipping the model with such a capacity allows it to learn languages at multiple levels of granularity, ranging from fine-grain connections across words to high-level discourse relations between sentences and paragraphs.", "spans": "[{\"corpusId\": 2937095, \"span\": \"Hill et al., 2016;\", \"start\": 84, \"end\": 102}, {\"corpusId\": 2116604, \"span\": \"Gan et al., 2017;\", \"start\": 102, \"end\": 119}, {\"corpusId\": 3920347, \"span\": \"Logeswaran et al., 2018;\", \"start\": 140, \"end\": 164}]", "conference": "emnlp", "year": 2020, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "84050", "title": "SLM: Learning a Discourse Language Representation with Sentence Unshuffling", "sectionTitle": "Introduction", "text": "We show that our method achieves robust improvements over standard BERT's performance on the following downstream NLP tasks: GLUE for Natural Language Inference (Wang et al., 2018), SQuAD for Question Answering (Rajpurkar et al., 2018), and DiscoEval  for discourse aware sentence representations. We match the score of Text-To-Text Transfer Transformer Base (T5 BASE ) (Raffel et al., 2020), a state-of-theart model that uses BERT BASE hyperparameters, while using only half the parameters, shorter training (3/8 tokens overall), and a fraction (1/37) of the data compared to T5. Moreover, we investigate the effect of the proposed objective through a qualitative analysis of the neighbor sentences of sentences that have similar sentential representations. We show that the results support our aim of enriching the transformer model with sentencelevel language understanding.", "spans": "[{\"corpusId\": 226222033, \"span\": \"our method\", \"start\": 23, \"end\": 23}, {\"corpusId\": 5034059, \"span\": \"(Wang et al., 2018)\", \"start\": 161, \"end\": 180}, {\"corpusId\": 47018994, \"span\": \"(Rajpurkar et al., 2018)\", \"start\": 211, \"end\": 235}, {\"corpusId\": 204838007, \"span\": \"(Raffel et al., 2020)\", \"start\": 370, \"end\": 391}]", "conference": "emnlp", "year": 2020, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "84051", "title": "SLM: Learning a Discourse Language Representation with Sentence Unshuffling", "sectionTitle": "Results", "text": "We compare our SLM model with the original BERT, XLNet (Yang et al., 2019), ELECTRA (Clark et al., 2019), ERNIE 2.0 (Sun et al., 2020), CONPONO (Iter et al., 2020), BART (Lewis et al., 2020) and T5 which are the current state-of-theart for the benchmark datasets we use. We mainly compare with models using BERT BASE hyperparameters. Table 1 shows the performance of our method on the GLUE dataset for all tasks except WNLI. Our method significantly improves the downstream NLP tasks in the GLUE dataset. While most tasks are improved from the original BERT, improvement of RTE by 12.1 points is the most significant. We assume this is because our model learns the relationship of sentences thanks to our objective and it is the most effective on the entailment task with relatively small data like RTE. While our average test score is the highest among Base-size models that is 0.3 points higher than T5 BASE , some scores  are even comparable with large models trained by more total tokens and data. Our average score is 0.9 points higher than BERT LARGE . Our SST-2 score is higher than BERT and ELECTRA's scores and MRPC score is higher than BERT, XLNet, and ELECTRA.", "spans": "[{\"corpusId\": 195069387, \"span\": \"(Yang et al., 2019)\", \"start\": 55, \"end\": 74}, {\"corpusId\": 213152193, \"span\": \"(Clark et al., 2019)\", \"start\": 84, \"end\": 104}, {\"corpusId\": 198968327, \"span\": \"(Sun et al., 2020)\", \"start\": 116, \"end\": 134}, {\"corpusId\": 218763303, \"span\": \"(Iter et al., 2020)\", \"start\": 144, \"end\": 163}, {\"corpusId\": 204960716, \"span\": \"(Lewis et al., 2020)\", \"start\": 170, \"end\": 190}, {\"corpusId\": 226222033, \"span\": \"our method\", \"start\": 377, \"end\": 377}, {\"corpusId\": 226222033, \"span\": \"Our method\", \"start\": 435, \"end\": 435}]", "conference": "emnlp", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "84052", "title": "SLM: Learning a Discourse Language Representation with Sentence Unshuffling", "sectionTitle": "Return", "text": "2) I heard the pulse of the besieging sea throb far away all night. I heard the wind fly crying, and convulse tumultuous palms. \u00d7 3) I took several long walks while collecting objects of natural history. The country is pleasant for exercise. 5) My maid is a treasure. My dressmaker is charming.  (Joshi et al., 2020), reordering of local permutations (Wang et al., 2019), detecting incorrectly replaced tokens (Clark et al., 2019), combining multiple tasks (Sun et al., 2020), a decoder-based masked word prediction (Song et al., 2019), and so on.", "spans": "[{\"corpusId\": 198229624, \"span\": \"(Joshi et al., 2020)\", \"start\": 296, \"end\": 316}, {\"corpusId\": 199552081, \"span\": \"(Wang et al., 2019)\", \"start\": 351, \"end\": 370}, {\"corpusId\": 213152193, \"span\": \"(Clark et al., 2019)\", \"start\": 410, \"end\": 430}, {\"corpusId\": 198968327, \"span\": \"(Sun et al., 2020)\", \"start\": 457, \"end\": 475}, {\"corpusId\": 146808476, \"span\": \"(Song et al., 2019)\", \"start\": 516, \"end\": 535}]", "conference": "emnlp", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "84053", "title": "SLM: Learning a Discourse Language Representation with Sentence Unshuffling", "sectionTitle": "Return", "text": "The effect of predicting textual segment order in pretrained language models has been widely investigated as well. BERT proposed the Next Sentence Prediction task (NSP) which predicts whether two given text segments are from the same documents or not. The results of SpanBERT (Joshi et al., 2020) question the value of NSP, suggesting this might be due to noise from merging 2 unrelated texts from different documents. Consequently, ALBERT (Lan et al., 2019) and StructBERT (Wang et al., 2019) added sentence ordering objectives by predicting the order of text segments. BART (Lewis et al., 2020) proposed the Sentence Permutation task which is similar with ours. It predicts the original sequence of sentences using an auto-regressive decoder, which reconstructs the whole sentences by word prediction. However, their approach does not provide any representation of each sentence. Moreover, while SLM shows strong task improvements, that is not the case for these models.", "spans": "[{\"corpusId\": 198229624, \"span\": \"(Joshi et al., 2020)\", \"start\": 276, \"end\": 296}, {\"corpusId\": 202888986, \"span\": \"(Lan et al., 2019)\", \"start\": 440, \"end\": 458}, {\"corpusId\": 199552081, \"span\": \"(Wang et al., 2019)\", \"start\": 474, \"end\": 493}, {\"corpusId\": 204960716, \"span\": \"(Lewis et al., 2020)\", \"start\": 576, \"end\": 596}]", "conference": "emnlp", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 5}
{"paperId": "529e997e0d9730c25ad4347502da7e5a753274b8", "title": "Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2022, "citationCount": 40, "openAccessPdf": {"url": "https://arxiv.org/pdf/2211.11875", "status": "GREEN", "license": null, "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2211.11875, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2022-11-21", "authors": [{"authorId": "49688913", "name": "E. Mitchell"}, {"authorId": "2188876463", "name": "Joseph J. Noh"}, {"authorId": "2118154098", "name": "Siyan Li"}, {"authorId": "122710477", "name": "William S. Armstrong"}, {"authorId": "2175519413", "name": "Ananth Agarwal"}, {"authorId": "152179044", "name": "Patrick Liu"}, {"authorId": "46881670", "name": "Chelsea Finn"}, {"authorId": "144783904", "name": "Christopher D. Manning"}], "abstract": "While large pre-trained language models are powerful, their predictions often lack logical consistency across test inputs. For example, a state-of-the-art Macaw question-answering (QA) model answers Yes to Is a sparrow a bird? and Does a bird have feet? but answers No to Does a sparrow have feet?. To address this failure mode, we propose a framework, Consistency Correction through Relation Detection, or ConCoRD, for boosting the consistency and accuracy of pre-trained NLP models using pre-trained natural language inference (NLI) models without fine-tuning or re-training. Given a batch of test inputs, ConCoRD samples several candidate outputs for each input and instantiates a factor graph that accounts for both the model\u2019s belief about the likelihood of each answer choice in isolation and the NLI model\u2019s beliefs about pair-wise answer choice compatibility. We show that a weighted MaxSAT solver can efficiently compute high-quality answer choices under this factor graph, improving over the raw model\u2019s predictions. Our experiments demonstrate that ConCoRD consistently boosts accuracy and consistency of off-the-shelf closed-book QA and VQA models using off-the-shelf NLI models, notably increasing accuracy of LXMERT on ConVQA by 5% absolute. See the project website (https://ericmitchell.ai/emnlp-2022-concord/) for code and data.", "corpusId": "253155214", "paragraphs": [{"paragraphId": "89569", "title": "Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference", "sectionTitle": "Related Work", "text": "NLI has long been used to maintain logical consistency in generated dialogue utterances (Welleck et al., 2019;Dziri et al., 2019;Song et al., 2020), radiology report domain entities (Miura et al., 2021), and summarization (Laban et al., 2022;Honovich et al., 2022). Perhaps most similarly, Jung et al. (2022) use NLI to estimate constraints between factual statements produced by GPT-3. These prior approaches support our intuition for using NLI models to improve logical consistency among batches of answers. While the authors explore applications of this framework to multi-step reasoning for True/False questions or statements, our work focuses on applying this methodology to more gen-Figure 2: An example factor graph for a simplified batch with two questions, q1 = What is the capital of Afghanistan? and q2 = What is the capital of Georgia?. Although Tbilisi is the most likely answer for both questions, the assignment of variables that is best under the estimated contradiction constraint flips the answer to the first question to Kabul. The top-2 answer choices for each question are sampled from the base model, and a soft contradiction constraint is detected between variables z1 (representing the truth of the answer Tbilisi for q1) and z3 (representing the truth of the answer Tbilisi for q2).", "spans": "[{\"corpusId\": 102351258, \"span\": \"Dziri et al., 2019;\", \"start\": 110, \"end\": 129}, {\"corpusId\": 244345901, \"span\": \"(Laban et al., 2022;\", \"start\": 222, \"end\": 242}, {\"corpusId\": 247694170, \"span\": \"Honovich et al., 2022)\", \"start\": 242, \"end\": 264}, {\"corpusId\": 253155214, \"span\": \"our work\", \"start\": 639, \"end\": 639}, {\"corpusId\": 253155214, \"span\": \"this method\", \"start\": 671, \"end\": 671}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 1}
{"paperId": "8a00cd8478625ba44787d18015c6f747a71cbeda", "title": "Design and Evaluation of a Social Media Writing Support Tool for People with Dyslexia", "venue": "International Conference on Human Factors in Computing Systems", "year": 2019, "citationCount": 44, "openAccessPdf": {"url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300746", "status": "BRONZE", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3290605.3300746?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3290605.3300746, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Psychology", "Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2019-05-02", "authors": [{"authorId": "1968133", "name": "Shaomei Wu"}, {"authorId": "144880783", "name": "Lindsay Reynolds"}, {"authorId": "2116235416", "name": "Xian Li"}, {"authorId": "144204682", "name": "Francisco Guzm\u00e1n"}], "abstract": "People with dyslexia face challenges expressing themselves in writing on social networking sites (SNSs). Such challenges come from not only the technicality of writing, but also the self-representation aspect of sharing and communicating publicly on social networking sites such as Facebook. To empower people with dyslexia-style writing to express them-selves more confidently on SNSs, we designed and implemented Additional Writing Help(AWH) - a writing assistance tool to proofread text produced by users with dyslexia before they post on Facebook. AWH was powered by a neural machine translation (NMT) model that translates dyslexia style to non-dyslexia style writing. We evaluated the performance and the design of AWH through a week-long field study with 19 people with dyslexia and received highly positive feedback. Our field study demonstrated the value of providing better and more extensive writing support on SNSs, and the potential of AI for building a more inclusive Internet.", "corpusId": "140233634", "paragraphs": [{"paragraphId": "68120", "title": "Design and Evaluation of a Social Media Writing Support Tool for People with Dyslexia", "sectionTitle": "LITERATURE REVIEW Dyslexia", "text": "Previous technical approaches to accessibility for dyslexia have focused on reading, including adding colored overlays, deploying special typography, increasing font size and margin space, and a combination of these changes [14,31,43]. Others have focused on improving reading comprehension by, for example, modifying content to be easier to read [45]. In contrast, little research has explored improving writing, and those that did have primarily explored and drawn from text samples written for school assignments [41,42,52].", "spans": "[{\"corpusId\": 305063, \"span\": \"[14,\", \"start\": 224, \"end\": 228}, {\"corpusId\": 16501419, \"span\": \"43]\", \"start\": 231, \"end\": 234}, {\"corpusId\": 11473010, \"span\": \"[45]\", \"start\": 347, \"end\": 351}, {\"corpusId\": 27148110, \"span\": \"52]\", \"start\": 523, \"end\": 526}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "68121", "title": "Design and Evaluation of a Social Media Writing Support Tool for People with Dyslexia", "sectionTitle": "Dyslexia-specific writing support tools", "text": "There have been eforts to create dyslexia-specifc spell checkers [32,41,44]. Pedler [40] identifed sets of words likely to be confused, and enhanced an online dictionary to better detect real-word errors. Real Check leveraged a probabilistic language model, a statistical dependency parser and Google n-grams to detect real-word errors in Spanish [44].", "spans": "[{\"corpusId\": 38945331, \"span\": \"[32,\", \"start\": 65, \"end\": 69}, {\"corpusId\": 15048167, \"span\": \"44]\", \"start\": 72, \"end\": 75}, {\"corpusId\": 2762304, \"span\": \"[40]\", \"start\": 84, \"end\": 88}, {\"corpusId\": 15048167, \"span\": \"[44]\", \"start\": 347, \"end\": 351}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "68122", "title": "Design and Evaluation of a Social Media Writing Support Tool for People with Dyslexia", "sectionTitle": "Machine learning for spell/grammar checking", "text": "There is much NLP research for automated spell/grammar checking [34,35]. Most popular systems are rule [6,23,39] or statistical language model based [18,26,38]. Rule-based systems rely on manually-created grammar rules, and are constrained on completeness and adaptability to new grammar and word usage [36]. They are also expensive to adapt for a new language, since the rules need to be re-evaluated or regenerated. Statistical language model systems leverage large text corpora to detect and correct spelling/grammar errors based how often the original and the corrected phrase/sentence occur in the training corpus. It is unsupervised and easily portable to other languages as long as sizable training corpora exist. However, a statistical language model can be biased towards the writing style of the training corpus, and can over-fre for low-frequency words/phrases. Both systems are limited by the types of corrections they make. Rule-based systems only make changes within the range of available rules; statistical language model based systems only make local lexical changes such as word replacement and the addition/removal of small functional words.", "spans": "[{\"corpusId\": 3064994, \"span\": \"[6,\", \"start\": 103, \"end\": 106}, {\"corpusId\": 12799954, \"span\": \"23,\", \"start\": 106, \"end\": 109}, {\"corpusId\": 13214115, \"span\": \"26,\", \"start\": 153, \"end\": 156}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "68123", "title": "Design and Evaluation of a Social Media Writing Support Tool for People with Dyslexia", "sectionTitle": "Understanding dyslexia writing dataset", "text": "Such challenges occur in other text correction tasks like grammatical error detection (GED) [8,11], and the conventional solution is to use more annotators. Two annotators per sentence is a common setup [37]. Despite these challenges, we were able to collect dyslexia style writing on SNSs with relatively high quality corrections that is almost 30 times bigger than existing dyslexia corpora [41]. The following example shows how a post was corrected.", "spans": "[{\"corpusId\": 15484870, \"span\": \"[8,\", \"start\": 92, \"end\": 95}, {\"corpusId\": 6733826, \"span\": \"11]\", \"start\": 95, \"end\": 98}, {\"corpusId\": 219306476, \"span\": \"[37]\", \"start\": 203, \"end\": 207}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "68124", "title": "Design and Evaluation of a Social Media Writing Support Tool for People with Dyslexia", "sectionTitle": "Model evaluation", "text": "Results. We calculated the precision and recall of our model and benchmarked against Microsoft Word (widely used by people with dyslexia for spell checking [46]). To get corrections made by Microsoft Word (Ofce 2018 on Windows), annotators copy-and-pasted the text from FB sample into Word, right-clicked every place that was underlined, and picked the top suggestion provided. Similar benchmarking data for the public sample was collected and shared by a third party tech blogger [51], which we used for our evaluation 8 .", "spans": "[{\"corpusId\": 49409610, \"span\": \"[46]\", \"start\": 156, \"end\": 160}, {\"corpusId\": 140233634, \"span\": \"our evaluation\", \"start\": 519, \"end\": 519}, {\"corpusId\": 15484870, \"span\": \"8\", \"start\": 520, \"end\": 521}]", "conference": "chi", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 5}
{"paperId": "9f240a56b8e13e9da50966eb5cfcb4c8aa91e631", "title": "Towards Sustainable ICTD in Bangladesh: Understanding the Program and Policy Landscape and Its Implications for CSCW and HCI", "venue": "Proc. ACM Hum. Comput. Interact.", "year": 2022, "citationCount": 18, "openAccessPdf": {"url": "https://dl.acm.org/doi/pdf/10.1145/3512973", "status": "BRONZE", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3512973?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3512973, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2022-03-30", "authors": [{"authorId": "2093608161", "name": "Manika Saha"}, {"authorId": "22699782", "name": "Delvin Varghese"}, {"authorId": "3132347", "name": "Tom Bartindale"}, {"authorId": "5162419", "name": "S. Thilsted"}, {"authorId": "145867840", "name": "Syed Ishtiaque Ahmed"}, {"authorId": "145171812", "name": "P. Olivier"}], "abstract": "Historically, Computer-Supported Cooperative Work (CSCW) and Human-Computer Interaction for Development (HCI4D) researchers in the Global South have advocated for a community-based approach to technology design and development. However, even with this \"bottom-up\" emphasis, the sustainability and scalability of the resulting innovations remain major challenges, and are poorly understood. To address this gap, we take the case of Bangladesh as a typical Global South context in which development work is carried out by a complex intertwined network of stakeholders across governments, NGOs, donors, and industries. To better understand the current development landscape and its priorities for digital technologies, we conducted interviews with 14 influential decision-makers in Bangladesh who play significant roles in the development of nutrition strategies. Our findings highlight a disconnect between the Bangladesh government's \"digital mandate\" and the reality of digital innovation practice within the nutrition development sector. Our paper contributes to the debate on factors that affect decision-making processes. We explore the dynamics of diverse actors and institutions who are intended to participate in, but can act as obstacles to sustained bottom-up innovations. Our findings expand understanding of institutional priorities, the dynamics of intermediaries, techno-solutionism, postcolonialism, bureaucracy, competition, and other important topics in CSCW scholarship. We suggest understanding the factors that guide the decision-making process of digital innovation practices in terms of four dimensions: internal, external, vertical, and horizontal. Consequently, we recommend CSCW and HCI researchers become mediators to connect decision-makers and communities and bring their voices in ICT innovations for global development. Finally, we offer recommendations for proactive engagement with decision-making stakeholders, enabling researchers to design community-centered sustainable digital innovations for development.", "corpusId": "248002679", "paragraphs": [{"paragraphId": "41468", "title": "Towards Sustainable ICTD in Bangladesh: Understanding the Program and Policy Landscape and Its Implications for CSCW and HCI", "sectionTitle": "INTRODUCTION", "text": "Over the last two decades in Global South contexts, researchers carrying out Computer-Supported Cooperative Work (CSCW) and Human-Computer Interaction for Development (HCI4D) have argued for the input of local communities, advocating for technology innovation that is culturally appropriate and non-technocratic. They commonly invoke innovation through bottom-up approaches to empower communities within development contexts [35]. However, the inability to sustain a more extended period to scale up technology-based programs and projects remain as absolute constraints in Global South countries [31,51,54,120,123,125]. It has also been recognized that for digital innovation to be successful and sustainable, the wider stakeholder landscape needs to be considered alongside local practices and participatory design processes [21]. The importance of understanding the collaborative nature of solution research, design, and use and collaboration with decision-making stakeholders has been emphasized by several researchers in CSCW and HCI [37,61,66,72,73,109]. Kumar and Dell [69] go further and have demonstrated the need for a deeper understanding of how global development practitioners use innovation to generate informed practice for successful HCI4D. However, it has remained under-studied why and how the bureaucratically led policymaking process, which often involves embarking on unfounded, overestimated, and expensive technology deployments, is mismatched with the demonstrable value gained from engaging communities on the ground. Further, there is little well-articulated literature on the high-level political contexts and actors in Global South countries, such as the political visions and priorities influencing and driving Information and Communication Technology for Development (ICTD) programs and how projects and policies change as they go through central authorities (from the government to national and international organizations) [124].", "spans": "[{\"corpusId\": 8472918, \"span\": \"[35]\", \"start\": 425, \"end\": 429}, {\"corpusId\": 8931650, \"span\": \"51,\", \"start\": 600, \"end\": 603}, {\"corpusId\": 16661269, \"span\": \"54,\", \"start\": 603, \"end\": 606}, {\"corpusId\": 2978543, \"span\": \"125]\", \"start\": 614, \"end\": 618}, {\"corpusId\": 16766714, \"span\": \"[21]\", \"start\": 826, \"end\": 830}, {\"corpusId\": 5049844, \"span\": \"[37,\", \"start\": 1038, \"end\": 1042}, {\"corpusId\": 29657914, \"span\": \"61,\", \"start\": 1042, \"end\": 1045}, {\"corpusId\": 15689982, \"span\": \"66,\", \"start\": 1045, \"end\": 1048}, {\"corpusId\": 140217731, \"span\": \"109]\", \"start\": 1054, \"end\": 1058}, {\"corpusId\": 53245485, \"span\": \"[69]\", \"start\": 1075, \"end\": 1079}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 10}, {"paragraphId": "41469", "title": "Towards Sustainable ICTD in Bangladesh: Understanding the Program and Policy Landscape and Its Implications for CSCW and HCI", "sectionTitle": "INTRODUCTION", "text": "2 RELATED WORK 2.1 Digital Technology and HCI for Sustainable Development CSCW, HCI, and related fields have long demonstrated their potential to influence international development where ICT is involved, and thus the intersection between HCI and ICT for Development is often at tailoring technologies for marginalized populations [60,117,127]. The review on HCI4D by Dell and Kumar noted that, \"nearly half of the papers (128) target 'ground-level users' to respond to their specific needs and challenges\" [35]. With this, we see a significant amount of HCI4D work has been conducted in the areas of sharing agricultural communication and information with farmers [43,94], health [68,92] and nutrition for women [23,110], facilitating field tasks with health workers [100], educational technology [121], monitoring and evaluation (M&E) purposes for NGOs [11,74], and safety and security goals for women [3,5]. Furthermore, researchers have also shown that there is a big push in the Global South to transfer technologies from the West and use them in international development contexts, copying the western practice of innovation [59], which is compounded by the UN and other NGOs advocating for the innovation and use of digital technology towards achieving all SDGs [89]. While there is a definite upward trend of using ICT in most development programs and projects, an inability to sustain such innovation for an extended period after the initial research is conducted, so as to be able to scale up technology-based programs and projects, remains an absolute constraint [8,31,51,54,123,124]. In their review, Avgerou and Walsham [9] stated that \"successful examples of computerization can be found . . . but frustrating stories of systems which failed . . . are more frequent. \"", "spans": "[{\"corpusId\": 52853291, \"span\": \"117,\", \"start\": 335, \"end\": 339}, {\"corpusId\": 56293018, \"span\": \"127]\", \"start\": 339, \"end\": 343}, {\"corpusId\": 8472918, \"span\": \"[35]\", \"start\": 507, \"end\": 511}, {\"corpusId\": 5380348, \"span\": \"94]\", \"start\": 669, \"end\": 672}, {\"corpusId\": 2766983, \"span\": \"[68,\", \"start\": 681, \"end\": 685}, {\"corpusId\": 3346245, \"span\": \"92]\", \"start\": 685, \"end\": 688}, {\"corpusId\": 12469639, \"span\": \"[23,\", \"start\": 713, \"end\": 717}, {\"corpusId\": 133040472, \"span\": \"110]\", \"start\": 717, \"end\": 721}, {\"corpusId\": 16141220, \"span\": \"[100]\", \"start\": 768, \"end\": 773}, {\"corpusId\": 6238696, \"span\": \"[121]\", \"start\": 798, \"end\": 803}, {\"corpusId\": 140226118, \"span\": \"[11,\", \"start\": 855, \"end\": 859}, {\"corpusId\": 3407655, \"span\": \"[3,\", \"start\": 904, \"end\": 907}, {\"corpusId\": 5422077, \"span\": \"5]\", \"start\": 907, \"end\": 909}, {\"corpusId\": 3128663, \"span\": \"[59]\", \"start\": 1131, \"end\": 1135}, {\"corpusId\": 8931650, \"span\": \"51,\", \"start\": 1580, \"end\": 1583}, {\"corpusId\": 16661269, \"span\": \"54,\", \"start\": 1583, \"end\": 1586}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 16}, {"paragraphId": "41470", "title": "Towards Sustainable ICTD in Bangladesh: Understanding the Program and Policy Landscape and Its Implications for CSCW and HCI", "sectionTitle": "INTRODUCTION", "text": "Understanding local contexts, including appropriate technology design and selection and social, cultural, economic, and political factors, is highlighted by many researchers on the developing world as important in addressing sustainable ICTD [8,51,53,120,123]. James C. Scott [105] showed, in relation to his large program failure cases, that successful program design needs to value local and practical knowledge for implementation. Anokwa et al. [6] also emphasized the understanding of challenges and the importance of collaboration at the local levels. Conversely, the unintentional practice of ICTD researchers conducting short-term visits to complete their research to make publications and recommendations without any meaningful impact is also highlighted as an ethical concern and a reason behind the lack of sustainable impact of ICTD in Global South contexts [32,33]. In response, Dearden and Tucker [33] suggested that \"actors in the broader field of ICTD implementation (i.e., action by NGOs, aid agencies, and other organizations innovating and applying technology to development challenges) should examine how resources are used and how decisions are taken so that systemic and sustainable capacity building is prioritized. \"", "spans": "[{\"corpusId\": 8931650, \"span\": \"51,\", \"start\": 245, \"end\": 248}, {\"corpusId\": 9736396, \"span\": \"[6]\", \"start\": 448, \"end\": 451}, {\"corpusId\": 11150412, \"span\": \"[32,\", \"start\": 869, \"end\": 873}, {\"corpusId\": 12123751, \"span\": \"33]\", \"start\": 873, \"end\": 876}, {\"corpusId\": 12123751, \"span\": \"[33]\", \"start\": 910, \"end\": 914}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "41471", "title": "Towards Sustainable ICTD in Bangladesh: Understanding the Program and Policy Landscape and Its Implications for CSCW and HCI", "sectionTitle": "INTRODUCTION", "text": "The importance of understanding the high-level decision-making context has also been well recognized and highlighted by the broader HCI community [12,57,72,73]. While many studies focus on the bottom-level local context of program implementation [6,31,120] and note the importance of understanding political analysis [123], there has been sparse reporting on the highlevel context in which policy and programs are formed. Heeks emphasized that the high rate of ICTD program failure arises from the \"design-reality gaps\" that arise from a lack of understanding of decision-makers' and program designers' contexts [53]. Overall, sufficient insights have not yet been articulated on the high-level political contexts and actors, such as the political visions and priorities influencing and driving ICTD programs and how projects and policies change as they go through a central authority (from the government to national and international organizations, including donors) [124]. We intend to contribute to this discussion by presenting the nature and roots of these gaps in the public health nutrition context in Bangladesh.", "spans": "[{\"corpusId\": 9356404, \"span\": \"[12,\", \"start\": 146, \"end\": 150}, {\"corpusId\": 20673019, \"span\": \"57,\", \"start\": 150, \"end\": 153}, {\"corpusId\": 9736396, \"span\": \"[6,\", \"start\": 246, \"end\": 249}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "41472", "title": "Towards Sustainable ICTD in Bangladesh: Understanding the Program and Policy Landscape and Its Implications for CSCW and HCI", "sectionTitle": "CSCW and HCI in Program and Policy Decision-Making Contexts", "text": "CSCW and HCI for program and policy research have a historical perspective informed by the work of social informatics researchers such as Kling, King, and Scacchi in the early '80s [65][66][67]. Kling provided rich insights on the \"cooperative\" and \"collaborative\" nature of social computing and the need to tie design, use, and technological impact together among stakeholders [66]. CSCW, HCI and ICT have historically had a relationship with participatory design (PD) and innovation-related programs and policymaking by specific political concerns [62,[65][66][67]122]. Jackson et al. [62] recognized that there is a disconnection among research, design, and practice in the field of CSCW and argued for a holistic orientation, proposing an interconnected \"knot model\" (among design, use, and collaboration with organizations within public policy systems) with a focus on policy, practice, and design. The role of policy design was also investigated by Jackson and colleagues, [63] who emphasized the need for collaboration and mutual learning between scientific study and policy to successfully navigate design, infrastructure, and organizational collaboration complexities. They highlighted that traditional CSCW is more focused on \"implication for design\" than \"implication for policy\" in regard to ambitions of long-term social impact. Similarly, Freeman et al. (2017) [42] pointed out the scarcity of empirical studies between design and policy contexts in HCI and CSCW.", "spans": "[{\"corpusId\": 6786169, \"span\": \"[65]\", \"start\": 181, \"end\": 185}, {\"corpusId\": 15689982, \"span\": \"[66]\", \"start\": 185, \"end\": 189}, {\"corpusId\": 6510735, \"span\": \"[67]\", \"start\": 189, \"end\": 193}, {\"corpusId\": 15689982, \"span\": \"[66]\", \"start\": 378, \"end\": 382}, {\"corpusId\": 28402439, \"span\": \"[62,\", \"start\": 550, \"end\": 554}, {\"corpusId\": 6786169, \"span\": \"[65]\", \"start\": 554, \"end\": 558}, {\"corpusId\": 15689982, \"span\": \"[66]\", \"start\": 558, \"end\": 562}, {\"corpusId\": 6510735, \"span\": \"[67]\", \"start\": 562, \"end\": 566}, {\"corpusId\": 15830723, \"span\": \"122]\", \"start\": 566, \"end\": 570}, {\"corpusId\": 28402439, \"span\": \"[62]\", \"start\": 587, \"end\": 591}, {\"corpusId\": 42478766, \"span\": \"[63]\", \"start\": 979, \"end\": 983}, {\"corpusId\": 17924509, \"span\": \"Freeman et al. (2017)\", \"start\": 1353, \"end\": 1374}, {\"corpusId\": 17924509, \"span\": \"[42]\", \"start\": 1375, \"end\": 1379}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "41473", "title": "Towards Sustainable ICTD in Bangladesh: Understanding the Program and Policy Landscape and Its Implications for CSCW and HCI", "sectionTitle": "CSCW and HCI in Program and Policy Decision-Making Contexts", "text": "The complex multi-sectoral nature of high-level decision making and the institutions that form these decision networks can be further understood through the concept of institutioning. Institutioning refers to working within diverse institutions [36], and is a useful frame for understanding the complexity within community-based design processes, particularly when conducting a program with a participatory design (PD) [114,115]. These scenarios are characterized as situations in which the process is constantly moving horizontally and vertically between and within diverse micro-meso and macro levels [58] and call for attention to the significant relationships between policy, institutions, and meta-cultural frames [58,115]. PD approaches in social computing are figured by a diverse group of institutions, and need to be understood in terms of the meso-and macro-level institutions that PD is dependent on and informed by [58]. Dearden and colleagues [33] also acknowledged the need to understand the institutioning involved in critical computing issues. In the debate on HCI and social innovation, they also contribute to the insufficiently studied issue of HCI designers' lack of attention past the research context to how innovations become distributed and adopted for social goods. Political issues surrounding technology, such as how decisions are made for technology adoption and scale-up in programs may be understood through the complexities of institutioning and the actors at the decision-making level [114,115], where these institutions and their individuals are broadly influenced by their own objectives and priorities, yet have to translate initiatives between designers and communities [25,26].", "spans": "[{\"corpusId\": 11579846, \"span\": \"[36]\", \"start\": 245, \"end\": 249}, {\"corpusId\": 216376925, \"span\": \"[114,\", \"start\": 419, \"end\": 424}, {\"corpusId\": 51929402, \"span\": \"115]\", \"start\": 424, \"end\": 428}, {\"corpusId\": 116156209, \"span\": \"[58]\", \"start\": 603, \"end\": 607}, {\"corpusId\": 116156209, \"span\": \"[58,\", \"start\": 719, \"end\": 723}, {\"corpusId\": 51929402, \"span\": \"115]\", \"start\": 723, \"end\": 727}, {\"corpusId\": 116156209, \"span\": \"[58]\", \"start\": 927, \"end\": 931}, {\"corpusId\": 12123751, \"span\": \"[33]\", \"start\": 956, \"end\": 960}, {\"corpusId\": 216376925, \"span\": \"[114,\", \"start\": 1517, \"end\": 1522}, {\"corpusId\": 51929402, \"span\": \"115]\", \"start\": 1522, \"end\": 1526}, {\"corpusId\": 225070443, \"span\": \"[25,\", \"start\": 1706, \"end\": 1710}, {\"corpusId\": 174799698, \"span\": \"26]\", \"start\": 1710, \"end\": 1713}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "41474", "title": "Towards Sustainable ICTD in Bangladesh: Understanding the Program and Policy Landscape and Its Implications for CSCW and HCI", "sectionTitle": "CSCW and HCI in Program and Policy Decision-Making Contexts", "text": "Actors who interact with both designer and users are considered \"intermediaries. \" They create opportunities to share, use, and implement technologies and technological innovations toward social innovation [25,111]. HCI researchers need to understand the relational dynamics of intermediaries in social innovation processes. Through configuring the role of intermediation and understanding how an artefact is shaped, embraced, and used in the real world, PD can improve HCI's approach to effective social innovations. Huybrechts et al. [58] also argued that besides doing micro-political work, PD researchers need to expand their boundaries \"for a more critical acknowledgement of the ways in which PD processes are inscribed in, and dependent on, institutional actors.\" Studies have noted that for better scaling of PD practice toward social innovation, we need to understand the \"institutional frames\" in which institutions' rules, agendas, and priorities work [58,76]. Various studies in the literature have highlighted gaps in understanding how innovations are shaped by intermediaries as actors; institutions; institutional norms and cultures; and actors' objectives, interests, practices, and political agendas [25,26,33,34,58,114,115].", "spans": "[{\"corpusId\": 225070443, \"span\": \"[25,\", \"start\": 206, \"end\": 210}, {\"corpusId\": 154566043, \"span\": \"111]\", \"start\": 210, \"end\": 214}, {\"corpusId\": 116156209, \"span\": \"[58]\", \"start\": 536, \"end\": 540}, {\"corpusId\": 116156209, \"span\": \"[58,\", \"start\": 963, \"end\": 967}, {\"corpusId\": 51930533, \"span\": \"76]\", \"start\": 967, \"end\": 970}, {\"corpusId\": 225070443, \"span\": \"[25,\", \"start\": 1217, \"end\": 1221}, {\"corpusId\": 174799698, \"span\": \"26,\", \"start\": 1221, \"end\": 1224}, {\"corpusId\": 12123751, \"span\": \"33,\", \"start\": 1224, \"end\": 1227}, {\"corpusId\": 14314427, \"span\": \"34,\", \"start\": 1227, \"end\": 1230}, {\"corpusId\": 116156209, \"span\": \"58,\", \"start\": 1230, \"end\": 1233}, {\"corpusId\": 216376925, \"span\": \"114,\", \"start\": 1233, \"end\": 1237}, {\"corpusId\": 51929402, \"span\": \"115]\", \"start\": 1237, \"end\": 1241}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "41475", "title": "Towards Sustainable ICTD in Bangladesh: Understanding the Program and Policy Landscape and Its Implications for CSCW and HCI", "sectionTitle": "Digitization in International Development", "text": "In the current democratic digital age, many prominent scholars in information technology and development studies have explored the political motivations and complexities of governance, institutions, and technology adoptions in global development. Many studies have investigated the common political tendency of governments in the Global South to push for innovations for all types of development. Gurumurthy points out that the tendency of this push for digitization extends power dynamics and contestations in top-down contexts [46][47][48]. Likewise, Maitet et al. critiques this promotion of digitization by governments as tending to widen the digital divide between the poor and the rich [77]. Through a meta-analysis of various digital contexts, Burns [22] highlights this promotion of digital innovation in light of governance and democracy-related political issues. He critiques decision-making stakeholder collaboration by governments, NGOs, INGOs, and donor organizations working towards international program development and implementation through digital innovation as a process driven by capitalism, resulting in wealth inequality and ignoring peoples' needs [22]. Similarly, the renowned economists Easterly [38] and Moyo [40] have criticized donor institutions as enlarging national-level government bureaucracies, preserving bad governance, and widening the inequity between rich and poor. They highlighted how factors of social and cultural capital impact participatory development in both top-down and bottom-up approaches to sustainable development in the Global South [112].", "spans": "[{\"corpusId\": 84240449, \"span\": \"[46]\", \"start\": 529, \"end\": 533}, {\"corpusId\": 235783704, \"span\": \"[48]\", \"start\": 537, \"end\": 541}, {\"corpusId\": 213945115, \"span\": \"[77]\", \"start\": 692, \"end\": 696}, {\"corpusId\": 239129077, \"span\": \"[22]\", \"start\": 757, \"end\": 761}, {\"corpusId\": 239129077, \"span\": \"[22]\", \"start\": 1171, \"end\": 1175}, {\"corpusId\": 53001359, \"span\": \"[38]\", \"start\": 1221, \"end\": 1225}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "41476", "title": "Towards Sustainable ICTD in Bangladesh: Understanding the Program and Policy Landscape and Its Implications for CSCW and HCI", "sectionTitle": "Digitization in International Development", "text": "Extensive work in a variety of e-governance sectors has been conducted by Bhatnagar and colleagues, primarily in India. They highlighted many potentials of e-government and also noted how inefficient and corrupt bureaucracy and overall poor-quality governance restrict sustainable innovations in developments in the Global South [13,14,24]. Toyoma broadly working in the interaction of ICTD and HCID, argued that digital innovations may amplify human development in a broad set of global development contexts, where institutions and responsible individuals work with optimistic and good intentions [118]. However, it has not been well-explored how multi-sectoral decision-makers, including national governments, INGOs, UN organizations, and donors, work, perceive, and interact in a very specific development sector (such as the public health nutrition development context in Bangladesh) towards digital innovation and their implications for CSCW and HCI practitioners for sustainable development.", "spans": "[{\"corpusId\": 26730837, \"span\": \"14,\", \"start\": 333, \"end\": 336}, {\"corpusId\": 27855843, \"span\": \"24]\", \"start\": 336, \"end\": 339}, {\"corpusId\": 18193450, \"span\": \"[118]\", \"start\": 598, \"end\": 603}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "41477", "title": "Towards Sustainable ICTD in Bangladesh: Understanding the Program and Policy Landscape and Its Implications for CSCW and HCI", "sectionTitle": "The Actors -Stakeholder Collaboration", "text": "While nutrition policy agendas are discussed and put into law by decision-makers in the capital, Dhaka city, projects to support the policies are undersigned by largely international donors (such as the World Bank and USAID). As a result, a strong and direct influence of global movements is visible in nutrition programs and policy development. For instance, the Millennium Development Goals (MDGs) of 2000 introduced specifically-targeted national nutritional surveillance system indicators. Various studies have highlighted the importance of integrating all relevant sectoral stakeholders for evidence-based nutrition policy formulation and implementation more coherently and collaboratively [15,17,49,50,103]. In 2014, the Second International Conference on Nutrition (ICN2) declared, \"it is well-established that nutrition objectives can only be achieved through a multisectoral response. This requires different sectors and stakeholders working together more coherently and collaboratively to address malnutrition in all its forms\" [41].", "spans": "[{\"corpusId\": 12237910, \"span\": \"17,\", \"start\": 699, \"end\": 702}, {\"corpusId\": 4408790, \"span\": \"50,\", \"start\": 705, \"end\": 708}, {\"corpusId\": 13953925, \"span\": \"103]\", \"start\": 708, \"end\": 712}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "41478", "title": "Towards Sustainable ICTD in Bangladesh: Understanding the Program and Policy Landscape and Its Implications for CSCW and HCI", "sectionTitle": "Understanding Decision-Making Contexts and Positioning for HCI Researchers", "text": "Our findings show how the priorities of higher-level stakeholders, such as governments, UN groups, and donor agencies, shape ICT innovations in nutrition development programs in Bangladesh and that the opportunities for bottom-up approaches to innovation in public health nutrition in Bangladesh are still limited. The tendency of governments and donors to push technology innovations into Global South contexts is not a new phenomenon, as discussed in literature that we highlighted in our related work section. However, distinctions between the ways in which top-down authority is invoked is necessary to clarify that the actions of high-level policymakers, government officeholders, and multinational NGOs are not necessarily antithetical to the success of development innovations. Those involved in CSCW and HCI4D have long advocated for engaging with under-represented groups and bringing under-explored topics to the fore. We extend this line of work by arguing for incorporating marginalized communities' voices as part of an engagement with program and policy makers into the decision-making process. Our findings highlight that this incorporation is often challenged by various internal and external factors in the local governing system. By considering the interactions among diverse top-down institutions [58,76,114,115] their institutioning, the intermediaries involved (such as multi-sectoral actors in government INGOs and donor agencies), and the dynamics of intermediation, we can articulate how they work and where HCI can contribute in the processes of digital innovations with and for marginalized communities. Hence, we suggest that HCI researchers develop a nuanced understanding of the policy and program-making contexts within which their intervention is placed. We suggest there is a potentially fruitful opportunity for HCI researchers to take a middle-man approach and connect the bottom-up and top-down contexts [37].", "spans": "[{\"corpusId\": 248002679, \"span\": \"Our findings\", \"start\": 12, \"end\": 12}, {\"corpusId\": 248002679, \"span\": \"Our findings\", \"start\": 1121, \"end\": 1121}, {\"corpusId\": 116156209, \"span\": \"[58,\", \"start\": 1316, \"end\": 1320}, {\"corpusId\": 51930533, \"span\": \"76,\", \"start\": 1320, \"end\": 1323}, {\"corpusId\": 216376925, \"span\": \"114,\", \"start\": 1323, \"end\": 1327}, {\"corpusId\": 51929402, \"span\": \"115]\", \"start\": 1327, \"end\": 1331}, {\"corpusId\": 5049844, \"span\": \"[37]\", \"start\": 1939, \"end\": 1943}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "41479", "title": "Towards Sustainable ICTD in Bangladesh: Understanding the Program and Policy Landscape and Its Implications for CSCW and HCI", "sectionTitle": "Understanding Decision-Making Contexts and Positioning for HCI Researchers", "text": "First, we need to consider external factors and actors. More specifically, CSCW and HCI4D designers and researchers need to know who the prominent multi-sectoral decision-making institutes and actors are (such as governments, NGOs, UN groups, and donors) in a targeted international development sector (such as public health nutrition). We need to be aware of and consider all external influences and motivations where these decision-makers work as \"innovation intermediaries\" [111] to shape and implement innovations. For instance, within these diverse top-down institutions, CSCW and HCI researchers need to consider external factors of institutioning [76], such as how the global and national mandates, agendas, evidence-based approaches, and priorities constantly move and shape innovations. Second, we need to consider internal factors to understand the dynamics of these intermediaries [58,114,115] by understanding their political motivations, existing competitions, perceptions, and expectations of using ICTs in development programs and policies. Third, we need to understand vertical mechanisms and interactions. For instance, we need to consider mechanisms such as the way top-down approaches and actors such as decision-makers inform the bottom-up actors such as marginalized citizens and vice-versa [38]. Finally, we need to consider horizontal mechanisms and interactions by considering existing practices and processes within innovation. These include understanding how these diverse decision-making actors work and collaborate with each other and the dynamics of their diverse collaborations and intermediaries. Consideration of both internal and external factors are also needed within both vertical and horizontal mechanisms of interaction. Accounting for the relevant dynamics in terms of these four dimensions can help HCI and CSCW researchers to understand the top-down decision-making environment for innovations and discover the gaps that need to be filled to successfully implement bottom-up approaches.", "spans": "[{\"corpusId\": 154566043, \"span\": \"[111]\", \"start\": 477, \"end\": 482}, {\"corpusId\": 51930533, \"span\": \"[76]\", \"start\": 654, \"end\": 658}, {\"corpusId\": 116156209, \"span\": \"[58,\", \"start\": 892, \"end\": 896}, {\"corpusId\": 216376925, \"span\": \"114,\", \"start\": 896, \"end\": 900}, {\"corpusId\": 51929402, \"span\": \"115]\", \"start\": 900, \"end\": 904}, {\"corpusId\": 53001359, \"span\": \"[38]\", \"start\": 1312, \"end\": 1316}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "41480", "title": "Towards Sustainable ICTD in Bangladesh: Understanding the Program and Policy Landscape and Its Implications for CSCW and HCI", "sectionTitle": "Configuring for Sustained Impact", "text": "Taking a closer look at some examples of technology innovations that have been able to create sustainable impact, we see that in addition to a commitment to work within local constraints and infrastructures, practitioners emphasize the value of collaborations with multiple NGO stakeholders and/or government agencies in contributing to their impact. As an example, Ushahidi (a platform for local communities to share their stories) [82,102] was successful due to strong collaborations with local NGOs, which not only added a layer of trust to NGO-verified contributions but also increased uptake [119]. Similarly, the 'Our Story' (currently known as 'Indaba') participatory video platform was pioneered by HCI researchers by leveraging the institutional networks of the Red Cross Movement's umbrella body IFRC (International Federation of Red Cross and Red Crescent Societies, who operate on both top-down and bottom-up dimensions [126]). Through this collaboration, a number of relationships with NGOs at the local level were brokered (with the Indonesian Red Cross and Namibian Red Cross, for example) [11] which were used by the IFRC to advocate for sustained use of the tool within the wider network. Finally, RootIO (a platform for low-cost community radio) similarly credits their success to extensive collaborations with content partners, politicians, community leaders, networks of youth centers, and contacts within government ministries [26,29]. Indeed, RootIO collaborated with national communications regulators and involved local community NGOs [28] in each deployment. We recommend that as part of the requirement of initial informationgathering within social computing and HCI for development project collaborations, researchers should find out the priorities of local political stakeholders who play influential roles in regional development and areas of alignment or difference between collaborators and other NGOs and government ministries who work in that sector.", "spans": "[{\"corpusId\": 5794809, \"span\": \"[82,\", \"start\": 433, \"end\": 437}, {\"corpusId\": 54092608, \"span\": \"[126]\", \"start\": 932, \"end\": 937}, {\"corpusId\": 140226118, \"span\": \"[11]\", \"start\": 1105, \"end\": 1109}, {\"corpusId\": 174799698, \"span\": \"[26,\", \"start\": 1448, \"end\": 1452}, {\"corpusId\": 21546420, \"span\": \"29]\", \"start\": 1452, \"end\": 1455}, {\"corpusId\": 176957502, \"span\": \"[28]\", \"start\": 1559, \"end\": 1563}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "41481", "title": "Towards Sustainable ICTD in Bangladesh: Understanding the Program and Policy Landscape and Its Implications for CSCW and HCI", "sectionTitle": "Configuring for Sustained Impact", "text": "Moreover, decades of work in Participatory Design (PD) has been advocating for such inclusion of all stakeholders; in fact, there have been a plethora of examples in HCI of local government bodies being included in designing projects of public interest. Through configuring the role of intermediation and understanding how an artefact is shaped, embraced, and used in the real world, PD in HCI can improve its approach to effective social innovations [25]. We want to emphasize that we advocate taking this strategy further. We do not only mean having some policymakers around the table along with other stakeholders to make the design more democratic, but also that they need to design for the challenges that policymakers face and involve local people in designing solutions for those problems. For example, as our data shows, policymakers are often tempted to deploy digital applications because there is external pressure from donors and the government but that have little use in the community. We suggest that this problem also be brought to the table when doing such as designing a nutrition program with the local community. A grassroots-level movement, for example, may create a nationwide awareness against such unjustified pressure to deploy digital technologies. We are excited about the potential of various HCI interventions that have allowed local people to voice such concerns in the Global South [11,81,84,121,122], and we believe that such technologies might be useful in addressing the problems at the top to help make a bottom-up design successful.", "spans": "[{\"corpusId\": 225070443, \"span\": \"[25]\", \"start\": 451, \"end\": 455}, {\"corpusId\": 140226118, \"span\": \"[11,\", \"start\": 1413, \"end\": 1417}, {\"corpusId\": 12554978, \"span\": \"81,\", \"start\": 1417, \"end\": 1420}, {\"corpusId\": 14397078, \"span\": \"84,\", \"start\": 1420, \"end\": 1423}, {\"corpusId\": 6238696, \"span\": \"121,\", \"start\": 1423, \"end\": 1427}, {\"corpusId\": 15830723, \"span\": \"122]\", \"start\": 1427, \"end\": 1431}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "41482", "title": "Towards Sustainable ICTD in Bangladesh: Understanding the Program and Policy Landscape and Its Implications for CSCW and HCI", "sectionTitle": "Tech Obsession in Policymaking", "text": "Our findings show that there is intense interests in developing new technology-related innovations among policy and program creators. We raise this as a critical challenge for ICT and HCI researchers, as this tendency to create new technologies raises a tension between their central priorities of \"innovations\" and \"sustainability. \" For instance, while policy and program makers have been also pursuing development of novel technology innovations for program management, our participants have advocated the need for more evidence-based sustainable program development. This intention create additional new technologies is a threat where questions of sustainability and scalability of those technologies are substantive, leading to many instances of technological innovations that fall under the heading of \"solutionism. \" This tendency is often cited in social and political science critiques as \"technology solutionism\" or the \"technology fix. \" In recent HCI design research, fixing problems that don't exist and proposing\"quick fixes\" or \"silver bullets\" for complicated social, political, and environmental challenges are criticized as \"solutionist\" [18,19,75,86]. The \"technosolutionism\" ideology was critiqued by Morozov [85], who pointed out the political tendency to believe blindly in the ability of technology to solve challenges with innovative design. On democratizing the potential of the internet and ICT, Morozov also highlighted a critical point of debate on political transformation in digital societies, expressing skepticism toward governments' ability to promote democracy through the internet in the West, adding that \"techno-solutionism\" ignores debates about politics, history, culture, actual needs and challenges, and people's capacities to adopt new technologies [85].", "spans": "[{\"corpusId\": 248002679, \"span\": \"Our findings\", \"start\": 12, \"end\": 12}, {\"corpusId\": 248002679, \"span\": \"our participants\", \"start\": 489, \"end\": 489}, {\"corpusId\": 207210135, \"span\": \"[18,\", \"start\": 1156, \"end\": 1160}, {\"corpusId\": 12635240, \"span\": \"19,\", \"start\": 1160, \"end\": 1163}, {\"corpusId\": 4638619, \"span\": \"75,\", \"start\": 1163, \"end\": 1166}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "41483", "title": "Towards Sustainable ICTD in Bangladesh: Understanding the Program and Policy Landscape and Its Implications for CSCW and HCI", "sectionTitle": "Tech Obsession in Policymaking", "text": "Such tendencies can be seen as a trend towards \"magical thinking\" regarding technology and institutional systems, which can be seen as a historical pattern. Larry Cuba pointed out that this tendency has a political aspect that goes beyond social factors and triggers political motivations [30]. These concepts bear resemblance to the concept of the \"sociotechnical imaginary\" that is broadly used in the field of social technology. Sociotechnical imaginaries are generally futureoriented visions of connected social and technological orders operated by key individuals and institutions [64]. Although scholars have noted that sociotechnical imaginaries can identify paths and actions for effective innovations, they caution that disparate imaginaries can bring very different programs and policies to society [64,108]. Our study also contributes to this growing area of literature on the relationship between decision-makers' power and techno-scientific innovations. As social computing and HCI4D researchers, we want to raise the possibility of positions and initiatives that address this techno-focused solutionism among decision-makers so as to resolve the contradictory vision between innovation and sustainability. Indeed, such tech obsession has already been reported in the CSCW and HCI4D literature (for example, see [83]), and various critical and speculative design interventions and ethnographic studies have been done in the HCI literature to counter such utopian thinking [10,36,97,106]. However, little has been done to operationalize this criticism in practice that can significantly impact policymaking. Moreover, a deliberate effort towards affordable (in both financial and human resource) technology design is required, using existing platforms to capture community voices in ways such as using participatory media to invite marginalized voices and to share with decision-makers to inform programs and policies. Such efforts should consider designing systems according to both high-level and bottom-up needs and capabilities. Additionally, as suggested by our findings, instead of building more social-mediastyle platforms, un-platforming innovations that leverage existing social media channels offer an alternative route to engagement. Un-platformed design is a conceptualization of coordinated participation in social media technologies, [71]. This study provides three exemplar projects in participatory health research, connective online learning, and strategic future foresight through the configuration of accessible and well-known social media apps such as WhatsApp and Facebook that act as clear examples of how this could be used. We also emphasize to social computing and HCI4D researchers that by building on existing platforms, practitioners could avoid the pitfalls of developing expensive bespoke solutions that may or may not work.", "spans": "[{\"corpusId\": 146189735, \"span\": \"[30]\", \"start\": 289, \"end\": 293}, {\"corpusId\": 248002679, \"span\": \"Our study\", \"start\": 828, \"end\": 828}, {\"corpusId\": 114326054, \"span\": \"[83]\", \"start\": 1325, \"end\": 1329}, {\"corpusId\": 15861344, \"span\": \"[10,\", \"start\": 1485, \"end\": 1489}, {\"corpusId\": 11579846, \"span\": \"36,\", \"start\": 1489, \"end\": 1492}, {\"corpusId\": 6893824, \"span\": \"97,\", \"start\": 1492, \"end\": 1495}, {\"corpusId\": 3251241, \"span\": \"106]\", \"start\": 1495, \"end\": 1499}, {\"corpusId\": 248002679, \"span\": \"our findings\", \"start\": 2087, \"end\": 2087}, {\"corpusId\": 218483436, \"span\": \"[71]\", \"start\": 2360, \"end\": 2364}, {\"corpusId\": 248002679, \"span\": \"This study\", \"start\": 2376, \"end\": 2376}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 8}, {"paragraphId": "41484", "title": "Towards Sustainable ICTD in Bangladesh: Understanding the Program and Policy Landscape and Its Implications for CSCW and HCI", "sectionTitle": "Leveraging Innovation Diffusers", "text": "Sustainable impact requires interventions to \"recognize and leverage resources already existing in the community, including physical and social infrastructure, skills, knowledge, networks, and environmental resources\" [95]. Partly driven by a political mandate to engage youth explicitly as part of their digital innovation strategy, our participants argued for leveraging youth potential, seeing them as agents of change. This a priori interest in youth engagement signifies how decisionmakers think of population segments, which will be key in successful innovation diffusion. Notably, this is not limited only to creating youth-friendly applications or creating \"lite\" youth versions of apps aimed at adults. Youth are traditionally construed as \"human becomings,\" \"denigrating their present lives, while focusing only on the adults they will become\" [7]. For decision-makers, the youth of today have an essential role to play in Bangladesh's digital innovation narrative in the present. This is also a strategic decision when it is considered that 40% of the country's population is under the age of 18, a phenomenon that is not exclusive to Bangladesh [104]. The UK's leading development institute, ODI, argues that since the world now has the largest generation aged 15-24 in history (and 90% of these youth live in Global South countries), a unique opportunity is afforded to development practitioners and theorists. There is \"a one-time window of opportunity for a concerted international effort to help developing countries reap a 'demographic dividend' from educated, healthy and gainfully employed young women and men, and achieve far higher economic growth rates\" [96]. However, we also urge caution here and advise that any attempts to mediate youth engagement with decision-makers needs to be carried out with the utmost care. Though ostensibly motivated by youth empowerment, authorities as well as non-state actors have repeatedly sought to disrupt spaces for youth participation or co-opt them towards their own political agendas. Moreover, if development projects consider youth perspectives and motivations for development, they can be included in initiatives whose primary target populations are adults. For instance, when targeting information dissemination to women farmers, we should consider young people's role as change-makers in farming communities. Hence, we recommend that every national and regional development context has population segments that are prioritized for innovation roll-out due to factors such as high early adoption rates or alignment with national agendas. When configuring projects, we recommend that HCI researchers consider how their projects will leverage these population segments to maximize their impact.", "spans": "[{\"corpusId\": 144207783, \"span\": \"[95]\", \"start\": 218, \"end\": 222}, {\"corpusId\": 248002679, \"span\": \"our participants\", \"start\": 350, \"end\": 350}, {\"corpusId\": 168426454, \"span\": \"[104]\", \"start\": 1157, \"end\": 1162}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 17}
{"paperId": "f958d4921951e394057a1c4ec33bad9a34e5dad1", "title": "A Convolutional Encoder Model for Neural Machine Translation", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2016, "citationCount": 460, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/P17-1012.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1611.02344, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2016-11-07", "authors": [{"authorId": "2401865", "name": "Jonas Gehring"}, {"authorId": "2325985", "name": "Michael Auli"}, {"authorId": "2529182", "name": "David Grangier"}, {"authorId": "2921469", "name": "Yann Dauphin"}], "abstract": "The prevalent approach to neural machine translation relies on bi-directional LSTMs to encode the source sentence. We present a faster and simpler architecture based on a succession of convolutional layers. This allows to encode the source sentence simultaneously compared to recurrent networks for which computation is constrained by temporal dependencies. On WMT\u201916 English-Romanian translation we achieve competitive accuracy to the state-of-the-art and on WMT\u201915 English-German we outperform several recently published results. Our models obtain almost the same accuracy as a very deep LSTM setup on WMT\u201914 English-French translation. We speed up CPU decoding by more than two times at the same or higher accuracy as a strong bi-directional LSTM.", "corpusId": "6728280", "paragraphs": [{"paragraphId": "76537", "title": "A Convolutional Encoder Model for Neural Machine Translation", "sectionTitle": "Related Work", "text": "Concurrently to our work, (Kalchbrenner et al., 2016) have introduced convolutional translation models without an explicit attention mechanism but their approach does not yet result in state-ofthe-art accuracy. (Lamb and Xie, 2016) also proposed a multi-layer CNN to generate a fixed-size encoder representation but their work lacks quantitative evaluation in terms of BLEU. Meng et al. (2015) and (Tu et al., 2015) applied convolutional models to score phrase-pairs of traditional phrasebased and dependency-based translation models. Convolutional architectures have also been successful in language modeling but so far failed to outperform LSTMs (Pham et al., 2016).", "spans": "[{\"corpusId\": 6728280, \"span\": \"our work\", \"start\": 24, \"end\": 24}, {\"corpusId\": 447679, \"span\": \"Meng et al. (2015)\", \"start\": 375, \"end\": 393}, {\"corpusId\": 529006, \"span\": \"(Tu et al., 2015)\", \"start\": 398, \"end\": 415}, {\"corpusId\": 16733173, \"span\": \"(Pham et al., 2016)\", \"start\": 648, \"end\": 667}]", "conference": "acl", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "76538", "title": "A Convolutional Encoder Model for Neural Machine Translation", "sectionTitle": "Datasets", "text": "We evaluate different encoders and ablate architectural choices on a small dataset from the German-English machine translation track of IWSLT 2014 (Cettolo et al., 2014) with a similar setting to (Ranzato et al., 2015). Unless otherwise stated, we restrict training sentences to have no more than 175 words; test sentences are not filtered. This is a higher threshold compared to other publications but ensures proper training of the position embeddings for non-recurrent encoders; the length threshold did not significantly effect recurrent encoders. Length filtering results in 167K sentence pairs and we test on the concatenation of tst2010, tst2011, tst2012, tst2013 and dev2010 comprising 6948 sentence pairs. 3 Our final results are on three major WMT tasks: WMT'16 English-Romanian. We use the same data and pre-processing as (Sennrich et al., 2016a) and train on 2.8M sentence pairs. 4 Our model is word-based instead of relying on byte-pair encoding (Sennrich et al., 2016b  mon Crawl and News Commentary v10 and apply the standard Moses tokenization to obtain 3.9M sentence pairs (Koehn et al., 2007). We report results on newstest2015. WMT'14 English-French. We use a commonly used subset of 12M sentence pairs (Schwenk, 2014), and remove sentences longer than 150 words. This results in 10.7M sentence-pairs for training. Results are reported on ntst14.", "spans": "[{\"corpusId\": 7147309, \"span\": \"(Ranzato et al., 2015)\", \"start\": 196, \"end\": 218}, {\"corpusId\": 1114678, \"span\": \"(Sennrich et al., 2016b\", \"start\": 959, \"end\": 982}, {\"corpusId\": 6728280, \"span\": \"This results\", \"start\": 1295, \"end\": 1295}]", "conference": "acl", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 2}
{"paperId": "e1e67cc7591f63a9ede64e808ceb78d0d3509565", "title": "Interactive 360-Degree Glasses-Free Tabletop 3D Display", "venue": "ACM Symposium on User Interface Software and Technology", "year": 2019, "citationCount": 14, "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3332165.3347948?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3332165.3347948, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2019-10-17", "authors": [{"authorId": "46601148", "name": "Motohiro Makiguchi"}, {"authorId": "1762551", "name": "Daisuke Sakamoto"}, {"authorId": "2003690", "name": "H. Takada"}, {"authorId": "2056888307", "name": "Kengo Honda"}, {"authorId": "2667839", "name": "T. Ono"}], "abstract": "We present an interactive 360-degree tabletop display system for collaborative work around a round table. Users are able to see 3D objects on the tabletop display anywhere around the table without 3D glasses. The system uses a visual perceptual mechanism for smooth motion parallax in the horizontal direction with fewer projectors than previous works. A 360-degree camera mounted above the table and image recognition software detects users' positions around the table and the heights of their faces (eyes) as they move around the table in real-time. Those mechanics help display correct vertical and horizontal direction motion parallax for different users simultaneously. Our system also has a user interaction function with a tablet device that manipulates 3D objects displayed on the table. These functions support collaborative work and communication between users. We implemented a prototype system and demonstrated the collaborative features of the 360-degree tabletop display system.", "corpusId": "204812021", "paragraphs": [{"paragraphId": "88401", "title": "Interactive 360-Degree Glasses-Free Tabletop 3D Display", "sectionTitle": "Init", "text": "Yagi et al. [49] proposed a method of projecting an image from all directions onto a fog screen with multiple projectors, and Yoshida et al. [51] proposed a method of projecting viewpoint images from 288 projectors onto a special coneshaped screen with narrow diffusion. The advantage of such a multiple-projector system is increasing the number of viewpoints without reducing the frame rate. On the other hand, the number of projectors and video rendering equipment has to be increased to increase the number of viewpoints. System configuration becomes complicated with increased equipment, and a high-level synchronization system is required when rendering each viewpoint video. In addition, enlarging the display surface of fog and cone-shaped screens is difficult.", "spans": "[{\"corpusId\": \"8379154\", \"span\": \"[49]\", \"start\": 12, \"end\": 16}, {\"corpusId\": 204812021, \"span\": \"proposed a method\", \"start\": 34, \"end\": 34}, {\"corpusId\": \"23056223\", \"span\": \"[51]\", \"start\": 141, \"end\": 145}, {\"corpusId\": 204812021, \"span\": \"proposed a method\", \"start\": 163, \"end\": 163}]", "conference": "uist", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "88402", "title": "Interactive 360-Degree Glasses-Free Tabletop 3D Display", "sectionTitle": "Interactions with 3D display and content", "text": "An example of operating close to 3D content is when Hachet et al. [10] proposed a system with which users can manipulate a 3D object with a touch panel by simultaneously viewing a 3D display and a 2D multi-touch display that uses a half mirror. Hancock et al. [11] showed that using 3 fingers on a 2D multi-touch display can control the 6 DOF movement of 3D objects. Wilson et al. [48] proposed an interaction system that creates physical responses to 3D objects by using a visionbased touch display. Hilliges et al. [12] and Butler et al. [4] proposed an interaction method that recognizes spatial hand gestures; direct interaction with 3D objects comes through hand gesture recognition using an infrared camera. Hirsch et al. [13] proposed a method of recognizing the user 3D hand gestures with a camera installed on the back of a 2D LCD and manipulating the displayed 3D object by moving a hand in front of the display. Prachyabrued et al. [39] proposed a spring model for applying the hand movement sensed by a data glove to a virtual hand and reduced visual discomfort when directly touching and manipulating 3D contents.", "spans": "[{\"corpusId\": \"15337229\", \"span\": \"[10]\", \"start\": 66, \"end\": 70}, {\"corpusId\": 204812021, \"span\": \"proposed a system\", \"start\": 88, \"end\": 88}, {\"corpusId\": \"6910873\", \"span\": \"[11]\", \"start\": 260, \"end\": 264}, {\"corpusId\": \"1130666\", \"span\": \"[48]\", \"start\": 381, \"end\": 385}, {\"corpusId\": \"10540067\", \"span\": \"[12]\", \"start\": 517, \"end\": 521}, {\"corpusId\": \"3480955\", \"span\": \"[13]\", \"start\": 728, \"end\": 732}, {\"corpusId\": 204812021, \"span\": \"proposed a method\", \"start\": 750, \"end\": 750}, {\"corpusId\": \"17230955\", \"span\": \"[39]\", \"start\": 943, \"end\": 947}]", "conference": "uist", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "88403", "title": "Interactive 360-Degree Glasses-Free Tabletop 3D Display", "sectionTitle": "Interactions with 3D display and content", "text": "Some methods that use a hand control device to operate out-ofreach objects or objects that cannot be touched directly have been proposed. Raycasting allows operations to be performed over longer distances. Forsberg et al. [8] and Grossman et al. [9] proposed a method of effectively selecting objects in an immersive virtual environment by raycasting. Pietroszek et al. [37] proposed an inexpensive raycasting system that uses a smartphone. Coffey et al. [7] proposed a system that allows users to manipulate 3D objects on a horizontal touch panel by hand while viewing the object displayed on the vertical 3D display in front of them. Malik et al. [37] proposed the vision-based hand tracking system over a tabletop surface area to perform hand gestural interactions with large displays from a distance. Tiltcasting [38] is a system that allows the user to select objects in the 3D environment by tilting their smartphone. Achibet et al. [1] proposed THING, which controls virtual hands by multi-touch input on a tablet.", "spans": "[{\"corpusId\": \"31491838\", \"span\": \"[8]\", \"start\": 222, \"end\": 225}, {\"corpusId\": \"6835315\", \"span\": \"[9]\", \"start\": 246, \"end\": 249}, {\"corpusId\": 204812021, \"span\": \"proposed a method\", \"start\": 267, \"end\": 267}, {\"corpusId\": \"32129647\", \"span\": \"[37]\", \"start\": 370, \"end\": 374}, {\"corpusId\": \"15950838\", \"span\": \"[7]\", \"start\": 455, \"end\": 458}, {\"corpusId\": 204812021, \"span\": \"proposed a system\", \"start\": 476, \"end\": 476}, {\"corpusId\": \"32129647\", \"span\": \"[37]\", \"start\": 649, \"end\": 653}, {\"corpusId\": \"17453484\", \"span\": \"[38]\", \"start\": 817, \"end\": 821}, {\"corpusId\": \"17948248\", \"span\": \"[1]\", \"start\": 939, \"end\": 942}]", "conference": "uist", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "88404", "title": "Interactive 360-Degree Glasses-Free Tabletop 3D Display", "sectionTitle": "Interactions between multiple users", "text": "Permulin [28] is an interface that presents individual images to multiple people with shutter glasses and has a 3D display placed on a tabletop. This system supports group work and individual work and the transition between them. Agrawala et al. [2] also proposed a tabletop system with shutter glasses for multiple users. In this system, the user wears 3D glasses, and communication is interrupted. Pivot [20] provides the personal and shared views without glasses, but the quality of the image degrades as the number of users increases. MisTable [32] establishes a personal workspace with a fog screen and shared space with a tabletop display, but users are fixed at four sides of the table and must sit with a fog screen between them and the tabletop. Our system does not require 3D glasses; it can be viewed anywhere around the circular screen, and there is no loss of resolution due to the number of people increasing. Therefore, it can be used as a collaborative work interface to solve existing limitations.", "spans": "[{\"corpusId\": \"14005244\", \"span\": \"[28]\", \"start\": 9, \"end\": 13}, {\"corpusId\": 204812021, \"span\": \"This system\", \"start\": 156, \"end\": 156}, {\"corpusId\": \"979046\", \"span\": \"[2]\", \"start\": 246, \"end\": 249}, {\"corpusId\": 204812021, \"span\": \"this system\", \"start\": 337, \"end\": 337}, {\"corpusId\": \"17294731\", \"span\": \"[20]\", \"start\": 406, \"end\": 410}, {\"corpusId\": \"18759168\", \"span\": \"[32]\", \"start\": 548, \"end\": 552}, {\"corpusId\": 204812021, \"span\": \"Our system\", \"start\": 765, \"end\": 765}]", "conference": "uist", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "88405", "title": "Interactive 360-Degree Glasses-Free Tabletop 3D Display", "sectionTitle": "Multi-user head tracking", "text": "Takeuchi et al. [46] or Benko et al. [3] used a depth camera for user head tracking, and they reproduced the motion parallax of 2D projection images. Jones et al. [19] demonstrated vertical tracking by a depth camera for smooth interpolation between multiple users on the multiple projector 3D screen system. Jones et al. [16] incorporated multi-user tracking for vertical parallax using a 2D camera for the teleconferencing system using eye contact. These tracking methods using a depth camera do not require a wearable object, but a single depth camera's field of view is too narrow to apply to a 360-degree viewing zone. One solution to this problem is integrating multiple depth cameras, but installation and alignment of multiple cameras, calibration of the coordinate system, and time synchronization between cameras is neither simple nor easy.", "spans": "[{\"corpusId\": \"17351161\", \"span\": \"[46]\", \"start\": 16, \"end\": 20}, {\"corpusId\": \"119082\", \"span\": \"[3]\", \"start\": 37, \"end\": 40}, {\"corpusId\": \"7121365\", \"span\": \"[19]\", \"start\": 163, \"end\": 167}, {\"corpusId\": \"13920122\", \"span\": \"[16]\", \"start\": 322, \"end\": 326}]", "conference": "uist", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "88406", "title": "Interactive 360-Degree Glasses-Free Tabletop 3D Display", "sectionTitle": "Multi-user head tracking", "text": "A simple method of recognizing a wide range with one camera is when Callemein et al. [5] proposed a system that measures the occupancy of meeting rooms with a ceiling-mounted 360degree camera. The system used a detection method that combines Darknet and OpenPose [6] to detect users even in low-resolution images. Komiya et al. [24] proposed using a 360-degree camera on the center of a round table and Open-Pose face recognition to estimate the attention level of users during interactions. We believed that a method that uses a 360degree camera and machine-learning-based image recognition could achieve head tracking with a simple device. Therefore, we adopted a configuration that detects users' head positions using image recognition from images taken from a single 360degree camera installed in the center of the screen.", "spans": "[{\"corpusId\": \"88485807\", \"span\": \"[5]\", \"start\": 85, \"end\": 88}, {\"corpusId\": 204812021, \"span\": \"proposed a system\", \"start\": 106, \"end\": 106}, {\"corpusId\": \"16224674\", \"span\": \"[6]\", \"start\": 263, \"end\": 266}]", "conference": "uist", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "88407", "title": "Interactive 360-Degree Glasses-Free Tabletop 3D Display", "sectionTitle": "Display performance", "text": "We measured the luminance distribution of our new spatially imaged iris plane screen for a 360-degree system to evaluate the applicability to linear blending. We placed a diffusion screen at the observation position (about 850 mm from the center of the screen), then projected a uniform white light on the spatially imaged iris plane screen and measured the luminance distribution of the focused image on the diffusion screen with a two-dimensional luminance meter (HI-LAND RISA-COLOR/ONE5). Figure 11 and Figure 12 show the 2D luminance distributions and 1D luminance distributions of one projector. Figure 11 shows results without a diffusion layer, and Figure 12 shows results with a diffusion layer. The horizontal 1D luminance distribution was measured at a height of 1700 mm, and the vertical distribution was measured at the center of the projector. Figure 11 shows that the Fresnel lens collected the light without spreading in the horizontal direction, and Figure 12 shows that the diffusion layer had smooth attenuation characteristics in the horizontal direction. In Figure 12, the height range of upper than half value (blue line) is 1400 mm to 1900 mm, so the distribution widened vertically due to the distortion of the imaged iris plane. This characteristic ensured linear blending even when the users' heights differed.   In the 1D luminance distribution of the screen without diffusion (Figure 11), the width of upper than half value including the peak is about 10 mm (0.7 degrees), and is 100 mm (6.7 degrees) with diffusion ( Figure 12). Since light passes through the diffusion layer twice, the diffusion angle of the diffusion film used in this implementation is estimated to be about 3 degrees. Figure 13 shows one-dimensional luminance distributions by the five adjacent projectors. This figure shows that the screen smoothed the transition between adjacent viewpoint images with viewpoint movement by superimposing the luminance. Figure 14 shows 360-degree photographs of the projected image. The upper in Figure 14 is a checkerboard-pattern 3D cube. This figure shows that the object can be observed from the entire circumference without distortion. The lower in Figure 14 shows that different angle images of car contents corresponding to the viewpoint positions in the horizontal direction were observed. We could also confirm the effect of stereoscopic vision due to binocular parallax and smooth motion parallax in actual observation. Figure 15 shows the users' bones by image recognition in a 360-degree camera image. Human bones are detected despite some distortion in the vertical direction from the image correction of the 360-degree camera. Since the 360-degree camera is mounted at almost the same height as the users' faces, the upper bodies of the standing users can be detected even when the tabletop screen hides the lower bodies of the users. The frame rate of detection was stable at 11 to 13 fps. Figure 16 shows the observed images with and without head tracking when the viewpoint heights were changed to three levels. Without head tracking, a red teapot appears to be collapsed by perspective distortion at low viewpoints, but the distortion was reduced with tracking. The figure shows that our prototype provides the correct angle of 3D content according to viewpoint height changes and more accurate representation through head tracking.", "spans": "[{\"corpusId\": \"7121365\", \"span\": \"\", \"start\": -33940, \"end\": -33936}, {\"corpusId\": \"9107462\", \"span\": \"\", \"start\": -33935, \"end\": -33931}, {\"corpusId\": \"929159\", \"span\": \"\", \"start\": -33931, \"end\": -33928}, {\"corpusId\": \"5696762\", \"span\": \"\", \"start\": -33928, \"end\": -33925}]", "conference": "uist", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "88408", "title": "Interactive 360-Degree Glasses-Free Tabletop 3D Display", "sectionTitle": "DISCUSSION", "text": "The tabletop 3D screen technology we propose can reproduce perfect 360-degree horizontal motion parallax around a table and vertical motion parallax based on multi-user head tracking. Our system requires fewer projectors than a conventional system due to the visual perception mechanism, and a simple Fresnel lens screen enlarges the display area. With our system, multiple users can view 3D content simultaneously without needing to wear 3D glasses, and they can interact with 3D objects in real-time by using the operation tablet.", "spans": "[{\"corpusId\": \"5726837\", \"span\": \"\", \"start\": -37415, \"end\": -37411}, {\"corpusId\": \"1669116\", \"span\": \"\", \"start\": -37411, \"end\": -37408}, {\"corpusId\": \"17351161\", \"span\": \"\", \"start\": -37408, \"end\": -37405}, {\"corpusId\": \"119082\", \"span\": \"\", \"start\": -37405, \"end\": -37403}, {\"corpusId\": 204812021, \"span\": \"we propose\", \"start\": 44, \"end\": 44}, {\"corpusId\": 204812021, \"span\": \"Our system\", \"start\": 194, \"end\": 194}, {\"corpusId\": 204812021, \"span\": \"our system\", \"start\": 363, \"end\": 363}]", "conference": "uist", "year": 2019, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "88409", "title": "Interactive 360-Degree Glasses-Free Tabletop 3D Display", "sectionTitle": "360-degree 3D display", "text": "Multiple viewpoint images need to be presented according to the users' positions for multiple users to view 3D images simultaneously [15,36,23]. Researchers have been working on presenting various methods of projecting viewpoint images from multiple projectors onto a screen with narrow diffusion characteristics [33,19,18,22]. In such a multi-view 3D display, the number of viewpoints is increased to smooth changes between viewpoints, present the binocular parallax, and widen the visual field area. A uniform viewpoint distribution is necessary for extending the viewing zone over 360-degree  horizontal directions around the table. Conventional methods  of expanding the viewing area to 360 degrees around the table   are roughly divided into a time division method, like a rotation mechanism, and a space division method with multiple  displays or projectors. Jones et al. [17] proposed a time division method that presents 360-degree 3D images with a high-speed video projector and a rotating mirror covered with a holographic diffuser. Inoue et al. [14] proposed a rotating screen system that uses a microelectro-mechanical systems spatial light modulator (MEMS SLM). Takaki et al. [45] proposed a configuration that has three projectors and a rotating screen. The systems of Inoue and Takaki both use a screen that is constructed with a Fresnel lens whose optical axis is shifted to focus light at the users' positions. With a configuration that uses a rotating mirror or a screen, the users' hands cannot be brought close to the 3D objects for their own safety. Butler et al. [4] proposed a 360-degree 3D display in which hands can be brought close to a 3D object because there is a rotating screen and a highspeed digital micromirror device (DMD) projector under the two parabolic mirrors placed opposite each other, and the 3D image is imaged in the air. Lim et al. [27] proposed a similar system that uses four synchronized high-speed DMDs.", "spans": "[{\"corpusId\": \"120354814\", \"span\": \"[15,\", \"start\": 133, \"end\": 137}, {\"corpusId\": \"9796146\", \"span\": \"36,\", \"start\": 137, \"end\": 140}, {\"corpusId\": \"62603810\", \"span\": \"23]\", \"start\": 140, \"end\": 143}, {\"corpusId\": \"3862413\", \"span\": \"[33,\", \"start\": 313, \"end\": 317}, {\"corpusId\": \"7121365\", \"span\": \"19,\", \"start\": 317, \"end\": 320}, {\"corpusId\": \"18642504\", \"span\": \"18,\", \"start\": 320, \"end\": 323}, {\"corpusId\": \"121546445\", \"span\": \"22]\", \"start\": 323, \"end\": 326}, {\"corpusId\": \"207163831\", \"span\": \"[17]\", \"start\": 878, \"end\": 882}, {\"corpusId\": \"22692024\", \"span\": \"[14]\", \"start\": 1056, \"end\": 1060}, {\"corpusId\": \"13582339\", \"span\": \"[45]\", \"start\": 1189, \"end\": 1193}, {\"corpusId\": \"42607020\", \"span\": \"[27]\", \"start\": 1877, \"end\": 1881}]", "conference": "uist", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 11}], "paragraphCount": 9}
{"paperId": "aea0600d241ee9b311ef92eee9c3976fbc7d6ed9", "title": "ExtEnD: Extractive Entity Disambiguation", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2022, "citationCount": 35, "openAccessPdf": {"url": "https://aclanthology.org/2022.acl-long.177.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://aclanthology.org/2022.acl-long.177, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": null, "authors": [{"authorId": "1810690342", "name": "Edoardo Barba"}, {"authorId": "1810690563", "name": "Luigi Procopio"}, {"authorId": "1733928", "name": "Roberto Navigli"}], "abstract": "Local models for Entity Disambiguation (ED) have today become extremely powerful, in most part thanks to the advent of large pre-trained language models. However, despite their significant performance achievements, most of these approaches frame ED through classification formulations that have intrinsic limitations, both computationally and from a modeling perspective. In contrast with this trend, here we propose ExtEnD, a novel local formulation for ED where we frame this task as a text extraction problem, and present two Transformer-based architectures that implement it. Based on experiments in and out of domain, and training over two different data regimes, we find our approach surpasses all its competitors in terms of both data efficiency and raw performance. ExtEnD outperforms its alternatives by as few as 6 F1 points on the more constrained of the two data regimes and, when moving to the other higher-resourced regime, sets a new state of the art on 4 out of 4 benchmarks under consideration, with average improvements of 0.7 F1 points overall and 1.1 F1 points out of domain. In addition, to gain better insights from our results, we also perform a fine-grained evaluation of our performances on different classes of label frequency, along with an ablation study of our architectural choices and an error analysis. We release our code and models for research purposes at https://github.com/SapienzaNLP/extend.", "corpusId": "248780243", "paragraphs": [{"paragraphId": "57677", "title": "ExtEnD: Extractive Entity Disambiguation\u00a0", "sectionTitle": "Introduction", "text": "Being able to associate entity mentions in a given text with the correct entity they refer to is a crucial task in Natural Language Processing (NLP). Formally referred to as Entity Disambiguation (ED), this task entails, given a mention m occurring in a text c m , identifying the correct entity e * out of a set of candidates e 1 , . . . , e n , coming from a reference knowledge base (KB). First introduced by Bunescu * Equal contribution. and Pa\u015fca (2006), ED aims to identify the actors involved in human language and, as such, has shown potential in downstream applications like Question Answering (Yin et al., 2016), Information Extraction (Ji and Grishman, 2011;Guo et al., 2013), Text Generation (Puduppully et al., 2019) and Semantic Parsing (Bevilacqua et al., 2021;Procopio et al., 2021).", "spans": "[{\"corpusId\": 588986, \"span\": \"Pa\\u015fca (2006)\", \"start\": 446, \"end\": 458}, {\"corpusId\": 557620, \"span\": \"(Yin et al., 2016)\", \"start\": 603, \"end\": 621}, {\"corpusId\": 7693051, \"span\": \"(Ji and Grishman, 2011;\", \"start\": 646, \"end\": 669}, {\"corpusId\": 5883983, \"span\": \"Guo et al., 2013)\", \"start\": 669, \"end\": 686}, {\"corpusId\": 174801388, \"span\": \"(Puduppully et al., 2019)\", \"start\": 704, \"end\": 729}, {\"corpusId\": 235349016, \"span\": \"(Bevilacqua et al., 2021;\", \"start\": 751, \"end\": 776}, {\"corpusId\": 235097669, \"span\": \"Procopio et al., 2021)\", \"start\": 776, \"end\": 798}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 7}, {"paragraphId": "57678", "title": "ExtEnD: Extractive Entity Disambiguation\u00a0", "sectionTitle": "Introduction", "text": "Since the advent of Deep Learning within the NLP community, this task has mostly been framed as a multi-label classification problem (Shahbazi et al., 2019;Broscheit, 2019), especially leveraging the bi-encoder paradigm (Humeau et al., 2020;. However, although simple and yet powerful enough to push scores past 90% inKB Micro F 1 on standard benchmarks, this formulation suffers from a number of downsides. First, the actual disambiguation is only modeled through a dot product between independent mention and entity vectors, which may not capture complex mention-entity interactions. Second, from a computational perspective, entities are represented through high-dimensional vectors that are cached in a pre-computed index. Thus, classifying against a large KB has a significant memory cost that, in fact, scales linearly with respect to the number of entities. Besides this, adding a new entity also requires modifying the index itself. To address these issues, De Cao et al. (2021b) have recently proposed an auto-regressive formulation where, given mentions in their context, models are trained to generate, token-by-token, the correct entity identifiers. 1 While this approach has addressed the aforementioned issues effectively, it requires an autoregressive decoding process, which has speed implications, and, what is more, does not let the model see its possible output choices, something that has shown significant potential in other semantic tasks (Barba et al., 2021a). In this work, we focus on these shortcomings and, inspired by this latter research trend, propose Extractive Entity Disambiguation (EXTEND), the first entity disambiguator that frames ED as a text extraction task. Given as input a context c m in which a mention m occurs, along with a text representation for each of the possible candidates e 1 , . . . , e n , a model has to extract the span associated with the text representation of the entity that best suits m. We implement this formulation through 2 architectures: i) a Transformer system (Vaswani et al., 2017; that features an almost identical modeling power to that of previous works, and ii) a variant that relaxes the computational requirements of our approach when using common Transformer-based architectures. Evaluating our two systems over standard benchmarks, we find our formulation to be particularly suited to ED. In particular, when restricting training resources to the AIDA-CoNLL dataset (Hoffart et al., 2011) only, EXTEND appears to be significantly more data-efficient than its alternatives, surpassing them by more than 6 inKB Micro F 1 points on average across in-domain and out-of-domain datasets. Furthermore, when pre-training on external ED data as in De Cao et al. (2021b), our system sets a new state of the art on 4 out of 6 benchmarks under consideration, with average improvements of 0.7 overall and 1.1 when moving out of domain. Finally, we also perform a thorough investigation of our system performances, providing insights and pinpointing the reasons behind our improvements via a fine-grained evaluation on different label-frequency classes.", "spans": "[{\"corpusId\": 208191596, \"span\": \"Broscheit, 2019)\", \"start\": 156, \"end\": 172}, {\"corpusId\": 210063976, \"span\": \"(Humeau et al., 2020;\", \"start\": 220, \"end\": 241}, {\"corpusId\": 222125277, \"span\": \"Cao et al. (2021b)\", \"start\": 969, \"end\": 987}, {\"corpusId\": 248780243, \"span\": \"this approach\", \"start\": 1183, \"end\": 1183}, {\"corpusId\": 235097236, \"span\": \"(Barba et al., 2021a)\", \"start\": 1461, \"end\": 1482}, {\"corpusId\": 248780243, \"span\": \"this work\", \"start\": 1496, \"end\": 1496}, {\"corpusId\": 13756489, \"span\": \"(Vaswani et al., 2017;\", \"start\": 2029, \"end\": 2051}, {\"corpusId\": 248780243, \"span\": \"our approach\", \"start\": 2205, \"end\": 2205}, {\"corpusId\": 248780243, \"span\": \"our two system\", \"start\": 2282, \"end\": 2282}, {\"corpusId\": 6216506, \"span\": \"(Hoffart et al., 2011)\", \"start\": 2444, \"end\": 2466}, {\"corpusId\": 248780243, \"span\": \"our system\", \"start\": 2750, \"end\": 2750}, {\"corpusId\": 248780243, \"span\": \"our system\", \"start\": 2964, \"end\": 2964}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 7}, {"paragraphId": "57679", "title": "ExtEnD: Extractive Entity Disambiguation\u00a0", "sectionTitle": "Related Work", "text": "Entity Disambiguation (ED) is the task of identifying, given a mention in context, the most suitable entity among a set of candidates stored in a knowledge base (KB). Generally the last step in an Entity Linking system (Broscheit, 2019), coming immediately after mention detection and candidate generation, this task has been the object of a vast and diverse literature, with approaches typically clustered into two groups, depending on how they model co-occurring mentions in the same document. On the one hand, global models strive to enforce a global coherence across the disambiguations within the same document, leveraging different techniques and heuristics to approximate this objective 2 (Hoffart et al., 2011;Moro et al., 2014;Yamada et al., 2016;Ganea and Hofmann, 2017;Le and Titov, 2018;Yang et al., 2018).", "spans": "[{\"corpusId\": 208191596, \"span\": \"(Broscheit, 2019)\", \"start\": 219, \"end\": 236}, {\"corpusId\": 6216506, \"span\": \"(Hoffart et al., 2011;\", \"start\": 696, \"end\": 718}, {\"corpusId\": 7851632, \"span\": \"Moro et al., 2014;\", \"start\": 718, \"end\": 736}, {\"corpusId\": 5267356, \"span\": \"Yamada et al., 2016;\", \"start\": 736, \"end\": 756}, {\"corpusId\": 1356505, \"span\": \"Ganea and Hofmann, 2017;\", \"start\": 756, \"end\": 780}, {\"corpusId\": 13747961, \"span\": \"Le and Titov, 2018;\", \"start\": 780, \"end\": 799}, {\"corpusId\": 3587087, \"span\": \"Yang et al., 2018)\", \"start\": 799, \"end\": 817}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "57680", "title": "ExtEnD: Extractive Entity Disambiguation\u00a0", "sectionTitle": "Related Work", "text": "On the other hand, local models disambiguate each mention independently of the others, conditioning the entity choice only on the mention and its context. Thanks to the advent of large pretrained language models, this group has recently witnessed a significant improvement in performances, which are nowadays on par with, or even above, those achieved by state-of-the-art global systems (Shahbazi et al., 2019). These approaches usually frame ED as a multi-label classification problem (Broscheit, 2019) and a diverse set of formulations have been proposed. Among these, the bi-encoder paradigm (Bromley et al., 1994;Humeau et al., 2020) has been particularly successful (Gillick et al., 2019;Tedeschi et al., 2021;Botha et al., 2020): here, two encoders are trained to learn vector representations in a shared space for mentions in context and entities, respectively. Classification of a given mention is then performed by retrieving the entity whose representation is closest according to some metric (e.g. cosine similarity).", "spans": "[{\"corpusId\": 208191596, \"span\": \"(Broscheit, 2019)\", \"start\": 486, \"end\": 503}, {\"corpusId\": 16394033, \"span\": \"(Bromley et al., 1994;\", \"start\": 595, \"end\": 617}, {\"corpusId\": 210063976, \"span\": \"Humeau et al., 2020)\", \"start\": 617, \"end\": 637}, {\"corpusId\": 202718954, \"span\": \"(Gillick et al., 2019;\", \"start\": 671, \"end\": 693}, {\"corpusId\": 244119690, \"span\": \"Tedeschi et al., 2021;\", \"start\": 693, \"end\": 715}, {\"corpusId\": 226254361, \"span\": \"Botha et al., 2020)\", \"start\": 715, \"end\": 734}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "57681", "title": "ExtEnD: Extractive Entity Disambiguation\u00a0", "sectionTitle": "Related Work", "text": "Nevertheless, while this approach can model more complex interactions, some of these can only occur indirectly inside the backtracking of their beam search. Furthermore, the disambiguation involves an auto-regressive decoding that, although mitigated by later efforts (De Cao et al., 2021a), has intrinsic speed limitations. In contrast, here we propose an extractive formulation, where a model receives as input the mention, its context and the text representation of each candidate, and has to extract the span corresponding to the representation of the entity that best matches the (mention, context) pair under consideration. Note that this differs from the aforementioned cross-encoder formulations (Logeswaran et al., 2019; where, instead, each entity was encoded together with the (mention, context) pair, but independently from all the other entities. With our schema, complex mention-entity and entity-entity interactions can be explicitly modeled by the neural system, as all the information is provided in input.", "spans": "[{\"corpusId\": 248780243, \"span\": \"this approach\", \"start\": 33, \"end\": 33}, {\"corpusId\": 237440319, \"span\": \"(De Cao et al., 2021a)\", \"start\": 268, \"end\": 290}, {\"corpusId\": 248780243, \"span\": \"we propose\", \"start\": 353, \"end\": 353}, {\"corpusId\": 189999659, \"span\": \"(Logeswaran et al., 2019;\", \"start\": 704, \"end\": 729}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "57682", "title": "ExtEnD: Extractive Entity Disambiguation\u00a0", "sectionTitle": "Comparison Systems", "text": "\u2022 Global Models: Ganea and Hofmann (2017) EXTEND Setup As previously mentioned, we use the Longformer model (Beltagy et al., 2020) as our reference architecture and retrieve the pre-trained weights, for both its base and large variants, from the HuggingFace Transformers library (Wolf et al., 2020); we refer to these variants as EXTEND Base (139M parameters) and EXTEND Large (435M parameters). Following GENRE standard practice, we use the last encoder output for the representation of each token and a simple linear layer on top of it to compute the start and end tokens probability distributions. We use a 64token attention window and fine-tune the whole architecture using the Rectified Adam  optimizer with 10 \u22125 learning rate for at most 100,000 steps. We use 8 steps of gradient accumulation and batches made of a maximum of 1024 tokens. We evaluate the model on the validation dataset every 2000 steps, enforcing a patience of 15 evaluation rounds. We train every model for a single run on a GeForce RTX 3090 graphic card with 24 gigabytes of VRAM. Due to computational constraints, we do not perform any hyperparameter tuning, except for the attention window where we try [32,64,128], and select the other hyperparameters following previous literature. We implement our work in PyTorch (Paszke et al., 2019), using classy 9 as the underlying framework.", "spans": "[{\"corpusId\": 208117506, \"span\": \"(Wolf et al., 2020)\", \"start\": 279, \"end\": 298}, {\"corpusId\": 248780243, \"span\": \"our work\", \"start\": 1284, \"end\": 1284}, {\"corpusId\": 202786778, \"span\": \"(Paszke et al., 2019)\", \"start\": 1296, \"end\": 1317}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 6}
{"paperId": "d2d3a9d755344019484811a5fbc57a29458948cc", "title": "CodeSwitch-Reddit: Exploration of Written Multilingual Discourse in Online Discussion Forums", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2019, "citationCount": 10, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/D19-1484.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1908.11841, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2019-08-30", "authors": [{"authorId": "2653682", "name": "Ella Rabinovich"}, {"authorId": "1380408473", "name": "Masih Sultani"}, {"authorId": "145584212", "name": "S. Stevenson"}], "abstract": "In contrast to many decades of research on oral code-switching, the study of written multilingual productions has only recently enjoyed a surge of interest. Many open questions remain regarding the sociolinguistic underpinnings of written code-switching, and progress has been limited by a lack of suitable resources. We introduce a novel, large, and diverse dataset of written code-switched productions, curated from topical threads of multiple bilingual communities on the Reddit discussion platform, and explore questions that were mainly addressed in the context of spoken language thus far. We investigate whether findings in oral code-switching concerning content and style, as well as speaker proficiency, are carried over into written code-switching in discussion forums. The released dataset can further facilitate a range of research and practical activities.", "corpusId": "201698192", "paragraphs": [{"paragraphId": "40778", "title": "CodeSwitch-Reddit: Exploration of Written Multilingual Discourse in Online Discussion Forums", "sectionTitle": "Code-switching and language competence", "text": "We estimate linguistic competence by computing a set of lexical and grammatical measures commonly used for language proficiency assessment (Kyle and Crossley, 2015;Lu and Ai, 2015;Rabinovich et al., 2018). All posts were tokenized and lemmatized, and non-alphabetic tokens were excluded from the computation. We produce the following metrics:", "spans": "[{\"corpusId\": \"31891046\", \"span\": \"(Kyle and Crossley, 2015;\", \"start\": 139, \"end\": 164}, {\"corpusId\": \"60099083\", \"span\": \"Lu and Ai, 2015;\", \"start\": 164, \"end\": 180}, {\"corpusId\": \"43963368\", \"span\": \"Rabinovich et al., 2018)\", \"start\": 180, \"end\": 204}]", "conference": "emnlp", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "40779", "title": "CodeSwitch-Reddit: Exploration of Written Multilingual Discourse in Online Discussion Forums", "sectionTitle": "Related Work", "text": "Many studies have elucidated the communicative functions of oral code-switching. These include conveying nuanced attitudes through linguistic choices reflecting emotion and sentiment (Dewaele and Nakano, 2013), as well as establishing a level of (in)formality (Fishman, 1970;Genesee, 1982;Myers-Scotton, 1995). Other studies have focused more on the characteristics of code-switchers themselves: While CS has mostly been viewed as a deliberate choice of a proficient bilingual speaker, requiring adept control of two simultaneously-activated linguistic systems (Costa and Santesteban, 2004;Kootstra et al., 2012), mixing two languages may also serve as a strategy for bridging lexical inefficacy in a second language (Grosjean, 1982;Faerch and Kasper, 1983;Poulisse, 1989).", "spans": "[{\"corpusId\": \"33603634\", \"span\": \"(Dewaele and Nakano, 2013)\", \"start\": 183, \"end\": 209}, {\"corpusId\": \"143659293\", \"span\": \"Genesee, 1982;\", \"start\": 275, \"end\": 289}, {\"corpusId\": \"55844577\", \"span\": \"\", \"start\": -27642, \"end\": -27631}, {\"corpusId\": \"145697937\", \"span\": \"\", \"start\": -27631, \"end\": -27598}, {\"corpusId\": \"145718906\", \"span\": \"(Costa and Santesteban, 2004;\", \"start\": 561, \"end\": 590}, {\"corpusId\": \"145056220\", \"span\": \"Kootstra et al., 2012)\", \"start\": 590, \"end\": 612}]", "conference": "emnlp", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "40780", "title": "CodeSwitch-Reddit: Exploration of Written Multilingual Discourse in Online Discussion Forums", "sectionTitle": "Related Work", "text": "Most large-scale computational work on CS in social media has focused on essential prerequisites for various NLP tasks, such as POS tagging (Solorio and Liu, 2008;Soto et al., 2018), tokenlevel language identification (Soto et al., 2018;Rijhwani et al., 2017), NER (Aguilar et al., 2018a), language modeling (Chandu et al., 2018), automatic speech recognition (Y\u0131lmaz et al., 2018), etc. Almost no work has addressed theoretical and sociolinguistic aspects of written multilingual discourse computationally, at scale (for an exception, see Rudra et al., 2016).", "spans": "[{\"corpusId\": \"1554898\", \"span\": \"(Solorio and Liu, 2008;\", \"start\": 140, \"end\": 163}, {\"corpusId\": \"51683657\", \"span\": \"Soto et al., 2018)\", \"start\": 163, \"end\": 181}, {\"corpusId\": \"51683657\", \"span\": \"(Soto et al., 2018;\", \"start\": 218, \"end\": 237}, {\"corpusId\": \"7373647\", \"span\": \"Rijhwani et al., 2017)\", \"start\": 237, \"end\": 259}, {\"corpusId\": \"51875128\", \"span\": \"(Aguilar et al., 2018a)\", \"start\": 265, \"end\": 288}, {\"corpusId\": \"51867289\", \"span\": \"(Chandu et al., 2018)\", \"start\": 308, \"end\": 329}, {\"corpusId\": \"15456486\", \"span\": \"Rudra et al., 2016)\", \"start\": 540, \"end\": 559}]", "conference": "emnlp", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 6}], "paragraphCount": 3}
{"paperId": "88b871d7d46c4e52d98e10a3c959f7230331cc5e", "title": "Boundary-Driven Table-Filling for Aspect Sentiment Triplet Extraction", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2022, "citationCount": 57, "openAccessPdf": {"url": "https://aclanthology.org/2022.emnlp-main.435.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://aclanthology.org/2022.emnlp-main.435, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference", "Review"], "publicationDate": null, "authors": [{"authorId": "51213827", "name": "Yice Zhang"}, {"authorId": "2108989300", "name": "Yifan Yang"}, {"authorId": "2116186839", "name": "Yihui Li"}, {"authorId": "144691693", "name": "Bin Liang"}, {"authorId": "2203985780", "name": "Shiwei Chen"}, {"authorId": "2118919097", "name": "Yixue Dang"}, {"authorId": "2144399430", "name": "Min Yang"}, {"authorId": "1753529", "name": "Ruifeng Xu"}], "abstract": "Aspect Sentiment Triplet Extraction (ASTE) aims to extract the aspect terms along with the corresponding opinion terms and the expressed sentiments in the review, which is an important task in sentiment analysis. Previous research efforts generally address the ASTE task in an end-to-end fashion through the table-filling formalization, in which the triplets are represented by a two-dimensional (2D) table of word-pair relations. Under this formalization, a term-level relation is decomposed into multiple independent word-level relations, which leads to relation inconsistency and boundary insensitivity in the face of multi-word aspect terms and opinion terms. To overcome these issues, we propose Boundary-Driven Table-Filling (BDTF), which represents each triplet as a relation region in the 2D table and transforms the ASTE task into detection and classification of relation regions. We also notice that the quality of the table representation greatly affects the performance of BDTF. Therefore, we develop an effective relation representation learning approach to learn the table representation, which can fully exploit both word-to-word interactions and relation-to-relation interactions. Experiments on several public benchmarks show that the proposed approach achieves state-of-the-art performances.", "corpusId": "256461400", "paragraphs": [{"paragraphId": "1367", "title": "Boundary-Driven Table-Filling for Aspect Sentiment Triplet Extraction", "sectionTitle": "Introduction", "text": "As a fine-grained task, Aspect-Based Sentiment Analysis (ABSA) focuses on the attitudes expressed on specific aspect terms (Pontiki et al., 2014). Opinion terms refer to words or phrases Figure 1: An example of the ASTE task. The aspect terms and the opinion terms are marked with orange and blue, respectively. expressing subjective sentiments. Intuitively, opinion terms are important clues when determining the sentiment polarity and could provide a more detailed sentiment description for the aspect terms. Previous work has generally concentrated on extracting aspect terms and opinion terms and classifying the sentiment expressed on the aspect term without explicitly considering the relations between aspect terms and opinion terms (He et al., 2019;Li et al., 2019;Chen and Qian, 2020). Therefore, Peng et al. (2020) propose the Aspect Sentiment Triplet Extraction (ASTE) task, which is exemplified in Figure 1. In the ASTE task, a triplet consists of an aspect term, the corresponding opinion term, and the expressed sentiment. Peng et al. (2020) adopt the pipeline approach to address the ASTE task. They first decompose the ASTE task into several subtasks and then learn models separately for each subtask. A more advanced alternative is learning a joint model to exploit the interactions between different subtasks Wu et al., 2020;Chen et al., 2021a;Mao et al., 2021;Xu et al., 2021;Jing et al., 2021). Among these works, Wu et al. (2020) andJing et al. (2021) tackle the ASTE task through a tablefilling approach, where the triplets are represented by a two-dimensional (2D) table of word-pair relations. In this approach, aspect terms and opinion terms are extracted through the diagonal elements of the table, and sentiments are treated as relation tags that are represented by the non-diagonal elements of the table. This formalization enables joint learning of different subtasks in ASTE, achieving superior performance over the pipeline approach.", "spans": "[{\"corpusId\": 222271911, \"span\": \"Wu et al., 2020;\", \"start\": 1327, \"end\": 1343}, {\"corpusId\": 236428724, \"span\": \"Xu et al., 2021;\", \"start\": 1379, \"end\": 1395}, {\"corpusId\": 222271911, \"span\": \"Wu et al. (2020) and\", \"start\": 1434, \"end\": 1454}, {\"corpusId\": 256461400, \"span\": \"this approach\", \"start\": 1634, \"end\": 1634}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "1368", "title": "Boundary-Driven Table-Filling for Aspect Sentiment Triplet Extraction", "sectionTitle": "Relation-Level Representation Construction", "text": "Most of the existing work constructs the relation representation between two words by feature concatenation (Wu et al., 2020;Jing et al., 2021;Xu et al., 2021). However, this method underutilizes word-to-word interactions because a relation is not a simple composition of two words. Inspired by Socher et al. (2013), we adopt a tensor-based operation to construct the relation-level representation. Given two words h i , h j \u2208 R d , the tensor-based operation is defined as:", "spans": "[{\"corpusId\": 222271911, \"span\": \"(Wu et al., 2020;\", \"start\": 108, \"end\": 125}, {\"corpusId\": 236428724, \"span\": \"Xu et al., 2021)\", \"start\": 143, \"end\": 159}, {\"corpusId\": 256461400, \"span\": \"this method\", \"start\": 181, \"end\": 181}, {\"corpusId\": 990233, \"span\": \"Socher et al. (2013)\", \"start\": 295, \"end\": 315}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "1369", "title": "Boundary-Driven Table-Filling for Aspect Sentiment Triplet Extraction", "sectionTitle": "Datasets", "text": "We evaluate our approach on four public datasets from SemEval 2014 3 (Pontiki et al., 2014), Se-mEval 2015 4 (Pontiki et al., 2015), and SemEval 2016 5 (Pontiki et al., 2016). For these datasets, Fan et al. (2019) Wu et al., 2020). Therefore,  refine these datasets and release ASTE-Data-v2. We compare our approach with previous methods and perform the ablation study on ASTE-Data-v2. Its data statistics is detailed in Table 1.", "spans": "[{\"corpusId\": 256461400, \"span\": \"our approach\", \"start\": 24, \"end\": 24}, {\"corpusId\": 61874237, \"span\": \"(Pontiki et al., 2015)\", \"start\": 109, \"end\": 131}, {\"corpusId\": 1021411, \"span\": \"(Pontiki et al., 2016)\", \"start\": 152, \"end\": 174}, {\"corpusId\": 222271911, \"span\": \"Wu et al., 2020)\", \"start\": 214, \"end\": 230}, {\"corpusId\": 256461400, \"span\": \"our approach\", \"start\": 315, \"end\": 315}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "1370", "title": "Boundary-Driven Table-Filling for Aspect Sentiment Triplet Extraction", "sectionTitle": "Baselines", "text": "We categorize the baselines into four groups: tablefilling methods, span-based methods, generative methods, and other methods. Table-Filling methods represent aspect terms and opinion terms along with their sentiment relations as word-pair relations. Wu et al. (2020) propose Grid Tagging Scheme (GTS) and design an inference strategy to exploit mutual indication between different opinion factors.  propose a multi-task learning framework (OTE-MTL) to jointly extract terms and parse sentiment dependencies. Dual-Encoder (Jing et al., 2021) and TGA +SFI (Wang et al., 2021a) Table 2 lists the comparison results on the ASTE task. According to these results, our approach consistently attains the best performance, demonstrating its effectiveness. More specifically, we have following observations. (1) Our approach achieves F 1 -score improvements of 2.50%, 2.36%, 2.85%, and 2.01% on the four datasets compared with the previous best baseline model without introducing the syntactic dependency tree (Xu et al., 2021). (2) Wu et al., 2020;Jing et al., 2021;Wang et al., 2021a;Chen et al., 2022), our approach shows substantial improvements in F 1 -score. These improvements in F 1 -score are more attributable to the improvements in Precision. For example, compared with Jing et al. (2021), our approach obtains F 1 -score gains of 4.80%, 2.63%, and 6.80% for Rest14, Lap14, and Rest15, while the corresponding Precision gains reach 7.58%, 6.82%, and 10.21%. This suggests that our approach produces fewer wrong predictions due to its boundary sensitivity.", "spans": "[{\"corpusId\": 222271911, \"span\": \"Wu et al. (2020)\", \"start\": 251, \"end\": 267}, {\"corpusId\": 256461400, \"span\": \"our approach\", \"start\": 671, \"end\": 671}, {\"corpusId\": 256461400, \"span\": \"Our approach\", \"start\": 815, \"end\": 815}, {\"corpusId\": 236428724, \"span\": \"(Xu et al., 2021)\", \"start\": 1001, \"end\": 1018}, {\"corpusId\": 222271911, \"span\": \"Wu et al., 2020;\", \"start\": 1024, \"end\": 1040}, {\"corpusId\": 256461400, \"span\": \"our approach\", \"start\": 1109, \"end\": 1109}, {\"corpusId\": 256461400, \"span\": \"our approach\", \"start\": 1304, \"end\": 1304}, {\"corpusId\": 256461400, \"span\": \"our approach\", \"start\": 1491, \"end\": 1491}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "1371", "title": "Boundary-Driven Table-Filling for Aspect Sentiment Triplet Extraction", "sectionTitle": "Aspect-Opinion Co-Extraction", "text": "In recent years, Aspect-Based Sentiment Analysis has attracted lots of researchers' interest (He et al., 2019;Yan et al., 2021;Zhang et al., 2021c;Liang et al., 2021;Mao et al., 2021;Liang et al., 2022a,b;Cao et al., 2022). As one of the most fundamental task in ABSA, Aspect term extraction has been studied in many prior works (Hu and Liu, 2004;Yin et al., 2016;Xu et al., 2018;Hu et al., 2019;Wang et al., 2021b). The sentiment expression of aspect terms often depends on opinion terms, and thus opinion terms can be applied as clues to extract aspect terms and determine corresponding sentiment polarity. As a result, the amount of related aspect and opinion co-extraction work has been gradually increasing (Wang et al., 2016(Wang et al., , 2017Li and Lam, 2017;Li et al., 2018;Fan et al., 2019;Chen et al., 2020;.", "spans": "[{\"corpusId\": 235367681, \"span\": \"Yan et al., 2021;\", \"start\": 110, \"end\": 127}, {\"corpusId\": 236460053, \"span\": \"Zhang et al., 2021c;\", \"start\": 127, \"end\": 147}, {\"corpusId\": 16841192, \"span\": \"Yin et al., 2016;\", \"start\": 347, \"end\": 364}, {\"corpusId\": 44009215, \"span\": \"Xu et al., 2018;\", \"start\": 364, \"end\": 380}, {\"corpusId\": 243865344, \"span\": \"Wang et al., 2021b)\", \"start\": 396, \"end\": 415}, {\"corpusId\": 11805625, \"span\": \"(Wang et al., 2016\", \"start\": 712, \"end\": 730}, {\"corpusId\": 29170646, \"span\": \"(Wang et al., , 2017\", \"start\": 730, \"end\": 750}, {\"corpusId\": 222134074, \"span\": \"Chen et al., 2020;\", \"start\": 800, \"end\": 818}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 8}, {"paragraphId": "1372", "title": "Boundary-Driven Table-Filling for Aspect Sentiment Triplet Extraction", "sectionTitle": "Aspect-Opinion Co-Extraction", "text": "Subsequent works address the ASTE task by transforming it into the position-aware tagging problem , the machine reading comprehension task (Chen et al., 2021a;Mao et al., 2021), the table-filling problem (Wu et al., 2020;Chen et al., 2021b;Jing et al., 2021;Chen et al., 2022), the span-relation extraction problem (Xu et al., 2021;Li et al., 2022a), and the sequence generation task (Yan et al., 2021;Zhang et al., 2021c;Mukherjee et al., 2021;Lu et al., 2022).", "spans": "[{\"corpusId\": 222271911, \"span\": \"(Wu et al., 2020;\", \"start\": 204, \"end\": 221}, {\"corpusId\": 236428724, \"span\": \"(Xu et al., 2021;\", \"start\": 315, \"end\": 332}, {\"corpusId\": 235367681, \"span\": \"(Yan et al., 2021;\", \"start\": 384, \"end\": 402}, {\"corpusId\": 236460053, \"span\": \"Zhang et al., 2021c;\", \"start\": 402, \"end\": 422}, {\"corpusId\": 238582981, \"span\": \"Mukherjee et al., 2021;\", \"start\": 422, \"end\": 445}, {\"corpusId\": 247419843, \"span\": \"Lu et al., 2022)\", \"start\": 445, \"end\": 461}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "1373", "title": "Boundary-Driven Table-Filling for Aspect Sentiment Triplet Extraction", "sectionTitle": "References", "text": "Heike Adel and Hinrich Sch\u00fctze. 2017. Global normalization of convolutional neural networks for joint entity and relation classification.   not required in AOPE. Considering their similarity, we also evaluate our approach on the AOPE task. To make our approach applicable to the AOPE task, we modify the type space of relation regions from {POS, NEU, NEG, Invalid} to {Pair, Invalid}. The corresponding experimental results are listed in Table 10 and 11. It can be observed that our approach also yields outstanding results on the AOPE task. On the dataset provided by Fan et al. (2019), many methods (Wu et al., 2021;Liu et al., 2022;Li et al., 2022a,b) introduce additional syntactic features to learn better feature representations. Although we do not use syntactic features, our approach still surpasses them, demonstrating its effectiveness.", "spans": "[{\"corpusId\": 256461400, \"span\": \"our approach\", \"start\": 221, \"end\": 221}, {\"corpusId\": 256461400, \"span\": \"our approach\", \"start\": 260, \"end\": 260}, {\"corpusId\": 256461400, \"span\": \"our approach\", \"start\": 491, \"end\": 491}, {\"corpusId\": 233864984, \"span\": \"(Wu et al., 2021;\", \"start\": 601, \"end\": 618}, {\"corpusId\": 247419843, \"span\": \"Liu et al., 2022;\", \"start\": 618, \"end\": 635}, {\"corpusId\": 256461400, \"span\": \"our approach\", \"start\": 791, \"end\": 791}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 7}
{"paperId": "d8cb361f6dd5da91b75fd498153acee6af0c7730", "title": "Constrained Fact Verification for FEVER", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2020, "citationCount": 5, "openAccessPdf": {"url": "https://doi.org/10.18653/v1/2020.emnlp-main.629", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://aclanthology.org/2020.emnlp-main.629, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2020-11-01", "authors": [{"authorId": "51132476", "name": "Adithya Pratapa"}, {"authorId": "31602573", "name": "Sai Muralidhar Jayanthi"}, {"authorId": "2008177410", "name": "Kavya Nerella"}], "abstract": "Fact-verification systems are well explored in the NLP literature with growing attention owing to shared tasks like FEVER. Though the task requires reasoning on extracted evidence to verify a claim\u2019s factuality, there is little work on understanding the reasoning process. In this work, we propose a new methodology for fact-verification, specifically FEVER, that enforces a closed-world reliance on extracted evidence. We present an extensive evaluation of state-of-the-art verification models under these constraints.", "corpusId": "226262202", "paragraphs": [{"paragraphId": "37060", "title": "Constrained Fact Verification for FEVER", "sectionTitle": "Related Work", "text": "We adopted the widely used document selection method from Hanselowski et al. (2018). Many recent state-of-the-art FEVER systems involve reasoning over evidence graphs Zhong et al., 2019;Liu et al., 2020;Zhao et al., 2020) along with competitive LMbased models (Soleimani et al., 2020). Dataset specific idiosyncrasies have been identified in FEVER (Thorne et al., 2019;Schuster et al., 2019) as well as in NLI (Gururangan et al., 2018;Poliak et al., 2018;Naik et al., 2018;McCoy et al., 2019), but is not the focus of this work.", "spans": "[{\"corpusId\": \"52162540\", \"span\": \"Hanselowski et al. (2018)\", \"start\": 58, \"end\": 83}, {\"corpusId\": \"215828553\", \"span\": \"Liu et al., 2020;\", \"start\": 186, \"end\": 203}, {\"corpusId\": \"212745235\", \"span\": \"Zhao et al., 2020)\", \"start\": 203, \"end\": 221}, {\"corpusId\": \"203837038\", \"span\": \"(Soleimani et al., 2020)\", \"start\": 260, \"end\": 284}, {\"corpusId\": \"202777662\", \"span\": \"(Thorne et al., 2019;\", \"start\": 348, \"end\": 369}, {\"corpusId\": \"199577588\", \"span\": \"Schuster et al., 2019)\", \"start\": 369, \"end\": 391}, {\"corpusId\": \"21382535\", \"span\": \"Poliak et al., 2018;\", \"start\": 435, \"end\": 455}, {\"corpusId\": \"46932607\", \"span\": \"Naik et al., 2018;\", \"start\": 455, \"end\": 473}, {\"corpusId\": \"59599752\", \"span\": \"McCoy et al., 2019)\", \"start\": 473, \"end\": 492}, {\"corpusId\": 226262202, \"span\": \"this work\", \"start\": 527, \"end\": 527}]", "conference": "emnlp", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 10}, {"paragraphId": "37061", "title": "Constrained Fact Verification for FEVER", "sectionTitle": "Table 7 :", "text": "More recently, Lee et al. (2020) developed a fact verification system solely based on large pretrained LMs and presented their superior zero-shot performance on FEVER compared to a random baseline. This result clearly shows the influence of factual knowledge embedded inside these LMs, but relying entirely on such knowledge directly contrasts to the evidence-based paradigm of factverification. Such reliance can be problematic, especially with evolving evidence (Wikipedia pages are constantly updated to reflect the latest events). Schuster et al. (2019) illustrate this phenomenon through an example fact, \"Halep failed to ever win a Wimbledon title\", which was valid until July 2019 but not thereafter.", "spans": "[{\"corpusId\": \"219531164\", \"span\": \"Lee et al. (2020)\", \"start\": 15, \"end\": 32}, {\"corpusId\": 226262202, \"span\": \"This result\", \"start\": 209, \"end\": 209}, {\"corpusId\": \"199577588\", \"span\": \"Schuster et al. (2019)\", \"start\": 535, \"end\": 557}]", "conference": "emnlp", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "37062", "title": "Constrained Fact Verification for FEVER", "sectionTitle": "Table 7 :", "text": "We build upon the work of Clark et al. (2020) that demonstrated the ability of transformers (BERT, RoBERTa) to function as soft theorem provers. They induce a closed-world reasoning process by fine-tuning on a carefully curated synthetic natural language rulebase. In this work, we transfer this ability to FEVER and gauge the feasibility of such closed-world reasoning. Additionally, we also construct an entity-anonymized version of FEVER following Hermann et al. (2015) for evaluating our proposed models. We construct the anonymized version by masking prominent named entities in the claim-evidence pairs, thereby reducing any reliance on pre-trained factual knowledge.", "spans": "[{\"corpusId\": \"211126663\", \"span\": \"Clark et al. (2020)\", \"start\": 26, \"end\": 45}, {\"corpusId\": 226262202, \"span\": \"this work\", \"start\": 277, \"end\": 277}, {\"corpusId\": \"6203757\", \"span\": \"Hermann et al. (2015)\", \"start\": 451, \"end\": 472}]", "conference": "emnlp", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "37063", "title": "Constrained Fact Verification for FEVER", "sectionTitle": "Table 7 :", "text": "Our experiments adopt the popular three-stage pipeline of FEVER task, comprising document selection, evidence sentence extraction, and claim verification (Thorne et al., 2018b). We primarily focus on the claim verification stage of FEVER, while using the state-of-the-art document selec-tion and evidence sentences extraction from Liu et al. (2020). Our focus is motivated since only the claim verification step involves a joint (often complicated) reasoning over the extracted evidence. Our main contributions are,", "spans": "[{\"corpusId\": \"53645946\", \"span\": \"(Thorne et al., 2018b)\", \"start\": 154, \"end\": 176}, {\"corpusId\": \"215828553\", \"span\": \"Liu et al. (2020)\", \"start\": 331, \"end\": 348}, {\"corpusId\": 226262202, \"span\": \"Our focus\", \"start\": 359, \"end\": 359}]", "conference": "emnlp", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "37064", "title": "Constrained Fact Verification for FEVER", "sectionTitle": "Constrained Verification", "text": "Traditionally, most FEVER systems rely on large pre-trained language models (LMs) to encode the claim and extracted evidence sentences. Previously, Schuster et al. (2019) studied various reasons for the surprisingly good performance of claim-only classifiers on FEVER and reported dataset idiosyncrasies to be the primary reason as opposed to world knowledge in word embeddings. However, they present only a preliminary analysis of the impact of world knowledge from GloVe embeddings (Pennington et al., 2014). In this work, we present an in-depth analysis because the issue is particularly relevant in the context of large pre-trained LMs. To the best of our knowledge, we are not aware of any other works that look into the impact of embedding's world knowledge on FEVER.", "spans": "[{\"corpusId\": \"199577588\", \"span\": \"Schuster et al. (2019)\", \"start\": 148, \"end\": 170}, {\"corpusId\": \"1957433\", \"span\": \"(Pennington et al., 2014)\", \"start\": 484, \"end\": 509}, {\"corpusId\": 226262202, \"span\": \"this work\", \"start\": 523, \"end\": 523}]", "conference": "emnlp", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 5}
{"paperId": "313e22afb1e33af6f950e2f2cb3671555aa1e3d8", "title": "Improving Complex Knowledge Base Question Answering via Question-to-Action and Question-to-Question Alignment", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2022, "citationCount": 11, "openAccessPdf": {"url": "http://arxiv.org/pdf/2212.13036", "status": "GREEN", "license": null, "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2212.13036, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2022-12-26", "authors": [{"authorId": "2047220181", "name": "Yechun Tang"}, {"authorId": "2149478197", "name": "Xiaoxia Cheng"}, {"authorId": "1776903", "name": "Weiming Lu"}], "abstract": "Complex knowledge base question answering can be achieved by converting questions into sequences of predefined actions. However, there is a significant semantic and structural gap between natural language and action sequences, which makes this conversion difficult. In this paper, we introduce an alignment-enhanced complex question answering framework, called ALCQA, which mitigates this gap through question-to-action alignment and question-to-question alignment. We train a question rewriting model to align the question and each action, and utilize a pretrained language model to implicitly align the question and KG artifacts. Moreover, considering that similar questions correspond to similar action sequences, we retrieve top-k similar question-answer pairs at the inference stage through question-to-question alignment and propose a novel reward-guided action sequence selection strategy to select from candidate action sequences. We conduct experiments on CQA and WQSP datasets, and the results show that our approach outperforms state-of-the-art methods and obtains a 9.88% improvements in the F1 metric on CQA dataset. Our source code is available at https://github.com/TTTTTTTTy/ALCQA.", "corpusId": "255125039", "paragraphs": [{"paragraphId": "94838", "title": "Improving Complex Knowledge Base Question Answering via Question-to-Action and Question-to-Question Alignment", "sectionTitle": "Introduction", "text": "Complex knowledge base question answering (CQA) aims to answer various natural language questions with a large-scale knowledge graph. Compared to simple questions with single or multihop of relations, complex questions have more kinds of answer types such as numeric or boolean types and require more kinds of aggregation operations like min/max or intersection/union to yield answers. Semantic parsing approaches typically map questions to intermediate logical forms such as query graphs (Yih et al., 2015;Bao et al., 2016;Bhutani et al., 2019;Maheshwari et al., 2019;Lan * Corresponding author. and Jiang, 2020;Qin et al., 2021), and further transform them into queries like SPARQL query language. Recently, many works (Liang et al., 2017;Hua et al., 2020a,b,c) predefine a collection of functions with constrained argument types and represent the intermediate logical form as a sequence of actions that can be generated using a seq2seq model. Sequencebased methods are natural to accomplish more complex operations by simply expanding the function set, thus making some logically complex questions answerable while they're difficult to answer using query graphs.", "spans": "[{\"corpusId\": 18309765, \"span\": \"(Yih et al., 2015;\", \"start\": 489, \"end\": 507}, {\"corpusId\": 18549358, \"span\": \"Bao et al., 2016;\", \"start\": 507, \"end\": 524}, {\"corpusId\": 207757236, \"span\": \"Bhutani et al., 2019;\", \"start\": 524, \"end\": 545}, {\"corpusId\": 53220882, \"span\": \"Maheshwari et al., 2019;\", \"start\": 545, \"end\": 569}, {\"corpusId\": 243865277, \"span\": \"Qin et al., 2021)\", \"start\": 613, \"end\": 630}, {\"corpusId\": 2742513, \"span\": \"(Liang et al., 2017;\", \"start\": 721, \"end\": 741}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 6}, {"paragraphId": "94839", "title": "Improving Complex Knowledge Base Question Answering via Question-to-Action and Question-to-Question Alignment", "sectionTitle": "Introduction", "text": "The seq2seq model has been widely used and achieved good results on many text generation tasks, such as machine translation, text summarization and style transfer. In these tasks, the source and the target sequence are both natural language texts and thus share some low-level features. However, semantic parsing aims to transform unstructured texts into structured logical forms, which requires a difficult alignment between them. This problem becomes more serious when the complexity of the question rises. Some works propose to solve this problem by modelling the hierarchical structure of logical forms. Dong and Lapata (2016) introduces a sequence-to-tree model with an attention mechanism. Dong and Lapata (2018) proposes to decode a sketch of the logical forms which contain a set of functions at first and then decode low-level details like arguments. Guo et al. (2021) iteratively segments a span from the question by a segmentation model and parses it using a base parser until the whole query is parsed.  uses a shift-reduce algorithm to obtain token sequences instead of predicting the start and end positions of the span. However, most of these works require intermediate logical forms or sub-questions to train models, which are usually difficult to obtain. Guo et al. (2021) and  propose to pretrain a base parser firstly, and then search good segments Figure 1: An overview of the proposed approach. The question is first converted into a more structured form, then multiple candidate action sequences are generated by the seq2seq model, and finally the candidate action sequences are scored based on similar question-answer pairs. that predicted sub logical forms are part of or can be composed into the golden meaning representation. They don't necessarily require training pairs but have the limitation that decomposed utterances are continuous segments of the original question.", "spans": "[{\"corpusId\": 15412473, \"span\": \"Dong and Lapata (2016)\", \"start\": 608, \"end\": 630}, {\"corpusId\": 44167998, \"span\": \"Dong and Lapata (2018)\", \"start\": 696, \"end\": 718}, {\"corpusId\": 229156144, \"span\": \"Guo et al. (2021)\", \"start\": 860, \"end\": 877}, {\"corpusId\": 229156144, \"span\": \"Guo et al. (2021)\", \"start\": 1272, \"end\": 1289}, {\"corpusId\": 255125039, \"span\": \"proposed approach\", \"start\": 1414, \"end\": 1414}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "94840", "title": "Improving Complex Knowledge Base Question Answering via Question-to-Action and Question-to-Question Alignment", "sectionTitle": "Experimental Setup", "text": "Our method aims to solve various complex questions, and we mainly evaluate it on ComplexQues-tionAnswering (CQA) (Saha et al., 2018) dataset which is a large-scale KBQA dataset containing seven types of complex questions, as shown in Table 1. We show the details and some examples of this dataset in Appendix A. We also conduct experiments on WebQuestionsSP (WQSP) (Yih et al., 2015) which contains 4737 simple questions. The results show that our method also works well on simple datasets.", "spans": "[{\"corpusId\": 255125039, \"span\": \"Our method\", \"start\": 10, \"end\": 10}, {\"corpusId\": 19240019, \"span\": \"(Saha et al., 2018)\", \"start\": 113, \"end\": 132}, {\"corpusId\": 18309765, \"span\": \"(Yih et al., 2015)\", \"start\": 365, \"end\": 383}, {\"corpusId\": 255125039, \"span\": \"our method\", \"start\": 454, \"end\": 454}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "94841", "title": "Improving Complex Knowledge Base Question Answering via Question-to-Action and Question-to-Question Alignment", "sectionTitle": "Baselines", "text": "We compare our framework with seq2seq based methods. KVmem (Saha et al., 2018) presents a model consisting of a hierarchical encoder and a key value memory network. CIPITR  proposes to mitigate reward sparsity with auxiliary rewards and restricts the program space to semantically correct programs. CIPITR proposes two training ways, one training a single model for all question categories, denoted by CIP-ALL, and the other training a separate model for each category, denoted by CIP-SEP. NSM (Liang et al., 2017) utilizes a key-variable memory to handle compositionality and helps find good programs by pruning the search space. MRL-CQA (Hua et al., 2020a) and MARL (Hua et al., 2020b) propose meta-reinforcement learning approaches that effectively adapts the meta-learned programmer to new questions to tackle potential distributional biases, where the former uses an unsupervised retrieval model and the latter learns it alternately with the programmer from weak supervision. NS-CQA (Hua et al., 2020c) presents a memory buffer that stores high-reward programs and proposes an adaptive reward function to improve training performance. SSRP (Ansari et al., 2019) presents a noise-resilient model that is distant-supervised by the final answer. CBR-KBQA (Das et al., 2021) generates complex logical forms conditioned on similar retrieved questions and their logical forms to generalize to unseen relations. We also compare our method with graph-based methods on WQSP dataset. STAGG (Yih et al., 2015) proposes a staged query graph generation framework and leverages the knowledge base in an early stage to prune the search space. TEX-TRAY (Bhutani et al., 2019) answers complex questions using a novel decompose-execute-join approach. QGG (Lan and Jiang, 2020) modifies STAGG with more flexible ways to handle constraints and multi-hop relations. OQGG (Qin et al., 2021) starts with the entire knowledge base and gradually shrinks it to the desired query graph.", "spans": "[{\"corpusId\": 19240019, \"span\": \"(Saha et al., 2018)\", \"start\": 59, \"end\": 78}, {\"corpusId\": 2742513, \"span\": \"(Liang et al., 2017\", \"start\": 494, \"end\": 513}, {\"corpusId\": 226222169, \"span\": \"(Hua et al., 2020a)\", \"start\": 639, \"end\": 658}, {\"corpusId\": 220485098, \"span\": \"(Hua et al., 2020b)\", \"start\": 668, \"end\": 687}, {\"corpusId\": 233296655, \"span\": \"(Das et al., 2021)\", \"start\": 1257, \"end\": 1275}, {\"corpusId\": 255125039, \"span\": \"our method\", \"start\": 1436, \"end\": 1436}, {\"corpusId\": 18309765, \"span\": \"(Yih et al., 2015)\", \"start\": 1485, \"end\": 1503}, {\"corpusId\": 207757236, \"span\": \"(Bhutani et al., 2019)\", \"start\": 1642, \"end\": 1664}, {\"corpusId\": 243865277, \"span\": \"(Qin et al., 2021)\", \"start\": 1855, \"end\": 1873}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "94842", "title": "Improving Complex Knowledge Base Question Answering via Question-to-Action and Question-to-Question Alignment", "sectionTitle": "Related Work", "text": "Semantic parsing is the task of translating natural language utterances into executable meaning representations. Recent semantic parsing based KBQA methods can be categorized as graph-based (Yih et al., 2015;Bao et al., 2016;Bhutani et al., 2019;Lan and Jiang, 2020;Qin et al., 2021) and sequence-based (Liang et al., 2017;Hua et al., 2020a,b,c;Das et al., 2021). Graph-based methods build a query  graph which is a graph-like logical form proposed by (Yih et al., 2015). (Bao et al., 2016) proposed multi-constraint query graph to improve performance. Ding et al. (2019) and Bhutani et al. (2019) decomposed complex query graph into a set of simple queries to overcome the long-tail problem. (Lan and Jiang, 2020) employed early incorporation of constraints to prune the search space.  leveraged the query structure to constrain the generation of the candidate queries. (Qin et al., 2021)  Compared to graph-based methods, sequencebased methods can generate logical forms directly using the seq2seq model, which is easier to implement and can handle more question categories by simply expanding the set of action functions. However, the semantic and structural gap between natural language utterances and action sequences leads to poor performance on translation.", "spans": "[{\"corpusId\": 18309765, \"span\": \"(Yih et al., 2015;\", \"start\": 190, \"end\": 208}, {\"corpusId\": 18549358, \"span\": \"Bao et al., 2016;\", \"start\": 208, \"end\": 225}, {\"corpusId\": 207757236, \"span\": \"Bhutani et al., 2019;\", \"start\": 225, \"end\": 246}, {\"corpusId\": 243865277, \"span\": \"Qin et al., 2021)\", \"start\": 266, \"end\": 283}, {\"corpusId\": 2742513, \"span\": \"(Liang et al., 2017;\", \"start\": 303, \"end\": 323}, {\"corpusId\": 233296655, \"span\": \"Das et al., 2021)\", \"start\": 345, \"end\": 362}, {\"corpusId\": 18309765, \"span\": \"(Yih et al., 2015)\", \"start\": 452, \"end\": 470}, {\"corpusId\": 18549358, \"span\": \"(Bao et al., 2016)\", \"start\": 472, \"end\": 490}, {\"corpusId\": 201668424, \"span\": \"Ding et al. (2019)\", \"start\": 553, \"end\": 571}, {\"corpusId\": 207757236, \"span\": \"Bhutani et al. (2019)\", \"start\": 576, \"end\": 597}, {\"corpusId\": 243865277, \"span\": \"(Qin et al., 2021)\", \"start\": 871, \"end\": 889}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 7}], "paragraphCount": 5}
{"paperId": "7a49beff86a855f237f96ae3f0aefc9780cb31be", "title": "bert2BERT: Towards Reusable Pretrained Language Models", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2021, "citationCount": 73, "openAccessPdf": {"url": "https://aclanthology.org/2022.acl-long.151.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2110.07143, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2021-10-14", "authors": [{"authorId": "2145775089", "name": "Cheng Chen"}, {"authorId": "1384668226", "name": "Yichun Yin"}, {"authorId": "50812138", "name": "Lifeng Shang"}, {"authorId": "2110310493", "name": "Xin Jiang"}, {"authorId": "50625437", "name": "Yujia Qin"}, {"authorId": "2109126455", "name": "Fengyu Wang"}, {"authorId": "2135451922", "name": "Zhi Wang"}, {"authorId": "2117025507", "name": "Xiao Chen"}, {"authorId": "2146374807", "name": "Zhiyuan Liu"}, {"authorId": "30738758", "name": "Qun Liu"}], "abstract": "In recent years, researchers tend to pre-train ever-larger language models to explore the upper limit of deep models. However, large language model pre-training costs intensive computational resources, and most of the models are trained from scratch without reusing the existing pre-trained models, which is wasteful. In this paper, we propose bert2BERT, which can effectively transfer the knowledge of an existing smaller pre-trained model to a large model through parameter initialization and significantly improve the pre-training efficiency of the large model. Specifically, we extend the previous function-preserving method proposed in computer vision on the Transformer-based language model, and further improve it by proposing a novel method, advanced knowledge for large model\u2019s initialization. In addition, a two-stage learning method is proposed to further accelerate the pre-training. We conduct extensive experiments on representative PLMs (e.g., BERT and GPT) and demonstrate that (1) our method can save a significant amount of training cost compared with baselines including learning from scratch, StackBERT and MSLT; (2) our method is generic and applicable to different types of pre-trained models. In particular, bert2BERT saves about 45% and 47% computational cost of pre-training BERT_{\\rm BASE} and GPT_{\\rm BASE} by reusing the models of almost their half sizes.", "corpusId": "238856697", "paragraphs": [{"paragraphId": "91300", "title": "bert2BERT: Towards Reusable Pretrained Language Models\u00a0", "sectionTitle": "Introduction", "text": "Pre-trained language models (PLMs), such as BERT (Devlin et al., 2019), GPT (Radford et al., 2018(Radford et al., , 2019Brown et al., 2020), ELECTRA (Clark et al., 2020), XLNet (Yang et al., 2019) and RoBERTa , have achieved great 0 1 2 3 4 5 6 7 8 FLOPs (1e19)  StackBERT (Gong et al., 2019) is based on the progressive training setting. More details are shown in Table 2.", "spans": "[{\"corpusId\": 52967399, \"span\": \"(Devlin et al., 2019)\", \"start\": 49, \"end\": 70}, {\"corpusId\": 160025533, \"span\": \"(Radford et al., , 2019\", \"start\": 97, \"end\": 120}, {\"corpusId\": 218971783, \"span\": \"Brown et al., 2020)\", \"start\": 120, \"end\": 139}, {\"corpusId\": 213152193, \"span\": \"(Clark et al., 2020)\", \"start\": 149, \"end\": 169}, {\"corpusId\": 195069387, \"span\": \"(Yang et al., 2019)\", \"start\": 177, \"end\": 196}, {\"corpusId\": 174799716, \"span\": \"(Gong et al., 2019)\", \"start\": 273, \"end\": 292}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 6}, {"paragraphId": "91301", "title": "bert2BERT: Towards Reusable Pretrained Language Models\u00a0", "sectionTitle": "Related Work", "text": "Efficient Pre-training in NLP. The efficiency of pre-training has been explored by previous work. Some works (Gong et al., 2019;Yang et al., 2020;Gu et al., 2021) propose progressive learning to accelerate the pre-training, which are motivated by the fact that different layers have some similar knowledge (e.g., attention patterns). They start pre-training a small model with fewer Transformer layers, and then iteratively expand the model by stacking the already trained layers on the top. Another line of work proposes to \"back distill\" the knowledge of the small models into large models, which is termed as knowledge inheritance (Qin et al., 2021). Some works focus on the data effi-ciency (Wu et al., 2021) and take notes for rare words during the pre-training process to help the model understand them when they occur next. ELECTRA (Clark et al., 2020) proposes a task of replaced token detection to predict whether each token in the input was replaced or not, which improves the pre-training efficiency. Our method is orthogonal to this kind of work and the combination of ELECTRA and bert2BERT could achieve better efficiency. In addition, there are several other orthogonal techniques for efficient pre-training: mixed-precision training (Shoeybi et al., 2019), large batch optimization (You et al., 2020), model architecture innovation , layer dropping technique , etc.", "spans": "[{\"corpusId\": 174799716, \"span\": \"(Gong et al., 2019;\", \"start\": 109, \"end\": 128}, {\"corpusId\": 165163737, \"span\": \"Yang et al., 2020;\", \"start\": 128, \"end\": 146}, {\"corpusId\": 225062299, \"span\": \"Gu et al., 2021)\", \"start\": 146, \"end\": 162}, {\"corpusId\": 235613669, \"span\": \"(Wu et al., 2021)\", \"start\": 695, \"end\": 712}, {\"corpusId\": 213152193, \"span\": \"(Clark et al., 2020)\", \"start\": 839, \"end\": 859}, {\"corpusId\": 238856697, \"span\": \"Our method\", \"start\": 1022, \"end\": 1022}, {\"corpusId\": 165163737, \"span\": \"(You et al., 2020)\", \"start\": 1297, \"end\": 1315}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "91302", "title": "bert2BERT: Towards Reusable Pretrained Language Models\u00a0", "sectionTitle": "Related Work", "text": "Reusable Neural Network. Reusable neural network, a topic related to transfer learning (Pan and Yang, 2010), is introduced to accelerate the model training in computer vision. One classical work is Net2Net (Chen et al., 2016), which first proposes the concept of the function-preserving transformation to make neural networks reusable. However, Net2Net randomly selects the neurons to be split. To handle this problem, some works (Wu et al., , 2020bWang et al., 2019b;Wu et al., 2020a) leverage a functional steepest descent idea to decide the optimal subset of neurons to be split. The pruning technique (Han et al., 2015) is also introduced for reusable neural networks (Feng and Panda, 2020). In this paper, we study the reusable pre-trained language model and propose a new method, bert2BERT, to accelerate the pre-training of BERT and GPT.", "spans": "[{\"corpusId\": 6702706, \"span\": \"(Chen et al., 2016)\", \"start\": 206, \"end\": 225}, {\"corpusId\": 227276414, \"span\": \"Wu et al., 2020a)\", \"start\": 468, \"end\": 485}, {\"corpusId\": 211818281, \"span\": \"(Feng and Panda, 2020)\", \"start\": 672, \"end\": 694}, {\"corpusId\": 238856697, \"span\": \"this paper\", \"start\": 709, \"end\": 709}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "91303", "title": "bert2BERT: Towards Reusable Pretrained Language Models\u00a0", "sectionTitle": "Advanced Knowledge Initialization", "text": "matrices based on not only the parameters of the same layer but also the parameters of the upper layer in the source model. The intuition is based on previous findings (Jawahar et al., 2019;Clark et al., 2019) that adjacent Transformer layers have similar functionality, which ensures that it will not damage the knowledge contained in the parameters of the current layer. Moreover, the knowledge that comes from adjacent layers can break the symmetry (Chen et al., 2016) appeared in FPI, which has been demonstrated beneficial. We give an illustrative example in Figure 4 and formulate AKI as:", "spans": "[{\"corpusId\": 195477534, \"span\": \"(Jawahar et al., 2019;\", \"start\": 168, \"end\": 190}, {\"corpusId\": 184486746, \"span\": \"Clark et al., 2019\", \"start\": 190, \"end\": 208}, {\"corpusId\": 6702706, \"span\": \"(Chen et al., 2016)\", \"start\": 452, \"end\": 471}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "91304", "title": "bert2BERT: Towards Reusable Pretrained Language Models\u00a0", "sectionTitle": "Experimental Setup", "text": "Fine-tuning Details. For the evaluation, we use tasks from GLUE benchmark (Wang et al., 2019a) and SQuADv1.1 (Rajpurkar et al., 2016). We report F1 for SQuADv1.1, Matthews correlation coefficient (Mcc) for CoLA (Warstadt et al., 2019) and accuracy (Acc) for other tasks. For the GLUE tasks fine-tuning, we set the batch size to 32, choose the learning rate from {5e-6, 1e-5, 2e-5, 3e-5} and epochs from {4, 5, 10}. For the SQuADv1.1 finetuning, we set the batch size to 16, the learning rate to 3e-5, and the number of training epochs to 4. All results are the average of 3 runs on the dev set.", "spans": "[{\"corpusId\": 5034059, \"span\": \"(Wang et al., 2019a)\", \"start\": 74, \"end\": 94}, {\"corpusId\": 11816014, \"span\": \"(Rajpurkar et al., 2016)\", \"start\": 109, \"end\": 133}, {\"corpusId\": 44072099, \"span\": \"(Warstadt et al., 2019)\", \"start\": 211, \"end\": 234}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "91305", "title": "bert2BERT: Towards Reusable Pretrained Language Models\u00a0", "sectionTitle": "Application on T5", "text": "Datasets. To demonstrate that our method can be used to train larger models, we use the Baidu Wikipedia, Sougou Wikipedia, and Zhihu to train the T5 model (Raffel et al., 2020). For the evaluation, we use the dataset of the original Chinese natural language inference task (OCNLI) (Hu et al., 2020).  =0). Note that the scale gap between the source model and the target model is over 10 times (31M vs. 360M), which is a challenging setting.", "spans": "[{\"corpusId\": 238856697, \"span\": \"our method\", \"start\": 40, \"end\": 40}, {\"corpusId\": 204838007, \"span\": \"(Raffel et al., 2020)\", \"start\": 155, \"end\": 176}, {\"corpusId\": 222291723, \"span\": \"(Hu et al., 2020)\", \"start\": 281, \"end\": 298}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 6}
{"paperId": "9521ca90922348d5e5f110b8968c4ed66542872e", "title": "PathQG: Neural Question Generation from Facts", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2020, "citationCount": 22, "openAccessPdf": {"url": "https://doi.org/10.18653/v1/2020.emnlp-main.729", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://aclanthology.org/2020.emnlp-main.729, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2020-11-01", "authors": [{"authorId": "2116420560", "name": "Siyuan Wang"}, {"authorId": "2712533", "name": "Zhongyu Wei"}, {"authorId": "9610143", "name": "Zhihao Fan"}, {"authorId": "3251920", "name": "Zengfeng Huang"}, {"authorId": "2152822047", "name": "Weijian Sun"}, {"authorId": "1409702669", "name": "Qi Zhang"}, {"authorId": "1790227", "name": "Xuanjing Huang"}], "abstract": "Existing research for question generation encodes the input text as a sequence of tokens without explicitly modeling fact information. These models tend to generate irrelevant and uninformative questions. In this paper, we explore to incorporate facts in the text for question generation in a comprehensive way. We present a novel task of question generation given a query path in the knowledge graph constructed from the input text. We divide the task into two steps, namely, query representation learning and query-based question generation. We formulate query representation learning as a sequence labeling problem for identifying the involved facts to form a query and employ an RNN-based generator for question generation. We first train the two modules jointly in an end-to-end fashion, and further enforce the interaction between these two modules in a variational framework. We construct the experimental datasets on top of SQuAD and results show that our model outperforms other state-of-the-art approaches, and the performance margin is larger when target questions are complex. Human evaluation also proves that our model is able to generate relevant and informative questions.", "corpusId": "226262318", "paragraphs": [{"paragraphId": "32105", "title": "PathQG: Neural Question Generation from Facts", "sectionTitle": "Introduction", "text": "Question Generation (QG) from text aims to automatically construct questions from textual input (Heilman and Smith, 2010). It receives increasing attentions from research communities recently, due to its broad applications in scenarios of dialogue system and educational reading comprehension (Piwek et al., 2007;. It can also help to augment the question set to enhance the performance of question answering systems. Current QG systems mainly follow the sequenceto-sequence structure with an encoder for modeling the textual input and a decoder for text generation (Du et al., 2017). These neural-based models have shown promising performance, however, they suffer from generating irrelevant and uninformative questions. Figure 1a presents two sample questions generated by a nueral QG model. Q2 contains irrelevant information \"Everton Fc\". Although Q1 is correct, it is a safe play without mentioning any specific information in the input text. One possible reason causing the problem is that current sequenceto-sequence models learn a latent representation for the input text without explicitly modeling semantic information included. We therefore argue that modeling facts in the input text can help to alleviate the problem of existing neural QG models.", "spans": "[{\"corpusId\": 1809816, \"span\": \"(Heilman and Smith, 2010)\", \"start\": 96, \"end\": 121}, {\"corpusId\": 571356, \"span\": \"(Piwek et al., 2007;\", \"start\": 293, \"end\": 313}, {\"corpusId\": 2172129, \"span\": \"(Du et al., 2017)\", \"start\": 566, \"end\": 583}]", "conference": "emnlp", "year": 2020, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "32106", "title": "PathQG: Neural Question Generation from Facts", "sectionTitle": "Introduction", "text": "Some researchers explore to incorporate the answer entity  or a so called question worthy phrase (Wang et al., 2019) as the fact to guide the generation of target question and make some progresses. However, a complex question usually involves multiple facts. Therefore, a single word piece or phrase is not able to provide enough information for the generation. In this paper, we propose to represent facts in the input text as a knowledge graph (KG) and present a novel task of generating a question given a query path from the KG. More specifically, a KG contains a set of fact triples, and a query path is an ordered sequence of triples in the KG. A fact triple consists of two entities and their relationship. Figure 1b shows the KG of the input text in Figure 1a and it includes two query paths. We can see that not all facts in a query path are mentioned in a specific target question (see Path 2 and GTQ2). Therefore, the model needs to extract the involved facts to form a query before it generates a question. Intuitively, we divide the task of question generation from a query path into two steps, namely, query representation learning and query-based question generation. We formulate the former step as a sequence labeling problem for identifying the involved facts to form a query. For query-based question generation, an RNN-based generator is used to generate the question word by word. We first train the two modules jointly in an end-to-end fashion (PathQG in Section 3). In order to further enforce the interaction between theses two modules, we employ a variational framework to train the two modules (Chen et al., 2018; that treats query representation learning as an inference process from the query path taking the generated question as the target (PathQG-V in Section 4).", "spans": "[{\"corpusId\": 59215159, \"span\": \"(Wang et al., 2019)\", \"start\": 97, \"end\": 116}, {\"corpusId\": 226262318, \"span\": \"this paper\", \"start\": 375, \"end\": 375}, {\"corpusId\": 226262318, \"span\": \"we propose\", \"start\": 387, \"end\": 387}, {\"corpusId\": 4669223, \"span\": \"(Chen et al., 2018;\", \"start\": 1620, \"end\": 1639}]", "conference": "emnlp", "year": 2020, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "32107", "title": "PathQG: Neural Question Generation from Facts", "sectionTitle": "Automatic Evaluation Results", "text": "For the automatic evaluation, we utlize some widely adopted metrics including BLEU 1-4 (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005) and ROUGE L (Lin and Hovy, 2003). Besides, we also compare results in the semantic content level by using a metric named SPICE (Anderson et al., 2016). It evaluates the similarity of scene graphs generated from candidate and reference questions. Evaluation results on both whole and complex datasets are shown in the Table 2 and 3. We have several findings:", "spans": "[{\"corpusId\": 11080756, \"span\": \"(Papineni et al., 2002)\", \"start\": 87, \"end\": 110}, {\"corpusId\": 7164502, \"span\": \"(Banerjee and Lavie, 2005)\", \"start\": 119, \"end\": 145}, {\"corpusId\": 16292125, \"span\": \"(Lin and Hovy, 2003)\", \"start\": 158, \"end\": 178}, {\"corpusId\": 11933981, \"span\": \"(Anderson et al., 2016)\", \"start\": 273, \"end\": 296}]", "conference": "emnlp", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "32108", "title": "PathQG: Neural Question Generation from Facts", "sectionTitle": "Related Work", "text": "Question Generation, aiming at generating questions from a range of inputs, such as raw text (Heilman and Smith, 2010), structured data (Serban et al., 2016) and images (Mostafazadeh et al., 2016;Fan et al., 2018a,b), has attracted increasing attention in recent years. Most previous studies on textual question generation are rule-based and transform a declarative sentence into an interrogative sentence according to hand-crafted patterns (Heilman and Smith, 2010;Heilman, 2011). With the advance of neural network, Du et al. (2017) propose to apply a seq2seq structure with attention for automatic question generation. As follow-up, ; Sun et al. (2018); Kim et al. (2019) propose to utilize the answers to decrease the generation uncertainty. Meanwhile,  and Li et al. (2019) explore to use answer-relevant context to guide question generation. Besides, some studies (Wang et al., 2017;Wang et al., 2019) take question generation as a subtask, and jointly learn it with other tasks, such as question answering and phrase extraction, which also help to alleviate the uncertainty and improve the generation performance.", "spans": "[{\"corpusId\": 1809816, \"span\": \"(Heilman and Smith, 2010;\", \"start\": 441, \"end\": 466}, {\"corpusId\": 2172129, \"span\": \"Du et al. (2017)\", \"start\": 518, \"end\": 534}, {\"corpusId\": 53083677, \"span\": \"Sun et al. (2018)\", \"start\": 638, \"end\": 655}, {\"corpusId\": 52176706, \"span\": \"Kim et al. (2019)\", \"start\": 657, \"end\": 674}, {\"corpusId\": 59215159, \"span\": \"Wang et al., 2019)\", \"start\": 889, \"end\": 907}]", "conference": "emnlp", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "32109", "title": "PathQG: Neural Question Generation from Facts", "sectionTitle": "Related Work", "text": "Another stream of research for question generation is from KG to question. Reddy et al. (2017); Elsahar et al. (2018) explore to generate questions from a single KG triple using text as context information. It is close to our setting, but we are different in two aspects. First, we propose to form a query path consisting of multiple triples for question generation instead of a single triple. Second, the context we process is where the extracted triples from. This setting is more natural and different from using retrieved text as context as they did.", "spans": "[{\"corpusId\": 8946168, \"span\": \"Reddy et al. (2017)\", \"start\": 75, \"end\": 94}, {\"corpusId\": 3444808, \"span\": \"Elsahar et al. (2018)\", \"start\": 96, \"end\": 117}, {\"corpusId\": 226262318, \"span\": \"we propose\", \"start\": 289, \"end\": 289}]", "conference": "emnlp", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 5}
{"paperId": "43b0f0d2abcafabb31222a6b5b44a085019057b5", "title": "Diverse Distributions of Self-Supervised Tasks for Meta-Learning in NLP", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2021, "citationCount": 21, "openAccessPdf": {"url": "https://aclanthology.org/2021.emnlp-main.469.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2111.01322, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2021-11-02", "authors": [{"authorId": "1858169", "name": "Trapit Bansal"}, {"authorId": "2007819739", "name": "K. Gunasekaran"}, {"authorId": "2116679419", "name": "Tong Wang"}, {"authorId": "2227827", "name": "Tsendsuren Munkhdalai"}, {"authorId": "143753639", "name": "A. McCallum"}], "abstract": "Meta-learning considers the problem of learning an efficient learning process that can leverage its past experience to accurately solve new tasks. However, the efficacy of meta-learning crucially depends on the distribution of tasks available for training, and this is often assumed to be known a priori or constructed from limited supervised datasets. In this work, we aim to provide task distributions for meta-learning by considering self-supervised tasks automatically proposed from unlabeled text, to enable large-scale meta-learning in NLP. We design multiple distributions of self-supervised tasks by considering important aspects of task diversity, difficulty, type, domain, and curriculum, and investigate how they affect meta-learning performance. Our analysis shows that all these factors meaningfully alter the task distribution, some inducing significant improvements in downstream few-shot accuracy of the meta-learned models. Empirically, results on 20 downstream tasks show significant improvements in few-shot learning \u2013 adding up to +4.2% absolute accuracy (on average) to the previous unsupervised meta-learning method, and perform comparably to supervised methods on the FewRel 2.0 benchmark.", "corpusId": "240419611", "paragraphs": [{"paragraphId": "70321", "title": "Diverse Distributions of Self-Supervised Tasks for Meta-Learning in NLP", "sectionTitle": "Introduction", "text": "In the supervised setting, in particular, metalearning task distribution is often defined by subsampling from the classes in a classification problem over a fixed dataset (Vinyals et al., 2016). This not only limits the applicability of meta-learning to the underlying classification problem, but also requires a diverse set of supervised datasets with a large number of classes to enable learning. Selfsupervised meta-learning, on the other hand, seeks to propose tasks from unlabelled data Bansal et al., 2020b), and has great potential to enable numerous important applications (Hospedales et al., 2020) such as neural architecture search, continual learning, hyper-parameter optimization, learning in low-resource settings, etc. Existing work in meta-learning for NLP, however, defaults to task distributions that tend to be overly simplistic, e.g. using existing supervised datasets (Han et al., 2018;Dou et al., 2019; or unsupervised cloze-style tasks with uniform selection of words from the vocabulary (Bansal et al., 2020b). Given the lack of exploration on this critical component, we propose to devise and evaluate various task distributions in the context of unsupervised meta-learning for NLP.", "spans": "[{\"corpusId\": 8909022, \"span\": \"(Vinyals et al., 2016)\", \"start\": 171, \"end\": 193}, {\"corpusId\": 221761685, \"span\": \"Bansal et al., 2020b)\", \"start\": 492, \"end\": 513}, {\"corpusId\": 53080736, \"span\": \"(Han et al., 2018;\", \"start\": 888, \"end\": 906}, {\"corpusId\": 201652627, \"span\": \"Dou et al., 2019;\", \"start\": 906, \"end\": 923}, {\"corpusId\": 221761685, \"span\": \"(Bansal et al., 2020b)\", \"start\": 1010, \"end\": 1032}, {\"corpusId\": 240419611, \"span\": \"we propose\", \"start\": 1102, \"end\": 1102}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "70322", "title": "Diverse Distributions of Self-Supervised Tasks for Meta-Learning in NLP", "sectionTitle": "Experiments", "text": "Our proposed approach shows significant improvements over previous few-shot classification results (Bansal et al., 2020b;Gao et al., 2019).", "spans": "[{\"corpusId\": 240419611, \"span\": \"Our proposed approach\", \"start\": 21, \"end\": 21}, {\"corpusId\": 221761685, \"span\": \"(Bansal et al., 2020b;\", \"start\": 99, \"end\": 121}, {\"corpusId\": 202789603, \"span\": \"Gao et al., 2019)\", \"start\": 121, \"end\": 138}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "70323", "title": "Diverse Distributions of Self-Supervised Tasks for Meta-Learning in NLP", "sectionTitle": "Meta-learning Model", "text": "We use the same model as in Bansal et al. (2020b) for our results to be comparable 1 . The model is a BERT transformer encoder coupled with a parameter generator, a 2layer MLP, that generates the initial point for classification layer for a task conditioned on the support examples. The model is meta-trained using the MAML algorithm (Finn et al., 2017), with learned per-layer learning rates, on the self-supervised task distributions. All model hyper-parameters are kept the same so that any change in performance can be attributed to differences in the task distribution. See Supplementary for all hyper-parameters.", "spans": "[{\"corpusId\": 221761685, \"span\": \"Bansal et al. (2020b)\", \"start\": 28, \"end\": 49}, {\"corpusId\": 240419611, \"span\": \"our results\", \"start\": 65, \"end\": 65}, {\"corpusId\": 6719686, \"span\": \"(Finn et al., 2017)\", \"start\": 334, \"end\": 353}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "70324", "title": "Diverse Distributions of Self-Supervised Tasks for Meta-Learning in NLP", "sectionTitle": "Methods Evaluated", "text": "We consider all the different approaches to self-supervised task distributions described in Sec 3 and the baseline approach of SMLMT: (1) Uniform: this is the SMLMT approach of Bansal et al. (2020b) which use uniform random sampling over word-types; (2) Frequency: SMLMT with a sampling proportional to log-frequency (see 3.1); (3) Cluster: SMLMT where labels are picked from same word cluster (see 3.1); (4) Dynamic: curriculum-based task sampling with Cluster as the static distribution (see 3.2); (5) Cluster-ccnet: same as Cluster but using ccnet (Wenzek et al., 2020) as the corpora, which consists of web crawled data; (6) SentCluster: alternative to SMLMT which proposes tasks from subsets of sentence clustering (see 3.3); (7) SentPair: the sentence-pair tasks (see 3.4). All methods, except SentCluster and Cluster-ccnet, have Wikipedia as the text corpora. The sentence embeddings for SentCluster task distribution were obtained from Du et al. (2020), and consist of embeddings of about 1 billion sentences from ccnet (Wenzek et al., 2020). For this reason, we also report Cluster-ccnet that uses this same set of sentences. We found it beneficial to include 25% Frequency tasks in the Cluster task distribution and SentPair tasks are included in all other task distributions unless otherwise noted. Note that we only consider completely unsupervised meta-learning methods for fair evaluation. However our results improve over Bansal et al. (2020b) which showed improvements over BERT and multi-task BERT baselines. As we utilize the same dataset splits released in their work, our results can be directly compared.", "spans": "[{\"corpusId\": 221761685, \"span\": \"Bansal et al. (2020b)\", \"start\": 177, \"end\": 198}, {\"corpusId\": 207870323, \"span\": \"(Wenzek et al., 2020)\", \"start\": 551, \"end\": 572}, {\"corpusId\": 207870323, \"span\": \"(Wenzek et al., 2020)\", \"start\": 1028, \"end\": 1049}, {\"corpusId\": 240419611, \"span\": \"our results\", \"start\": 1423, \"end\": 1423}, {\"corpusId\": 221761685, \"span\": \"Bansal et al. (2020b)\", \"start\": 1437, \"end\": 1458}, {\"corpusId\": 240419611, \"span\": \"our results\", \"start\": 1599, \"end\": 1599}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "70325", "title": "Diverse Distributions of Self-Supervised Tasks for Meta-Learning in NLP", "sectionTitle": "Evaluation on diverse downstream classification tasks", "text": "(3) Entity typing: CoNLL-2003 (Sang and De Meulder, 2003) entity mention classification into 4 coarse types, MIT-Restaurant (Liu et al., 2013) task on classifying mentions in user queries about restaurants into 8 types; (4) Sentence-pair classification: Scitail, a scientific natural language inference dataset (Khot et al., 2018), RTE task on textual entailment and MRPC task on paraphrase classification from the GLUE benchmark . (5) Other text classification: multiple social-media datasets on classifying tweets into (a) 2-way: political audience, bias or mention of a disaster, (b) 9-way: classifying based on political message, (c) 13-way: classifying emotion.", "spans": "[{\"corpusId\": 2470716, \"span\": \"(Sang and De Meulder, 2003)\", \"start\": 30, \"end\": 57}, {\"corpusId\": 14903208, \"span\": \"(Liu et al., 2013)\", \"start\": 124, \"end\": 142}, {\"corpusId\": 24462950, \"span\": \"(Khot et al., 2018)\", \"start\": 311, \"end\": 330}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "70326", "title": "Diverse Distributions of Self-Supervised Tasks for Meta-Learning in NLP", "sectionTitle": "Evaluation on FewRel 2.0 benchmark", "text": "FewRel (Han et al., 2018;Gao et al., 2019) is a common benchmark for few-shot learning in NLP, which consists of many few-shot relation classification tasks created by sub-sampling from a pool of relation labels. The resemblance to the popular few-shot benchmarks like MiniImageNet (Vinyals et al., 2016) makes FewRel one of the few widely used datasets for training and evaluating NLP metalearning methods. Before submitting to the competition site for test set results, we first use the validation set to select the best model(s), where we observed that the Cluster approaches performs better than the other task proposals (see validation results in Supplementary).  ", "spans": "[{\"corpusId\": 53080736, \"span\": \"(Han et al., 2018;\", \"start\": 7, \"end\": 25}, {\"corpusId\": 202789603, \"span\": \"Gao et al., 2019)\", \"start\": 25, \"end\": 42}, {\"corpusId\": 8909022, \"span\": \"(Vinyals et al., 2016)\", \"start\": 282, \"end\": 304}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "70327", "title": "Diverse Distributions of Self-Supervised Tasks for Meta-Learning in NLP", "sectionTitle": "Related Work", "text": "Meta-learning applications in NLP have yielded improvements on specific tasks (Gu et al., 2018;Han et al., 2018;Dou et al., 2019). Unsupervised meta-learning has been explored in computer vision Khodadadeh et al., 2019) and reinforcement learning (Gupta et al., 2018).  cluster images using pre-trained embeddings to create tasks. Metz et al. (2019) meta-learn an unsupervised update rule in a semisupervised framework. Bansal et al. (2020b) developed the SMLMT approach to unsupervised meta-learning in NLP. Contemporary work (Murty et al., 2021) explored the use of clustering, though focused only on natural language inference tasks. Curriculum learning (Bengio et al., 2009) in the context of meta-learning has been unexplored in NLP, prior to this work. Jabri et al. (2019) found unsupervised curriculum to be beneficial for metareinforcement learning. We refer to Hospedales et al. (2020) for a comprehensive review of metalearning. Self-supervised learning has emerged as an efficient approach to representation learning in NLP (Howard and Ruder, 2018;Peters et al., 2018;Devlin et al., 2018;Radford et al., 2019;Yang et al., 2019). Multi-task learning of pre-trained models has shown improved results on many tasks (Phang et al., 2018;Liu et al., 2019a), including few-shot setting. Yin et al. (2020) leveraged entailment tasks for few-shot learning. Du et al. (2020) developed self-training methods for semi-supervised few-shot learning. Recently, extremely large language models have been shown to have few-shot capacities (Brown et al., 2020), while Schick and Sch\u00fctze (2020) demonstrated few-shot capacities for small models in the semi-supervised setting. Meanwhile, Bansal et al. (2020a,b) showed meta-learning to be effective at improving few-shot performance in multi-task and unsupervised settings, as well as improving performance for small models.", "spans": "[{\"corpusId\": 53080736, \"span\": \"Han et al., 2018;\", \"start\": 95, \"end\": 112}, {\"corpusId\": 201652627, \"span\": \"Dou et al., 2019)\", \"start\": 112, \"end\": 129}, {\"corpusId\": 4554680, \"span\": \"Metz et al. (2019)\", \"start\": 331, \"end\": 349}, {\"corpusId\": 221761685, \"span\": \"Bansal et al. (2020b)\", \"start\": 420, \"end\": 441}, {\"corpusId\": 233393629, \"span\": \"(Murty et al., 2021)\", \"start\": 527, \"end\": 547}, {\"corpusId\": 873046, \"span\": \"(Bengio et al., 2009)\", \"start\": 657, \"end\": 678}, {\"corpusId\": 240419611, \"span\": \"this work\", \"start\": 757, \"end\": 757}, {\"corpusId\": 202788946, \"span\": \"Jabri et al. (2019)\", \"start\": 759, \"end\": 778}, {\"corpusId\": 40100965, \"span\": \"(Howard and Ruder, 2018;\", \"start\": 1035, \"end\": 1059}, {\"corpusId\": 3626819, \"span\": \"Peters et al., 2018;\", \"start\": 1059, \"end\": 1079}, {\"corpusId\": 160025533, \"span\": \"Radford et al., 2019;\", \"start\": 1099, \"end\": 1120}, {\"corpusId\": 195069387, \"span\": \"Yang et al., 2019)\", \"start\": 1120, \"end\": 1138}, {\"corpusId\": 222142136, \"span\": \"Yin et al. (2020)\", \"start\": 1291, \"end\": 1308}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 13}], "paragraphCount": 7}
{"paperId": "60c713cf96246f6b8bbce6d1b713a8f76196cf58", "title": "Online Learning Meets Machine Translation Evaluation: Finding the Best Systems with the Least Human Effort", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2021, "citationCount": 7, "openAccessPdf": {"url": "https://aclanthology.org/2021.acl-long.242.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2105.13385, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2021-05-27", "authors": [{"authorId": "2106387095", "name": "Vania Mendoncca"}, {"authorId": "15631652", "name": "Ricardo Rei"}, {"authorId": "1771718", "name": "Lu\u00edsa Coheur"}, {"authorId": "3233831", "name": "Alberto Sardinha"}, {"authorId": "2106387251", "name": "Ana L'ucia Santos INESC-ID Lisboa"}, {"authorId": "103016698", "name": "Instituto Superior T'ecnico"}, {"authorId": "2106387394", "name": "AI Unbabel"}, {"authorId": "103083101", "name": "C. D. L. D. U. D. Lisboa"}, {"authorId": "102247492", "name": "Faculdade de Ciencias da Universidade de Lisboa"}], "abstract": "In Machine Translation, assessing the quality of a large amount of automatic translations can be challenging. Automatic metrics are not reliable when it comes to high performing systems. In addition, resorting to human evaluators can be expensive, especially when evaluating multiple systems. To overcome the latter challenge, we propose a novel application of online learning that, given an ensemble of Machine Translation systems, dynamically converges to the best systems, by taking advantage of the human feedback available. Our experiments on WMT\u201919 datasets show that our online approach quickly converges to the top-3 ranked systems for the language pairs considered, despite the lack of human feedback for many translations.", "corpusId": "235248256", "paragraphs": [{"paragraphId": "6479", "title": "Online Learning Meets Machine Translation Evaluation: Finding the Best Systems with the Least Human Effort", "sectionTitle": "Introduction", "text": "In Machine Translation (MT), measuring the quality of a large amount of automatic translations can be a challenge. Automatic metrics like BLEU (Papineni et al., 2002) remain popular due to their fast and free computations. Yet, in the last few years we have seen that, as MT quality improves, automatic metrics become less reliable (Ma et al., 2019;Mathur et al., 2020). For example, in the Conference on Machine Translation (WMT)'19 News Translation shared task, the winning system according to human annotators was not even in the top-5 according to BLEU (Barrault et al., 2019). On the other hand, using human assessments can be expensive, especially when evaluating multiple systems. In a real world scenario, given an arbitrary number of MT systems, one would need to evaluate them individually to find the best systems for a given language pair. However, that requires a considerable effort and there may not be enough human annotators to evaluate all the systems' translations. For instance, in the aforementioned WMT'19 shared task, many translations from the competing systems did not receive any human assessment.", "spans": "[{\"corpusId\": 11080756, \"span\": \"(Papineni et al., 2002)\", \"start\": 143, \"end\": 166}, {\"corpusId\": 201742578, \"span\": \"(Ma et al., 2019;\", \"start\": 332, \"end\": 349}, {\"corpusId\": 219573654, \"span\": \"Mathur et al., 2020)\", \"start\": 349, \"end\": 369}]", "conference": "acl", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "6480", "title": "Online Learning Meets Machine Translation Evaluation: Finding the Best Systems with the Least Human Effort", "sectionTitle": "Online learning for Machine Translation", "text": "There has been a number of online learning approaches applied to MT in the past, mainly in Interactive MT and/or post-editing MT systems. However, most approaches aim at learning the parameters or feature weights of an MT model (Mathur et al., 2013;Denkowski et al., 2014;Ortiz-Mart\u00ednez, 2016;Sokolov et al., 2016;Nguyen et al., 2017;Lam et al., 2018) or fine-tuning a pretrained model for domain adaptation (Turchi et al., 2017;Karimova et al., 2018;Peris and Casacuberta, 2019). Even in cases where the MT model is composed of several sub-models (e.g., Ortiz-Mart\u00ednez (2016)), the goal is to online learn each sub-model's specific parameters (while our learning goal is the weights of each system in an ensemble). Another key difference between these approaches and ours is that most of them use human post-edited translations as a source of feedback. The exceptions to this are the systems competing for WMT'17 shared task on online bandit learning for MT (Sokolov et al., 2017), as well as Lam et al. (2018), who use (simulated) quality judgments. The most similar proposal to ours is that of Naradowsky et al. (2020), who ensemble different MT systems and dynamically select the best one for a given MT task or domain using stochastic multiarmed bandits and contextual bandits. The bandit algorithms learn from feedback simulated using a sentence-level BLEU score between the selected automatic translation and a reference translation.", "spans": "[{\"corpusId\": 6640780, \"span\": \"(Mathur et al., 2013;\", \"start\": 228, \"end\": 249}, {\"corpusId\": 18106982, \"span\": \"Ortiz-Mart\\u00ednez, 2016;\", \"start\": 272, \"end\": 293}, {\"corpusId\": 1144118, \"span\": \"Sokolov et al., 2016;\", \"start\": 293, \"end\": 314}, {\"corpusId\": 215824512, \"span\": \"Nguyen et al., 2017;\", \"start\": 314, \"end\": 334}, {\"corpusId\": 49235047, \"span\": \"(Turchi et al., 2017;\", \"start\": 408, \"end\": 429}, {\"corpusId\": 3609576, \"span\": \"Peris and Casacuberta, 2019)\", \"start\": 451, \"end\": 479}, {\"corpusId\": 1687938, \"span\": \"(Sokolov et al., 2017)\", \"start\": 959, \"end\": 981}, {\"corpusId\": 211259268, \"span\": \"Naradowsky et al. (2020)\", \"start\": 1097, \"end\": 1121}]", "conference": "acl", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 8}], "paragraphCount": 2}
{"paperId": "2f918e0232d3b7c2cabecaaa7edc976e068ce0c6", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "venue": "International Conference on Human Factors in Computing Systems", "year": 2023, "citationCount": 22, "openAccessPdf": {"url": "https://arxiv.org/pdf/2302.09540", "status": "GREEN", "license": null, "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2302.09540, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2023-02-19", "authors": [{"authorId": "20985588", "name": "Orestis Papakyriakopoulos"}, {"authorId": "66181683", "name": "Severin Engelmann"}, {"authorId": "2143255336", "name": "Amy Winecoff"}], "abstract": "A significant share of political discourse occurs online on social media platforms. Policymakers and researchers try to understand the role of social media design in shaping the quality of political discourse around the globe. In the past decades, scholarship on political discourse theory has produced distinct characteristics of different types of prominent political rhetoric such as deliberative, civic, or demagogic discourse. This study investigates the relationship between social media reaction mechanisms (i.e., upvotes, downvotes) and political rhetoric in user discussions by engaging in an in-depth conceptual analysis of political discourse theory. First, we analyze 155 million user comments in 55 political subforums on Reddit between 2010 and 2018 to explore whether users\u2019 style of political discussion aligns with the essential components of deliberative, civic, and demagogic discourse. Second, we perform a quantitative study that combines confirmatory factor analysis with difference in differences models to explore whether different reaction mechanism schemes (e.g., upvotes only, upvotes and downvotes, no reaction mechanisms) correspond with political user discussion that is more or less characteristic of deliberative, civic, or demagogic discourse. We produce three main takeaways. First, despite being \u201cideal constructs of political rhetoric,\u201d we find that political discourse theories describe political discussions on Reddit to a large extent. Second, we find that discussions in subforums with only upvotes, or both up- and downvotes are associated with user discourse that is more deliberate and civic. Third, and perhaps most strikingly, social media discussions are most demagogic in subreddits with no reaction mechanisms at all. These findings offer valuable contributions for ongoing policy discussions on the relationship between social media interface design and respectful political discussion among users.1", "corpusId": "257039050", "paragraphs": [{"paragraphId": "76126", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "INTRODUCTION", "text": "Political exchange among citizens occurs largely on social media platforms. Platforms have become the \"de facto public sphere\" [121] to discuss political topics [113], perform political campaigning [73], and communicate important messages for the pursuit of social causes and protests [67]. However, they have also become common places for users to engage in hateful [86] and low-credibility political rhetoric [124]. Social media platforms are not simply digital representations of offline political activity. They are key spaces for articulation, organization, and implementation of political action [27]. Indeed, they are not intermediaries of communication processes, but function as their curators [51]. When billions of people interact in a common space, a platform's design has enormous power over the production, mediation, and dissemination of user discussions. A platform's choice of communication reaction mechanisms (i.e., \"likes,\" \"upvotes/downvotes\" etc.) and its recommendation algorithms critically influence the nature of user interactions on the platform. On the one hand, such reaction mechanisms -as means of evaluation -condition what type of information users produce, and, on the other hand, recommendation algorithms determine what information users will come to interact with [23,76,90,93].", "spans": "[{\"corpusId\": 148690057, \"span\": \"[73]\", \"start\": 198, \"end\": 202}, {\"corpusId\": 54458291, \"span\": \"[86]\", \"start\": 367, \"end\": 371}, {\"corpusId\": 4549072, \"span\": \"[124]\", \"start\": 411, \"end\": 416}, {\"corpusId\": 236347485, \"span\": \"[27]\", \"start\": 602, \"end\": 606}, {\"corpusId\": 205230357, \"span\": \"[23,\", \"start\": 1301, \"end\": 1305}, {\"corpusId\": 206637477, \"span\": \"76,\", \"start\": 1305, \"end\": 1308}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": false, "refCount": 6}, {"paragraphId": "76127", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "INTRODUCTION", "text": "Prior research studies illustrate that social media platforms have transformative effects on political communication, albeit intense debates about whether and how design features influence the quality of discourse among users [11,13,84,119,120]. Scholarship on political rhetoric has proposed a vast set of rhetoric devices that are essential to the corresponding modes of political discourse [9,44,68,75,91].", "spans": "[{\"corpusId\": 52112071, \"span\": \"[11,\", \"start\": 226, \"end\": 230}, {\"corpusId\": 1345712, \"span\": \"13,\", \"start\": 230, \"end\": 233}, {\"corpusId\": 149417622, \"span\": \"120]\", \"start\": 240, \"end\": 244}, {\"corpusId\": 158478247, \"span\": \"[9,\", \"start\": 393, \"end\": 396}, {\"corpusId\": 147799675, \"span\": \"44,\", \"start\": 396, \"end\": 399}, {\"corpusId\": 212817336, \"span\": \"68,\", \"start\": 399, \"end\": 402}, {\"corpusId\": 143594879, \"span\": \"91]\", \"start\": 405, \"end\": 408}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": false, "refCount": 7}, {"paragraphId": "76128", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "INTRODUCTION", "text": "In this research, we first explore to what extent essential components of political discourse theories characterize political discussions on Reddit. Second, we study how specific digital reaction mechanisms on platforms (such as liking, voting, retweeting) that navigate user feedback on content [38] and optimize platforms' recommendation systems [33,117] impact the prevalence of specific types of political discourse [58]. To this end, we analyze an extensive dataset of political discussions on Reddit against the theoretical framework of three prominent political discourse theories: deliberative, civic, and demagogic discourse. Finally, we answer the following research questions.", "spans": "[{\"corpusId\": 257039050, \"span\": \"this research\", \"start\": 16, \"end\": 16}, {\"corpusId\": 1198566, \"span\": \"[38]\", \"start\": 296, \"end\": 300}, {\"corpusId\": 207240067, \"span\": \"[33,\", \"start\": 348, \"end\": 352}, {\"corpusId\": 3031274, \"span\": \"[58]\", \"start\": 420, \"end\": 424}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "76129", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "BACKGROUND & RELATED WORK 2.1 Understanding political discourse theories", "text": "Political theorists and scientists develop analytic frames to understand how people speak when they discuss topics of political relevance [20,35,62,89]. In the last century, this line of scholarship has advanced prominent conceptions of political rhetoric, including the ones we study in this work (civic, deliberative, demagogic rhetoric). Deliberative discourse requires the giving and receiving of reasons when discussing propositions [20]. In contrast, the rhetoric elements of civic discourse are less constrained by rationalization [12]. Demagogic speech tends to oversimplify complex societal issues [78]. We provide an in-depth discussion of these three discourse theories in Section 3.", "spans": "[{\"corpusId\": 145281078, \"span\": \"[20,\", \"start\": 138, \"end\": 142}, {\"corpusId\": 154333605, \"span\": \"62,\", \"start\": 145, \"end\": 148}, {\"corpusId\": 144101389, \"span\": \"89]\", \"start\": 148, \"end\": 151}, {\"corpusId\": 257039050, \"span\": \"this work\", \"start\": 297, \"end\": 297}, {\"corpusId\": 145281078, \"span\": \"[20]\", \"start\": 438, \"end\": 442}, {\"corpusId\": 150692156, \"span\": \"[12]\", \"start\": 538, \"end\": 542}, {\"corpusId\": 158787326, \"span\": \"[78]\", \"start\": 607, \"end\": 611}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "76130", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "Political discourse & social media", "text": "Our study builds on and significantly extends research studies that have performed first steps towards understanding social media users' political rhetoric. For example, using quantitative interviewing, Semaan et al. [108] investigated whether social media users' interactions could be characterized by deliberative and civic agency. They described deliberation as the presence of reasoned and respectful discussions and civic agency as the ability to interact and participate in the public sphere. Both Friess et al. [48] and Wright et al. [127] developed coding schemes for labeling user content as deliberative based on features such as rationality and constructiveness. Guimaraes et al. [55] formulated the conversational archetypes \"harmony\", \"discrepancy\", \"disruption\", and \"dispute\" to describe online political discourse. Lee et al. [77] connected user behavior on social media such as debating, posting or forwarding news, to features of civic engagement. Connecting online and offline behavior, Hampton et al. [59] investigated the association of social media usage with the level of offline deliberation, which they defined as the propensity to discuss political issues with others. Evidently, prior research that investigates political rhetoric on social media has only used basic conceptualizations of political discourse theories. We see this as an opportunity to perform a more in-depth engagement with scholarship on deliberative, civic, and demagogic discourse theories to understand the extent to which their essential components map to political discussions on Reddit.", "spans": "[{\"corpusId\": 257039050, \"span\": \"Our study\", \"start\": 9, \"end\": 9}, {\"corpusId\": 30243235, \"span\": \"[108]\", \"start\": 217, \"end\": 222}, {\"corpusId\": 226333944, \"span\": \"[48]\", \"start\": 518, \"end\": 522}, {\"corpusId\": 2115237, \"span\": \"[127]\", \"start\": 541, \"end\": 546}, {\"corpusId\": 189818438, \"span\": \"[55]\", \"start\": 691, \"end\": 695}, {\"corpusId\": 778344, \"span\": \"[77]\", \"start\": 842, \"end\": 846}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "76131", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "Platform design and content structure.", "text": "level of deliberation. Furthermore, Arag\u00f3n et al. [7] showed that changing a linear to a hierarchical interface design increased social reciprocity on Men\u00e9ame, a popular Spanish social news platform. In their study, Wijenayake et al. [125] manipulated user interactivity and response visibility in an online environment and found that these variables influence the level of conformity of users. Seering et al. found that presenting CAPTCHAs with positive stimuli to users leads them to externalize more positivity of tone and analytical complexity in their arguments [107]. Liang et al. [79] found that the maximum depth of a Reddit thread, and consequently of the respective discussions, was positively related to its rating (difference between up-to downvotes). In addition, Gilbert et al. [50] showed that users' tendency to focus on submissions that have higher rating on the platform resulted in an incidental \"filtering\" of information that would otherwise be of interest to them.", "spans": "[{\"corpusId\": 7897159, \"span\": \"[7]\", \"start\": 50, \"end\": 53}, {\"corpusId\": 218606784, \"span\": \"[125]\", \"start\": 234, \"end\": 239}, {\"corpusId\": 140227682, \"span\": \"[107]\", \"start\": 567, \"end\": 572}, {\"corpusId\": 13043280, \"span\": \"[79]\", \"start\": 587, \"end\": 591}, {\"corpusId\": 2237151, \"span\": \"[50]\", \"start\": 792, \"end\": 796}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "76132", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "Reaction mechanisms and user behavior.", "text": "Besides design interventions that structure the content in a digital environment, many research studies have shown that reaction mechanisms have an impact on how users behave. Cheng et al. [31] found that a higher number of downvotes across multiple social media platforms resulted in worsening the quality of discourse, while a higher count of positive reactions did not improve discourse significantly. Warut Khern-am-nuai et al. [71] showed that after removing downvoting in a popular public forum, the number of both posts and replies significantly increased. Furthermore they found a decrease in toxicity and an increase in the diversity of replies. Shmargad et al. [109] demonstrated that upvoting incivility incentivized users to generate more toxic content. In a field experiment, Matias et al. [81,88] showed that hiding downvotes increased the percentage of commenters who had not been vocal on political subreddits before. On Twitter, Adelani et al. [1] demonstrated that user feedback expressed as likes and retweets significantly affected topic continuation in discussions. Stroud et al. [114] concluded that the type of feedback that users gave by pressing a button (recommend, like, respect) altered the frequency and the scope of its use (see also [115]). Focusing on Reddit, Graham et al. [53] found that indeed users rarely use the voting reaction mechanisms as community guidelines dictate. Generalizing, Hayes et al. [61] found that users interpreted and applied the same reaction mechanism differently, depending on system, social, and structural factors. Taken together, these studies underline that reaction mechanisms exert significant influence on user discourse in public online spheres.", "spans": "[{\"corpusId\": 7403868, \"span\": \"[31]\", \"start\": 189, \"end\": 193}, {\"corpusId\": 234297356, \"span\": \"[109]\", \"start\": 671, \"end\": 676}, {\"corpusId\": 4809150, \"span\": \"88]\", \"start\": 807, \"end\": 810}, {\"corpusId\": 221400085, \"span\": \"[1]\", \"start\": 961, \"end\": 964}, {\"corpusId\": 7291314, \"span\": \"[114]\", \"start\": 1101, \"end\": 1106}, {\"corpusId\": 239053665, \"span\": \"[53]\", \"start\": 1306, \"end\": 1310}, {\"corpusId\": 53630100, \"span\": \"[61]\", \"start\": 1437, \"end\": 1441}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "76133", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "Reaction mechanisms and recommender systems.", "text": "In addition to the direct impact of reaction mechanisms on social media discourse, reaction mechanism designs may have additional indirect consequences since user reactions are often used as signals in training data for recommendation algorithms, such as those used to order news feeds. Both existing [117] and proposed recommender systems [10,25,30] take different forms of user feedback as input to suggest content, be that likes, retweets, or other actions facilitated by reaction mechanisms. Such feedback does not always represent explicit user preferences about content, but rather is used as a way to overcome training issues of recommender systems. It is also useful for suggesting content that will keep users engaged, regardless of potential \"spill over effects\", i.e., users externalizing further unforeseen behaviors. [3,4,64,133].", "spans": "[{\"corpusId\": 257039050, \"span\": \"proposed recommender system\", \"start\": 338, \"end\": 338}, {\"corpusId\": 3672550, \"span\": \"[10,\", \"start\": 340, \"end\": 344}, {\"corpusId\": 58006104, \"span\": \"25,\", \"start\": 344, \"end\": 347}, {\"corpusId\": 58006258, \"span\": \"30]\", \"start\": 347, \"end\": 350}, {\"corpusId\": 3053204, \"span\": \"[3,\", \"start\": 830, \"end\": 833}, {\"corpusId\": 11925511, \"span\": \"4,\", \"start\": 833, \"end\": 835}, {\"corpusId\": 10537313, \"span\": \"64,\", \"start\": 835, \"end\": 838}, {\"corpusId\": 13754838, \"span\": \"133]\", \"start\": 838, \"end\": 842}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 8}, {"paragraphId": "76134", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "Reaction mechanisms and recommender systems.", "text": "Although user reactions can serve as a proxy, albeit imperfect, for user preferences where ground truth about these preferences is not available, the use of such proxies in training recommendation algorithms can also have undesirable effects. Prior research studies demonstrate that recommender algorithms' suggestions correlate with user radicalization [100], discriminate against users and social groups [56], and replicate political bias in discussions [66,95]. However, only few studies bridge between political discourse theories, design, and engineering [59,83] to produce a better understanding of these phenomena.", "spans": "[{\"corpusId\": 201316434, \"span\": \"[100]\", \"start\": 354, \"end\": 359}, {\"corpusId\": 235624228, \"span\": \"[56]\", \"start\": 406, \"end\": 410}, {\"corpusId\": 239049863, \"span\": \"[66,\", \"start\": 456, \"end\": 460}, {\"corpusId\": 211830167, \"span\": \"95]\", \"start\": 460, \"end\": 463}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "76135", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "Reaction mechanisms as technical features.", "text": "Before we engage in the theoretical discussion on the three political discourse theories, we need to point out the important conceptual distinction between reaction mechanisms as technical features of a platform and platform affordances as relational, community-specific behaviors that result from interacting with reaction mechanisms in a nondeterministic manner [26,45,118]. The technical features of digital artifacts (e.g., the downvoting functionality) are exactly the same to each user. However, different users may perceive and use such technical features differently resulting in the different interaction affordances that a common technical artifact provides to users. The key takeaway from this conceptual distinction is that the technical features of an artifact do not necessarily determine how users relate to and use the artifact. Thus, in our study, we refer to upvoting and downvoting as reaction mechanisms because we do not explore how specific online communities and cultures differ in the perception, use, and interactions with such reaction mechanisms.", "spans": "[{\"corpusId\": 158379198, \"span\": \"[26,\", \"start\": 364, \"end\": 368}, {\"corpusId\": 3107939, \"span\": \"45,\", \"start\": 368, \"end\": 371}, {\"corpusId\": 166406353, \"span\": \"118]\", \"start\": 371, \"end\": 375}, {\"corpusId\": 257039050, \"span\": \"our study\", \"start\": 863, \"end\": 863}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "76136", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "MINIMAL CONCEPTUALIZATION OF POLITICAL DISCOURSE THEORIES", "text": "This study investigates essential rhetoric components of deliberation, civic engagement, and demagoguery. Foreshadowing stark differences, demagoguery oversimplifies complex societal issues [57,101]. Demagoguery's rhetoric polarization lays the groundwork for action-based political mobilization: you are either with \"us\" or with \"them\" [63,78]. Civic engagement interactions are unstructured and characterized by multiple forms of communication and action, with its discourse being frequently characterized as \"messy conversation\" that facilitates participation [35]. Civic engagement interactions aim to be inclusive -a key goal of civic engagement movements [89]. Deliberation, from a Habermasian perspective, requires intersubjective propositional knowledge between conversation members [20]. That is, knowledge-claims must fulfill standards of intersubjectivity: ideally, all discussants are able to relate to the beliefs that underlie a proposition. Propositions must be grounded in logical plausibility, factual correctness, and communal narratives. Discussants' claims must have pragmatic value (i.e, \"propositionality\") in order to support the group's goal of reaching an understanding. Only when everyone can relate to the proposed statements, can deliberative rhetoric help solve a social, civil, or communal issue that is important to the group [62].", "spans": "[{\"corpusId\": 257039050, \"span\": \"This study\", \"start\": 10, \"end\": 10}, {\"corpusId\": 143910059, \"span\": \"[57,\", \"start\": 190, \"end\": 194}, {\"corpusId\": 155071922, \"span\": \"101]\", \"start\": 194, \"end\": 198}, {\"corpusId\": 144400694, \"span\": \"[63,\", \"start\": 337, \"end\": 341}, {\"corpusId\": 158787326, \"span\": \"78]\", \"start\": 341, \"end\": 344}, {\"corpusId\": 144101389, \"span\": \"[89]\", \"start\": 661, \"end\": 665}, {\"corpusId\": 145281078, \"span\": \"[20]\", \"start\": 791, \"end\": 795}, {\"corpusId\": 154333605, \"span\": \"[62]\", \"start\": 1357, \"end\": 1361}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 8}, {"paragraphId": "76137", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "Demagogic discourse", "text": "Demagogic discourse oversimplifies, distorts, or exaggerates complex societal challenges and has little regard for the truthfulness of propositions [57,101]. In offering simple solutions that often entail \"pseudo-reasoning\" [57], demagogic statements are difficult to falsify if not even impervious and unresponsive to opposing arguments [101]. Not only does this impede a constructive exchange of propositions but, for the demagogue, it renders perspectivetaking of opposing positions irrelevant. The oversimplification of complex social phenomena results in a polarization that facilitates political mobilization [78]. Demagogic talk aims to contrast social groups, highlighting apparent identity differences and putting them in competition with each other. It promises to care for the needs of \"ordinary\" people, creating an ethos around the often hateful division into laypeople and experts, elites and the forgotten, or poor and rich [101,102]. The disregard for truthfulness and the evocation of a collective identity based on hate, fear-mongering, and scapegoating means that demagogic rhetoric necessarily contains emotional linguistic components [57]. For example, it typically expresses fear of outsiders and hatred against elites [63,102].", "spans": "[{\"corpusId\": 143910059, \"span\": \"[57,\", \"start\": 148, \"end\": 152}, {\"corpusId\": 155071922, \"span\": \"101]\", \"start\": 152, \"end\": 156}, {\"corpusId\": 143910059, \"span\": \"[57]\", \"start\": 224, \"end\": 228}, {\"corpusId\": 155071922, \"span\": \"[101]\", \"start\": 338, \"end\": 343}, {\"corpusId\": 158787326, \"span\": \"[78]\", \"start\": 615, \"end\": 619}, {\"corpusId\": 155071922, \"span\": \"[101,\", \"start\": 939, \"end\": 944}, {\"corpusId\": 143910059, \"span\": \"[57]\", \"start\": 1155, \"end\": 1159}, {\"corpusId\": 144400694, \"span\": \"[63,\", \"start\": 1241, \"end\": 1245}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "76138", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "Civic discourse", "text": "Civic engagement aims to mobilize people to solve a commonly defined social or political issue. It allows for speech that remains unconstrained by \"overrationalization\" [12,89]. Several authors suggest that civic discourse considers rationality, neutrality, and a lack of emotional talk as hindrances for multiple forms of speech [12,35]. \"Norms of deliberation\" and their associated speaking styles represent social privilege that can have a silencing effect for some participants [131]. However, the relationship between civic engagement and deliberation is not as clear cut. Some perspectives (for example, [2]) claim that civic engagement requires at least some deliberation to enable discussants to work towards a public goal. It needs to connect personal experience with public issues and thus encourages personal anecdotes, storytelling, or brainstorming [89]. While civic engagement does not place priority on how participants formulate an argument and how well supported arguments are by evidence, it would be wrong to assume that the telling of personal experiences by participants does not contain any truthfulness. Indeed, if such personal anecdotes had no epistemic validity in the life of the community, then they could not produce a sense of connection and interrelatedness that is pivotal for civic engagement [40].", "spans": "[{\"corpusId\": 150692156, \"span\": \"[12,\", \"start\": 169, \"end\": 173}, {\"corpusId\": 144101389, \"span\": \"89]\", \"start\": 173, \"end\": 176}, {\"corpusId\": 150692156, \"span\": \"[12,\", \"start\": 330, \"end\": 334}, {\"corpusId\": 31798756, \"span\": \"[131]\", \"start\": 482, \"end\": 487}, {\"corpusId\": 143699829, \"span\": \"[2]\", \"start\": 610, \"end\": 613}, {\"corpusId\": 144101389, \"span\": \"[89]\", \"start\": 862, \"end\": 866}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "76139", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "Deliberative discourse", "text": "Different from demagoguery and civic engagement, deliberation rests on the ideal of reasoning, truth, and truthfulness [20,58,62,131]. Its rhetoric devices consist of logical reasoning and argumentation [58].", "spans": "[{\"corpusId\": 145281078, \"span\": \"[20,\", \"start\": 119, \"end\": 123}, {\"corpusId\": 3031274, \"span\": \"58,\", \"start\": 123, \"end\": 126}, {\"corpusId\": 154333605, \"span\": \"62,\", \"start\": 126, \"end\": 129}, {\"corpusId\": 31798756, \"span\": \"131]\", \"start\": 129, \"end\": 133}, {\"corpusId\": 3031274, \"span\": \"[58]\", \"start\": 203, \"end\": 207}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "76140", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "Deliberative discourse", "text": "While public reasoning does not (and cannot) fulfill the demands of scientific proof, \"(it) should not contradict the claims supported by the best available evidence\" [62]: evidence that is publicly available and comprehensible for citizens. Besides drawing on the best available evidence, deliberative reasoning requires interaction that presupposes motivated participants that are able to provide justifications for their assertions [131]. Deliberative discussions aim to follow a particular structuring order. After rounds of debates, some members of the group may summarize others' claims and hence evaluate the considerations that speak in favor or against the presented propositions [58].", "spans": "[{\"corpusId\": 154333605, \"span\": \"[62]\", \"start\": 167, \"end\": 171}, {\"corpusId\": 31798756, \"span\": \"[131]\", \"start\": 435, \"end\": 440}, {\"corpusId\": 3031274, \"span\": \"[58]\", \"start\": 689, \"end\": 693}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "76141", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "Deliberative discourse", "text": "Deliberative discourse works in the service of accomplishing a public goal that, eventually, should help improve participants' lives. Communicative practices allow for and even encourage criticism of other participants' arguments. However, counter argumentation is only legitimate when it rests on the premises and standards of public reasoning. Otherwise it \"trangresse(s) the limits of civility\" [62]. In deliberative discourse, the ideal of reasoning is intimately connected to the moral principles of respect, equality, and trust [20,85]. Such moral principles are often used to argue that deliberation is inclusive, a claim that has been met with scepticism by some authors [12,131].", "spans": "[{\"corpusId\": 154333605, \"span\": \"[62]\", \"start\": 398, \"end\": 402}, {\"corpusId\": 145281078, \"span\": \"[20,\", \"start\": 534, \"end\": 538}, {\"corpusId\": 144848192, \"span\": \"85]\", \"start\": 538, \"end\": 541}, {\"corpusId\": 150692156, \"span\": \"[12,\", \"start\": 679, \"end\": 683}, {\"corpusId\": 31798756, \"span\": \"131]\", \"start\": 683, \"end\": 687}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "76142", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "Mapping theories to essential components", "text": "Our previous discussion demonstrates some of the conceptual plurality inherent to different political discourse theories. After an in-depth engagement with and critical reading of the literature, and several subsequent rounds of discussion among co-authors, we argue that there is sufficient agreement among scholars on the Deliberative discourse Argument is part of theory (+) Argument is not part of theory (-) fact-related argument [18,20,49,62,85] we vs. them [20] structured argument [18,62,85,103] generalized call for action [62,85,129] counterargument [20,58] who instead of what [20,62] empathy/reciprocity [20,131] emotional language [20,58,62] unsupported argument [20,58,62] Civic discourse Argument is part of theory (+) Argument is not part of theory (-) situational call for action [2,24,35,110] fact-related argument [12,35,89] we vs. them [24,35,82,89] structured argument [12,35,89] counterargument [12,89] generalized call for action [2,35] empathy/reciprocity [12,35,89,131] emotional language [12,35,89,131] collective rhetoric [24,35,89] Demagogic discourse Argument is part of theory (+) Argument is not part of theory (-) you in the epicenter [57,78] fact-related argument [57,101,102] we vs. them [63,102] structured argument [57,101,102] generalized call for action [63,102] empathy/reciprocity [57,78] who instead of what [57] counterargument [101,102] emotional language [57,101] unsupported argument [57,101] collective rhetoric [57,63,102] essential components of each type of political discourse to train a classifier that is able to discriminate among them. Developing the corresponding set of labels was a cyclical rather than a linear process. After critical engagement with the cited literature on the three political discourse theories, two co-authors separately developed codes based on their analysis of the most essential components of each political discourse theory. Then, they compared the created categories and, with the aid of a third co-author, agreed on an initial set of components. Through multiple rounds of discussion, two co-authors assigned the essential components to each of the three discourse theories. This process led to further discussion on the definitional scope of the components. Thus, through multiple rounds of discussion between three co-authors, going back and forth between the choices of essential components and their assignment to the three discourse theories, we finally agreed on thirteen essential components that could be operationalized in a multilabel classification task (see final set of components together with their definitions in Appendix B & Table 5). We document disagreement among co-authors on the definition and assignment of some of the components in Appendix B (see Fact-related argument in Appendix B.3 and Identity Labels in Appendix B.8). Table 1 presents an overview of the essential components and how we assigned them to each political discourse theory for our multilabel classification task.", "spans": "[{\"corpusId\": 15377073, \"span\": \"[18,\", \"start\": 435, \"end\": 439}, {\"corpusId\": 145281078, \"span\": \"20,\", \"start\": 439, \"end\": 442}, {\"corpusId\": 154333605, \"span\": \"62,\", \"start\": 445, \"end\": 448}, {\"corpusId\": 144848192, \"span\": \"85]\", \"start\": 448, \"end\": 451}, {\"corpusId\": 145281078, \"span\": \"[20]\", \"start\": 464, \"end\": 468}, {\"corpusId\": 15377073, \"span\": \"[18,\", \"start\": 489, \"end\": 493}, {\"corpusId\": 154333605, \"span\": \"62,\", \"start\": 493, \"end\": 496}, {\"corpusId\": 144848192, \"span\": \"85,\", \"start\": 496, \"end\": 499}, {\"corpusId\": 17497450, \"span\": \"103]\", \"start\": 499, \"end\": 503}, {\"corpusId\": 154333605, \"span\": \"[62,\", \"start\": 532, \"end\": 536}, {\"corpusId\": 144848192, \"span\": \"85,\", \"start\": 536, \"end\": 539}, {\"corpusId\": 195069387, \"span\": \"129]\", \"start\": 539, \"end\": 543}, {\"corpusId\": 145281078, \"span\": \"[20,\", \"start\": 560, \"end\": 564}, {\"corpusId\": 3031274, \"span\": \"58]\", \"start\": 564, \"end\": 567}, {\"corpusId\": 145281078, \"span\": \"[20,\", \"start\": 588, \"end\": 592}, {\"corpusId\": 154333605, \"span\": \"62]\", \"start\": 592, \"end\": 595}, {\"corpusId\": 145281078, \"span\": \"[20,\", \"start\": 616, \"end\": 620}, {\"corpusId\": 31798756, \"span\": \"131]\", \"start\": 620, \"end\": 624}, {\"corpusId\": 145281078, \"span\": \"[20,\", \"start\": 644, \"end\": 648}, {\"corpusId\": 3031274, \"span\": \"58,\", \"start\": 648, \"end\": 651}, {\"corpusId\": 154333605, \"span\": \"62]\", \"start\": 651, \"end\": 654}, {\"corpusId\": 145281078, \"span\": \"[20,\", \"start\": 676, \"end\": 680}, {\"corpusId\": 3031274, \"span\": \"58,\", \"start\": 680, \"end\": 683}, {\"corpusId\": 154333605, \"span\": \"62]\", \"start\": 683, \"end\": 686}, {\"corpusId\": 143699829, \"span\": \"[2,\", \"start\": 797, \"end\": 800}, {\"corpusId\": 143810585, \"span\": \"24,\", \"start\": 800, \"end\": 803}, {\"corpusId\": 40002677, \"span\": \"110]\", \"start\": 806, \"end\": 810}, {\"corpusId\": 150692156, \"span\": \"[12,\", \"start\": 833, \"end\": 837}, {\"corpusId\": 144101389, \"span\": \"89]\", \"start\": 840, \"end\": 843}, {\"corpusId\": 143810585, \"span\": \"[24,\", \"start\": 856, \"end\": 860}, {\"corpusId\": 144101389, \"span\": \"89]\", \"start\": 866, \"end\": 869}, {\"corpusId\": 150692156, \"span\": \"[12,\", \"start\": 890, \"end\": 894}, {\"corpusId\": 144101389, \"span\": \"89]\", \"start\": 897, \"end\": 900}, {\"corpusId\": 150692156, \"span\": \"[12,\", \"start\": 917, \"end\": 921}, {\"corpusId\": 144101389, \"span\": \"89]\", \"start\": 921, \"end\": 924}, {\"corpusId\": 143699829, \"span\": \"[2,\", \"start\": 953, \"end\": 956}, {\"corpusId\": 150692156, \"span\": \"[12,\", \"start\": 980, \"end\": 984}, {\"corpusId\": 144101389, \"span\": \"89,\", \"start\": 987, \"end\": 990}, {\"corpusId\": 31798756, \"span\": \"131]\", \"start\": 990, \"end\": 994}, {\"corpusId\": 150692156, \"span\": \"[12,\", \"start\": 1014, \"end\": 1018}, {\"corpusId\": 144101389, \"span\": \"89,\", \"start\": 1021, \"end\": 1024}, {\"corpusId\": 31798756, \"span\": \"131]\", \"start\": 1024, \"end\": 1028}, {\"corpusId\": 143810585, \"span\": \"[24,\", \"start\": 1049, \"end\": 1053}, {\"corpusId\": 144101389, \"span\": \"89]\", \"start\": 1056, \"end\": 1059}, {\"corpusId\": 143910059, \"span\": \"[57,\", \"start\": 1167, \"end\": 1171}, {\"corpusId\": 158787326, \"span\": \"78]\", \"start\": 1171, \"end\": 1174}, {\"corpusId\": 143910059, \"span\": \"[57,\", \"start\": 1197, \"end\": 1201}, {\"corpusId\": 155071922, \"span\": \"101,\", \"start\": 1201, \"end\": 1205}, {\"corpusId\": 144400694, \"span\": \"[63,\", \"start\": 1222, \"end\": 1226}, {\"corpusId\": 143910059, \"span\": \"[57,\", \"start\": 1251, \"end\": 1255}, {\"corpusId\": 155071922, \"span\": \"101,\", \"start\": 1255, \"end\": 1259}, {\"corpusId\": 144400694, \"span\": \"[63,\", \"start\": 1292, \"end\": 1296}, {\"corpusId\": 143910059, \"span\": \"[57,\", \"start\": 1321, \"end\": 1325}, {\"corpusId\": 158787326, \"span\": \"78]\", \"start\": 1325, \"end\": 1328}, {\"corpusId\": 143910059, \"span\": \"[57]\", \"start\": 1349, \"end\": 1353}, {\"corpusId\": 155071922, \"span\": \"[101,\", \"start\": 1370, \"end\": 1375}, {\"corpusId\": 143910059, \"span\": \"[57,\", \"start\": 1399, \"end\": 1403}, {\"corpusId\": 155071922, \"span\": \"101]\", \"start\": 1403, \"end\": 1407}, {\"corpusId\": 143910059, \"span\": \"[57,\", \"start\": 1429, \"end\": 1433}, {\"corpusId\": 155071922, \"span\": \"101]\", \"start\": 1433, \"end\": 1437}, {\"corpusId\": 143910059, \"span\": \"[57,\", \"start\": 1458, \"end\": 1462}, {\"corpusId\": 144400694, \"span\": \"63,\", \"start\": 1462, \"end\": 1465}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 17}, {"paragraphId": "76143", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "Annotation & model training", "text": "To map our minimal conceptualization of deliberative, demagogic, and civic discourse to discussions on Reddit, we labeled a set of comments from our Reddit corpus and trained a large language model in a multilabel classification task. Two coders labelled 4,500 unique comments with at least one of the thirteen types of essential components extracted from our theoretical analysis (see label development documentation in Section 3.4 and Appendix B). To ensure intercoder reliability and the representativeness of the sample, we performed the following procedures. First, coders discussed the developed minimal theoretic conceptualization, reviewed predefined examples for each class, and resolved any questions about the nature of the classes. Then, both coders labelled the same set of 100 random comments from the corpus, yielding a Krippendorf alpha of 0.7. After discussing prevailing differences in the coding tactics, coders learned to adjust their coding in a way that conformed more to the theoretic framework. Coders then relabelled the same corpus, yielding an intercoder reliability of 0.75. This was higher than the expected minimum for coding complicated language tasks in the literature (>0.6 -see e.g., [5,37,43,92,105,122]). Since coders' labeling practices were robust, they proceeded with the selection and labeling of further comments. Specifically, an initial sample of 1650 comments was labeled, containing 30 comments from each subreddit in the dataset. Next, a second batch of 1000 comments was annotated, which we randomly selected by stratified sampling among subreddits. To assess how many comments were necessary for an accurate classifier, we trained a preliminary language model on these 2750 comments, finding that for reliable prediction for each class, at least 300 observations were necessary. To satisfy this condition, we continued labeling comments by stratified random sampling until an annotated sample of 4500 comments was produced.", "spans": "[{\"corpusId\": 208509488, \"span\": \"[5,\", \"start\": 1218, \"end\": 1221}, {\"corpusId\": 11053125, \"span\": \"37,\", \"start\": 1221, \"end\": 1224}, {\"corpusId\": 249872628, \"span\": \"43,\", \"start\": 1224, \"end\": 1227}, {\"corpusId\": 49564827, \"span\": \"92,\", \"start\": 1227, \"end\": 1230}, {\"corpusId\": 252910615, \"span\": \"122]\", \"start\": 1234, \"end\": 1238}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "76144", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "Annotation & model training", "text": "For the final model, we split the corpus of the 4500 comments in a 80-20 train/test set. We kept capitalization and punctuation of comments in their original form and removed the quoted content in the case that a user was quoting another user. To train our model, we used the large language model XLnet [129]. XLnet is an architecture that combines transformers and auto-regressive modeling. We selected XLnet over other commonly used language models such as BERT [39] because it still holds the top performance in multiple text classification benchmarks (e.g., first place in Amazon-5, Amazon-2, DBpedia, Yelp-2, AG News, second place in IMDb, Yelp-5) [126]. We applied a warm-up initialization of 0.1, a learning rate of 3e-5, and a maximum sequence length of 100 words. Our final model resulted in a label ranking average precision score of 91%, while all class specific F1 scores were higher than 0.87. To ensure the robustness of our model, we additionally created an evaluation set of 200 comments, in which each class of the dataset appeared at least ten times. On the evaluation set, the model achieved an accuracy of 0.72, label ranking average precision score of 0.85, while all class specific F-1 scores were higher than 0.76 ( Figure 2). Given the obtained model accuracy, we then analyzed a total of 155 million comments in our corpus. To understand to what extent the essential components of deliberation, civic discourse, and demagoguery characterize social media discussions, we conducted a confirmatory factor analysis (CFA). CFA is generally used to test hypotheses about plausible model structures [21], and has commonly been used to model different types of data, from survey information to time-series [22]. Until now, the application of CFA in NLP-driven questions has been limited (e.g., [96]), and our study serves as an inspiration for exploiting its capabilities, but also understanding its limits in machine-learning based research. Factor analysis allowed us to mathematically represent the political theories as latent unobserved variables (factors) as described by a set of observed variables (items). The observed variables corresponded to the different rhetoric components as predicted by the language model. We chose CFA rather than exploratory factor analysis (EFA) since we were investigating whether a specific conceptualization of discourse theories empirically characterized social media discussions, and not which general argument structures were best described by our data. With CFA, we could construct structures of variables that complied with the minimal conceptualizations of political theories and by assessing the quality of model-fit, we explored to what extent political theories can describe how users discuss political topics on Reddit. Furthermore, we quantified which arguments were empirically associated with which theories and their corresponding magnitude of importance.", "spans": "[{\"corpusId\": 195069387, \"span\": \"[129]\", \"start\": 303, \"end\": 308}, {\"corpusId\": 11294702, \"span\": \"[96]\", \"start\": 1811, \"end\": 1815}, {\"corpusId\": 257039050, \"span\": \"our study\", \"start\": 1831, \"end\": 1831}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "76145", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "22:", "text": "The CFA's results reveal that there is a clear connection between theory and social media discussions, and also show which key rhetoric components of deliberative, civic, and demagogic discourse describe user interactions in our sample (RQ1). Although user comments included central features of each discourse, such as fact-related and structured arguments in deliberation, collective rhetoric in civic discourse, and unsupported, emotional, and identity-related (\"we vs. them\") statements for demagogic discourse, other properties prescribed by theorists to each discourse did not empirically connect to the latent constructs. Nonetheless, there is a sufficient overlap between theoretical conceptions of political discourse and discussions taking place on social media, which also allows us to answer RQ2 -whether a specific part of the platform's digital environment, its available reaction mechanisms, relate to the prevalence of the above political discourse types. On Reddit, subreddit moderators are free to customize the user interface. In particular, moderators can determine the types of reaction mechanisms (upvote, downvote) that subreddit members can use for interacting with other members. This creates a rich Table 4: Magnitude of factor loadings for the expansive and best CFA model. For each discourse type (deliberative, civic, demagogic) we provide which factors are (+) or are not (-) constitutive components. If a factor is part of a model and complies with the minimal theoretic conceptualization it is colored in green. If it is part of the a model but contradicts the theororetic conceptualization it is colored in red. If we were not able to include it in a error-free model it is colored in orange. pool of behavioral data that describe political discourse dynamics in the presence or absence of different reaction mechanisms. To assess this relationship, we created a quantitative model based on a difference in differences (DID) analysis that compares how specific interventions, i.e., the change of available reaction mechanisms by moderators within subreddits, relate to changes in the type of political discourse among users. In general, DID analysis attempts to measure the effects of a sudden change in the environment, policy, or general treatment on a group of individuals or entities [52]. It evaluates how the time-series or observations of a treatment group suddenly change based on a specific intervention, compared to a control group that is not subjected to the treatment. DID largely assumes that in the absence of treatment, the average outcomes for treated and comparison groups would have followed parallel paths over time, without any significant variation [28]. Therefore, any difference between treatment and control after the intervention can be attributed to the intervention itself, revealing causal relations. In our case, although we apply DID and fulfill the parallel-trends assumption in pre-treatment periods, we are still careful in reporting our results, which we claim are mainly observational. Detected associations related only to the specific social media platform and time-periods, and to generate generalized knowledge, more in detail experimentation and research studies need to take place.", "spans": "[{\"corpusId\": 125274031, \"span\": \"[52]\", \"start\": 2320, \"end\": 2324}, {\"corpusId\": 55563061, \"span\": \"[28]\", \"start\": 2703, \"end\": 2707}, {\"corpusId\": 257039050, \"span\": \"our results\", \"start\": 3011, \"end\": 3011}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "76146", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "22:", "text": "To further control for other factors that could plausibly affect the outcome, we again used the Wayback Machine [8] to extract different moderation rules that existed in each subreddit during the investigated period. Since we analyzed how people discuss within each community, we controlled for further factors that could have influenced interactions [6,97]. We create six different variables that represent different moderation rules that could be associated with how user discourse takes place [87]: Anonymity, which describes whether a user's real identity should remain hidden in a subreddit. No troll, which encompasses guidelines that explicitly prohibit trolling/spamming behavior that in themselves contain the usage of inflammatory language or repeated posting of nonconstructive information that can make discourse less deliberative. No hate-speech, which forbids the usage of offensive and hateful speech towards individuals and social groups, which generally leads to emotional and ungrounded rhetoric. Civility, which encompasses direct prompts in the guidelines to use civil language, and deliberation, which includes moderation rules that promote evidence-based arguments and multi-perspective discussions. We also create a variable in-group for subreddits that do focus only on the perspective of one social group (e.g., r/vegan, r/enoughtrumpspam) and explicitly mention in their guidelines that other opinions about an issue will not be tolerated, potentially leading to higher \"we vs. them\" rhetoric and less counterargument structures. These variables serve as proxies of either the implementation of rules that explicitly aimed to alter the nature of discourse [17,41,104] or that have been implemented because of abrupt incidents and patterns in user dynamics that moderators wanted to control [72,111,116]. Besides these moderation rules, we also use the \"nest level\" of a comment as a control. The nest level quantifies how deep a comment appeared in a specific discussion.", "spans": "[{\"corpusId\": 14627931, \"span\": \"[6,\", \"start\": 351, \"end\": 354}, {\"corpusId\": 59413857, \"span\": \"97]\", \"start\": 354, \"end\": 357}, {\"corpusId\": 140369949, \"span\": \"[87]\", \"start\": 496, \"end\": 500}, {\"corpusId\": 140224583, \"span\": \"41,\", \"start\": 1686, \"end\": 1689}, {\"corpusId\": 212618549, \"span\": \"104]\", \"start\": 1689, \"end\": 1693}, {\"corpusId\": 16053246, \"span\": \"[72,\", \"start\": 1816, \"end\": 1820}, {\"corpusId\": 151084817, \"span\": \"111,\", \"start\": 1820, \"end\": 1824}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "76147", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "DISCUSSION", "text": "As we pointed out in Section 2.3, our investigation concentrated on reaction mechanisms rather than affordances. Future research should further investigate the relationship between communityspecific uses of reaction mechanisms (i.e., as affordances) and political rhetoric among social media users. Users do not evaluate reaction mechanisms simply by their technical functionality. In Reddit, voting is inseparable from the culture of the platform, with users disregarding platform rules by making, and enforcing, their own rules and norms as voting is used for pointing out who and what is \"right\", to assign and recognize social status, and to negotiate meaning and ethical norms [53]. While reaction mechanisms create the propensity to behave in specific ways, what kind of behaviors will dominate interactions depends on complex social dynamics in online communities that are difficult to control for. It is no coincidence therefore that the same reaction mechanisms can have varying effects in different digital environments and also can lead to different dimensions of user behavior (e.g., the content of posts, the frequency of posting, how long users will remain in a community, etc.) [31,71]. This social dimension of reaction mechanisms can already be recognized when evaluating the reasons why moderators on specific subreddits decide to change reaction mechanisms. For example, in our own analysis, we found that the exmuslim subreddit deactivated downvotes because of button abuse and because its usage did not end up conforming to the general rules of reddit, while other subreddits did not have a downvote in order to create a \"safe space\" for its members. These discrepancies reveal the relationship between social dimensions of the platforms and their technical design, which cannot be neglected when integrating or evaluating design features on platforms.", "spans": "[{\"corpusId\": 257039050, \"span\": \"our investigation\", \"start\": 51, \"end\": 51}, {\"corpusId\": 239053665, \"span\": \"[53]\", \"start\": 682, \"end\": 686}, {\"corpusId\": 7403868, \"span\": \"[31,\", \"start\": 1193, \"end\": 1197}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "76148", "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit", "sectionTitle": "B.8 Identity labels", "text": "Challenges of defining identity labels among co-authors: Social media posts that discuss politics commonly include references to groups and the membership in groups or collectives. Engaging with the literature on demagogic and civic discourse revealed identity labels to be relevant for these two types of discourse but not deliberative discourse (for demagogic discourse, see [57,63,102]; for civic discourse, see [2,24,60]). However, conceptualizing different identity references for demagogic and civic discourse proved to be challenging and authors disagreed on how to define identity labels for demagoguery and civic engagement. Out of all three political discourse theories, civic engagement is the most contested one. It allows for the most diverse definitions of what it's essential components are (e.g., compare [40] and [24]). We first agreed on a basic identity label to identify comments that expressed the existence of collective or group (i.e., collective rhetoric). One author then proposed an identity label to highlight group differences, a feature of both demagogic and civic discourse [35,60,63]. This label was called \"we vs. them\" to underline the competitive nature of interaction in both demagoguery and civic engagement. In demagogic discourse, members often degrade another group to establish a sense of unity. Here, a unity is formed around group characteristics and people that appear to best embody such characteristics. In short, narratives of unity are not formed around a serious discussion around policy-making to bring about political change but around important personas. This, one author pointed out could be a decisive conceptual distinction between identity in demagoguery and civic discourse. To account for the lack of engagement with policy-making topics to establish a sense of unity (as is the case for civic engagement), we finally agreed on two more identity labels for demagogic discourse: \"you in the epicenter\" and \"who instead of what. \" The first label highlights the importance of a group and why it should be treated preferentially while the second appeals to the characteristics of in-group or out-group members. In civic discourse, we added the labels \"empathy/reciprocity, \" \"counterargument\", and \"situational call to action\" that, together with \"we vs. them, \" would sample comments that expressed a sense of unity but that at the same time featured constructive and productive interactions on specific policy-making goals.", "spans": "[{\"corpusId\": 143910059, \"span\": \"[57,\", \"start\": 377, \"end\": 381}, {\"corpusId\": 144400694, \"span\": \"63,\", \"start\": 381, \"end\": 384}, {\"corpusId\": 143699829, \"span\": \"[2,\", \"start\": 415, \"end\": 418}, {\"corpusId\": 143810585, \"span\": \"24,\", \"start\": 418, \"end\": 421}, {\"corpusId\": 143810585, \"span\": \"[24]\", \"start\": 830, \"end\": 834}, {\"corpusId\": 144400694, \"span\": \"63]\", \"start\": 1111, \"end\": 1114}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 23}
{"paperId": "e177cbffa664e1f1d62f4213f89de8f3fbd4d9ec", "title": "Accessibility of Profile Pictures: Alt Text and Beyond to Express Identity Online", "venue": "International Conference on Human Factors in Computing Systems", "year": 2023, "citationCount": 7, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3544548.3580710?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3544548.3580710, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2023-04-19", "authors": [{"authorId": "2214762757", "name": "Martez E Mott"}, {"authorId": "2048736809", "name": "John Tang"}, {"authorId": "1722375", "name": "Edward Cutrell"}], "abstract": "Profile pictures can convey rich social signals that are often inaccessible to blind and low vision screen reader users. Although there have been efforts to understand screen reader users\u2019 preferences for alternative (alt) text descriptions when encountering images online, profile pictures evoke distinct information needs. We conducted semi-structured interviews with 16 screen reader users to understand their preferences for various styles of profile picture image descriptions in different social contexts. We also interviewed seven sighted individuals to explore their thoughts on authoring alt text for profile pictures. Our findings suggest that detailed image descriptions and user narrated alt text can provide screen reader users enjoyable and informative experiences when exploring profile pictures. We also identified mismatches between how sighted individuals would author alt text with what screen reader users prefer to know about profile pictures. We discuss the implications of our findings for social applications that support profile pictures.", "corpusId": "258217677", "paragraphs": [{"paragraphId": "3499", "title": "Accessibility of Profile Pictures: Alt Text and Beyond to Express Identity Online", "sectionTitle": "INTRODUCTION", "text": "Social platforms must consider how they will support users when authoring alt text for profle pictures. Although there are guidelines [36,37] that provide best practices for authoring alt text descriptions, researchers have found that these practices are often poorly suited for describing people who appear in images due to the complexities of representing gender, race, and disability [3]. Researchers have also noted that one-size-fts-all image descriptions are inadequate for addressing the information preferences of blind and low vision people, which necessitates the need for contextually relevant image descriptions [27,28]. Context can be particularly important when determining how to describe images of people, as research by Bennet et al. [3] identifed six contexts where additional appearance descriptions could be benefcial. Due to the vital role alt texts play in providing access to visual content, and the importance of profle pictures as expressions of users' identities online, it is important to further our understanding of how context impacts what screen reader users want to know about profle pictures, and how they prefer that information to be conveyed.", "spans": "[{\"corpusId\": 232084526, \"span\": \"[3]\", \"start\": 387, \"end\": 390}, {\"corpusId\": 210176691, \"span\": \"[27,\", \"start\": 624, \"end\": 628}, {\"corpusId\": 239012031, \"span\": \"28]\", \"start\": 628, \"end\": 631}, {\"corpusId\": 232084526, \"span\": \"[3]\", \"start\": 751, \"end\": 754}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "3500", "title": "Accessibility of Profile Pictures: Alt Text and Beyond to Express Identity Online", "sectionTitle": "Approaches for Providing Non-visual Image Descriptions", "text": "Screen reader users typically interact with images through screen reader software that reads the alternative (alt) text that accompanies images. Over the years there has been increased interest in understanding how to establish guidelines and methods that provide screen reader users access to the visual content present in images. The Web Content Accessibility Guidelines ofered by the World Wide Web Consortium (W3C) instructs content creators to provide text alternatives for non-text content, but the instructions are general and lack the specifcity that can be helpful when creating an image description [36]. For example, the guidelines propose that alt text for \"informative images\", like photos and illustrations, \"should be at least a short description conveying the essential information presented by the image\" [36]. The National Center for Accessible Media (NCAM) provides general guidelines for alt text, such as consider your audience, be concise, and be objective, as well as specifc description guidelines for diferent types of visual media, like maps, diagrams, and photographs [37]. Researchers have proposed strategies that build upon and improve the use of these guidelines in practice. Morash et al. [20] studied how two methods for creating alt text afected the quality of image descriptions composed by novice authors and found that a template-based approach was more efective than providing the guidelines alone. Mack et al. [18] built a prototype interface for constructing alt text in the context of Microsoft PowerPoint and found that interfaces that provided suggestions on what to include in an image description resulted in higher quality alt text. Morris et al. [21] proposed a taxonomy that could be used to represent visual content non-visually, which included alternative representations such as music and kinesthetic feedback.", "spans": "[{\"corpusId\": 632530, \"span\": \"[20]\", \"start\": 1221, \"end\": 1225}, {\"corpusId\": 239011667, \"span\": \"[18]\", \"start\": 1449, \"end\": 1453}, {\"corpusId\": 5064279, \"span\": \"[21]\", \"start\": 1693, \"end\": 1697}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "3501", "title": "Accessibility of Profile Pictures: Alt Text and Beyond to Express Identity Online", "sectionTitle": "Approaches for Providing Non-visual Image Descriptions", "text": "In addition to human-based approaches, there have been eforts to develop automatic solutions for creating image descriptions. Wu et al. [32] designed and deployed an automatic alt text system for Facebook that used computer vision techniques to identify salient themes (e.g., people, objects, activities) in images to compose image descriptions. Gleason et al. [9] created Twitter A11y, a browser extension that uses optical character recognition and other automated methods, like Caption Crawler [12], to provide alt text for images on Twitter. Seeing AI [38] is a service from Microsoft that uses computer vision technologies to describe images, recognize people, and to perform other identifcation activities like reading currency.", "spans": "[{\"corpusId\": 10857293, \"span\": \"[32]\", \"start\": 136, \"end\": 140}, {\"corpusId\": 211569943, \"span\": \"[9]\", \"start\": 361, \"end\": 364}, {\"corpusId\": 5040111, \"span\": \"[12]\", \"start\": 497, \"end\": 501}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "3502", "title": "Accessibility of Profile Pictures: Alt Text and Beyond to Express Identity Online", "sectionTitle": "Information Needs of Screen Reader Users", "text": "Findings from the studies conducted by Petrie et al. [23] and Stangl et al. [27] also conclude that where an image appears can CHI '23, April 23-28, 2023, Hamburg, Germany afect how a person interprets the image description. In their investigation of how context might impact image description needs, Stangl et al. [28] found that information needs can be similar but also considerably diferent for an image that appears across multiple contexts. For example, when an image containing multiple people in a park was placed within the context of visiting a news site, participants wanted to know the attributes of the park, the attributes of the people, and the activity of the people. When that same image was placed within the context of a social networking site, participants wanted to know the experience of the people and the relationship between them. Other forms of context can also be important for infuencing information needs. Bennett et al. [3] found that image descriptions of people that included descriptions of race, gender, and disability could be important in six scenarios; avatar creation; encountering unknown people; during discussions about identity and appearance; when seeking to read a room and fnd community; learning representation in media; and seeking specifc perspectives.", "spans": "[{\"corpusId\": 210176691, \"span\": \"[27]\", \"start\": 76, \"end\": 80}, {\"corpusId\": 239012031, \"span\": \"[28]\", \"start\": 315, \"end\": 319}, {\"corpusId\": 232084526, \"span\": \"[3]\", \"start\": 950, \"end\": 953}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "3503", "title": "Accessibility of Profile Pictures: Alt Text and Beyond to Express Identity Online", "sectionTitle": "Prior Experiences with Profle Picture Alt Text and Avatars", "text": "We started our interviews with discussions on participants' prior experiences with alt text for images on social platforms, including profle pictures. Our fndings are consistent with existing research that found that screen reader users frequently encounter images with no alt text, or with alt text that appeared to be created through automated methods [2,19,22,30]. Our participants generally felt that it was better to have automated image descriptions than to have no description at all, but they also felt that the information provided in the descriptions was too generic to be particularly useful. For example, SRU1 mentioned that some descriptive information might be conveyed, but that there was no way to verify the validity of the description: \"Sometimes you may get a little quick description of the graphic with the person standing outside or something like that. It's like person smiling, glasses. . . usually you just don't know. And you really can't see. . .like there's no way to try to fgure it out, but everything is just usually real vague. \"", "spans": "[{\"corpusId\": 258217677, \"span\": \"our interviews\", \"start\": 25, \"end\": 25}, {\"corpusId\": 5049521, \"span\": \"[2,\", \"start\": 354, \"end\": 357}, {\"corpusId\": 20580817, \"span\": \"19,\", \"start\": 357, \"end\": 360}, {\"corpusId\": 1292068, \"span\": \"22,\", \"start\": 360, \"end\": 363}, {\"corpusId\": 207230990, \"span\": \"30]\", \"start\": 363, \"end\": 366}, {\"corpusId\": 258217677, \"span\": \"Our participants\", \"start\": 384, \"end\": 384}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "3504", "title": "Accessibility of Profile Pictures: Alt Text and Beyond to Express Identity Online", "sectionTitle": "DISCUSSION", "text": "Researchers and practitioners in the accessibility community have spent considerable efort discovering how to provide screen reader users access to visual information present in images [4,6,12,14,16,18,21,23,25,27,28,35]. Our work builds upon and extends these prior eforts by focusing on the information screen reader users prefer to know when encountering profle pictures, and on the perspectives sighted individuals have around what should be included in profle picture descriptions. The focus of our work was to expand our understanding of how the appearance of profle pictures within diferent contexts infuences the information needs of screen reader users, ultimately so that applications and platforms can provide relevant image descriptions when and how users want them. Also, by understanding the misconceptions sighted individuals have regarding profle picture alt text, we can think about how to prompt users to author descriptions that meet the needs of screen reader users. In this section, we discuss the role of profle pictures as a form of identity representation; how context infuenced information needs; the disjointed image description experiences between screen reader and sighted users; the potential of narrated image descriptions; and the unique image description challenges posed by avatars.", "spans": "[{\"corpusId\": 207203755, \"span\": \"[4,\", \"start\": 185, \"end\": 188}, {\"corpusId\": 5995953, \"span\": \"6,\", \"start\": 188, \"end\": 190}, {\"corpusId\": 5040111, \"span\": \"12,\", \"start\": 190, \"end\": 193}, {\"corpusId\": 235212079, \"span\": \"14,\", \"start\": 193, \"end\": 196}, {\"corpusId\": 249578822, \"span\": \"16,\", \"start\": 196, \"end\": 199}, {\"corpusId\": 239011667, \"span\": \"18,\", \"start\": 199, \"end\": 202}, {\"corpusId\": 5064279, \"span\": \"21,\", \"start\": 202, \"end\": 205}, {\"corpusId\": 3645507, \"span\": \"25,\", \"start\": 208, \"end\": 211}, {\"corpusId\": 210176691, \"span\": \"27,\", \"start\": 211, \"end\": 214}, {\"corpusId\": 239012031, \"span\": \"28,\", \"start\": 214, \"end\": 217}, {\"corpusId\": 258217677, \"span\": \"Our work\", \"start\": 230, \"end\": 230}, {\"corpusId\": 258217677, \"span\": \"our work\", \"start\": 508, \"end\": 508}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": false, "refCount": 11}, {"paragraphId": "3505", "title": "Accessibility of Profile Pictures: Alt Text and Beyond to Express Identity Online", "sectionTitle": "The Impact of Context", "text": "Our fndings show that screen reader users would like access to detailed information present in profle pictures, and our participants provided numerous examples to illustrate how they would use that information when completing diferent tasks. These fndings are in line with prior work that has consistently shown that screen reader users typically prefer to have certain details conveyed in image descriptions [23,27,28], although the relevance of more specifc information can be heavily infuenced by the context of where the image appears [27,28]. Within the context of hiring, participants mentioned wanting descriptions of clothing or jewelry so they could determine if job candidates were presenting themselves professionally. In particular, the style and type of clothing could be helpful, such as the distinction between a t-shirt and a collared shirt. Style of dress has been proposed as a detail of interest for images that appear on e-commerce sites [26] but our fndings suggest that similar details might be benefcial on platforms like LinkedIn that are tailored toward hiring and job seeking.", "spans": "[{\"corpusId\": 258217677, \"span\": \"our participants\", \"start\": 132, \"end\": 132}, {\"corpusId\": 210176691, \"span\": \"27,\", \"start\": 413, \"end\": 416}, {\"corpusId\": 239012031, \"span\": \"28]\", \"start\": 416, \"end\": 419}, {\"corpusId\": 210176691, \"span\": \"[27,\", \"start\": 539, \"end\": 543}, {\"corpusId\": 239012031, \"span\": \"28]\", \"start\": 543, \"end\": 546}, {\"corpusId\": 51932320, \"span\": \"[26]\", \"start\": 958, \"end\": 962}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "3506", "title": "Accessibility of Profile Pictures: Alt Text and Beyond to Express Identity Online", "sectionTitle": "Mismatches Between Screen Reader and Sighted Users", "text": "We found that our sighted participants were often unsure about what should be included in image descriptions, and frequently questioned the importance of various details. For example, the comment by SP7 that backgrounds were not important is in opposition to the opinions expressed by our screen reader participants, who found value in the social signals provided by descriptions of backgrounds. Overall, the tendency was for our sighted participants to suggest that less information be provided. An issue at play is that our sighted participants' views on what should be included in image descriptions were typically based on their personal opinions, not on what they thought might be useful to screen reader users. Mismatches between screen reader and sighted users is an example of Problem 1 of \"Why CSCW applications fail\" presented by Grudin [11]: the disparity between who does the work and who gets the beneft. This problem is often exacerbated in accessibility contexts since the people who do the work often do not understand the needs or perspectives of the people who will beneft. Prior research has explored the efectiveness of various methods for authoring alt text for diferent types of imagery, including memes [8], charts [20], and images in PowerPoint [18]. Future research should explore the creation and evaluation of diferent approaches (templates, guidelines, etc.) for eliciting high-quality image descriptions for profle pictures.", "spans": "[{\"corpusId\": 18572930, \"span\": \"[11]\", \"start\": 847, \"end\": 851}, {\"corpusId\": 204917542, \"span\": \"[8]\", \"start\": 1226, \"end\": 1229}, {\"corpusId\": 632530, \"span\": \"[20]\", \"start\": 1238, \"end\": 1242}, {\"corpusId\": 239011667, \"span\": \"[18]\", \"start\": 1269, \"end\": 1273}]", "conference": "chi", "year": 2023, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 8}
{"paperId": "ffb1f31ea5ba1d00099155248df18e364f8aea90", "title": "Designing Effective Interview Chatbots: Automatic Chatbot Profiling and Design Suggestion Generation for Chatbot Debugging", "venue": "International Conference on Human Factors in Computing Systems", "year": 2021, "citationCount": 55, "openAccessPdf": {"url": "https://arxiv.org/pdf/2104.04842", "status": "GREEN", "license": null, "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2104.04842, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference", "Review"], "publicationDate": "2021-04-10", "authors": [{"authorId": "2110981037", "name": "Xu Han"}, {"authorId": "1705742", "name": "Michelle X. Zhou"}, {"authorId": "2049502034", "name": "Matthew J. Turner"}, {"authorId": "1704158", "name": "Tom Yeh"}], "abstract": "Recent studies show the effectiveness of interview chatbots for information elicitation. However, designing an effective interview chatbot is non-trivial. Few tools exist to help designers design, evaluate, and improve an interview chatbot iteratively. Based on a formative study and literature reviews, we propose a computational framework for quantifying the performance of interview chatbots. Incorporating the framework, we have developed iChatProfile, an assistive chatbot design tool that can automatically generate a profile of an interview chatbot with quantified performance metrics and offer design suggestions for improving the chatbot based on such metrics. To validate the effectiveness of iChatProfile, we designed and conducted a between-subject study that compared the performance of 10 interview chatbots designed with or without using iChatProfile. Based on the live chats between the 10 chatbots and 1349 users, our results show that iChatProfile helped the designers build significantly more effective interview chatbots, improving both interview quality and user experience.", "corpusId": "233209707", "paragraphs": [{"paragraphId": "19688", "title": "Designing Effective Interview Chatbots: Automatic Chatbot Profiling and Design Suggestion Generation for Chatbot Debugging", "sectionTitle": "INTRODUCTION", "text": "During the past few years, chatbots have been used to conduct interviews by engaging users in one-on-one text-based conversations [67]. Recent studies show that interview chatbots are more effective at engaging users and eliciting quality information from the users, compared to traditional online surveys [31,66,67].", "spans": "[{\"corpusId\": 219794844, \"span\": \"[67]\", \"start\": 130, \"end\": 134}, {\"corpusId\": 140257137, \"span\": \"[31,\", \"start\": 306, \"end\": 310}, {\"corpusId\": 67771004, \"span\": \"66,\", \"start\": 310, \"end\": 313}, {\"corpusId\": 219794844, \"span\": \"67]\", \"start\": 313, \"end\": 316}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "19689", "title": "Designing Effective Interview Chatbots: Automatic Chatbot Profiling and Design Suggestion Generation for Chatbot Debugging", "sectionTitle": "INTRODUCTION", "text": "Despite their promises, it is challenging and time consuming to build effective interview chatbots due to the limitations in today's technologies and the complexity involved in interview conversations [18,65]. Like building any complex interactive systems [42], one potential approach is to design and improve an interview chatbot iteratively. Specifically, the iterative design of an interview chatbot is to fulfill two main goals. First, like designing any user interviews or surveys [7,42], designers of an interview chatbot need to ensure the effective design of an interview task (e.g., proper and clear wording of questions). Second, like building any conversational agents [29], designers of an interview chatbot need to make sure that the chatbot can successfully carry out such an interview task [65].", "spans": "[{\"corpusId\": 140274744, \"span\": \"[18,\", \"start\": 201, \"end\": 205}, {\"corpusId\": 211031876, \"span\": \"65]\", \"start\": 205, \"end\": 208}, {\"corpusId\": 17748574, \"span\": \"[42]\", \"start\": 256, \"end\": 260}, {\"corpusId\": 145120835, \"span\": \"[7,\", \"start\": 486, \"end\": 489}, {\"corpusId\": 17748574, \"span\": \"42]\", \"start\": 489, \"end\": 492}, {\"corpusId\": 211031876, \"span\": \"[65]\", \"start\": 805, \"end\": 809}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "19690", "title": "Designing Effective Interview Chatbots: Automatic Chatbot Profiling and Design Suggestion Generation for Chatbot Debugging", "sectionTitle": "RELATED WORK 2.1 Chatbots for Information Elicitation", "text": "AI-powered conversational user interfaces, also known as AI chatbots or chatbots for short, allow users to communicate with computers in natural language, providing more flexible [5] and personalized user experience [69]. Such benefits have encouraged the creation of a wide array of chatbot applications, such as virtual assistants [38], social companions [56], and interview chatbots [37]. Our work is most relevant to the use of chatbots for information elicitation [31,66,67].", "spans": "[{\"corpusId\": 3124237, \"span\": \"[38]\", \"start\": 333, \"end\": 337}, {\"corpusId\": 4325193, \"span\": \"[56]\", \"start\": 357, \"end\": 361}, {\"corpusId\": 16650901, \"span\": \"[37]\", \"start\": 386, \"end\": 390}, {\"corpusId\": 233209707, \"span\": \"Our work\", \"start\": 400, \"end\": 400}, {\"corpusId\": 140257137, \"span\": \"[31,\", \"start\": 469, \"end\": 473}, {\"corpusId\": 67771004, \"span\": \"66,\", \"start\": 473, \"end\": 476}, {\"corpusId\": 219794844, \"span\": \"67]\", \"start\": 476, \"end\": 479}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "19691", "title": "Designing Effective Interview Chatbots: Automatic Chatbot Profiling and Design Suggestion Generation for Chatbot Debugging", "sectionTitle": "RELATED WORK 2.1 Chatbots for Information Elicitation", "text": "Researchers have developed various chatbots to elicit information from users through text-based conversations. For example, Bohus and Rudnicky introduce dialog systems that gather required information for performing specific tasks (e.g., making travel reservations) [4]. More recently, a number of interview chatbots have been developed to elicit information from a target audience. For example, a chatbot is built to interview students for effective teaming [66] and another chatbot to interview gamers for eliciting their game opinions [67]. Williams et al. have developed a chatbot to interview employees for workplace productivity [64]. Compared to traditional, static online surveys, these interview chatbots enhance information elicitation [31,66] by providing interactive feedback [8] and asking follow-up questions [46]. Our work is directly related to the efforts of creating interview chatbots. However, existing work focuses on developing interview chatbots for specific information elicitation tasks (e.g., [64,66,67]) or powering interview chatbots with specific skills (e.g., giving them a personality [71] and active listening skills [65]). While we learn from these efforts, our work reported here has a very different focus: we want to build a tool that can automatically evaluate the performance of an interview chatbot and provide design suggestions for improving the chatbot.", "spans": "[{\"corpusId\": 207041476, \"span\": \"[4]\", \"start\": 266, \"end\": 269}, {\"corpusId\": 67771004, \"span\": \"[66]\", \"start\": 459, \"end\": 463}, {\"corpusId\": 219794844, \"span\": \"[67]\", \"start\": 538, \"end\": 542}, {\"corpusId\": 5058047, \"span\": \"[64]\", \"start\": 635, \"end\": 639}, {\"corpusId\": 140257137, \"span\": \"[31,\", \"start\": 746, \"end\": 750}, {\"corpusId\": 67771004, \"span\": \"66]\", \"start\": 750, \"end\": 753}, {\"corpusId\": 237367931, \"span\": \"[8]\", \"start\": 788, \"end\": 791}, {\"corpusId\": 216012133, \"span\": \"[46]\", \"start\": 823, \"end\": 827}, {\"corpusId\": 233209707, \"span\": \"Our work\", \"start\": 837, \"end\": 837}, {\"corpusId\": 5058047, \"span\": \"[64,\", \"start\": 1019, \"end\": 1023}, {\"corpusId\": 67771004, \"span\": \"66,\", \"start\": 1023, \"end\": 1026}, {\"corpusId\": 219794844, \"span\": \"67]\", \"start\": 1026, \"end\": 1029}, {\"corpusId\": 211031876, \"span\": \"[65]\", \"start\": 1149, \"end\": 1153}, {\"corpusId\": 233209707, \"span\": \"our work\", \"start\": 1199, \"end\": 1199}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "19692", "title": "Designing Effective Interview Chatbots: Automatic Chatbot Profiling and Design Suggestion Generation for Chatbot Debugging", "sectionTitle": "Design Suggestion Generation for Effective Interaction", "text": "Our work on generating design suggestions is also related to various efforts on guiding the design of human-computer interfaces, such as chatbot systems [21] and graphical user interfaces (GUI) [36,68]. For example, Han et al. combine domain-specific knowledge together with observational studies to generate rule-based design suggestions for task-oriented chatbots [21]. One of the drawbacks of this approach lies in its inflexibility of adapting design suggestions to changing design goals or dynamic design issues occurring in real time. On the other hand, Lee et al. use autoencoder and k-nearest neighbor algorithms to recommend GUI design examples that help designers in real time [36]. Moreover, Xu et al. have developed a system that incorporates crowdsourcing to generate design suggestions for GUI designers [68]. While we learn from these approaches, we are unaware of any approach to automatic generation of design suggestions based on computed chatbot performance as our approach does. ", "spans": "[{\"corpusId\": 233209707, \"span\": \"Our work\", \"start\": 8, \"end\": 8}, {\"corpusId\": 210701459, \"span\": \"[36,\", \"start\": 194, \"end\": 198}, {\"corpusId\": 14554012, \"span\": \"68]\", \"start\": 198, \"end\": 201}, {\"corpusId\": 233209707, \"span\": \"this approach\", \"start\": 409, \"end\": 409}, {\"corpusId\": 210701459, \"span\": \"[36]\", \"start\": 687, \"end\": 691}, {\"corpusId\": 14554012, \"span\": \"[68]\", \"start\": 818, \"end\": 822}, {\"corpusId\": 233209707, \"span\": \"our approach\", \"start\": 992, \"end\": 992}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "19693", "title": "Designing Effective Interview Chatbots: Automatic Chatbot Profiling and Design Suggestion Generation for Chatbot Debugging", "sectionTitle": "Supporting Interview Chatbots", "text": "First, recent studies show that other researchers have used Juji to build various interview chatbots, which matches our focus on aiding the design of effective interview chatbots [37,61,65,66]. Building and deploying an interview chatbot on Juji is very similar to creating a survey on a popular survey platform like SurveyMonkey or Qualtrics. Designers use Juji's GUI to enter a set of interview questions and Juji will automatically generate a publicly accessible interview chatbot with a set of default conversational skills [67]. Juji also automatically handles side talking and keeps a conversation on track to ensure the completion of an interview [65].", "spans": "[{\"corpusId\": 233209707, \"span\": \"our focus\", \"start\": 125, \"end\": 125}, {\"corpusId\": 16650901, \"span\": \"[37,\", \"start\": 179, \"end\": 183}, {\"corpusId\": 218483563, \"span\": \"61,\", \"start\": 183, \"end\": 186}, {\"corpusId\": 211031876, \"span\": \"65,\", \"start\": 186, \"end\": 189}, {\"corpusId\": 67771004, \"span\": \"66]\", \"start\": 189, \"end\": 192}, {\"corpusId\": 219794844, \"span\": \"[67]\", \"start\": 528, \"end\": 532}, {\"corpusId\": 211031876, \"span\": \"[65]\", \"start\": 654, \"end\": 658}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "19694", "title": "Designing Effective Interview Chatbots: Automatic Chatbot Profiling and Design Suggestion Generation for Chatbot Debugging", "sectionTitle": "COMPUTATIONAL FRAMEWORK FOR QUANTIFYING INTERVIEW CHATBOT EFFECTIVENESS", "text": "Since our formative study indicated that chatbot designers wish to obtain certain quantitative feedback on the performance of their existing chatbot (T1), we first formulated a computational framework that quantitatively measures the effectiveness of such an interview chatbot from multiple aspects. The framework aims at achieving two goals: 1) providing quantified insights into the performance of an interview chatbot; 2) using such insights to provide specific and practical design suggestions for improving the chatbot. Based on the previous work on assessing human interviews [3,7,15,20,24,50], communication theories for conducting effective interviews [47,67], and evaluating chatbot effectiveness [12,19,55,65,70], we formulated a set of performance metrics to quantitatively assess the effectiveness of an interview chatbot from three main dimensions: elicitation ability, user experience, and ethics.", "spans": "[{\"corpusId\": 145488766, \"span\": \"[3,\", \"start\": 582, \"end\": 585}, {\"corpusId\": 145120835, \"span\": \"7,\", \"start\": 585, \"end\": 587}, {\"corpusId\": 4012641, \"span\": \"15,\", \"start\": 587, \"end\": 590}, {\"corpusId\": 2627823, \"span\": \"20,\", \"start\": 590, \"end\": 593}, {\"corpusId\": 55292794, \"span\": \"24,\", \"start\": 593, \"end\": 596}, {\"corpusId\": 15322343, \"span\": \"50]\", \"start\": 596, \"end\": 599}, {\"corpusId\": 148132585, \"span\": \"[47,\", \"start\": 660, \"end\": 664}, {\"corpusId\": 219794844, \"span\": \"67]\", \"start\": 664, \"end\": 667}, {\"corpusId\": 211031876, \"span\": \"65,\", \"start\": 716, \"end\": 719}, {\"corpusId\": 56657857, \"span\": \"70]\", \"start\": 719, \"end\": 722}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 10}, {"paragraphId": "19695", "title": "Designing Effective Interview Chatbots: Automatic Chatbot Profiling and Design Suggestion Generation for Chatbot Debugging", "sectionTitle": "Elicitation Ability", "text": "The primary task of interview chatbots is to elicit high-quality responses from participants. Existing literature shows that the success of an interview is often determined by two aspects: the elicited response quality and level of user engagement [7,15,19,43,55,65]. We thus model an interview chatbot's elicitation abilities from two sub-dimensions: response quality and user engagement. While response quality directly assesses the quality of user responses to an interview question, the level of user engagement quantifies how much a participant is engaged with a chatbot from multiple aspects (e.g., how long an engagement is).", "spans": "[{\"corpusId\": 145120835, \"span\": \"[7,\", \"start\": 248, \"end\": 251}, {\"corpusId\": 4012641, \"span\": \"15,\", \"start\": 251, \"end\": 254}, {\"corpusId\": 1841742, \"span\": \"43,\", \"start\": 257, \"end\": 260}, {\"corpusId\": 211031876, \"span\": \"65]\", \"start\": 263, \"end\": 266}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "19696", "title": "Designing Effective Interview Chatbots: Automatic Chatbot Profiling and Design Suggestion Generation for Chatbot Debugging", "sectionTitle": "Level of User Engagement.", "text": "In the context of interviews, the level of user engagement measures a user's behavior during an interview [15]. Specifically, we have defined a set of metrics to assess a respondent's behavior when engaging with an interview chatbot. Response Length. This metric computes the word count of a respondent's free-text response to an interview question. We chose this metric because previous work indicates that engaged respondents are more willing to give long responses [67]. Designers can use this metric to gauge their chatbot performance and to make corresponding design improvements (e.g., adding follow-up questions or changing a yes/no question to an open-ended question to elicit longer responses). Engagement Duration. This metric indicates how long a participant is willing to engage with an interview question. Although engagement duration alone does not signal the quality of user responses [67], we hope to use it as an indicator of potential issues with an interview question. For example, if the engagement duration of a particular open-ended interview question is exceedingly short, it might signal that the question is too narrow and needs to be rephrased to encourage more open and longer engagement. Completion Rate. This metric computes the percentage of participants completing an interview question or an entire interview. It is a commonly used metric to measure the effectiveness of an interviewer [7,20]. To better help designers improve their chatbots question by question (see Section 6), we compute the completion rate for each interview question (Q) by counting the number of users who completed the question ( ) and the number of users who responded to the question ( ):", "spans": "[{\"corpusId\": 4012641, \"span\": \"[15]\", \"start\": 106, \"end\": 110}, {\"corpusId\": 219794844, \"span\": \"[67]\", \"start\": 468, \"end\": 472}, {\"corpusId\": 219794844, \"span\": \"[67]\", \"start\": 900, \"end\": 904}, {\"corpusId\": 145120835, \"span\": \"[7,\", \"start\": 1418, \"end\": 1421}, {\"corpusId\": 2627823, \"span\": \"20]\", \"start\": 1421, \"end\": 1424}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "19697", "title": "Designing Effective Interview Chatbots: Automatic Chatbot Profiling and Design Suggestion Generation for Chatbot Debugging", "sectionTitle": "User Experience", "text": "Informed by literature in interaction design [54] and interview design [7,20], we proposed five metrics to measure a user's experience with an interview chatbot.", "spans": "[{\"corpusId\": 7003533, \"span\": \"[54]\", \"start\": 45, \"end\": 49}, {\"corpusId\": 145120835, \"span\": \"[7,\", \"start\": 71, \"end\": 74}, {\"corpusId\": 2627823, \"span\": \"20]\", \"start\": 74, \"end\": 77}, {\"corpusId\": 233209707, \"span\": \"we propose\", \"start\": 89, \"end\": 89}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "19698", "title": "Designing Effective Interview Chatbots: Automatic Chatbot Profiling and Design Suggestion Generation for Chatbot Debugging", "sectionTitle": "User Experience", "text": "User Satisfaction Rating. This metric is directly computed from participants' ratings of their chatbot interview experience. This rating can be easily obtained: when piloting an interview chatbot, a question like \"How satisfied are you with the interview experience?\"  [14,23] can be added at the end of an interview session for a participant to report their level of satisfaction. User Trust Rating. This metric measures participants' perceived trust in an interview chatbot. Trust is important because it affects participants' willingness to share information [37]. Similar to obtaining the user satisfaction rating, a question like \"How much do you trust this chatbot? Please rate it on a scale of 1 to 5\" can be added at the end of an interview when piloting an interview chatbot. User Sentiment. This metric evaluates participants' sentiment toward an interview chatbot since such a metric is widely used to measure user satisfaction with interviews/surveys [7]. To obtain user sentiment, one can elicit participants' rationale (why) when eliciting their satisfaction rating and trust rating during pilot interviews. Currently, we use the Vader model [16] to perform sentimental analysis on the collected users responses, and compute the percentages of positive, neutral and negative responses. Level of Empathy. This measures the level of empathy an interview chatbot has since research shows that an empathetic chatbot is able to elicit higher quality responses [65]. Currently, we compute the level of empathy by the frequency of empathetic words used by a chatbot. Specifically, given a conversation segment associated with interview question Q, we normalize the number of empathetic words ( ) over the total number of words within chatbot utterances ( ) in this segment:", "spans": "[{\"corpusId\": 16650901, \"span\": \"[37]\", \"start\": 562, \"end\": 566}, {\"corpusId\": 145120835, \"span\": \"[7]\", \"start\": 963, \"end\": 966}, {\"corpusId\": 12233345, \"span\": \"[16]\", \"start\": 1156, \"end\": 1160}, {\"corpusId\": 211031876, \"span\": \"[65]\", \"start\": 1469, \"end\": 1473}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "19699", "title": "Designing Effective Interview Chatbots: Automatic Chatbot Profiling and Design Suggestion Generation for Chatbot Debugging", "sectionTitle": "Template-based Natural Language Generation.", "text": "For each metric, we have defined a template that contains one or more design guidelines for improving a chatbot (Table 3). These design guidelines are formulated based on previous research findings and commercial product design guidelines (Alexa, Google Home and Juji) for improving interview quality and user experience [8,11,14,22,28,44,45,55,65,70]. For example, there are two guidelines on improving the metric informativeness: one is to better articulate or explain an interview question to minimize ambiguity, while the other is to improve a chatbot with active listening skills to make users feel heard [65].", "spans": "[{\"corpusId\": 237367931, \"span\": \"[8,\", \"start\": 321, \"end\": 324}, {\"corpusId\": 143131071, \"span\": \"22,\", \"start\": 330, \"end\": 333}, {\"corpusId\": 216012133, \"span\": \"45,\", \"start\": 339, \"end\": 342}, {\"corpusId\": 211031876, \"span\": \"65,\", \"start\": 345, \"end\": 348}, {\"corpusId\": 56657857, \"span\": \"70]\", \"start\": 348, \"end\": 351}, {\"corpusId\": 211031876, \"span\": \"[65]\", \"start\": 610, \"end\": 614}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "19700", "title": "Designing Effective Interview Chatbots: Automatic Chatbot Profiling and Design Suggestion Generation for Chatbot Debugging", "sectionTitle": "Design guideline Metric", "text": "Add polite probings and explanations to the question Informativeness, Completion Rate [11,45] Add customizations to show the chatbot is actively listening Informativeness, Engagement Duration [65] Set a minimum response length to handle short user input Response Length, Engagement Duration [28] Add customized chatbot responses to handle user digressions Response Length, Engagement Duration, Repetition Rate [55,65,67] Reword the question to make it more acceptable to users Completion Rate, Repetition Rate [11,14,22] Personalize the chat experience, e.g., addressing users their names Completion Rate [14,22,28] Add default empathetic chatbot responses to handle unknown user input Level of Empathy [14,28,70] Customize chatbot responses to give empathetic feedback on user input Level of Empathy [14,70] Remove all the hate or offensive speech Hate Speech Rate [14] Avoid asking private or sensitive information without user consent Privacy Intrusion Rate [14] randomly divided into two groups, 5 in each group. Each designer started with a 15-minute tutorial of the Juji platform by watching a tutorial video and learning several key Juji features (e.g., how to customize a chatbot's actions). They were given additional time to play with Juji and get familiar with various design features. Each designer was then given the baseline chatbot for them to import into their own account so they could preview and improve the baseline. They also had access to the report dashboard and all the interviewee responses extracted from the 128 conducted chatbot interviews as described in section 3.2. They were asked to describe the good and bad aspects of the baseline chatbot. Next, they were asked to improve the baseline chatbot along three dimensions: user response quality, user experience, and ethics. They were allowed to use any chatbot customizations (e.g., rewording a question or customizing a chatbot's reactions to user input) as long as all the original interview questions and the question order were kept. All the designers in one group (Group B, w/ iChatProfile) were also given iChatProfile to view the generated profile of the baseline chatbot and corresponding design suggestions, while the other group (Group A, w/o iChatProfile) was not given the tool but only the interviewee responses . We also collected the participants' demographics, including their gender and age, and their chatbot experience (chatbot interaction or design experience).", "spans": "[{\"corpusId\": 216012133, \"span\": \"45]\", \"start\": 90, \"end\": 93}, {\"corpusId\": 211031876, \"span\": \"[65]\", \"start\": 192, \"end\": 196}, {\"corpusId\": 211031876, \"span\": \"65,\", \"start\": 414, \"end\": 417}, {\"corpusId\": 219794844, \"span\": \"67]\", \"start\": 417, \"end\": 420}, {\"corpusId\": 143131071, \"span\": \"22]\", \"start\": 517, \"end\": 520}, {\"corpusId\": 143131071, \"span\": \"22,\", \"start\": 609, \"end\": 612}, {\"corpusId\": 56657857, \"span\": \"70]\", \"start\": 710, \"end\": 713}, {\"corpusId\": 56657857, \"span\": \"70]\", \"start\": 805, \"end\": 808}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "19701", "title": "Designing Effective Interview Chatbots: Automatic Chatbot Profiling and Design Suggestion Generation for Chatbot Debugging", "sectionTitle": "Study Results", "text": "Before running ANCOVA analyses, we also examined the correlations among all dependent variables. Consistent with prior findings [67], informativeness was not correlated with engagement duration. Moreover, engagement duration did not significantly correlate with any other metrics except repetition rate. We also noted that a chatbot's empathy level significantly correlated with informativeness and response length. Intuitively, this result is sensible since respondents would be more cooperative with an empathetic chatbot [65].", "spans": "[{\"corpusId\": 219794844, \"span\": \"[67]\", \"start\": 128, \"end\": 132}, {\"corpusId\": 233209707, \"span\": \"this result\", \"start\": 440, \"end\": 440}, {\"corpusId\": 211031876, \"span\": \"[65]\", \"start\": 524, \"end\": 528}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "19702", "title": "Designing Effective Interview Chatbots: Automatic Chatbot Profiling and Design Suggestion Generation for Chatbot Debugging", "sectionTitle": "Future Work and Design Implications", "text": "One possible direction of future work is to construct a multi-layer framework for evaluating the performance of interview chatbots. Following [52], this framework could have three layers: design quality (e.g., the question-level performance metrics used in our current work), user belief (user perceived chatbot performance, such as perceived usefulness [51] and ease of use [6]), and user attitude (users' overall feelings towards the whole chatbot, such as perceived trust and satisfaction in our work). A path model can then be generated to reveal causal relationships between different layers to make chatbot profiling and design suggestions more explainable.", "spans": "[{\"corpusId\": 7687260, \"span\": \"[52]\", \"start\": 142, \"end\": 146}, {\"corpusId\": 6274371, \"span\": \"[51]\", \"start\": 354, \"end\": 358}, {\"corpusId\": 17019085, \"span\": \"[6]\", \"start\": 375, \"end\": 378}, {\"corpusId\": 233209707, \"span\": \"our work\", \"start\": 503, \"end\": 503}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 4}], "paragraphCount": 15}
{"paperId": "c7ff66f3654a351b66a8d94919f9cc5a2f6c121c", "title": "Gospels of Modernity: Digital Cattle Markets, Urban Religiosity, and Secular Computing in the Global South", "venue": "International Conference on Human Factors in Computing Systems", "year": 2021, "citationCount": 28, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3411764.3445259?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3411764.3445259, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2021-05-06", "authors": [{"authorId": "3314179", "name": "Nusrat Jahan Mim"}], "abstract": "This paper joins the growing body of critical HCI work that studies the digitization of the Global South and reports the elements of \u2018secularization\u2019 in it. Based on a year-long ethnography on the contemporary transformations in religious practices in Dhaka, Bangladesh, this paper presents how the emerging \u201cdigital\u201d cattle marketplaces subdue various forms of traditional manifestations of urban religiosity during Eid-ul-Adha, the second-largest Islamic festival in the city. This paper further depicts how such secularization contributes to diminishing rural-urban linkages, affecting electoral politics, and reducing the tolerance to religious celebrations in a city. Drawing from a rich body of work in critical urban studies, postcolonial computing, and sociology of religions, we explain how such oft-overlooked embedding of secularization in computing affects the religious fabrics in the urban regions of the Global South, and discuss its implication for HCI scholarship in diversity, inclusion, and development.", "corpusId": "233987774", "paragraphs": [{"paragraphId": "20830", "title": "Gospels of Modernity: Digital Cattle Markets, Urban Religiosity, and Secular Computing in the Global South", "sectionTitle": "Urban Design, Modernity, and Religion", "text": "Now we bring the literature of Urban Modernity, Religion, and Urban Public Space of the Global South to the fore to better understand the embedded complexities of these contexts, where various Western digital interventions are embarking on. While modernity is marked by a set of values, processes, technologies, and the timeperiod when scientifc revolution, industrialization, and capitalism rapidly expanded across the West [128], Urban modernity is characterized by the adoption of modernist ideology in the urban built environment and as a tool to respond to emerging social and political tensions [1]. Predominantly concentrated on urban development strategies and planning policies engendered in the west, urban modernity is globally understood as a product of secular institutions, practices, and discourses [58]. A signifcant portion of knowledge in the urban studies developed in the 19th and 20th century read the cities through scientifc rationalities and measures a city's performativity through the standards of \"industrialized progress. \" [89,91,134] With the theorization of the Global City in the 1980s, this new paradigm of modern urbanism started to expand beyond the West and infuence the spatial, political, and economic readings of modern cities worldwide [116]. These scholarly and design practices reinforced the qualities of western modernity as the standards of a successful, global, modern city [58]. In the late twentieth and early twenty-frst centuries, scholars like David Harvey [62], Edward Soja [124], Saskia Sassen [116], et al. mapped the urban spatial responses around global fows of capital, technology, information and pointed toward the failures of such modernist advancement at diferent scales in an urban setting. Soja [124], Jane Jacobs [78], Fainstein [52], Sandercock [115], and many others shed light on diferent forms of social inequalities and injustices that were introduced by modern cities. Although it was not at the center of their criticism, the western concept of modernity has also always upheld the idea of secularization, and there has been a predominant secular spirit among the modernist planners or scholars toward understanding a city [31,58].", "spans": "[{\"corpusId\": \"140288090\", \"span\": \"[128]\", \"start\": 425, \"end\": 430}, {\"corpusId\": \"143135374\", \"span\": \"[58]\", \"start\": 814, \"end\": 818}, {\"corpusId\": \"154101012\", \"span\": \"91,\", \"start\": 1056, \"end\": 1059}, {\"corpusId\": \"143135374\", \"span\": \"[58]\", \"start\": 1420, \"end\": 1424}, {\"corpusId\": \"143999958\", \"span\": \"[52]\", \"start\": 1793, \"end\": 1797}, {\"corpusId\": \"142711827\", \"span\": \"[115]\", \"start\": 1810, \"end\": 1815}, {\"corpusId\": \"143135374\", \"span\": \"58]\", \"start\": 2198, \"end\": 2201}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "20831", "title": "Gospels of Modernity: Digital Cattle Markets, Urban Religiosity, and Secular Computing in the Global South", "sectionTitle": "Urban Design, Modernity, and Religion", "text": "While the twentieth-century world witnessed the advent of human rationality and technological progress, this century, by contrast, is experiencing a rise in religious/spiritual values and faith-based communities [31]. The massive globalization [123], intercontinental migrations [142], and forced mobilities of the refugees [98,109] have started to question diferent aspects of the modern secular urban planning systems of the West [31]. For the last few decades, the geopolitics of the religious have received a great deal of attention as the cities of diferent parts of the world are observing a rise in religious nationalism, fundamentalism, and communal violence [58]. Hence, in this era of globalization, religiosity is neither a unique 'feature' of the Global South, nor is there a dichotomy between the North and the South. However, since in the Global South, urban religion and the city coexist from the very beginning, scholars like Robert Orsi have suggested looking at the regional scholarly work from the Global South to understand the necessity of dynamic engagement of religion with the city [106].", "spans": "[{\"corpusId\": \"55805833\", \"span\": \"[123]\", \"start\": 244, \"end\": 249}, {\"corpusId\": \"225447944\", \"span\": \"[98,\", \"start\": 324, \"end\": 328}, {\"corpusId\": \"143135374\", \"span\": \"[58]\", \"start\": 667, \"end\": 671}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "20832", "title": "Gospels of Modernity: Digital Cattle Markets, Urban Religiosity, and Secular Computing in the Global South", "sectionTitle": "Urban Design, Modernity, and Religion", "text": "Next, we turn to urban spatials to explain why, in the global south, it is difcult to understand urban religion without taking space and spatial politics seriously. Various scholarly works conducted in South Asian and African cities demonstrate several forms of complex yet inevitable engagements among urban religion, spaces, and functions. For instance, AbdouMaliq Simone has examined how the traditional Islamic institution \"zawiyyah\" helps urban Africans to act efectively within a larger globalized economic domain [123]. Zawiyyah provides space and a trans-local network through which marginalized urban entrepreneurs or businessmen can connect, react to, or resist the globalized urban world. Through examples of urban violence, such as the Godhra Station incident and riot in Ahmedabad in 2002, Yasmeen Arif has reported how rehabilitative religious activities take control over urban space, when 'secular' or state-sponsored eforts fail [28]. Similarly, through her ethnographic work, Ara Wilson has demonstrated how multiple vernacular economic systems sustain in Bangkok's global economic setting as the religious shrines invade and disrupt the mobilities of capital and labor [133]. Parthasarathy has taken this further by exploring the spatial politicization of religion in urban Mumbai during the religious festival Chhat Puja [108]. With similar spirit around religious festivals, Mehrotra et al. explain how, during Kumbh Mela, a kinetic city emerges in India and challenges the very necessity of permanency in defning the urban [96]. Taken together, this line of work clearly shows the urgency of studying spatial manifestations of urban religion since religion cannot be seen as peripheral or even antithetical to the urban modernities and civic futures of cities in the global south, which is gradually embracing various digital interventions.", "spans": "[{\"corpusId\": \"55805833\", \"span\": \"[123]\", \"start\": 520, \"end\": 525}, {\"corpusId\": \"142389796\", \"span\": \"[28]\", \"start\": 946, \"end\": 950}, {\"corpusId\": \"55704694\", \"span\": \"[133]\", \"start\": 1188, \"end\": 1193}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "20833", "title": "Gospels of Modernity: Digital Cattle Markets, Urban Religiosity, and Secular Computing in the Global South", "sectionTitle": "HCI and Religion", "text": "straightforward marketplace applications, and the popularity of social media platforms have made selling and buying products and services online a widely prevalent practice in the urban regions of the country [70,120,140]. Thus, a large portion of the population is actively participating in this new mode of the digital economy. Thousands of products and services are being published, promoted, and purchased over various online platforms ranging from government-developed websites to personal Facebook pages of the sellers [20,66,100]. One of the newest additions of this trend is the digitization of the 'physical' cattle markets (traditionally held in the urban areas during Eid), which has received signifcant attention in Bangladesh recently. Such transformations often engender many socio-cultural tensions and put the efort of digitizing the countries in the Global South into question. While a rich body of literature in Human-Computer Interaction (HCI), Information and Communication Technology and Development (ICTD), and related felds has focused on diferent aspects of digital marketplaces [36,50,59,101], very few studies have been conducted in the context of the Global South [42,104,131]. Hence, how these digital marketplaces impact various cultural dimensions there, has hardly appeared in HCI literature. In this paper, we address this gap by studying the digitization of cattle markets in Dhaka, Bangladesh, and report its multi-faceted impacts on the social, cultural, and political dimensions of urban Bangladesh.", "spans": "[{\"corpusId\": 233987774, \"span\": \"this paper\", \"start\": 1337, \"end\": 1337}, {\"corpusId\": \"148180870\", \"span\": \"\", \"start\": 15224, \"end\": 15228}, {\"corpusId\": \"2394201\", \"span\": \"\", \"start\": 15228, \"end\": 15232}, {\"corpusId\": \"8267742\", \"span\": \"\", \"start\": 15232, \"end\": 15236}, {\"corpusId\": \"11731762\", \"span\": \"\", \"start\": 15538, \"end\": 15543}, {\"corpusId\": \"221348896\", \"span\": \"\", \"start\": 15688, \"end\": 15693}, {\"corpusId\": \"17247053\", \"span\": \"\", \"start\": 16136, \"end\": 16141}, {\"corpusId\": \"140288090\", \"span\": \"\", \"start\": 16181, \"end\": 16186}, {\"corpusId\": \"218482534\", \"span\": \"\", \"start\": 16973, \"end\": 16978}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "20834", "title": "Gospels of Modernity: Digital Cattle Markets, Urban Religiosity, and Secular Computing in the Global South", "sectionTitle": "HCI and Religion", "text": "The studies mentioned above inform HCI of the need for exploring religious values, socio-cultural-religious norms, active participation of religious groups with technologies, and their evolved religious practices and lifestyles. This work, situated in an urban setting of Bangladesh, essentially represents a tension between tradition and modernity -a story that may have a resonance in many other places, too. This tension situates itself in Bangladesh through a historical trajectory of 'otherness' -while a part of this is formed by the contemporary manifestation of socio-religiosity, it is also comprised of the history of colonization, modernization, NGO-ization, and industrialization. Thus the message of this paper, in spirit, aligns with the postcolonial computing movement in HCI that critically examines the 'misplaced' and 'displaced' values through design [19,74,128].", "spans": "[{\"corpusId\": \"226511913\", \"span\": \"\", \"start\": -16772, \"end\": -16768}, {\"corpusId\": \"169205193\", \"span\": \"\", \"start\": -16768, \"end\": -16764}, {\"corpusId\": 233987774, \"span\": \"This work\", \"start\": 238, \"end\": 238}, {\"corpusId\": 233987774, \"span\": \"this paper\", \"start\": 723, \"end\": 723}, {\"corpusId\": \"15630273\", \"span\": \"[19,\", \"start\": 870, \"end\": 874}, {\"corpusId\": \"3128663\", \"span\": \"74,\", \"start\": 874, \"end\": 877}, {\"corpusId\": \"140288090\", \"span\": \"128]\", \"start\": 877, \"end\": 881}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "20835", "title": "Gospels of Modernity: Digital Cattle Markets, Urban Religiosity, and Secular Computing in the Global South", "sectionTitle": "DIGITIZATION OF CATTLE MARKET", "text": "Bangladesh, being an agrarian economy, put additional emphasis on the digitization of agricultural markets at the governmental and non-governmental level. In many cases, agricultural sectors entered the digital world through supermarkets' websites. Meat and dairy products gained additional attention among the higher-middle income and high-income urban population, who prefer hassle-free delivery services at home. In 2013 during Eid ul Adha, several ecommerce sites such as bikroy. , and many other business companies have come up with additional Qurbani services such as slaughtering, meat processing, and home delivery of packaged meat of the sacrifcial animal.", "spans": "[{\"corpusId\": \"14824740\", \"span\": \"\", \"start\": -24939, \"end\": -24935}, {\"corpusId\": \"52176328\", \"span\": \"\", \"start\": -24935, \"end\": -24932}, {\"corpusId\": \"4868043\", \"span\": \"\", \"start\": -24932, \"end\": -24929}, {\"corpusId\": \"3510415\", \"span\": \"\", \"start\": -24929, \"end\": -24925}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "20836", "title": "Gospels of Modernity: Digital Cattle Markets, Urban Religiosity, and Secular Computing in the Global South", "sectionTitle": "DIGITIZATION OF CATTLE MARKET", "text": "In 2020, due to the COVID-19 pandemic, the digitization of the cattle markets experienced a sudden boom during Eid ul Adha in August. Along with the existing front-end agricultural companies, established digital marketplaces (sheba.xyz, Daraz, eOrder, paoajay.com, etc.), and super shops, several new and small-scale business entrepreneurs started selling cattle heads on diferent digital platforms ranging from mobile phone applications to Facebook. To limit the spread of COVID-19 from physical cattle markets, the government also encouraged people to buy their sacrifcial animals online. Through a governmental website digitalhaat.net, 54 selected farms could sell their cattle heads. Through another website foodfornation.gov.bd [10]. individual farmers could upload images and information about their cattle heads and sell those online.", "spans": "[{\"corpusId\": \"13470074\", \"span\": \"\", \"start\": -25518, \"end\": -25514}, {\"corpusId\": \"189998675\", \"span\": \"\", \"start\": -25514, \"end\": -25510}, {\"corpusId\": \"5046823\", \"span\": \"\", \"start\": -25510, \"end\": -25506}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "20837", "title": "Gospels of Modernity: Digital Cattle Markets, Urban Religiosity, and Secular Computing in the Global South", "sectionTitle": "METHODS", "text": "In the frst phase, we concentrated on studying (i) sacrifcial animal production in rural Bangladesh, (ii) urban activities at traditional cattle markets in Dhaka city, and (iii) traditional religious performances of the urban dwellers during this religious festival of Eid ul Adha. To document sacrifcial animal production, mobilization, and marketing, we selected fve villages (Talgachi, Garadoho, Purantepri, Mushipur, and Barabil) of Sirajganj District, which were popular for raising cattle heads for Eid. After selecting these villages, the ethnographer reached out to people in her social network to access the farmers' communities in each of these villages. For each of these villages, we had more than one 'gatekeepers' [90]. The gatekeepers would live in those villages for at least ten years, and they were also connected to cattle farms and farmers' communities there. In these villages we interviewed 7 khamaris, 12 byaparis, and 14 individual farmers (8 men, 6 women). The age of these participants ranged from 22-50 yrs. Eleven among them never received any formal education. The interviews were semi-structured and were 30-40 minutes long on average. We asked them about their farm's business model, the impacts of digitization of the country on their farm, and their future plans, among others. We also asked the farmers about their cattle-raising processes and their experiences of staying in Dhaka for selling their cattle heads during Eid ul Adha. We observed and took note of the cattle-raising spaces and associated infrastructures as well. We then had fve focus group discussions with the farmers, political leaders (popularly known as 'Chairman'), and the byaparis. In these FGDs, we discussed how they worked together to arrange the \"chalan\" or supply of cattle heads before Eid, how the Chairmen infuenced the overall process, and how convenient mobile phone applications (Imo, Viber, What-sApp, etc.) were for the farmers, among others. The participants' ages ranged from 25-60 yrs. In total, 19 people participated in these 5 FGDs (4-8 participants in one group). Each FGD was 40 minutes long on average. Although female members of the farmers' families (who were directly involved with the cattle-raising process) participated in the individual interviews, they were not present in the FGDs following the village norms. Both the interviews and FGDs followed the local cultural norms. We kept studying the village farmhouses until our study reached a theoretical saturation [107].", "spans": "[{\"corpusId\": \"55632514\", \"span\": \"\", \"start\": -29003, \"end\": -29000}, {\"corpusId\": 233987774, \"span\": \"our study\", \"start\": 2467, \"end\": 2467}, {\"corpusId\": \"54593780\", \"span\": \"[107]\", \"start\": 2501, \"end\": 2506}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "20838", "title": "Gospels of Modernity: Digital Cattle Markets, Urban Religiosity, and Secular Computing in the Global South", "sectionTitle": "METHODS", "text": "The last segment of the frst phase included documenting the urban dwellers' traditional religious performances during Eid ul Adha. Since the ethnographer was born and raised in a Muslim family in Dhaka, she was familiar with the Qurbani rituals and urban engagements with this festival from her childhood. She visited, observed, and documented urban spatial transformations of six residential areas in Dhaka, including Arambag, Shantinagar, Shahjahanpur, Badda, Khilgaon, and Gulshan Niketon. We chose these areas to ensure socio-economic diversities in the study. On Eid day, we documented Qurbani rituals (from slaughtering to meat distribution) at six residential buildings in Arambag and Shantinagar residential areas. we also conducted short interviews with 1 Imam (leads Muslim worshipers in prayer in the local mosque, 35yrs old, male), 4 meat processors (26-35 yrs old, male, original occupation rickshaw pulling), and 6 needy meat collectors (21-40 yrs old, 2 male, 4 female, beggars) on the Eid day. As the last step of this phase, we conducted FGDs with 15 afuent Muslim families (2-5 adult members in each family, including men and women) from the above-mentioned residential areas. We approached all of them through our social network, and they participated voluntarily to share their experiences with us. We asked about their family traditions around this religious event, their urban engagements at neighborhood and city level during Eid, and the infuence of the emerging digital cattle markets on their ritual, among others. We conducted the FGDs after Eid day. The FGDs were 30-40 minutes long on average. In total, we had 20 male (age range 20-70 yrs) and 19 female (age range 22-57 yrs) participants for these family-level FGDs. We kept studying urban Muslim families until our study reached a theoretical saturation [107].", "spans": "[{\"corpusId\": \"143540362\", \"span\": \"\", \"start\": -32559, \"end\": -32555}, {\"corpusId\": 233987774, \"span\": \"our study\", \"start\": 1802, \"end\": 1802}, {\"corpusId\": \"54593780\", \"span\": \"[107]\", \"start\": 1836, \"end\": 1841}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "20839", "title": "Gospels of Modernity: Digital Cattle Markets, Urban Religiosity, and Secular Computing in the Global South", "sectionTitle": "METHODS", "text": "We conducted the second phase of our study (February 2020-August 2020) remotely amid the COVID-19 pandemic. The rules around social distancing, controlled mobilities, and other health regulations gave an impetus to the growing digital haat scenario in Bangladesh during Eid-ul-Adha in 2020.Hence, we essentially focused on documenting these digital marketplaces' impacts on urban Dhaka and beyond in the second phase of our study. This phase included (i) analyzing design details of digital haat websites (both governmental and non-governmental), (ii) observing and documenting comments, conversations, and debates on Facebook pages that were used as online trading platforms for cattle heads, (iii) conducting 15 semi-structured phone-interviews with online cattle sellers (6, men, 21-45 yrs old, 5 received formal education) and buyers (6 men, 3 women, age ranged from 25 to 53 yrs, working individuals). We approached our participants through our social network. Interviews were 20-30 minutes long and focused on the participants' experience around digital selling/shopping of Qurbani animals. We primarily selected the websites and Facebook pages we studied based on the recommendations of our interview participants. Later, from the comment sections of those Facebook pages, we came to know about more pages and websites, which were selling Qurbani animals during Eid ul Adha in 2020 2 . We kept studying the websites and Facebook pages until our study reached a theoretical saturation [107].", "spans": "[{\"corpusId\": \"1042556\", \"span\": \"\", \"start\": -34208, \"end\": -34204}, {\"corpusId\": \"145136159\", \"span\": \"\", \"start\": -34204, \"end\": -34201}, {\"corpusId\": \"10161542\", \"span\": \"\", \"start\": -34201, \"end\": -34198}, {\"corpusId\": \"158892979\", \"span\": \"\", \"start\": -34198, \"end\": -34194}, {\"corpusId\": \"207214926\", \"span\": \"\", \"start\": -34194, \"end\": -34190}, {\"corpusId\": 233987774, \"span\": \"our study\", \"start\": 42, \"end\": 42}, {\"corpusId\": 233987774, \"span\": \"our study\", \"start\": 429, \"end\": 429}, {\"corpusId\": 233987774, \"span\": \"our participants\", \"start\": 937, \"end\": 937}, {\"corpusId\": 233987774, \"span\": \"our interview\", \"start\": 1207, \"end\": 1207}, {\"corpusId\": 233987774, \"span\": \"our study\", \"start\": 1457, \"end\": 1457}, {\"corpusId\": \"54593780\", \"span\": \"[107]\", \"start\": 1491, \"end\": 1496}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "20840", "title": "Gospels of Modernity: Digital Cattle Markets, Urban Religiosity, and Secular Computing in the Global South", "sectionTitle": "Reduced visibility in Urban Media:", "text": "Case 6: Mr. Shohel (47, an individual farmer from Talgachhi village in Sirajganj) has been selling Qurbani animals in Dhaka for the last 20 years. However, from 2020 he has started selling his cows online since his younger brother says that the digital marketplace is the future of this business. Shohel sends the photos and essential information (breed, weight, age, etc.) of his cattle heads via Viber to his brother. His brother posts those photos and information on several online haat Facebook pages. Due to his limited digital literacy, Shohel entirely depended on his younger brother for selling cows online. Without even having a \"true\" conversation with a customer, Shohel sold his cows online during Eid of 2020. He was sitting at his \"dawa\" (veranda of a rural house) when middlemen from Dhaka came and picked his cows up from his small farm. Shohel is concerned about this type of online shopping, where no one acknowledges his contribution to this holy festival, and he becomes invisible. He says, \"I was interviewed by Somoy TV channel reporter in 2017, when I was in Dhaka, selling my cows at Gabtoli cattle market. That was one of the best days of my life.", "spans": "[{\"corpusId\": \"29407163\", \"span\": \"\", \"start\": -60455, \"end\": -60452}, {\"corpusId\": \"28206549\", \"span\": \"\", \"start\": -60452, \"end\": -60449}, {\"corpusId\": \"29438247\", \"span\": \"\", \"start\": -60449, \"end\": -60446}, {\"corpusId\": \"207214926\", \"span\": \"\", \"start\": -60446, \"end\": -60442}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "20841", "title": "Gospels of Modernity: Digital Cattle Markets, Urban Religiosity, and Secular Computing in the Global South", "sectionTitle": "Devaluation of a religious commodity", "text": "The cattle heads raised to sell for Qurbani (sacrifce) attain a religious value as per Islamic tradition. Hence, the sacrifcial animals are raised under the farmers' maximum supervision, handled and transported with care, provided with good quality food and medicine (if needed). The religious value of these animals gets transferred from the rural cattle seller to urban Muslim buyer as they interact at urban haats. Cattle head buyers continue to take care of their sacrifcial animals till the Eid day, which is considered as one of many religious instructions of this ritual. The majority of our rural participants complained that online cattle marketplaces fail to apprehend the religious value of a sacrifcial animal and quantifes each animal by some numerical terms, for example, price, live weight, height, and amount of meat can be processed out of it. This phenomenon sidelines the religious signifcance of a sacrifcial animal and converts it into a regular product available in online marketplaces.", "spans": "[{\"corpusId\": \"110409700\", \"span\": \"\", \"start\": -62313, \"end\": -62309}, {\"corpusId\": \"55568950\", \"span\": \"\", \"start\": -62306, \"end\": -62303}, {\"corpusId\": \"218482498\", \"span\": \"\", \"start\": -62303, \"end\": -62300}, {\"corpusId\": \"6254681\", \"span\": \"\", \"start\": -62300, \"end\": -62296}, {\"corpusId\": \"10889001\", \"span\": \"\", \"start\": -62296, \"end\": -62292}, {\"corpusId\": \"109050912\", \"span\": \"\", \"start\": -62292, \"end\": -62288}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "20842", "title": "Gospels of Modernity: Digital Cattle Markets, Urban Religiosity, and Secular Computing in the Global South", "sectionTitle": "Designing Digital Marketplaces", "text": "We argue that to make online marketplaces more diverse, inclusive, and sustainable, we must include the values and sentiments from religious groups in the design and development phases. For instance, in this case of online cattle markets, such inclusion should essentially be achieved by incorporating the religious sentiments of all the actors involved in various phases of Eid ul Adha's religious ritual (ranging from cattle production to sacrifce). As mentioned in our fndings, farmers raising sacrifcial animals should be provided with digital facilities that support them to express their spiritual attachment with their animals while making a sale online. Religious sentiments of the buyers should also be incorporated while designing such marketplaces to avoid doubts and spiritual dissatisfactions we documented in our feld study. The information needed for a product to sell online (i.e., images, description, review, price, etc.) should be carefully screened and published so that the users' personal beliefs or religious sentiments are not hurt. In other words, the transition, translation, or transformation of a physical marketplace into an online marketplace is an essential mode of this design, but that cannot be done at the expense of the religiosity that these communities hold high. Borrowing from Chandra et al.s' analysis of the digitization of informal marketplaces in the Global South [42], we also suggest that cultural practices (for instance, clientalization, bargaining, and testing) of a physical marketplace should be incorporated in the online market in a meaningful way to make the designs sustainable. Moreover, scholars and practitioners from diferent religious backgrounds should be involved in designing the framework of digital marketplaces to help defning the materiality of such online platforms. They can provide important suggestions on which products or commodities can be sold online and how, without hampering their religious signifcance. Such 'religious' transformation is still largely missing in digital marketplace design.", "spans": "[{\"corpusId\": \"207191655\", \"span\": \"\", \"start\": -67329, \"end\": -67325}, {\"corpusId\": \"110021325\", \"span\": \"\", \"start\": -67322, \"end\": -67319}, {\"corpusId\": \"13470074\", \"span\": \"[42]\", \"start\": 1408, \"end\": 1412}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "20843", "title": "Gospels of Modernity: Digital Cattle Markets, Urban Religiosity, and Secular Computing in the Global South", "sectionTitle": "Designing Digital Marketplaces", "text": "We also argue that the design, development, and deployment of online marketplace need to be analyzed with respect to the seller's and consumer's relative positions in the broader non-secular political contexts, where needed. For instance, social media technologies (Instagram, Facebook pages, Lives, etc.) for promoting and selling commodities online should provide multi-modal options through which sellers can more actively engage with the market system without any fear of being judged or ridiculed. Designs similar to IVR Junctions [132], text-free user interfaces [95], and CGNet Swara [94] can support the farmers with limited digital literacy to participate actively in the market system. Cutting-edge AR and VR technologies have made signifcant progress in providing the users with some sort of 'tacit' feeling of an object remotely and developing empathy [22,61,64]. Similar technologies could be extended to allow religious communities to interact with the cattle sellers in a more intimate way. In addition, these online marketplaces should allow people to choose and buy religious commodities collectively (instead of its existing mode of 'individual buying'), when needed. Such technologies may help growing communal bonds which these communities value. Moreover, our fndings point toward the emergence of a new working group in the process of the digitization of cattle markets-the digital middleman (who collects sacrifcial animals from rural areas and delivers to urban buyers' houses or simply help the farmers to post advertisements of their cattle heads online). Proper integration of such services in design and development phases is essential to ensure the market system's overall permanence. Finally, more involvement of local government and political leaders in the online digital space should be ensured as well.", "spans": "[{\"corpusId\": \"6238696\", \"span\": \"[132]\", \"start\": 536, \"end\": 541}, {\"corpusId\": \"984396\", \"span\": \"[95]\", \"start\": 569, \"end\": 573}, {\"corpusId\": \"218483271\", \"span\": \"[94]\", \"start\": 591, \"end\": 595}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "20844", "title": "Gospels of Modernity: Digital Cattle Markets, Urban Religiosity, and Secular Computing in the Global South", "sectionTitle": "HCI and Rural-Urban Linkages", "text": "Our study shows how all these connections between the rural and urban regions start to disappear as online cattle markets emerge. Many established lines of work in HCI and ICTD explore how digital divides between the rural and the urban are engendered from uneven distributions of digital literacy, afordability, infrastructural support, etc. [19,41,80,97,112,136] However, how computational interventions contribute to dividing, disconnecting, or detaching the rural from the urban culturally and politically, is still largely understudied. This paper depicts some ramifcations of such computing praxis and argues that conceptualization of the complex rural-urban linkages is essential in HCI and ICTD studies to develop more inclusive, diverse, and 'just' design strategies.", "spans": "[{\"corpusId\": 233987774, \"span\": \"Our study\", \"start\": 9, \"end\": 9}, {\"corpusId\": \"15630273\", \"span\": \"[19,\", \"start\": 343, \"end\": 347}, {\"corpusId\": \"205267937\", \"span\": \"41,\", \"start\": 347, \"end\": 350}, {\"corpusId\": \"62213927\", \"span\": \"112,\", \"start\": 356, \"end\": 360}, {\"corpusId\": \"3288587\", \"span\": \"136]\", \"start\": 360, \"end\": 364}, {\"corpusId\": 233987774, \"span\": \"This paper\", \"start\": 552, \"end\": 552}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "20845", "title": "Gospels of Modernity: Digital Cattle Markets, Urban Religiosity, and Secular Computing in the Global South", "sectionTitle": "HCI and the Non-secular Urban", "text": "Our study builds on critical urban theories around modernism and secularism to develop a deeper understanding of the relationship between HCI and religious values in an urban context. Our data show how our participants were experiencing a reduction of religious visibility, sensitivity, and performativity in diferent socioeconomic contexts of their urban lives in both the physical and online worlds. One of the popular strands of critical urban theory explains such reduction of religiosity as modernism's limitation to comprehend the complex entanglements of religion in the lives of urban dwellers. Our fndings are aligned with this line of critical work by various scholars (inter alia, AbdouMaliq Simone [123], Ara Wilson [133], Hancock [58], and Parthasarathy [108]), who critically address how scientifc tools and techniques reinforce a 'simplifed' version of urban life that is stripped of its complex religious and political relationships, and suppress the growth of alternative religion-backed modernities in urban contexts, especially in the Global South. While urban scholars are bringing religion to the disciplinary conversations to subjugate modernism's limitations, HCI is still struggling to go beyond implementing the scientifc rationalities and modernist assumptions to address the contextual needs of diferent religious groups [128]. An emerging group of scholars have started shedding light on these limitations of HCI, and providing important design implications to overcome them [73,103,113,128].Our study joins this scholarship, and argues that the existing praxis of urban HCI, urban computing, and related felds seldom address the needs of diferent religious groups, and religiosity hardly gets mediated through urban spatial, political, and socio-cultural design within HCI. We believe that this is essential to include religiosity-backed urban spatial politics in HCI conversations, which will create novel avenues of research and design for HCI and ICTD scholarship. Several HCI design paradigms including Value Sensitive Design (VSD) and Participatory Design (PD) might be useful to make designs more inclusive of religious values and practices. The contribution of this paper is not exactly about the 'process' of design, but about understanding the nature of modernity that is being extended through the use of digital tools and techniques. Thus, this paper connects HCI literature on urban HCI to a rich thread of work in social science and STS around the criticism of scientifc modernity [88], epistemic pluralism in design [51], and the appropriation of material infrastructure in urban areas [43].", "spans": "[{\"corpusId\": \"3891480\", \"span\": \"\", \"start\": -72924, \"end\": -72920}, {\"corpusId\": \"17458661\", \"span\": \"\", \"start\": -72920, \"end\": -72917}, {\"corpusId\": 233987774, \"span\": \"Our study\", \"start\": 9, \"end\": 9}, {\"corpusId\": 233987774, \"span\": \"our participants\", \"start\": 218, \"end\": 218}, {\"corpusId\": \"55805833\", \"span\": \"[123]\", \"start\": 710, \"end\": 715}, {\"corpusId\": \"55704694\", \"span\": \"[133]\", \"start\": 728, \"end\": 733}, {\"corpusId\": \"143135374\", \"span\": \"[58]\", \"start\": 743, \"end\": 747}, {\"corpusId\": \"140288090\", \"span\": \"[128]\", \"start\": 1348, \"end\": 1353}, {\"corpusId\": \"218482534\", \"span\": \"103,\", \"start\": 1507, \"end\": 1511}, {\"corpusId\": \"221348896\", \"span\": \"113,\", \"start\": 1511, \"end\": 1515}, {\"corpusId\": \"140288090\", \"span\": \"128]\", \"start\": 1515, \"end\": 1519}, {\"corpusId\": 233987774, \"span\": \"Our study\", \"start\": 1529, \"end\": 1529}, {\"corpusId\": 233987774, \"span\": \"this paper\", \"start\": 2207, \"end\": 2207}, {\"corpusId\": 233987774, \"span\": \"this paper\", \"start\": 2390, \"end\": 2390}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "20846", "title": "Gospels of Modernity: Digital Cattle Markets, Urban Religiosity, and Secular Computing in the Global South", "sectionTitle": "LIMITATIONS AND FUTURE WORK", "text": "Our study took place in Dhaka, the capital of Bangladesh that represents Dhaka's culture around the haat activities, which are diferent in many ways from the other urban areas of the country. This study also does not cover the experiences of other religious groups of the city during Eid ul Adha, especially the Hindu Communities. The urban cattle markets are usually extremely male-dominated spaces, and women purchasers are less welcomed in the haats. However, our study did not include a gendered lens to analyze urban public space and how digital cattle markets could help women avoid gender-based spatial discrimination. Furthermore, the fndings of our study are limited within the participants that we chose through our social network and convenience. Hence, we refrain from any generalization of our fndings beyond the studied setting. We rather focus on the strength of such ethnographic studies in the richness of the details and depth of data. By using critical interpretative tools in our analysis, we have presented a deep meaning of the observed practices in our feld sites. We hope to expand and deepen our fndings in future with an extended engagement with the community.", "spans": "[{\"corpusId\": \"6504971\", \"span\": \"\", \"start\": -75354, \"end\": -75350}, {\"corpusId\": \"15288292\", \"span\": \"\", \"start\": -75350, \"end\": -75347}, {\"corpusId\": \"107461934\", \"span\": \"\", \"start\": -75347, \"end\": -75344}, {\"corpusId\": \"3903875\", \"span\": \"\", \"start\": -75344, \"end\": -75341}, {\"corpusId\": \"57269397\", \"span\": \"\", \"start\": -75341, \"end\": -75338}, {\"corpusId\": \"14805710\", \"span\": \"\", \"start\": -75338, \"end\": -75334}, {\"corpusId\": \"67871807\", \"span\": \"\", \"start\": -75334, \"end\": -75330}, {\"corpusId\": 233987774, \"span\": \"Our study\", \"start\": 9, \"end\": 9}, {\"corpusId\": 233987774, \"span\": \"This study\", \"start\": 202, \"end\": 202}, {\"corpusId\": 233987774, \"span\": \"our study\", \"start\": 472, \"end\": 472}, {\"corpusId\": 233987774, \"span\": \"our study\", \"start\": 663, \"end\": 663}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 8}], "paragraphCount": 17}
{"paperId": "b896b846ae180d804c7290d8b9ae9ffc55325866", "title": "Language-agnostic BERT Sentence Embedding", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2020, "citationCount": 1076, "openAccessPdf": {"url": "https://aclanthology.org/2022.acl-long.62.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2007.01852, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2020-07-03", "authors": [{"authorId": "3129590", "name": "Fangxiaoyu Feng"}, {"authorId": "2118771180", "name": "Yinfei Yang"}, {"authorId": "46724030", "name": "Daniel Matthew Cer"}, {"authorId": "3365231", "name": "N. Arivazhagan"}, {"authorId": "2158624629", "name": "Wei Wang"}], "abstract": "While BERT is an effective method for learning monolingual sentence embeddings for semantic similarity and embedding based transfer learning BERT based cross-lingual sentence embeddings have yet to be explored. We systematically investigate methods for learning multilingual sentence embeddings by combining the best methods for learning monolingual and cross-lingual representations including: masked language modeling (MLM), translation language modeling (TLM), dual encoder translation ranking, and additive margin softmax. We show that introducing a pre-trained multilingual language model dramatically reduces the amount of parallel training data required to achieve good performance by 80%. Composing the best of these methods produces a model that achieves 83.7% bi-text retrieval accuracy over 112 languages on Tatoeba, well above the 65.5% achieved by LASER, while still performing competitively on monolingual transfer learning benchmarks. Parallel data mined from CommonCrawl using our best model is shown to train competitive NMT models for en-zh and en-de. We publicly release our best multilingual sentence embedding model for 109+ languages at https://tfhub.dev/google/LaBSE.", "corpusId": "220347683", "paragraphs": [{"paragraphId": "47461", "title": "Language-agnostic BERT Sentence Embedding\u00a0", "sectionTitle": "Introduction", "text": "In this paper, we systematically explore using pretraining language models in combination with the best of existing methods for learning cross-lingual sentence embeddings. Such embeddings are useful for clustering, retrieval, and modular use of text representations for downstream tasks. While existing cross-lingual sentence embedding models incorporate large transformer models, using large pretrained language models is not well explored. Rather in prior work, encoders are trained directly on translation pairs (Artetxe and Schwenk, 2019b;Guo et al., 2018;Yang et al., 2019a), or on translation pairs combined with monolingual inputresponse prediction (Chidambaram et al., 2019;Yang et al., 2019b). In our exploration, as illustrated in figure 1, we make use of dual-encoder models, which have been demonstrated as an effective approach for learning bilingual sentence embeddings (Guo et al., 2018;Yang et al., 2019a). However, diverging from prior work, rather than training encoders from scratch, we investigate using pre-trained encoders based on large language models. We contrast models with and without additive margin softmax (Yang et al., 2019a) 1 . Figure 2 illustrates where our work stands (shaded) in the field of LM pre-training and sentence embedding learning.", "spans": "[{\"corpusId\": 220347683, \"span\": \"this paper\", \"start\": 13, \"end\": 13}, {\"corpusId\": 56895585, \"span\": \"(Artetxe and Schwenk, 2019b;\", \"start\": 515, \"end\": 543}, {\"corpusId\": 67855880, \"span\": \"Yang et al., 2019a)\", \"start\": 560, \"end\": 579}, {\"corpusId\": 53111724, \"span\": \"(Chidambaram et al., 2019;\", \"start\": 656, \"end\": 682}, {\"corpusId\": 67855880, \"span\": \"Yang et al., 2019a)\", \"start\": 902, \"end\": 921}, {\"corpusId\": 67855880, \"span\": \"(Yang et al., 2019a)\", \"start\": 1137, \"end\": 1157}, {\"corpusId\": 220347683, \"span\": \"our work\", \"start\": 1197, \"end\": 1197}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "47462", "title": "Language-agnostic BERT Sentence Embedding\u00a0", "sectionTitle": "Introduction", "text": "Our massively multilingual models outperform the previous state-of-the-art on large bi-text retrieval tasks including the United Nations (UN)  corpus (Ziemski et al., 2016) and BUCC (Zweigenbaum et al., 2018). Table 1 compares our best model with other recent multilingual work. Both the UN corpus and BUCC cover resource rich languages (fr, de, es, ru, and zh). We further evaluate our models on the Tatoeba retrieval task (Artetxe and Schwenk, 2019b) that covers 112 languages. Compare to LASER (Artetxe and Schwenk, 2019b), our models perform significantly better on low-resource languages, boosting the overall accuracy on 112 languages to 83.7%, from the 65.5% achieved by the previous state-of-art. Surprisingly, we observe our models performs well on 30+ Tatoeba languages for which we have no explicit monolingual or bilingual training data. Finally, our embeddings perform competitively on the SentEval sentence embedding transfer learning benchmark (Conneau and Kiela, 2018).", "spans": "[{\"corpusId\": 11644625, \"span\": \"(Ziemski et al., 2016)\", \"start\": 150, \"end\": 172}, {\"corpusId\": 43282987, \"span\": \"(Zweigenbaum et al., 2018)\", \"start\": 182, \"end\": 208}, {\"corpusId\": 56895585, \"span\": \"(Artetxe and Schwenk, 2019b\", \"start\": 424, \"end\": 451}, {\"corpusId\": 56895585, \"span\": \"(Artetxe and Schwenk, 2019b)\", \"start\": 497, \"end\": 525}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "47463", "title": "Language-agnostic BERT Sentence Embedding\u00a0", "sectionTitle": "Downstream Classification", "text": "We also evaluate the transfer performance of multilingual sentence embeddings on downstream classification tasks from the SentEval benchmark (Conneau and Kiela, 2018). We evaluate on select tasks from SentEval including: (MR) movie reviews (Pang and Lee, 2005)), (SST) sentiment 14 About 9.5 million after de-duping. 15 Reranking models can further improve performance (e.g. margin based scorers (Artetxe and Schwenk, 2019a) and BERT based classifiers (Yang et al., 2019a)). However, this is tangential to assessing the raw embedding retrieval performance.", "spans": "[{\"corpusId\": 3264224, \"span\": \"(Pang and Lee, 2005)\", \"start\": 240, \"end\": 260}, {\"corpusId\": 53217060, \"span\": \"(Artetxe and Schwenk, 2019a)\", \"start\": 396, \"end\": 424}, {\"corpusId\": 67855880, \"span\": \"(Yang et al., 2019a)\", \"start\": 452, \"end\": 472}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "47464", "title": "Language-agnostic BERT Sentence Embedding\u00a0", "sectionTitle": "Downstream Classification", "text": "analysis (Socher et al., 2013), (TREC) questiontype (Voorhees and Tice, 2000), (CR) product reviews (Hu and Liu, 2004), (SUBJ) subjectivity/objectivity (Pang and Lee, 2004), (MPQA) opinion polarity (Wiebe et al., 2005), and (MRPC) paraphrasing detection (Dolan et al., 2004). While SentEval is English only, we make use of this benchmark in order to directly compare to prior work on sentence embedding models. Table 2 shows the performance on the UN and Tatoeba bitext retrieval tasks and compares against the prior state-of-the-art bilingual models Yang et al. (2019a), LASER (Artetxe and Schwenk, 2019b), and the multilingual universal sentence encoder (m-USE) (Yang et al., 2019b) 16 . Row 1-3 show the performance of baseline models, as reported in the original papers.", "spans": "[{\"corpusId\": 990233, \"span\": \"(Socher et al., 2013)\", \"start\": 9, \"end\": 30}, {\"corpusId\": 207155218, \"span\": \"(Hu and Liu, 2004)\", \"start\": 100, \"end\": 118}, {\"corpusId\": 388, \"span\": \"(Pang and Lee, 2004)\", \"start\": 152, \"end\": 172}, {\"corpusId\": 67855880, \"span\": \"Yang et al. (2019a)\", \"start\": 551, \"end\": 570}, {\"corpusId\": 56895585, \"span\": \"(Artetxe and Schwenk, 2019b)\", \"start\": 578, \"end\": 606}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "47465", "title": "Language-agnostic BERT Sentence Embedding\u00a0", "sectionTitle": "Mining Parallel Text from CommonCrawl", "text": "We use the LaBSE model to mine parallel text from CommonCrawl, a large-scale multilingual web corpus, and then train NMT models on the mined data. We experiment with two language pairs: English-to-Chinese (en-zh) and English-to-German (en-de). We mine translations from monolingual CommonCrawl data processed as described above for self-supervised MLM pretraining. After processing, there are 1.17B, 0.6B, 7.73B sentences for Chinese (zh), German (de), and English (en), respectively. LaBSE embeddings are used to pair each non-English sentence with its nearest English neighbor, dropping pairs with a similarity score < 0.6. 20 For en-de and en-zh, we train a model with Transformer-Big (Vaswani et al., 2017) in the following way: First we train the model on the mined data as is for 120k steps with batch size 10k. Then we select the best 20% using Wang  Results in table 7 show the effectiveness of the mined training data. By referencing previous results (Edunov et al., 2018), we see that the model using the en-de mined data yields performance that is only 2.8 BLEU away from performance of the best system that made use of the official WMT17 en-de parallel data. Compare to prior en-zh results (Sennrich et al., 2017), we see that our model using mined en-zh training data is as good as a WMT17 NMT model that is trained on the official WMT en-zh parallel data. The table also gives BLEU performance on the TED test set (Qi et al., 2018), with performance of models trained on our mined training data being comparable with models trained using CCMatrix (Schwenk et al., 2019). 21", "spans": "[{\"corpusId\": 13756489, \"span\": \"(Vaswani et al., 2017)\", \"start\": 688, \"end\": 710}, {\"corpusId\": 215827207, \"span\": \"(Sennrich et al., 2017)\", \"start\": 1202, \"end\": 1225}, {\"corpusId\": 4929974, \"span\": \"(Qi et al., 2018)\", \"start\": 1428, \"end\": 1445}, {\"corpusId\": 207863306, \"span\": \"(Schwenk et al., 2019)\", \"start\": 1561, \"end\": 1583}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 5}
{"paperId": "4988a269e9f61c6fd1da502e34648b93dfd1a54d", "title": "Collective Entity Resolution with Multi-Focal Attention", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2016, "citationCount": 107, "openAccessPdf": {"url": "https://doi.org/10.18653/v1/p16-1059", "status": "BRONZE", "license": null, "disclaimer": "Notice: Paper or abstract available at https://aclanthology.org/P16-1059, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2016-08-01", "authors": [{"authorId": "1786843", "name": "A. Globerson"}, {"authorId": "2849560", "name": "N. Lazic"}, {"authorId": "40941894", "name": "Soumen Chakrabarti"}, {"authorId": "1726492", "name": "A. Subramanya"}, {"authorId": "2895331", "name": "Michael Ringgaard"}, {"authorId": "145366908", "name": "Fernando C Pereira"}], "abstract": "Entity resolution is the task of linking each mention of an entity in text to the corresponding record in a knowledge base (KB). Coherence models for entity resolution encourage all referring expressions in a document to resolve to entities that are related in the KB. We explore attention-like mechanisms for coherence, where the evidence for each candidate is based on a small set of strong relations, rather than relations to all other entities in the document. The rationale is that document-wide support may simply not exist for non-salient entities, or entities not densely connected in the KB. Our proposed sys-tem outperforms state-of-the-art systems on the CoNLL 2003, TAC KBP 2010, 2011 and 2012 tasks.", "corpusId": "17507793", "paragraphs": [{"paragraphId": "40335", "title": "Collective Entity Resolution with Multi-Focal Attention", "sectionTitle": "Introduction", "text": "Entity resolution (ER) is the task of mapping mentions of entities in text to corresponding records in a knowledge base (KB) (Bunescu and Pasca, 2006;Cucerzan, 2007;Kulkarni et al., 2009;Dredze et al., 2010;Hoffart et al., 2011;Hachey et al., 2013). ER is a challenging problem because mentions are often ambiguous on their own, and can only be resolved given appropriate context. For example, the mention Beirut may refer to the capital of Lebanon, the band from New Mexico, or a drinking game (Figure 1). Names may also refer to entities that are not in the KB, a problem known as NIL detection.", "spans": "[{\"corpusId\": 588986, \"span\": \"(Bunescu and Pasca, 2006;\", \"start\": 125, \"end\": 150}, {\"corpusId\": 7577640, \"span\": \"Cucerzan, 2007;\", \"start\": 150, \"end\": 165}, {\"corpusId\": 1632184, \"span\": \"Kulkarni et al., 2009;\", \"start\": 165, \"end\": 187}, {\"corpusId\": 6216506, \"span\": \"Hoffart et al., 2011;\", \"start\": 207, \"end\": 228}, {\"corpusId\": 12263057, \"span\": \"Hachey et al., 2013)\", \"start\": 228, \"end\": 248}]", "conference": "acl", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "40336", "title": "Collective Entity Resolution with Multi-Focal Attention", "sectionTitle": "Introduction", "text": "Most ER systems consist of a mention model, a context model, and a coherence model (Milne and Witten, 2008;Cucerzan, 2007;Ratinov et al., * Currently at Tel Aviv University \u2020 Currently at IIT Bombay 2011; Hoffart et al., 2011;Hachey et al., 2013). The mention model associates each entity with its possible textual representations (also known as aliases or surface forms). The context model helps resolve an ambiguous mention using textual features extracted from the surrounding context. The coherence model, the focus of this work, encourages all mentions to resolve to entities that are related to each other. Relations may be established via the KB, Web links, embeddings, or other resources.", "spans": "[{\"corpusId\": 207170378, \"span\": \"(Milne and Witten, 2008;\", \"start\": 83, \"end\": 107}, {\"corpusId\": 7577640, \"span\": \"Cucerzan, 2007;\", \"start\": 107, \"end\": 122}, {\"corpusId\": 6430811, \"span\": \"Ratinov et al.\", \"start\": 122, \"end\": 136}, {\"corpusId\": 6216506, \"span\": \"Hoffart et al., 2011;\", \"start\": 205, \"end\": 226}, {\"corpusId\": 12263057, \"span\": \"Hachey et al., 2013)\", \"start\": 226, \"end\": 246}, {\"corpusId\": 17507793, \"span\": \"this work\", \"start\": 532, \"end\": 532}]", "conference": "acl", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 6}, {"paragraphId": "40337", "title": "Collective Entity Resolution with Multi-Focal Attention", "sectionTitle": "Introduction", "text": "Our system uses mention and context models similar to those of Lazic et al. (2015), along with our novel multi-focal attention model to enforce coherence, leading to significant performance improvements on CoNLL 2003 (Hoffart et al., 2011) and TAC KBP 2010-2012 tasks (Ji et al., 2010;Ji et al., 2011;Mayfield et al., 2012). In particular, we achieve a 20% relative reduction in error from Chisholm and Hachey (2015) on CoNLL, and a 22% error reduction from Cucerzan (2012) on TAC 2012. Our contributions thus consist of defining a novel multi-focal attention model and applying it successfully to an entity resolution system.", "spans": "[{\"corpusId\": 17507793, \"span\": \"Our system\", \"start\": 10, \"end\": 10}, {\"corpusId\": 2061341, \"span\": \"Lazic et al. (2015)\", \"start\": 63, \"end\": 82}, {\"corpusId\": 6216506, \"span\": \"(Hoffart et al., 2011)\", \"start\": 217, \"end\": 239}, {\"corpusId\": 854997, \"span\": \"(Ji et al., 2010;\", \"start\": 268, \"end\": 285}, {\"corpusId\": 854997, \"span\": \"Ji et al., 2011;\", \"start\": 285, \"end\": 301}, {\"corpusId\": 854997, \"span\": \"Mayfield et al., 2012)\", \"start\": 301, \"end\": 323}, {\"corpusId\": 10523208, \"span\": \"Chisholm and Hachey (2015)\", \"start\": 390, \"end\": 416}]", "conference": "acl", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "40338", "title": "Collective Entity Resolution with Multi-Focal Attention", "sectionTitle": "Definitions and notation", "text": "Similarly to previous work, our approach to disambiguation relies on local and pairwise candidate scores, which we denote by s i (y i ) and s ij (y i , y j ) respectively. The local score is based only on local evidence, such as the mention phrase and textual features, while the pairwise score is based on the relatedness of the two candidates. In Sections 3.2 and 3.3 we discuss how these scores may be parameterized and learned. Many systems (Cucerzan, 2007;Milne and Witten, 2008;Kulkarni et al., 2009) simply hardwire pairwise scores.", "spans": "[{\"corpusId\": 17507793, \"span\": \"our approach\", \"start\": 40, \"end\": 40}, {\"corpusId\": 7577640, \"span\": \"(Cucerzan, 2007;\", \"start\": 445, \"end\": 461}, {\"corpusId\": 207170378, \"span\": \"Milne and Witten, 2008;\", \"start\": 461, \"end\": 484}, {\"corpusId\": 1632184, \"span\": \"Kulkarni et al., 2009\", \"start\": 484, \"end\": 505}]", "conference": "acl", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "40339", "title": "Collective Entity Resolution with Multi-Focal Attention", "sectionTitle": "Coherence scores", "text": "Several systems (Milne and Witten, 2008;Kulkarni et al., 2009;Hoffart et al., 2011) use the \"Milne and Witten\" measure for relatedness between a pair of entities, which is based on the number of Wikipedia articles citing each entity page, and the number of articles citing both; Cucerzan (2007) has also relied on the Wikipedia category structure. Internal links from one entity page to another in Wikipedia also provide direct evidence of relatedness between them. Another (possibly more noisy) source of information are Web pages containing links (Singh et al., 2012) to Wikipedia pages of both entities. Such links have been used in several recent systems (Cheng and Roth, 2013;Chisholm and Hachey, 2015). Yamada et al. (2016) train embedding vectors for entities, and use them to define similarities.", "spans": "[{\"corpusId\": 207170378, \"span\": \"(Milne and Witten, 2008;\", \"start\": 16, \"end\": 40}, {\"corpusId\": 1632184, \"span\": \"Kulkarni et al., 2009;\", \"start\": 40, \"end\": 62}, {\"corpusId\": 6216506, \"span\": \"Hoffart et al., 2011)\", \"start\": 62, \"end\": 83}, {\"corpusId\": 17784265, \"span\": \"(Cheng and Roth, 2013;\", \"start\": 659, \"end\": 681}, {\"corpusId\": 10523208, \"span\": \"Chisholm and Hachey, 2015)\", \"start\": 681, \"end\": 707}]", "conference": "acl", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "40340", "title": "Collective Entity Resolution with Multi-Focal Attention", "sectionTitle": "Collective inference for ER", "text": "Optimizing most global coherence objectives is intractable. Milne and Witten (2008) and Ferragina and Scaiella (2010) decompose the problem over mentions and select the candidate that maximizes their relatedness score, which includes relations to all other mentions. Hoffart et al. (2011) use an iterative heuristic to remove unpromising mentionentity edges. Cucerzan (2007) creates a relation vector for each candidate, and disambiguates each entity to the candidate whose vector is most similar to the aggregate (which includes both correct and incorrect labels). Cheng and Roth (2013) use an integer linear program solver and Kulkarni et al. (2009) use a convex relaxation. Ratinov et al. (2011) use relation scores as features in a ranking SVM. Belief propagation without attention has been used by Ganea et al. (2015). Personalized PageRank (PPR) (Jeh and Widom, 2003) is another tractable alternative, adopted by several recent systems (Han and Sun, 2011;He et al., 2013;Alhelbawy and Gaizauskas, 2014;Pershina et al., 2015). Laplacian smoothing (Huang et al., 2014) is closely related.", "spans": "[{\"corpusId\": 207170378, \"span\": \"Milne and Witten (2008)\", \"start\": 60, \"end\": 83}, {\"corpusId\": 6216506, \"span\": \"Hoffart et al. (2011)\", \"start\": 267, \"end\": 288}, {\"corpusId\": 17784265, \"span\": \"Cheng and Roth (2013)\", \"start\": 566, \"end\": 587}, {\"corpusId\": 1632184, \"span\": \"Kulkarni et al. (2009)\", \"start\": 629, \"end\": 651}, {\"corpusId\": 6430811, \"span\": \"Ratinov et al. (2011)\", \"start\": 677, \"end\": 698}, {\"corpusId\": 14297281, \"span\": \"(Jeh and Widom, 2003)\", \"start\": 852, \"end\": 873}, {\"corpusId\": 1662965, \"span\": \"(Han and Sun, 2011;\", \"start\": 942, \"end\": 961}, {\"corpusId\": 7512771, \"span\": \"He et al., 2013;\", \"start\": 961, \"end\": 977}, {\"corpusId\": 17826594, \"span\": \"Alhelbawy and Gaizauskas, 2014;\", \"start\": 977, \"end\": 1008}, {\"corpusId\": 14186198, \"span\": \"Pershina et al., 2015)\", \"start\": 1008, \"end\": 1030}, {\"corpusId\": 8963258, \"span\": \"(Huang et al., 2014)\", \"start\": 1052, \"end\": 1072}]", "conference": "acl", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 11}, {"paragraphId": "40341", "title": "Collective Entity Resolution with Multi-Focal Attention", "sectionTitle": "Attention models", "text": "Attention models have shown great promise in several applications, including machine translation (Bahdanau et al., 2014) and image caption generation (Xu et al., 2015). We address a new application of attention, and introduce a significantly different attention mechanism, which allows each variable to focus on multiple objects. We develop a novel smooth version of the multi-focus attention function, which generalizes the single focus softmax-function. While some existing entity resolution systems (Jin et al., 2014;Lazic et al., 2015) may be viewed as having attention mechanisms, these are intended for single textual features and not readily extensible to structured inference. 6 Experiments 6.1 Evaluation data CoNLL: The CoNLL dataset (Hoffart et al., 2011) contains 1393 articles with about 34K mentions, and the standard performance metric is mention-averaged accuracy. The documents are partitioned into train, test-a and test-b. Like most authors, we report performance on the 231 test-b documents with 4483 linkable mentions.", "spans": "[{\"corpusId\": 640052, \"span\": \"(Jin et al., 2014;\", \"start\": 502, \"end\": 520}, {\"corpusId\": 2061341, \"span\": \"Lazic et al., 2015)\", \"start\": 520, \"end\": 539}, {\"corpusId\": 6216506, \"span\": \"(Hoffart et al., 2011)\", \"start\": 744, \"end\": 766}]", "conference": "acl", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 7}
{"paperId": "6bbbcb727af7964b05109629d7f05c0da8aa7130", "title": "LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2022, "citationCount": 164, "openAccessPdf": {"url": "https://aclanthology.org/2022.acl-long.534.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2202.13669, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2022-02-28", "authors": [{"authorId": "48094112", "name": "Jiapeng Wang"}, {"authorId": "144838978", "name": "Lianwen Jin"}, {"authorId": "2053138829", "name": "Kai Ding"}], "abstract": "Structured document understanding has attracted considerable attention and made significant progress recently, owing to its crucial role in intelligent document processing. However, most existing related models can only deal with the document data of specific language(s) (typically English) included in the pre-training collection, which is extremely limited. To address this issue, we propose a simple yet effective Language-independent Layout Transformer (LiLT) for structured document understanding. LiLT can be pre-trained on the structured documents of a single language and then directly fine-tuned on other languages with the corresponding off-the-shelf monolingual/multilingual pre-trained textual models. Experimental results on eight languages have shown that LiLT can achieve competitive or even superior performance on diverse widely-used downstream benchmarks, which enables language-independent benefit from the pre-training of document layout structure. Code and model are publicly available at https://github.com/jpWang/LiLT.", "corpusId": "247158521", "paragraphs": [{"paragraphId": "7490", "title": "LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding\u00a0", "sectionTitle": "Introduction", "text": "Recently, inspired by the rapid development of pre-trained language models of plain texts (Devlin et al., 2019;Liu et al., 2019b;Bao et al., 2020;Chi et al., 2021), many researches on structured document pre-training (Xu et al., , 2021aLi et al., 2021a,b,c;Appalaraju et al., 2021) have also * Corresponding author.", "spans": "[{\"corpusId\": 52967399, \"span\": \"(Devlin et al., 2019;\", \"start\": 90, \"end\": 111}, {\"corpusId\": 211572655, \"span\": \"Bao et al., 2020;\", \"start\": 129, \"end\": 146}, {\"corpusId\": 220525491, \"span\": \"Chi et al., 2021)\", \"start\": 146, \"end\": 163}, {\"corpusId\": 229923949, \"span\": \"(Xu et al., , 2021a\", \"start\": 217, \"end\": 236}, {\"corpusId\": 235592814, \"span\": \"Appalaraju et al., 2021)\", \"start\": 257, \"end\": 281}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "7491", "title": "LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding\u00a0", "sectionTitle": "Introduction", "text": "Based on this inspiration, in this paper, we propose a simple yet effective Language-independent Layout Transformer (LiLT) for structured document understanding. In our framework, the text and layout information are first decoupled and jointoptimized during pre-training, and then re-coupled for fine-tuning. To ensure that the two modalities have sufficient language-independent interaction, we further propose a novel bi-directional attention complementation mechanism (BiACM) to enhance the cross-modality cooperation. Moreover, we present the key point location (KPL) and crossmodal alignment identification (CAI) tasks, which are combined with the widely-used masked visual-language modeling (MVLM) to serve as our pretraining objectives. During fine-tuning, the layout flow (LiLT) can be separated and combined with the off-the-shelf pre-trained textual models (such as RoBERTa (Liu et al., 2019b), XLM-R (Conneau et al., 2020), InfoXLM (Chi et al., 2021), etc) to deal with the downstream tasks. In this way, our method decouples and learns the layout knowledge from the monolingual structured documents before generalizing it to the multilingual ones.", "spans": "[{\"corpusId\": 247158521, \"span\": \"this paper\", \"start\": 40, \"end\": 40}, {\"corpusId\": 247158521, \"span\": \"we propose\", \"start\": 52, \"end\": 52}, {\"corpusId\": 207880568, \"span\": \"(Conneau et al., 2020)\", \"start\": 911, \"end\": 933}, {\"corpusId\": 220525491, \"span\": \"(Chi et al., 2021)\", \"start\": 943, \"end\": 961}, {\"corpusId\": 247158521, \"span\": \"our method\", \"start\": 1026, \"end\": 1026}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "7492", "title": "LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding\u00a0", "sectionTitle": "Language-specific Fine-tuning", "text": "We first evaluate LiLT on four widely-used monolingual datasets -FUNSD (Jaume et al., 2019), CORD (Park et al., 2019), EPHOIE  and RVL-CDIP (Lewis et al., 2006), and the results are shown in Table 2, 3, 4 and 5. We have found that (1) LiLT is flexible since it can work with monolingual or multilingual plain text models to deal with downstream tasks.", "spans": "[{\"corpusId\": 173188931, \"span\": \"(Jaume et al., 2019)\", \"start\": 71, \"end\": 91}, {\"corpusId\": 207900784, \"span\": \"(Park et al., 2019)\", \"start\": 98, \"end\": 117}, {\"corpusId\": 19516087, \"span\": \"(Lewis et al., 2006)\", \"start\": 140, \"end\": 160}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "7493", "title": "LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding\u00a0", "sectionTitle": "Related Work", "text": "During the past decade, deep learning methods became the mainstream for document understanding tasks (Yang et al., 2017;Augusto Borges Oliveira et al., 2017;Siegel et al., 2018). Grid-based methods (Katti et al., 2018;Denk and Reisswig, 2019;Lin et al., 2021) were proposed for 2D document representation where text pixels were encoded using character or word embeddings and classified into specific field types, using a convolutional neural network. GNN-based approaches (Liu et al., 2019a;Yu et al., 2021;Tang et al., 2021) adopted multi-modal features of text segments as nodes to model the document graph, and used graph neural networks to propagate information between neighboring nodes to attain a richer representation.", "spans": "[{\"corpusId\": 2272015, \"span\": \"(Yang et al., 2017;\", \"start\": 101, \"end\": 120}, {\"corpusId\": 4741889, \"span\": \"Augusto Borges Oliveira et al., 2017;\", \"start\": 120, \"end\": 157}, {\"corpusId\": 4698432, \"span\": \"Siegel et al., 2018)\", \"start\": 157, \"end\": 177}, {\"corpusId\": 202558968, \"span\": \"Denk and Reisswig, 2019;\", \"start\": 218, \"end\": 242}, {\"corpusId\": 235187077, \"span\": \"Lin et al., 2021)\", \"start\": 242, \"end\": 259}, {\"corpusId\": 85528598, \"span\": \"(Liu et al., 2019a;\", \"start\": 472, \"end\": 491}, {\"corpusId\": 235623830, \"span\": \"Tang et al., 2021)\", \"start\": 507, \"end\": 525}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "7494", "title": "LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding\u00a0", "sectionTitle": "Related Work", "text": "In recent years, self-supervised pre-training has achieved great success. Inspired by the development of the pre-trained language models in various NLP tasks, recent studies on structured document pre-training (Xu et al., , 2021aLi et al., 2021a,b,c;Appalaraju et al., 2021) have pushed the limits. LayoutLM  modified the BERT (Devlin et al., 2019) architecture by adding 2D spatial coordinate embeddings. In comparison, our LiLT can be regarded as a more powerful and flexible solution for structured document understanding. LayoutLMv2 (Xu et al., 2021a) improved over LayoutLM by treating the visual fea-   tures as separate tokens. Furthermore, additional pre-training tasks were explored to improve the utilization of unlabeled document data. SelfDoc (Li et al., 2021b) established the contextualization over a block of content, while StructuralLM (Li et al., 2021a) proposed cell-level 2D position embeddings and the corresponding pre-training objective. Recently, StrucTexT (Li et al., 2021c) introduced a unified solution to efficiently extract semantic features from different levels and modalities to handle the entity labeling and entity linking tasks. Doc-Former (Appalaraju et al., 2021) designed a novel multi-modal self-attention layer capable of fusing textual, vision and spatial features. Nevertheless, the aforementioned SDU approaches mainly focus on a single language -typically English, which is extremely limited with respect to multilingual application scenarios. To the best of our knowledge, LayoutXLM (Xu et al., 2021b) was the only pre-existing multilingual SDU model, which adopted the multilingual textual model InfoXLM (Chi et al., 2021) as the initialization, and adapted the LayoutLMv2 (Xu et al., 2021a) framework to multilingual structured document pre-training. However, it required a heavy process of multilingual data collection, cleaning and pre-training. On the contrary, our LiLT can deal with the multilingual structured documents by pre-training on the monolingual IIT-CDIP Test Collection 1.0 (Lewis et al., 2006) only.", "spans": "[{\"corpusId\": 229923949, \"span\": \"(Xu et al., , 2021a\", \"start\": 210, \"end\": 229}, {\"corpusId\": 235592814, \"span\": \"Appalaraju et al., 2021)\", \"start\": 250, \"end\": 274}, {\"corpusId\": 52967399, \"span\": \"(Devlin et al., 2019)\", \"start\": 327, \"end\": 348}, {\"corpusId\": 229923949, \"span\": \"(Xu et al., 2021a)\", \"start\": 537, \"end\": 555}, {\"corpusId\": 235358528, \"span\": \"(Li et al., 2021b)\", \"start\": 755, \"end\": 773}, {\"corpusId\": 235166279, \"span\": \"(Li et al., 2021a)\", \"start\": 852, \"end\": 870}, {\"corpusId\": 236950714, \"span\": \"(Li et al., 2021c)\", \"start\": 980, \"end\": 998}, {\"corpusId\": 235592814, \"span\": \"(Appalaraju et al., 2021\", \"start\": 1174, \"end\": 1198}, {\"corpusId\": 220525491, \"span\": \"(Chi et al., 2021)\", \"start\": 1649, \"end\": 1667}, {\"corpusId\": 229923949, \"span\": \"(Xu et al., 2021a)\", \"start\": 1718, \"end\": 1736}, {\"corpusId\": 19516087, \"span\": \"(Lewis et al., 2006)\", \"start\": 2036, \"end\": 2056}]", "conference": "acl", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 8}], "paragraphCount": 5}
{"paperId": "2bde99745ed5650cc7c79117d2699da757c66ef9", "title": "Going Dark: Social Factors in Collective Action Against Platform Operators in the Reddit Blackout", "venue": "International Conference on Human Factors in Computing Systems", "year": 2016, "citationCount": 119, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/2858036.2858391?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2858036.2858391, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Sociology", "Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2016-05-07", "authors": [{"authorId": "145426686", "name": "J. N. Matias"}], "abstract": null, "corpusId": "9897274", "paragraphs": [{"paragraphId": "18249", "title": "Going Dark: Social Factors in Collective Action Against Platform Operators in the Reddit Blackout", "sectionTitle": "INTRODUCTION", "text": "The many volunteers who lead online communities exercise tremendous power and influence as they create, maintain, and govern social relations online. For that reason, research has highlighted their role in user activism aimed at online platform operators. In the late 1990s, America Online volunteer community leaders protested Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions@acm.org. CHI ' their treatment by the company, resulting in a class action lawsuit that was settled in 2011 for $15 million U.S. dollars [39]. Although community leaders have most famously responded to the tensions of unpaid and freely given labor in platform economies [71,63], forum moderators have also played important roles in collective action by waged crowd workers [65] and political bloggers [68] attempting to change policies on the platforms they use.", "spans": "[{\"corpusId\": 9897274, \"span\": \"this work\", \"start\": 397, \"end\": 397}, {\"corpusId\": 9897274, \"span\": \"this work\", \"start\": 647, \"end\": 647}, {\"corpusId\": 153872482, \"span\": \"[71,\", \"start\": 1165, \"end\": 1169}, {\"corpusId\": 144865243, \"span\": \"63]\", \"start\": 1169, \"end\": 1172}, {\"corpusId\": 16272139, \"span\": \"[65]\", \"start\": 1268, \"end\": 1272}, {\"corpusId\": 154849827, \"span\": \"[68]\", \"start\": 1296, \"end\": 1300}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "18250", "title": "Going Dark: Social Factors in Collective Action Against Platform Operators in the Reddit Blackout", "sectionTitle": "BACKGROUND AND RELATED WORK", "text": "For at least 40 years, online platforms have relied on community leaders to facilitate and support social interactions. In the mid 1970s, the librarians and shopkeepers of Berkeley's Community Memory supported users to contribute, even as a 25 cent per-message fee was introduced to deter unacceptable participation [13]. In the 1980s, the WELL's conference hosts, BBS SysOps [64], and Usenet moderators [14] fostered conversations and maintained order. In the 1990s, tens of thousands of AOL volunteer community leaders managed its chatrooms [63]. Moderators remained fundamentally important to on-Designing Quality in Social Media #chi4good, CHI 2016, San Jose, CA, USA line social interactions in the Web 2.0 period, even as platforms attempted to use machine learning [21], voting systems [29,43,41], and flagging systems to distribute the work of moderators more widely and disclaim responsibility for governance activity [17]. These roles are played by Wikipedia's administrators [1], Facebook's admins [23], Slashdot's moderators [42], Meetup's group organizers [40] and XBOX's enforcement united [28]. On platforms like Twitter with no official moderator role, users find the need to invent them [51,37]. Although this work is often carried out informally [54], formally-defined community leaders are founders, designers, promoters, facilitators recruiters, legislators, responders, and enforcers of online social interactions [15] for millions of people every day.", "spans": "[{\"corpusId\": 60960570, \"span\": \"[13]\", \"start\": 316, \"end\": 320}, {\"corpusId\": 31845838, \"span\": \"[14]\", \"start\": 404, \"end\": 408}, {\"corpusId\": 144865243, \"span\": \"[63]\", \"start\": 543, \"end\": 547}, {\"corpusId\": 5560081, \"span\": \"[21]\", \"start\": 772, \"end\": 776}, {\"corpusId\": 45375095, \"span\": \"43,\", \"start\": 797, \"end\": 800}, {\"corpusId\": 207548645, \"span\": \"[42]\", \"start\": 1037, \"end\": 1041}, {\"corpusId\": 29534873, \"span\": \"[40]\", \"start\": 1069, \"end\": 1073}, {\"corpusId\": 9897274, \"span\": \"this work\", \"start\": 1231, \"end\": 1231}, {\"corpusId\": 303648, \"span\": \"[54]\", \"start\": 1264, \"end\": 1268}, {\"corpusId\": 167050028, \"span\": \"[15]\", \"start\": 1435, \"end\": 1439}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 10}, {"paragraphId": "18251", "title": "Going Dark: Social Factors in Collective Action Against Platform Operators in the Reddit Blackout", "sectionTitle": "Collective Action and Social Movement Theories", "text": "The goal of this paper is to describe the factors that led to participation in the reddit blackout. While this paper does not test academic theories of collective action or social movements, it does gesture toward ways that its qualitative and quantitative findings can relate to these theories. A substantial quantitative research tradition has asked what factors come together for a collective action such as a decision or political action to occur or be successful [60,16]. When explaining a protest or strike, political opportunity theories would focus on the nature of the grievances of movement actors, expecting that those with greater grievances would be more likely to take action [55]. Political opportunity theories would also emphasize network relations among movement actors as important factors in joining a social movement [52]. Resource mobilization theories would focus on group resources as important factors in social movement mobilization, as well as the relative isolation of a group from other participating social movement groups [53].", "spans": "[{\"corpusId\": 9897274, \"span\": \"this paper\", \"start\": 22, \"end\": 22}, {\"corpusId\": 9897274, \"span\": \"this paper\", \"start\": 116, \"end\": 116}, {\"corpusId\": 143735420, \"span\": \"[55]\", \"start\": 690, \"end\": 694}, {\"corpusId\": 146740020, \"span\": \"[52]\", \"start\": 838, \"end\": 842}, {\"corpusId\": 2550587, \"span\": \"[53]\", \"start\": 1053, \"end\": 1057}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "18252", "title": "Going Dark: Social Factors in Collective Action Against Platform Operators in the Reddit Blackout", "sectionTitle": "Online Community Leadership", "text": "Although many subreddit participants supported the blackout, the demands made in the blackout were focused entirely on the distinct interests of subreddit moderators, leaders of the site's communities. For this reason, research on the development of distinct interests among online community leaders offers a backdrop for the inductive work of this paper. In studies on a class-action lawsuit by AOL community leaders, Postigo emphasizes poor company relations with community leaders, restrictivelydesigned moderation software, and coordination among community leaders as three important factors that led volunteers to see themselves as cheated employees rather than freely-contributing volunteers [62,63]. In a study of 683 wikis drawing from scholarship on union organizations [56,47], Shaw and Hill test internal characteristics of peer communities that predict the what they term \"goal transformation\"-the development of interests distinct to a community's leaders. They find goal transformation more likely among older, more complex groups [69].", "spans": "[{\"corpusId\": 9897274, \"span\": \"this paper\", \"start\": 354, \"end\": 354}, {\"corpusId\": 143670882, \"span\": \"[62,\", \"start\": 698, \"end\": 702}, {\"corpusId\": 144865243, \"span\": \"63]\", \"start\": 702, \"end\": 705}, {\"corpusId\": 14074403, \"span\": \"[69]\", \"start\": 1045, \"end\": 1049}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "18253", "title": "Going Dark: Social Factors in Collective Action Against Platform Operators in the Reddit Blackout", "sectionTitle": "Participatory Hypothesis Testing as Action Research", "text": "This study's methods are drawn from the action research tradition, which begin in the 1930s with studies by factory workers and university-based researchers in the early years of social psychology. Setting out to produce knowledge with and for workers rather than solely for factory operators, researchers and workers collaborated on studies to answer questions about leadership, cooperation, and management that were led by worker interests [4]. Within HCI, action research has been influential in participatory design [31] and in emancipatory action research, often supporting specific political interests[20] [6].", "spans": "[{\"corpusId\": 9897274, \"span\": \"This study's method\", \"start\": 19, \"end\": 19}, {\"corpusId\": 145242755, \"span\": \"[4]\", \"start\": 442, \"end\": 445}, {\"corpusId\": 18993804, \"span\": \"[31]\", \"start\": 520, \"end\": 524}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "18254", "title": "Going Dark: Social Factors in Collective Action Against Platform Operators in the Reddit Blackout", "sectionTitle": "Participatory Hypothesis Testing as Action Research", "text": "As a study that sets out to describe and explain rather than create, this work of action research brings together virtual ethnography [11] with the emerging practice of \"popular data,\" where researchers and participants create questions and interpretations together [10,19]. Since participants on reddit commonly create, share, and discuss data about their social behavior [30], reddit is well suited to this approach. Finally, since reddit moderators do not primarily talk about themselves as a well-defined interest group, the researcher has taken a \"friendly outsider\" stance rather than explicit political objectives [31].", "spans": "[{\"corpusId\": 9897274, \"span\": \"this work\", \"start\": 78, \"end\": 78}, {\"corpusId\": 10870077, \"span\": \"[30]\", \"start\": 373, \"end\": 377}, {\"corpusId\": 9897274, \"span\": \"this approach\", \"start\": 417, \"end\": 417}, {\"corpusId\": 18993804, \"span\": \"[31]\", \"start\": 621, \"end\": 625}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "18255", "title": "Going Dark: Social Factors in Collective Action Against Platform Operators in the Reddit Blackout", "sectionTitle": "Implications for Social Movement Mobilization Theories and Collective Action Theories", "text": "Insofar as these findings correspond to grievance-based theories of social movement mobilization, they are consistent with expectations that groups with greater grievances are more likely to mobilize [55]. Relations between moderators were also important social factors in the blackout, as expected by political opportunity theories [52]. Yet the nature of grievances among digital volunteerism and online labor are still questions of substantial scholarly discussion [67], at a time when the nature of platforms policies towards users are also still being theorized [27].", "spans": "[{\"corpusId\": 143735420, \"span\": \"[55]\", \"start\": 200, \"end\": 204}, {\"corpusId\": 146740020, \"span\": \"[52]\", \"start\": 333, \"end\": 337}, {\"corpusId\": 206726748, \"span\": \"[27]\", \"start\": 567, \"end\": 571}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "18256", "title": "Going Dark: Social Factors in Collective Action Against Platform Operators in the Reddit Blackout", "sectionTitle": "Implications for Social Movement Mobilization Theories and Collective Action Theories", "text": "Finally, the quantitative findings of this paper do appear to correspond with theories on the development of distinct interests among organization leaders [69]. Older subreddits and those with less engaged moderators were more likely to join the blackout. Research that sets out to test these theories could include further covariates related specifically to subreddit policies and the work of subreddit governance. Special care should be taken to account for overlapping leadership responsibilities across subreddits and wider leadership structures such as \"networks\" of subreddits [72].", "spans": "[{\"corpusId\": 9897274, \"span\": \"this paper\", \"start\": 48, \"end\": 48}, {\"corpusId\": 14074403, \"span\": \"[69]\", \"start\": 155, \"end\": 159}, {\"corpusId\": 207210224, \"span\": \"[72]\", \"start\": 583, \"end\": 587}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 8}
{"paperId": "e54e916259c5ed798f2341c07b67471df6b99d78", "title": "B2B-Swipe: Swipe Gesture for Rectangular Smartwatches from a Bezel to a Bezel", "venue": "International Conference on Human Factors in Computing Systems", "year": 2016, "citationCount": 33, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1145/2858036.2858216?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2858036.2858216, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2016-05-07", "authors": [{"authorId": "145280648", "name": "Yuki Kubo"}, {"authorId": "1765222", "name": "B. Shizuki"}, {"authorId": "144705533", "name": "J. Tanaka"}], "abstract": null, "corpusId": "146333", "paragraphs": [{"paragraphId": "62144", "title": "B2B-Swipe: Swipe Gesture for Rectangular Smartwatches from a Bezel to a Bezel", "sectionTitle": "INTRODUCTION", "text": "To solve this problem, recent products provide input methods using other modalities, such as wrist shake gestures and voice input, although these methods cannot be used in some environments (e.g., libraries and crowded places) because they are obtrusive. In the HCI field, a trend in increasing the input vocabulary of smartwatches has been to add sensors, such as infrared sensors [11,14,9], touch sensors [19,16], a magnetometer [6], joysticks [20], and a camera [5]. For example, Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions@acm.org. CHI' 16 Table 1. B2B-Swipes (#1 -#16) and the touch gestures that we used in our experiment (#17 -#24). The orange and blue circles show the start and end bezels for the gestures, respectively.", "spans": "[{\"corpusId\": 6908544, \"span\": \"[11,\", \"start\": 382, \"end\": 386}, {\"corpusId\": 676506, \"span\": \"14,\", \"start\": 386, \"end\": 389}, {\"corpusId\": 7921957, \"span\": \"9]\", \"start\": 389, \"end\": 391}, {\"corpusId\": 6832498, \"span\": \"16]\", \"start\": 411, \"end\": 414}, {\"corpusId\": 8410317, \"span\": \"[6]\", \"start\": 431, \"end\": 434}, {\"corpusId\": 17892810, \"span\": \"[20]\", \"start\": 446, \"end\": 450}, {\"corpusId\": 18602949, \"span\": \"[5]\", \"start\": 465, \"end\": 468}, {\"corpusId\": 146333, \"span\": \"this work\", \"start\": 552, \"end\": 552}, {\"corpusId\": 146333, \"span\": \"this work\", \"start\": 802, \"end\": 802}, {\"corpusId\": 6832498, \"span\": \"16\", \"start\": 1064, \"end\": 1066}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 8}, {"paragraphId": "62145", "title": "B2B-Swipe: Swipe Gesture for Rectangular Smartwatches from a Bezel to a Bezel", "sectionTitle": "RELATED WORK", "text": "Some eyes-free input methods for smartwatches have been proposed [15,3,4,16]. Among them, the most similar to B2B-Swipe were developed by G\u00e1bor and Fiener [4], who proposed an input method using a bezel as a tactile landmark for interaction that allows the user to perform eyes-free input. Similarly, B2B-Swipe uses the bezels of a rectangular smartwatch as tactile landmarks so that the user can specify the start bezel without looking at the smartwatch. Some work has used sensors other than the touch screen to realize eyes-free input methods. For example, WatchIt [16] embedded touch sensors within a watchband and allowed the user to perform swiping and tapping on the band; Pasquero et al. [15] used Hall-effect sensors and a force sensor that enable the user to perform various eyes-free gestures, including covering the watch's face and turning the watch's bezel. In contrast, B2B-Swipe uses only a single-touch screen.", "spans": "[{\"corpusId\": 16981752, \"span\": \"[15,\", \"start\": 65, \"end\": 69}, {\"corpusId\": 15947682, \"span\": \"3,\", \"start\": 69, \"end\": 71}, {\"corpusId\": 12284478, \"span\": \"4,\", \"start\": 71, \"end\": 73}, {\"corpusId\": 6832498, \"span\": \"16]\", \"start\": 73, \"end\": 76}, {\"corpusId\": 12284478, \"span\": \"[4]\", \"start\": 155, \"end\": 158}, {\"corpusId\": 6832498, \"span\": \"[16]\", \"start\": 568, \"end\": 572}, {\"corpusId\": 16981752, \"span\": \"[15]\", \"start\": 696, \"end\": 700}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "62146", "title": "B2B-Swipe: Swipe Gesture for Rectangular Smartwatches from a Bezel to a Bezel", "sectionTitle": "RELATED WORK", "text": "Touch gestures utilizing the bezels of touch screens of mobile devices other than smartwatches have been proposed [2,18,7,10,17,8]. Among them, Bezel Swipe [17] stands out. It is a touch gesture that starts by crossing a bezel. In contrast, a B2B-Swipe is a double-crossing touch gesture, which starts by crossing a bezel and ends by crossing a bezel. Doublecrossing touch gestures are not new; Kurosawa et al. [10] proposed Bezel Check, which starts by crossing a bezel and ends by crossing the same bezel, as a touch gesture to store data in a clipboard placed at the bezel where the gesture was performed. Bezel Check crosses the same bezel of tablets twice. In contrast, B2B-Swipe utilizes the short distances among the four bezels of smartwatches. Bezel Menus [8] explored different bezel-initiated marking menu layouts for eyes-free interaction on small mobile devices. The menus are initiated with Bezel Swipe; thus, B2B-Swipe could co-exist with Bezel Menus.", "spans": "[{\"corpusId\": 18528897, \"span\": \"[2,\", \"start\": 114, \"end\": 117}, {\"corpusId\": 10170121, \"span\": \"18,\", \"start\": 117, \"end\": 120}, {\"corpusId\": 3015068, \"span\": \"7,\", \"start\": 120, \"end\": 122}, {\"corpusId\": 14742516, \"span\": \"10,\", \"start\": 122, \"end\": 125}, {\"corpusId\": 5725980, \"span\": \"17,\", \"start\": 125, \"end\": 128}, {\"corpusId\": 2989191, \"span\": \"8]\", \"start\": 128, \"end\": 130}, {\"corpusId\": 5725980, \"span\": \"[17]\", \"start\": 156, \"end\": 160}, {\"corpusId\": 14742516, \"span\": \"[10]\", \"start\": 411, \"end\": 415}, {\"corpusId\": 2989191, \"span\": \"[8]\", \"start\": 765, \"end\": 768}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 6}], "paragraphCount": 3}
{"paperId": "00ee24a7fc7b1ee8cc3050d388ce775045c16ef1", "title": "Participatory Design Goes to School: Co-Teaching as a Form of Co-Design for Educational Technology", "venue": "International Conference on Human Factors in Computing Systems", "year": 2022, "citationCount": 28, "openAccessPdf": {"url": "https://eprints.ncl.ac.uk/fulltext.aspx?url=281253/BDF82079-4E23-4B74-AD5F-F5911E822805.pdf&pub_id=281253", "status": "GREEN", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3491102.3517667?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3491102.3517667, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2022-04-27", "authors": [{"authorId": "2059305368", "name": "Rebecca Nicholson"}, {"authorId": "3132347", "name": "Tom Bartindale"}, {"authorId": "2445830", "name": "Ahmed Kharrufa"}, {"authorId": "2064542093", "name": "David S. Kirk"}, {"authorId": "1402234693", "name": "Caroline Walker-Gleaves"}], "abstract": "Educational technologies offer benefits in the classroom but there are barriers to their successful integration, including teachers\u2019 pedagogical beliefs and their skills and experience. Participatory Design (PD) approaches offer one way in which teachers can be directly involved in the design of classroom technologies, however PD processes alone fail to address the challenges of integrating technology within existing practices. In this paper we propose co-teaching as a novel form of co-design practice. We describe a two year longitudinal Co-Teaching project resulting in the development and use of three digital designs for the classroom. Using the TPACK model to guide our reflections we offer insights into the ways that co-teaching can support the design and integration of educational technologies. We suggest that co-teaching as a form of co-design practice offers a way to move teachers from passive adopters of technology to active participants in the design and integration of educational technologies.", "corpusId": "248419471", "paragraphs": [{"paragraphId": "67507", "title": "Participatory Design Goes to School: Co-Teaching as a Form of Co-Design for Educational Technology", "sectionTitle": "INTRODUCTION", "text": "The use of educational technology in the classroom offers many benefits, from improving students' engagement and confidence [8] to supporting more authentic learning experiences [27], as well as increases in achievement generally [109]. It particularly supports student-centered constructivist approaches to teaching and learning such as 'deep learning' [25] and higher-order thinking [65,107]. Despite the possible benefits of using educational technology in the classroom, successfully integrating it into teachers' practices long term remains an ongoing challenge [66]. It is thought that there are a number of barriers to successful integration, both extrinsic barriers such as access to technology and training, as well as intrinsic barriers such as teachers' pedagogical beliefs and established classroom practices [22,73]. Tondeur et al. suggest one of the biggest challenges is understanding the interaction between teachers' pedagogical beliefs and their use of digital technology [73]. Understanding teachers' pedagogical beliefs, however, is challenging as they are complex and ever-changing [26,28] and vary by discipline, with many teachers exhibiting discipline specific or 'signature pedagogies' [90].", "spans": "[{\"corpusId\": 178526897, \"span\": \"[8]\", \"start\": 124, \"end\": 127}, {\"corpusId\": 10521493, \"span\": \"[27]\", \"start\": 178, \"end\": 182}, {\"corpusId\": 69820772, \"span\": \"[109]\", \"start\": 230, \"end\": 235}, {\"corpusId\": 61979302, \"span\": \"[65,\", \"start\": 385, \"end\": 389}, {\"corpusId\": 230768082, \"span\": \"[66]\", \"start\": 567, \"end\": 571}, {\"corpusId\": 14120998, \"span\": \"[22,\", \"start\": 821, \"end\": 825}, {\"corpusId\": 17263321, \"span\": \"73]\", \"start\": 825, \"end\": 828}, {\"corpusId\": 17263321, \"span\": \"[73]\", \"start\": 990, \"end\": 994}, {\"corpusId\": 54608426, \"span\": \"[26,\", \"start\": 1103, \"end\": 1107}, {\"corpusId\": 155034235, \"span\": \"28]\", \"start\": 1107, \"end\": 1110}, {\"corpusId\": 16871941, \"span\": \"[90]\", \"start\": 1211, \"end\": 1215}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 10}, {"paragraphId": "67508", "title": "Participatory Design Goes to School: Co-Teaching as a Form of Co-Design for Educational Technology", "sectionTitle": "INTRODUCTION", "text": "One way of supporting the successful integration of digital technologies is to make sure that teachers have control over any changes in their day-to-day practice [93], something that can be achieved by ensuring that teachers have real ownership of technological innovations [64]. Approaches in HCI such as design research that focus on the active involvement of the user in the design of systems offer ways to engage teachers in the design of educational technologies that better align with their practices and beliefs. Participatory, and co-design, approaches specifically ensure teachers are involved [80] and have been shown to have substantial effects on the adoption of tools designed [20] as well as encouraging curriculum innovation and technology implementation [70]. There are, however, relatively few instances in HCI literature of teachers participating in co-design processes, with literature more often reporting engagement with students or parents [51]. Studies that do use co-design methodologies with teachers, often primarily consider their involvement in the early stages of the research to gather ideas through workshops and other ideation activities rather than throughout the process, e.g., [51,99], or more commonly report on evaluations of the artefact created rather than the process, e.g., [3,53,55,74,98]. As a result, case studies often do not offer detailed insights into ways researchers can support the teacher to take ownership of these technologies and integrate them into their practices.", "spans": "[{\"corpusId\": 143953702, \"span\": \"[93]\", \"start\": 162, \"end\": 166}, {\"corpusId\": 123166559, \"span\": \"[64]\", \"start\": 274, \"end\": 278}, {\"corpusId\": 210967159, \"span\": \"[20]\", \"start\": 690, \"end\": 694}, {\"corpusId\": 203704234, \"span\": \"[70]\", \"start\": 770, \"end\": 774}, {\"corpusId\": 221856678, \"span\": \"[51]\", \"start\": 962, \"end\": 966}, {\"corpusId\": 221856678, \"span\": \"[51,\", \"start\": 1212, \"end\": 1216}, {\"corpusId\": 212688116, \"span\": \"99]\", \"start\": 1216, \"end\": 1219}, {\"corpusId\": 210116543, \"span\": \"[3,\", \"start\": 1315, \"end\": 1318}, {\"corpusId\": 17176983, \"span\": \"53,\", \"start\": 1318, \"end\": 1321}, {\"corpusId\": 218482886, \"span\": \"55,\", \"start\": 1321, \"end\": 1324}, {\"corpusId\": 7770977, \"span\": \"74,\", \"start\": 1324, \"end\": 1327}, {\"corpusId\": 211522087, \"span\": \"98]\", \"start\": 1327, \"end\": 1330}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 11}, {"paragraphId": "67509", "title": "Participatory Design Goes to School: Co-Teaching as a Form of Co-Design for Educational Technology", "sectionTitle": "INTRODUCTION", "text": "Another way of supporting successful integration is to consider the skills and knowledges teachers need to confidently integrate technology long term [21,73]. One such model that considers this is Technological Pedagogical Content Knowledge (TPACK) [59]which aims to conceptualize the different kinds of knowledges teachers need. Teachers with well-developed TPACK competence have been shown to be more effective in their planning and enacting of technology enhanced instruction [30]. Voogt et al. [102] suggest that both technological and pedagogical beliefs were reflected in the forms of teachers' TPACK, and as such TPACK has been suggested as an 'orientation' towards using technology in the classroom [7]. As an orientation it can be used as a lens in design processes to consider both how teachers' beliefs and knowledge affect their orientation to implement educational technology in the classroom and how these design processes could support them to gain the necessary knowledge and confidence to integrate technology long term.", "spans": "[{\"corpusId\": 17263321, \"span\": \"73]\", \"start\": 154, \"end\": 157}, {\"corpusId\": 9440559, \"span\": \"[59]\", \"start\": 249, \"end\": 253}, {\"corpusId\": 9140208, \"span\": \"[102]\", \"start\": 498, \"end\": 503}, {\"corpusId\": 121102167, \"span\": \"[7]\", \"start\": 707, \"end\": 710}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "67510", "title": "Participatory Design Goes to School: Co-Teaching as a Form of Co-Design for Educational Technology", "sectionTitle": "Educational Technology Adoption in the Classroom", "text": "Technology adoption and integration in the classroom is a known challenge in educational technology and one that the wider educational technology community has regularly explored identifying a range of barriers [22,23,33]. One popular conceptualization of these barriers is as first and second-order barriers. First-order barriers are extrinsic concerns such as access to digital technology resources as well as factors found at an institutional level such as the curriculum or assessment policies [22,24], as well as the context of the school including its social background [34]. Second order barriers are intrinsic concerns such as teachers' attitudes and beliefs, their technological skill, and their established routines and vision [21,92]. These barriers present challenges for long-term adoption of technology in the classroom as they suggest a range of complex factors that have the potential to clash with the introduction of educational technology even when first order barriers have been overcome [6,94]. Professional development has been a popular consideration in the field [41] such as the 'train the teacher model' [78] or 'flipped PD' model [108]. As a result, teachers' technological skills and how to improve them are often the focus of much of the literature considering how to integrate educational technologies into teachers' practices, e.g., [4,21,30,38].Developing this knowledge, however, can be time-consuming and does not fully take into account the complexity of the challenge [44], not least because of the changing nature of digital technologies [69]. While the affordances of digital technology do influence its use [4], it has been suggested that second-order barriers (teachers' attitudes and beliefs) are the 'true gatekeepers', particularly once first order barriers of access have been overcome [22]. These attitudes and beliefs are known to affect teachers' technology use [95] and are often linked to teachers' perceptions about the value of digital technology in learning environments [9,101] as well as their confidence and self-efficacy [21,73]. In order to successfully integrate educational technology into the classroom, it is clear that any approach needs to support 1. The development of teachers' technical competency, and 2. An understanding of and confidence in how to integrate the use of educational technology into their pedagogy.", "spans": "[{\"corpusId\": 14120998, \"span\": \"[22,\", \"start\": 211, \"end\": 215}, {\"corpusId\": 208840362, \"span\": \"23,\", \"start\": 215, \"end\": 218}, {\"corpusId\": 11277825, \"span\": \"33]\", \"start\": 218, \"end\": 221}, {\"corpusId\": 14120998, \"span\": \"[22,\", \"start\": 498, \"end\": 502}, {\"corpusId\": 110332870, \"span\": \"24]\", \"start\": 502, \"end\": 505}, {\"corpusId\": 236203666, \"span\": \"[34]\", \"start\": 576, \"end\": 580}, {\"corpusId\": 55019789, \"span\": \"[6,\", \"start\": 1008, \"end\": 1011}, {\"corpusId\": 8971229, \"span\": \"[41]\", \"start\": 1087, \"end\": 1091}, {\"corpusId\": 1915342, \"span\": \"[78]\", \"start\": 1130, \"end\": 1134}, {\"corpusId\": 208108152, \"span\": \"[108]\", \"start\": 1157, \"end\": 1162}, {\"corpusId\": 18954239, \"span\": \"[4,\", \"start\": 1364, \"end\": 1367}, {\"corpusId\": 45917377, \"span\": \"38]\", \"start\": 1373, \"end\": 1376}, {\"corpusId\": 42674854, \"span\": \"[44]\", \"start\": 1504, \"end\": 1508}, {\"corpusId\": 154076785, \"span\": \"[69]\", \"start\": 1575, \"end\": 1579}, {\"corpusId\": 18954239, \"span\": \"[4]\", \"start\": 1646, \"end\": 1649}, {\"corpusId\": 14120998, \"span\": \"[22]\", \"start\": 1830, \"end\": 1834}, {\"corpusId\": 63854734, \"span\": \"[95]\", \"start\": 1909, \"end\": 1913}, {\"corpusId\": 206931716, \"span\": \"101]\", \"start\": 2026, \"end\": 2030}, {\"corpusId\": 17263321, \"span\": \"73]\", \"start\": 2081, \"end\": 2084}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 16}, {"paragraphId": "67511", "title": "Participatory Design Goes to School: Co-Teaching as a Form of Co-Design for Educational Technology", "sectionTitle": "Frameworks for Acceptance and Integration", "text": "In the educational technology field, there are various frameworks that consider how to successfully integrate educational technology into the classroom. Two specific frameworks are discussed in this section: the Technology Acceptance Model (TAM) and the Technology Pedagogy And Content Knowledge (TPACK) model. The Technology Acceptance Model (TAM) [15] was designed to consider technology acceptance more widely but has been applied quite regularly to education contexts [12,68]. TAM suggests that two factors influence the acceptance of a new technology; perceived ease of use, and perceived usefulness, but it has been extended and modified to suit specific settings including to understand teachers' acceptance of digital educational games [16]. Although used within educational technology, TAM does not consider the pedagogical use specifically, which is known to present specific challenges to the integration of technology in the classroom.", "spans": "[{\"corpusId\": 12476939, \"span\": \"[15]\", \"start\": 349, \"end\": 353}, {\"corpusId\": 15450655, \"span\": \"[12,\", \"start\": 472, \"end\": 476}, {\"corpusId\": 39465191, \"span\": \"68]\", \"start\": 476, \"end\": 479}, {\"corpusId\": 26287305, \"span\": \"[16]\", \"start\": 744, \"end\": 748}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "67512", "title": "Participatory Design Goes to School: Co-Teaching as a Form of Co-Design for Educational Technology", "sectionTitle": "Frameworks for Acceptance and Integration", "text": "One framework that does consider pedagogy and has been used when identifying successful integration in the classroom is Technological Pedagogical Content Knowledge (TPACK) [44]. It seeks to understand the nature of knowledge required by teachers to integrate technology into their practices and is an extension of Shulman's Pedagogical Content Knowledge [89]. Koehler et al. (2007) suggested that TPACK development is \"a multigenerational process, involving the development of deeper understandings of the complex web of relationships between content, pedagogy, and technology and the contexts in which they function\" [46]. (1) Technological Knowledge -knowledge of the ways digital technology can be used as well as their potential advantages and disadvantages. (2) Pedagogical Knowledge -knowledge of how to teach including taking into account teachers' beliefs, theory, teaching and learning strategies, and reflection on the potential advantages and disadvantages of given pedagogies (3) Content Knowledge -knowledge of the central subject specific concepts, subject matter, and curricula that are taught to students.", "spans": "[{\"corpusId\": 42674854, \"span\": \"[44]\", \"start\": 172, \"end\": 176}, {\"corpusId\": 1673489, \"span\": \"[89]\", \"start\": 354, \"end\": 358}, {\"corpusId\": 17965248, \"span\": \"Koehler et al. (2007)\", \"start\": 360, \"end\": 381}, {\"corpusId\": 17965248, \"span\": \"[46]\", \"start\": 618, \"end\": 622}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "67513", "title": "Participatory Design Goes to School: Co-Teaching as a Form of Co-Design for Educational Technology", "sectionTitle": "Frameworks for Acceptance and Integration", "text": "(1) Pedagogical Content Knowledge (PCK) -understanding how the subject specific concepts can be taught, how they might best be organized, as well as any common misconceptions. It has been suggested that some of TPACK is domain-generic where others are domain-specific [32]. As such, there have been calls for more research that considers TPACK with subject disciplines, focusing on discipline-specific practices [81]. There have been some considerations of TPACK applied to various disciplines including computer science [100], science [38], as well as music [5]. Teachers' understanding of how to integrate content, pedagogy and technology is linked to experience of using digital technologies in specific curriculum areas [36,65] and it has been shown that teachers with well-developed TPACK competence are more effective in their planning and enacting of technology enhanced instruction [30].", "spans": "[{\"corpusId\": 59935917, \"span\": \"[81]\", \"start\": 412, \"end\": 416}, {\"corpusId\": 199022790, \"span\": \"[100]\", \"start\": 521, \"end\": 526}, {\"corpusId\": 45917377, \"span\": \"[38]\", \"start\": 536, \"end\": 540}, {\"corpusId\": 147496566, \"span\": \"[5]\", \"start\": 559, \"end\": 562}, {\"corpusId\": 1435157, \"span\": \"[36,\", \"start\": 724, \"end\": 728}, {\"corpusId\": 61979302, \"span\": \"65]\", \"start\": 728, \"end\": 731}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "67514", "title": "Participatory Design Goes to School: Co-Teaching as a Form of Co-Design for Educational Technology", "sectionTitle": "Frameworks for Acceptance and Integration", "text": "Rosenberg suggests TPACK is embedded in the social context [81] and as such recently it has been conceptualized as a distributed form of knowledge shared by members of a teaching community [10,17,39]. One popular approach used to engage teachers in developing their TPACK knowledge for technology integration is \"Learning by Design\" (LBD) [45,46]. This approach engages teachers in collaborative design with each other enabling them to share knowledge with colleagues who have other specialist expertise [4,91] and to work on authentic design problems related to technology integration [46]. Voogt et al. go further and suggest that TPACK can best be developed through learning by design [104]. TPACK as a model can offer a useful way of conceptualizing the variety of knowledges that teachers need to develop in order to successfully integrate technology into the classroom. As such it provides a useful framework within which to consider how to support the integration of educational technology and support the knowledge development of teachers.", "spans": "[{\"corpusId\": 59935917, \"span\": \"[81]\", \"start\": 59, \"end\": 63}, {\"corpusId\": 224950464, \"span\": \"[10,\", \"start\": 189, \"end\": 193}, {\"corpusId\": 63593865, \"span\": \"17,\", \"start\": 193, \"end\": 196}, {\"corpusId\": 55686682, \"span\": \"39]\", \"start\": 196, \"end\": 199}, {\"corpusId\": 54703142, \"span\": \"[45,\", \"start\": 339, \"end\": 343}, {\"corpusId\": 17965248, \"span\": \"46]\", \"start\": 343, \"end\": 346}, {\"corpusId\": 248419471, \"span\": \"This approach\", \"start\": 361, \"end\": 361}, {\"corpusId\": 18954239, \"span\": \"[4,\", \"start\": 504, \"end\": 507}, {\"corpusId\": 14689069, \"span\": \"91]\", \"start\": 507, \"end\": 510}, {\"corpusId\": 17965248, \"span\": \"[46]\", \"start\": 586, \"end\": 590}, {\"corpusId\": 152160330, \"span\": \"[104]\", \"start\": 688, \"end\": 693}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 10}, {"paragraphId": "67515", "title": "Participatory Design Goes to School: Co-Teaching as a Form of Co-Design for Educational Technology", "sectionTitle": "Co-design with Teachers", "text": "Participatory and co-design approaches have a long history in HCI [83,84] given its particular focus on the role of human-centered design practices. Participatory Action Research (PAR) is one participatory approach to research that specifically seeks to bring about change [50]. It is deeply rooted in practice and is often seen as a commitment to observe and problematize social enquiry through practice [57], one which is 'democratic, collaborative, and interdisciplinary' [31]. Although sharing several of the same commitments to including participants in the research process, co-design differs in its specific focus on design-led practices with the aim of co-designing an artefact.", "spans": "[{\"corpusId\": 111148589, \"span\": \"[83,\", \"start\": 66, \"end\": 70}, {\"corpusId\": 11414413, \"span\": \"84]\", \"start\": 70, \"end\": 73}, {\"corpusId\": 143998802, \"span\": \"[50]\", \"start\": 273, \"end\": 277}, {\"corpusId\": 156538925, \"span\": \"[57]\", \"start\": 405, \"end\": 409}, {\"corpusId\": 18993804, \"span\": \"[31]\", \"start\": 475, \"end\": 479}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "67516", "title": "Participatory Design Goes to School: Co-Teaching as a Form of Co-Design for Educational Technology", "sectionTitle": "Co-design with Teachers", "text": "Co-design as an approach is one that could support educational technology integration as research suggests that encouraging teachers to gain design thinking skills might support them to harness educational technology in the classroom. For example, Tsai and Chi [97] suggest that a lack of design thinking skills poses a third-order barrier to integrating technology into their practices. Considering technology in a more 'designerly' way [14], then, might encourage teachers to appropriate it into their practices [41], something supported by McKenney et al. who suggest that co-design can be used as a way of supporting teachers to develop design skills [56].", "spans": "[{\"corpusId\": 54207780, \"span\": \"[97]\", \"start\": 261, \"end\": 265}, {\"corpusId\": 56763911, \"span\": \"[14]\", \"start\": 438, \"end\": 442}, {\"corpusId\": 8971229, \"span\": \"[41]\", \"start\": 514, \"end\": 518}, {\"corpusId\": 62718264, \"span\": \"[56]\", \"start\": 655, \"end\": 659}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "67517", "title": "Participatory Design Goes to School: Co-Teaching as a Form of Co-Design for Educational Technology", "sectionTitle": "Co-design with Teachers", "text": "Co-design has been suggested as a way of democratizing innovation and increasing teacher capacity through teachers engaging in professional development activities alongside design activities [70]. Penuel et al specifically suggest that co-designing with teachers can support and encourage curriculum innovation as well as technology implementation [70].In the learning sciences more widely, this has been demonstrated as co-design processes have led to the development of curriculum materials including in science [76,88], and mathematics [79].", "spans": "[{\"corpusId\": 203704234, \"span\": \"[70]\", \"start\": 191, \"end\": 195}, {\"corpusId\": 203704234, \"span\": \"[70]\", \"start\": 348, \"end\": 352}, {\"corpusId\": 10569941, \"span\": \"[76,\", \"start\": 514, \"end\": 518}, {\"corpusId\": 41696767, \"span\": \"[79]\", \"start\": 539, \"end\": 543}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "67518", "title": "Participatory Design Goes to School: Co-Teaching as a Form of Co-Design for Educational Technology", "sectionTitle": "Co-design with Teachers", "text": "Although there are a number of reported benefits to including teachers in the co-design process, there are relatively few instances in HCI literature of teachers participating in co-design processes, with literature more often reporting engagement with students or parents [51]. Where co-design with teachers is reported in HCI, this has been used in a number of contexts such as in the creation of a layered story-telling approach to analytics [55], in exploring wearables for classroom orchestration [74], the co-design of computing curricula at K-12 [98], as well as for the creation of immersive experiences for collective inquiry [53]. While these papers all report on studies that resulted in artefacts that were successfully aligned with classroom practices as a result of co-design processes, the papers themselves primarily focus on the evaluation of these artefacts within their given context. As such, there is less of a focus on specific insights into ways researchers can support the teacher to take ownership of these technologies and integrate them into their practices.", "spans": "[{\"corpusId\": 221856678, \"span\": \"[51]\", \"start\": 273, \"end\": 277}, {\"corpusId\": 218482886, \"span\": \"[55]\", \"start\": 445, \"end\": 449}, {\"corpusId\": 7770977, \"span\": \"[74]\", \"start\": 502, \"end\": 506}, {\"corpusId\": 211522087, \"span\": \"[98]\", \"start\": 553, \"end\": 557}, {\"corpusId\": 17176983, \"span\": \"[53]\", \"start\": 635, \"end\": 639}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "67519", "title": "Participatory Design Goes to School: Co-Teaching as a Form of Co-Design for Educational Technology", "sectionTitle": "Co-design with Teachers", "text": "Where co-design has been conducted with teachers in the wider educational technology domain, researchers have demonstrated that co-designing new science curricula with teachers offers benefits including a substantial effect on the adoption of the technological tools and the curriculum [20], while other researchers recognized the value of including teachers' expertise in the process [87]. Roschelle et al. suggest that key considerations for co-designing with teachers include creating a \"concrete, tangible innovation challenge\", investigating \"current practice and classroom contexts\", and involving \"central accountability for the quality of the products of the co-design\" [80]. One area where co-design with teachers is becoming more prevalent and methods are often discussed explicitly is in the learning analytics field, specifically with a renewed interest in the application of human-centered design approaches to the design of learning analytics tools, e.g., [2,35,58,99].", "spans": "[{\"corpusId\": 210967159, \"span\": \"[20]\", \"start\": 286, \"end\": 290}, {\"corpusId\": 63112528, \"span\": \"[87]\", \"start\": 385, \"end\": 389}, {\"corpusId\": 212687885, \"span\": \"[2,\", \"start\": 970, \"end\": 973}, {\"corpusId\": 201128632, \"span\": \"35,\", \"start\": 973, \"end\": 976}, {\"corpusId\": 212687888, \"span\": \"58,\", \"start\": 976, \"end\": 979}, {\"corpusId\": 212688116, \"span\": \"99]\", \"start\": 979, \"end\": 982}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "67520", "title": "Participatory Design Goes to School: Co-Teaching as a Form of Co-Design for Educational Technology", "sectionTitle": "Co-design with Teachers", "text": "Co-design approaches in the educational technology field have more commonly been employed in the design requirements stages of the process rather than in the evaluation. It is known, however, that teachers' pedagogical practices and beliefs can often vary between their espoused beliefs and enacted practices [22,54], highlighting the critical need to explore both teachers' espoused and enacted beliefs and practices. Longitudinal co-design processes that include teachers in the design and evaluation of educational technologies in the classroom are one way that this could be explored. There are however some well-reported tensions in the co-design process when used in an educational setting. For example, teachers and designers often have different criteria for evaluating the success of co-design processes [88]. Teachers often see researchers' solutions as too theoretical and not suited to real life classrooms [22,54] while researchers often view teachers' limited knowledge of technology as a barrier to effectively contributing to design processes [88], which points to a need for more engaged and embedded design practices. It is clear from previous literature that successful co-design requires teachers to feel their ideas are respected and that there is an \"atmosphere of trust and inclusion\" in co-design partnerships [13]. The use of 'traditional' co-design in educational technology, despite careful consideration of teachers' pedagogies and the design of the resulting artefact, has still not been able to address all of the challenges of long-term integration of educational technology in the classroom.", "spans": "[{\"corpusId\": 14120998, \"span\": \"[22,\", \"start\": 309, \"end\": 313}, {\"corpusId\": 23375410, \"span\": \"54]\", \"start\": 313, \"end\": 316}, {\"corpusId\": 14120998, \"span\": \"[22,\", \"start\": 919, \"end\": 923}, {\"corpusId\": 23375410, \"span\": \"54]\", \"start\": 923, \"end\": 926}, {\"corpusId\": 62640005, \"span\": \"[13]\", \"start\": 1334, \"end\": 1338}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "67521", "title": "Participatory Design Goes to School: Co-Teaching as a Form of Co-Design for Educational Technology", "sectionTitle": "CO-TEACHING METHOD", "text": "In this paper we conceptualize co-teaching as a form of design practice and suggest it as a suitable method for the design of educational technology. Co-teaching, through its embedded and situated approach to design and evaluation, offers the potential to reduce some of the known tensions within co-design practices in the classroom. It offers a method of design practice specifically for use in the educational technology field and as such is a suitable method to consider the unique challenges of designing technology for the classroom. Alongside ensuring teachers remain active in the design process, we suggest it also offers a potential way of supporting the development of teachers' (and arguably designers') TPACK, something known to support integration of educational technology in the classroom [30]. Co-design as a design practice specifically encourages collaboration between stakeholders with a particular emphasis on the sharing of relevant expertise. The user is positioned as an expert of their experience while the researcher or designer offers tools for ideation as well as technological knowledge [83]. Co-teaching, meanwhile is traditionally a term used to define the practice of two teachers working collaboratively to teach a class and is often used as a method of teacher training e.g. [37,77]. It facilitates the creation of student-centered environments as well as supporting successful school improvement programs through its focus on collaborative reflection and action [61]. Roth & Tobin suggest that co-teaching as a practice offers the opportunity for 'co-generative dialogue', a term to define the collaborative reflection on praxis Teaching Implementing the design in the context. Evaluating", "spans": "[{\"corpusId\": 248419471, \"span\": \"this paper\", \"start\": 13, \"end\": 13}, {\"corpusId\": 111148589, \"span\": \"[83]\", \"start\": 1116, \"end\": 1120}, {\"corpusId\": 142049570, \"span\": \"[37,\", \"start\": 1309, \"end\": 1313}, {\"corpusId\": 143717246, \"span\": \"77]\", \"start\": 1313, \"end\": 1316}, {\"corpusId\": 144765774, \"span\": \"[61]\", \"start\": 1497, \"end\": 1501}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "67522", "title": "Participatory Design Goes to School: Co-Teaching as a Form of Co-Design for Educational Technology", "sectionTitle": "Context", "text": "The lead author worked together with Amy (a pseudonym), the Head of Performing Arts in a UK Secondary School (ages [11][12][13][14][15][16][17][18] from July 2018 to January 2020. The lead author is a qualified secondary teacher and had three years prior experience of teaching in a secondary school setting. Before undertaking this project, they last taught in a secondary school in 2017. They are currently a design-researcher and teach in Higher Education settings alongside their research. The lead author's research focusses on design-led explorations of educational technology in the classroom, particularly the performing arts classroom. There was no relationship between Amy and the lead researcher prior to the project, Amy answered a call for participation sent through a network that supports secondary music teachers in one local authority in the UK. The call for participation sought teachers who were interested in exploring how technology could support their pedagogy in the secondary music classroom.", "spans": "[{\"corpusId\": 15450655, \"span\": \"[12]\", \"start\": 119, \"end\": 123}, {\"corpusId\": 62640005, \"span\": \"[13]\", \"start\": 123, \"end\": 127}, {\"corpusId\": 56763911, \"span\": \"[14]\", \"start\": 127, \"end\": 131}, {\"corpusId\": 12476939, \"span\": \"[15]\", \"start\": 131, \"end\": 135}, {\"corpusId\": 26287305, \"span\": \"[16]\", \"start\": 135, \"end\": 139}, {\"corpusId\": 63593865, \"span\": \"[17]\", \"start\": 139, \"end\": 143}, {\"corpusId\": 16314852, \"span\": \"[18]\", \"start\": 143, \"end\": 147}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "67523", "title": "Participatory Design Goes to School: Co-Teaching as a Form of Co-Design for Educational Technology", "sectionTitle": "Data Analysis", "text": "TPACK was used as a way to frame this deductive analysis as it is known that improving teachers' TPACK can support the integration of technology in the classroom [30]. Other design-led practices such as 'Learning by Design' have been used to develop teachers' TPACK knowledge [45,46,104]. In this same way, we sought to understand how co-teaching as a method could support teachers to develop TPACK as a route to better embedding technology use in the classroom. As such, the findings below are discussed in relation to aspects of the TPACK model, particularly TK , TPK and PCK. TK was highlighted as teachers' lack of technological knowledge and confidence is known to be a barrier to integrating educational technology [21,73]. TK is discussed in the findings in relation to confidence as it is suggested that TK is not improved by technology knowledge alone but rather influenced by the other factors including self-efficacy about their technology knowledge [1]. One way in which surveys have measured self-efficacy is to consider confidence as a way of understanding teachers' applied self-efficacy in the classroom [40]. Confidence, specifically, has previously been discussed in relation to TPACK [47]. A teachers' lack of confidence in their technological capability is also a key barrier in integrating technology in the classroom [21,73].", "spans": "[{\"corpusId\": 54703142, \"span\": \"[45,\", \"start\": 276, \"end\": 280}, {\"corpusId\": 17965248, \"span\": \"46,\", \"start\": 280, \"end\": 283}, {\"corpusId\": 152160330, \"span\": \"104]\", \"start\": 283, \"end\": 287}, {\"corpusId\": 17263321, \"span\": \"73]\", \"start\": 725, \"end\": 728}, {\"corpusId\": 15001712, \"span\": \"[1]\", \"start\": 961, \"end\": 964}, {\"corpusId\": 23733465, \"span\": \"[40]\", \"start\": 1120, \"end\": 1124}, {\"corpusId\": 9453168, \"span\": \"[47]\", \"start\": 1203, \"end\": 1207}, {\"corpusId\": 17263321, \"span\": \"73]\", \"start\": 1343, \"end\": 1346}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "67524", "title": "Participatory Design Goes to School: Co-Teaching as a Form of Co-Design for Educational Technology", "sectionTitle": "Long Term Support in Implementation", "text": "This study is an empirical example that supports existing work suggesting that professional development could be an important way of integrating digital technologies into the classroom. Ways of integrating off-the-shelf digital technologies in the classroom have been explored at length in the educational technology community with professional development suggested as one of the most important aspects that leads to greater acceptance and use of technology in the classroom, particularly that which enhances a teacher's self-efficacy [85]. Various models exist that offer ways to consider offering professional development for teachers such as the 'train the teacher model' or the 'flipped PD' model [78,108]. Both these models separate research and professional development encouraging professional development as a route to embedding technology created as part of theory-driven processes. Rather than see professional development as a hurdle to overcome to ensure effective technology integration within the classroom, we saw research and professional development happening alongside one another throughout the development and evaluation of digital technologies. Such co-teaching practices allow us to more readily explore theorydriven but practice-oriented approaches to educational technology research, something that has been called for in the educational technology field [72]. They also allow us to consider ways in which theoretical, pedagogic and technological development can be integrated, something that has been shown to improve both learning and teaching [29].", "spans": "[{\"corpusId\": 248419471, \"span\": \"This study\", \"start\": 10, \"end\": 10}, {\"corpusId\": 53736326, \"span\": \"[85]\", \"start\": 536, \"end\": 540}, {\"corpusId\": 1915342, \"span\": \"[78,\", \"start\": 702, \"end\": 706}, {\"corpusId\": 208108152, \"span\": \"108]\", \"start\": 706, \"end\": 710}, {\"corpusId\": 145812776, \"span\": \"[72]\", \"start\": 1380, \"end\": 1384}, {\"corpusId\": 59929678, \"span\": \"[29]\", \"start\": 1571, \"end\": 1575}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "67525", "title": "Participatory Design Goes to School: Co-Teaching as a Form of Co-Design for Educational Technology", "sectionTitle": "Value of Co-teaching for Researchers", "text": "There are challenges for educational technology designers when designing technology to support teachers pedagogies. Firstly, teachers' espoused and enacted pedagogical practices often differ due to the impact of policy and the context [22,54] and secondly, disciplines are known to have unique, or 'signature', pedagogies [90], and therefore the way pedagogical knowledge intersects with technological and content knowledge differs depending on the subject [5]. Utilizing co-teaching as a method in this project allowed the researcher to understand the impact of context on teachers' enacted practices and how these differed from the ones described at the beginning of the design process. This was similarly the case in offering the researcher the ability to gain a situated and contextual understanding of discipline specific pedagogies.", "spans": "[{\"corpusId\": 14120998, \"span\": \"[22,\", \"start\": 235, \"end\": 239}, {\"corpusId\": 23375410, \"span\": \"54]\", \"start\": 239, \"end\": 242}, {\"corpusId\": 16871941, \"span\": \"[90]\", \"start\": 322, \"end\": 326}, {\"corpusId\": 147496566, \"span\": \"[5]\", \"start\": 457, \"end\": 460}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "67526", "title": "Participatory Design Goes to School: Co-Teaching as a Form of Co-Design for Educational Technology", "sectionTitle": "Pedagogically Aligned Technology Design", "text": "The learning analytics tool was not accepted nor integrated, and supported previous work that demonstrates the complexity of teachers' pedagogical beliefs and enacted practices [26,28]. Pedagogical beliefs are often tacit and as such are often complex to discern [22]. In this case, these beliefs were not evident until the tool was used within the classroom context with current student data. Although the tool was not integrated into their practice, the environment created by the co-teaching allowed for supported experimentation with the tool that may not have otherwise happened. As a result, in this case, using co-teaching offered the researcher significant insights into the use of learning analytics in specific disciplinary practices.", "spans": "[{\"corpusId\": 54608426, \"span\": \"[26,\", \"start\": 177, \"end\": 181}, {\"corpusId\": 155034235, \"span\": \"28]\", \"start\": 181, \"end\": 184}, {\"corpusId\": 14120998, \"span\": \"[22]\", \"start\": 263, \"end\": 267}]", "conference": "chi", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 20}
{"paperId": "41cea65919caea6b3e1a41a037ac3e624b87b289", "title": "Shaping the Design of Smartphone-Based Interventions for Self-Harm", "venue": "International Conference on Human Factors in Computing Systems", "year": 2020, "citationCount": 19, "openAccessPdf": {"url": "https://pure.manchester.ac.uk/ws/files/157862485/CHI2020_UPP_1_.pdf", "status": "GREEN", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3313831.3376370?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3313831.3376370, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science", "Psychology"], "publicationTypes": ["JournalArticle", "Book", "Conference", "Review"], "publicationDate": "2020-03-02", "authors": [{"authorId": "10435957", "name": "M. Honary"}, {"authorId": "33789945", "name": "Beth T. Bell"}, {"authorId": "1787300", "name": "S. Clinch"}, {"authorId": "145555233", "name": "Julio Vega"}, {"authorId": "50209200", "name": "L. Kroll"}, {"authorId": "71596202", "name": "A. Sefi"}, {"authorId": "2440800", "name": "R. Mcnaney"}], "abstract": "Self-harm is a prevalent issue amongst young people, yet it is thought around 40% will never seek professional help due to stigma surrounding it. It is generally a way of coping with emotional distress and can have a range of triggers which are highly heterogeneous to the individual. In a move towards enhancing the accessibility of personalized interventions for self-harm, we undertook a three-stage study. We first conducted interviews with 4 counsellors in self-harm to understand how they clinically respond to self-harm triggers. We then ran a survey with 37 young people, to explore perceptions of mobile sensing, and current and future uses for smartphone-based interventions. Finally, we ran a workshop with 11 young people to further explore how a context-aware self-management application might be used to support them. We contribute an in-depth understanding of how triggers for self-harm might be identified and subsequently predicted and prevented using mobile-sensing technology.", "corpusId": "216505674", "paragraphs": [{"paragraphId": "11888", "title": "Shaping the Design of Smartphone-Based Interventions for Self-Harm", "sectionTitle": "INTRODUCTION", "text": "Self-harm refers to the deliberate injury of one's self (mainly characterised in mainstream media through cutting) [44]. It is particularly common among adolescents; with prevalence rates thought to be between 13-28% in non-clinical samples of adolescents [42]. The average age of onset for self-harm is around 12-14 years old [32] and adolescent girls are more likely to engage in self harm practices than adolescent boys [58]. It is estimated that 40% of the youth who self-harm will not report they do so or seek professional help, largely due to the stigma associated with self-harm, fears surrounding confidentiality and perceptions of negative reaction from others [55]. As a consequence, reported self-harm prevalence rates may underestimate the proportion of adolescents experiencing these negative thoughts and behaviours.", "spans": "[{\"corpusId\": 25482728, \"span\": \"[32]\", \"start\": 327, \"end\": 331}, {\"corpusId\": 25482728, \"span\": \"[32]\", \"start\": 327, \"end\": 331}, {\"corpusId\": 35890163, \"span\": \"[58]\", \"start\": 423, \"end\": 427}, {\"corpusId\": 35890163, \"span\": \"[58]\", \"start\": 423, \"end\": 427}, {\"corpusId\": 22106006, \"span\": \"[55]\", \"start\": 671, \"end\": 675}, {\"corpusId\": 22106006, \"span\": \"[55]\", \"start\": 671, \"end\": 675}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "11889", "title": "Shaping the Design of Smartphone-Based Interventions for Self-Harm", "sectionTitle": "INTRODUCTION", "text": "Self-harm is a major public health concern. However, due to the stigma surrounding self-harm, understanding and intervening in this issue is a challenge. Developing an enhanced understanding of the causes of self-harm during adolescence is of paramount importance, as too is the need to develop effective interventions which are appropriate to adolescents. Current research in supporting young people with self-harm experiences is mainly focused on creating self-help tools (e.g. web-based and mobile apps) based on a wide range of evidenced-based therapy approaches (e.g. cognitivebehavioral therapy (CBT) and dialectical behavioral therapy (DBT)). For example the BlueIce app, offers a variety of functionalities including strategies based on CBT and DBT, mood diary, mindfulness exercises, and mood-lifting activities [27]. While there are advancements in the field of smartphone-based sensing in a range of mental health categories (e.g. [67,69], the self-harm space remains relatively disconnected. In a systematic review of digital interventions for self-harm, there was a clear gap for mobile sensing solutions [73]. The majority of studies focused on offering evidenced-based therapies (e.g. acceptance-based therapy [65]. In the same review, only one study designed a game-like app called Therapeutic Evaluative Conditioning (TEC) to increase aversion to self-harm [25]. The results from 1 month trial of TEC showed reduction in self-cutting episodes by almost 40%.", "spans": "[{\"corpusId\": 3501920, \"span\": \"[27]\", \"start\": 821, \"end\": 825}, {\"corpusId\": 3501920, \"span\": \"[27]\", \"start\": 821, \"end\": 825}, {\"corpusId\": 49593830, \"span\": \"[67,\", \"start\": 942, \"end\": 946}, {\"corpusId\": 49593830, \"span\": \"[67,\", \"start\": 942, \"end\": 946}, {\"corpusId\": 477939, \"span\": \"69]\", \"start\": 946, \"end\": 949}, {\"corpusId\": 477939, \"span\": \"69]\", \"start\": 946, \"end\": 949}, {\"corpusId\": 3886023, \"span\": \"[73]\", \"start\": 1118, \"end\": 1122}, {\"corpusId\": 3886023, \"span\": \"[73]\", \"start\": 1118, \"end\": 1122}, {\"corpusId\": 2843431, \"span\": \"[65]\", \"start\": 1225, \"end\": 1229}, {\"corpusId\": 2843431, \"span\": \"[65]\", \"start\": 1225, \"end\": 1229}, {\"corpusId\": 6597057, \"span\": \"[25]\", \"start\": 1374, \"end\": 1378}, {\"corpusId\": 6597057, \"span\": \"[25]\", \"start\": 1374, \"end\": 1378}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": false, "refCount": 6}, {"paragraphId": "11890", "title": "Shaping the Design of Smartphone-Based Interventions for Self-Harm", "sectionTitle": "BACKGROUND Understanding Self-Harm", "text": "Non-suicidal self-injury, commonly known as self-harm, refers to thoughts and behaviours relating to the deliberate and direct damage of body tissue without suicidal intent [44]. Selfharm behaviours include cutting, burning, scratching, and selfhitting [71], and can vary in terms of function, severity and trajectory [11]; many individuals report using several of these methods to injure themselves [24]. Thoughts related to selfharm are defined as a serious desire to engage in self-injury, usually happening when the person is alone and experiencing negative thoughts that last for 1-30 min; with occurrence of up to 5 times per week [46]. Though, by definition, self-harm occurs without suicidal intent, suicidal behaviour and self-harm can coexist [45] and acts of self-harm are a strong risk factor for subsequent suicide attempts [62,72]. Young people who engage in self-harm do so for a multitude of reasons, both intrapersonal (e.g., low self-esteem, impulsivity, poor coping skills) and interpersonal (e.g., bullying, breakdown of a relationship, childhood trauma) [19,58]. According to the Experiential Avoidance Model (EAM), people engage in self-harm as an attempt to regulate and reduce overwhelming emotional states [17]. These unwanted emotional states can be triggered by stressful life events that the person perceives as particularly overwhelming and difficult to handle [44]. They can also be caused by underlying psychological difficulties, such as depression, anxiety, low self-esteem, relationship difficulties, and life stressors. Correlational and longitudinal research has identified multiple risk factors for engagement in self-harm including depression and anxiety, low self-esteem, childhood trauma, alexithymia (i.e., difficulty in identifying and describing own emotional states) , impulsivity, and attention and conduct difficulties [14,19,57].", "spans": "[{\"corpusId\": 13591479, \"span\": \"[71]\", \"start\": 253, \"end\": 257}, {\"corpusId\": 13591479, \"span\": \"[71]\", \"start\": 253, \"end\": 257}, {\"corpusId\": 143563991, \"span\": \"[11]\", \"start\": 318, \"end\": 322}, {\"corpusId\": 143563991, \"span\": \"[11]\", \"start\": 318, \"end\": 322}, {\"corpusId\": 75763904, \"span\": \"[24]\", \"start\": 400, \"end\": 404}, {\"corpusId\": 75763904, \"span\": \"[24]\", \"start\": 400, \"end\": 404}, {\"corpusId\": 19335701, \"span\": \"[46]\", \"start\": 637, \"end\": 641}, {\"corpusId\": 19335701, \"span\": \"[46]\", \"start\": 637, \"end\": 641}, {\"corpusId\": 8080368, \"span\": \"[45]\", \"start\": 753, \"end\": 757}, {\"corpusId\": 8080368, \"span\": \"[45]\", \"start\": 753, \"end\": 757}, {\"corpusId\": 21892453, \"span\": \"[62,\", \"start\": 837, \"end\": 841}, {\"corpusId\": 21892453, \"span\": \"[62,\", \"start\": 837, \"end\": 841}, {\"corpusId\": 461391, \"span\": \"72]\", \"start\": 841, \"end\": 844}, {\"corpusId\": 461391, \"span\": \"72]\", \"start\": 841, \"end\": 844}, {\"corpusId\": 20844212, \"span\": \"[19,\", \"start\": 1075, \"end\": 1079}, {\"corpusId\": 20844212, \"span\": \"[19,\", \"start\": 1075, \"end\": 1079}, {\"corpusId\": 35890163, \"span\": \"58]\", \"start\": 1079, \"end\": 1082}, {\"corpusId\": 35890163, \"span\": \"58]\", \"start\": 1079, \"end\": 1082}, {\"corpusId\": 1918485, \"span\": \"[17]\", \"start\": 1231, \"end\": 1235}, {\"corpusId\": 1918485, \"span\": \"[17]\", \"start\": 1231, \"end\": 1235}, {\"corpusId\": 37229693, \"span\": \"[14,\", \"start\": 1865, \"end\": 1869}, {\"corpusId\": 37229693, \"span\": \"[14,\", \"start\": 1865, \"end\": 1869}, {\"corpusId\": 20844212, \"span\": \"19,\", \"start\": 1869, \"end\": 1872}, {\"corpusId\": 20844212, \"span\": \"19,\", \"start\": 1869, \"end\": 1872}, {\"corpusId\": 7825754, \"span\": \"57]\", \"start\": 1872, \"end\": 1875}, {\"corpusId\": 7825754, \"span\": \"57]\", \"start\": 1872, \"end\": 1875}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 12}, {"paragraphId": "11891", "title": "Shaping the Design of Smartphone-Based Interventions for Self-Harm", "sectionTitle": "Ecological Momentary Assessment (EMA) of Self-Harm", "text": "Cross-sectional and longitudinal studies may help to understand long term risk factors of self-harm, but struggle to elucidate the more immediate contextual factors contributing to thoughts and behaviours around self-harm as and when they happen. Retrospective techniques (e.g., interview studies) that attempt to study these factors are prone to cognitive bias [54] and so more recent research has sought to use Ecological Momentary Assessment (EMA) techniques that gather real-time, real-world data on self-harm using mobile phone and web-based applications to encourage individuals who engage in self-harm to track their mood, situation and self-harm behaviours (e.g., [30,54]). EMA research has shown that self-harm engagement is preceded by an increase in negative emotions and followed by a decrease in these same emotions (e.g., [3,6]), lending empirical support to theories that conceptualise self-harm as a form of emotional regulation [43] through a physical 'release' of pain. Importantly, this research has shown that the increase in negative emotions preceding self-harm engagement takes place hours before [3,6], suggesting there may be a critical window wherein preventative measures may be employed.", "spans": "[{\"corpusId\": 5007540, \"span\": \"[54]\", \"start\": 362, \"end\": 366}, {\"corpusId\": 5007540, \"span\": \"[54]\", \"start\": 362, \"end\": 366}, {\"corpusId\": 5007540, \"span\": \"54]\", \"start\": 676, \"end\": 679}, {\"corpusId\": 5007540, \"span\": \"54]\", \"start\": 676, \"end\": 679}, {\"corpusId\": 1532708, \"span\": \"[3,\", \"start\": 836, \"end\": 839}, {\"corpusId\": 1532708, \"span\": \"[3,\", \"start\": 836, \"end\": 839}, {\"corpusId\": 205983862, \"span\": \"6]\", \"start\": 839, \"end\": 841}, {\"corpusId\": 205983862, \"span\": \"6]\", \"start\": 839, \"end\": 841}, {\"corpusId\": 146591211, \"span\": \"[43]\", \"start\": 945, \"end\": 949}, {\"corpusId\": 146591211, \"span\": \"[43]\", \"start\": 945, \"end\": 949}, {\"corpusId\": 216505674, \"span\": \"this research\", \"start\": 1014, \"end\": 1014}, {\"corpusId\": 1532708, \"span\": \"[3,\", \"start\": 1120, \"end\": 1123}, {\"corpusId\": 1532708, \"span\": \"[3,\", \"start\": 1120, \"end\": 1123}, {\"corpusId\": 205983862, \"span\": \"6]\", \"start\": 1123, \"end\": 1125}, {\"corpusId\": 205983862, \"span\": \"6]\", \"start\": 1123, \"end\": 1125}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "11892", "title": "Shaping the Design of Smartphone-Based Interventions for Self-Harm", "sectionTitle": "Ecological Momentary Assessment (EMA) of Self-Harm", "text": "Other research taking an EMA approach has also highlighted aspects of the situational context contributing to self-harm behaviour, such as being alone [46]. However, such research is limited. A recent review of EMA studies found that the majority of studies had focused on understanding the emotional context of self-harm behaviour, rather than cognitive or situational factors [54]. This may be because many participants struggle to articulate the motives of their self-harm behaviour, including cognitive and situational factors [3]. The same review also highlighted a lack of research using EMA with adolescent samples.", "spans": "[{\"corpusId\": 19335701, \"span\": \"[46]\", \"start\": 151, \"end\": 155}, {\"corpusId\": 19335701, \"span\": \"[46]\", \"start\": 151, \"end\": 155}, {\"corpusId\": 5007540, \"span\": \"[54]\", \"start\": 378, \"end\": 382}, {\"corpusId\": 5007540, \"span\": \"[54]\", \"start\": 378, \"end\": 382}, {\"corpusId\": 1532708, \"span\": \"[3]\", \"start\": 531, \"end\": 534}, {\"corpusId\": 1532708, \"span\": \"[3]\", \"start\": 531, \"end\": 534}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "11893", "title": "Shaping the Design of Smartphone-Based Interventions for Self-Harm", "sectionTitle": "Self-harm in Computer Science and HCI", "text": "Mental health and wellbeing is a growing application area for computing and human-computer interaction [7,20,52,53,64]. Computing in mental health has primarily been leveraged for (1) explorations of online resource use (e.g., social media, online communities) by those who engage in self-harm behaviours, and (2) use of technology (particularly mobile apps) as an intervention to monitor or reduce self-harm behaviour.", "spans": "[{\"corpusId\": 3153370, \"span\": \"[7,\", \"start\": 103, \"end\": 106}, {\"corpusId\": 3153370, \"span\": \"[7,\", \"start\": 103, \"end\": 106}, {\"corpusId\": 7202179, \"span\": \"20,\", \"start\": 106, \"end\": 109}, {\"corpusId\": 7202179, \"span\": \"20,\", \"start\": 106, \"end\": 109}, {\"corpusId\": 8792375, \"span\": \"52,\", \"start\": 109, \"end\": 112}, {\"corpusId\": 8792375, \"span\": \"52,\", \"start\": 109, \"end\": 112}, {\"corpusId\": 2161796, \"span\": \"53,\", \"start\": 112, \"end\": 115}, {\"corpusId\": 2161796, \"span\": \"53,\", \"start\": 112, \"end\": 115}, {\"corpusId\": 8040927, \"span\": \"64]\", \"start\": 115, \"end\": 118}, {\"corpusId\": 8040927, \"span\": \"64]\", \"start\": 115, \"end\": 118}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "11894", "title": "Shaping the Design of Smartphone-Based Interventions for Self-Harm", "sectionTitle": "Studies of Online Behaviour", "text": "Online resources have been identified as the preferred source for information and communication amongst adolescents who engage in self-harm [60,21]. Online resources can help to overcome problems of access and awareness [34] but are also perceived as being easier to engage with than face-to-face support, allowing young people to be more open about their behavior and feel less judged [33]. Thus, the Internet can provide anonymity, acceptance and support at a safe distance [38], allowing adolescents to overcome their fears surrounding shame and stigma to access important support and information. However, these same qualities that can make the web a safe space for supportive recovery communities also allow for the sharing of incorrect and deliberately harmful information [49].", "spans": "[{\"corpusId\": 145417105, \"span\": \"[60,\", \"start\": 140, \"end\": 144}, {\"corpusId\": 145417105, \"span\": \"[60,\", \"start\": 140, \"end\": 144}, {\"corpusId\": 4879663, \"span\": \"21]\", \"start\": 144, \"end\": 147}, {\"corpusId\": 4879663, \"span\": \"21]\", \"start\": 144, \"end\": 147}, {\"corpusId\": 72710078, \"span\": \"[34]\", \"start\": 220, \"end\": 224}, {\"corpusId\": 72710078, \"span\": \"[34]\", \"start\": 220, \"end\": 224}, {\"corpusId\": 22836262, \"span\": \"[33]\", \"start\": 386, \"end\": 390}, {\"corpusId\": 22836262, \"span\": \"[33]\", \"start\": 386, \"end\": 390}, {\"corpusId\": 12086933, \"span\": \"[38]\", \"start\": 476, \"end\": 480}, {\"corpusId\": 12086933, \"span\": \"[38]\", \"start\": 476, \"end\": 480}, {\"corpusId\": 207244185, \"span\": \"[49]\", \"start\": 779, \"end\": 783}, {\"corpusId\": 207244185, \"span\": \"[49]\", \"start\": 779, \"end\": 783}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "11895", "title": "Shaping the Design of Smartphone-Based Interventions for Self-Harm", "sectionTitle": "Studies of Online Behaviour", "text": "Pater and Mynatt coined the term 'digital self-harm' [49] to describe online activities that contribute to self-inflicted intentional, non-suicidal harm. Their definition includes both direct (e.g., self-wounding) and indirect (e.g., eating disorders, reckless behavior) self-harm, and suggests directions for future research that incorporate a wide set of disciplinary and theoretical approaches. (Note that this same term has also been used in the literature to describe other non-physical harmful behaviors directed at the self [48]). However, for the purposes of this paper, we use the term self-harm to refer only to 'direct' harmful activities. Digital self-harm activities have emerged even in very general studies of adolescents' online behaviour [51] and in studies of other mental health conditions (e.g., depression [2], eating disorder [50]), however a small number of researchers have explicitly focused on online representations of self-harm [13,22,26,23,31,36,40,41,56,70]. For a review of studies relating to social media use for the discussion of self-harm and viewing of associated content (1998-2014), see Dyson et al. [22].", "spans": "[{\"corpusId\": 207244185, \"span\": \"[49]\", \"start\": 53, \"end\": 57}, {\"corpusId\": 207244185, \"span\": \"[49]\", \"start\": 53, \"end\": 57}, {\"corpusId\": 3650036, \"span\": \"[48]\", \"start\": 531, \"end\": 535}, {\"corpusId\": 3650036, \"span\": \"[48]\", \"start\": 531, \"end\": 535}, {\"corpusId\": 216505674, \"span\": \"this paper\", \"start\": 577, \"end\": 577}, {\"corpusId\": 3224448, \"span\": \"[51]\", \"start\": 755, \"end\": 759}, {\"corpusId\": 3224448, \"span\": \"[51]\", \"start\": 755, \"end\": 759}, {\"corpusId\": 3331765, \"span\": \"[2]\", \"start\": 827, \"end\": 830}, {\"corpusId\": 3331765, \"span\": \"[2]\", \"start\": 827, \"end\": 830}, {\"corpusId\": 2776444, \"span\": \"[50]\", \"start\": 848, \"end\": 852}, {\"corpusId\": 2776444, \"span\": \"[50]\", \"start\": 848, \"end\": 852}, {\"corpusId\": 2505089, \"span\": \"[13,\", \"start\": 956, \"end\": 960}, {\"corpusId\": 2505089, \"span\": \"[13,\", \"start\": 956, \"end\": 960}, {\"corpusId\": 37479306, \"span\": \"22,\", \"start\": 960, \"end\": 963}, {\"corpusId\": 37479306, \"span\": \"22,\", \"start\": 960, \"end\": 963}, {\"corpusId\": 195328306, \"span\": \"26,\", \"start\": 963, \"end\": 966}, {\"corpusId\": 195328306, \"span\": \"26,\", \"start\": 963, \"end\": 966}, {\"corpusId\": 19484323, \"span\": \"23,\", \"start\": 966, \"end\": 969}, {\"corpusId\": 19484323, \"span\": \"23,\", \"start\": 966, \"end\": 969}, {\"corpusId\": 23307695, \"span\": \"31,\", \"start\": 969, \"end\": 972}, {\"corpusId\": 23307695, \"span\": \"31,\", \"start\": 969, \"end\": 972}, {\"corpusId\": 20802109, \"span\": \"36,\", \"start\": 972, \"end\": 975}, {\"corpusId\": 20802109, \"span\": \"36,\", \"start\": 972, \"end\": 975}, {\"corpusId\": 4958509, \"span\": \"40,\", \"start\": 975, \"end\": 978}, {\"corpusId\": 4958509, \"span\": \"40,\", \"start\": 975, \"end\": 978}, {\"corpusId\": 25252954, \"span\": \"41,\", \"start\": 978, \"end\": 981}, {\"corpusId\": 25252954, \"span\": \"41,\", \"start\": 978, \"end\": 981}, {\"corpusId\": 4987460, \"span\": \"56,\", \"start\": 981, \"end\": 984}, {\"corpusId\": 4987460, \"span\": \"56,\", \"start\": 981, \"end\": 984}, {\"corpusId\": 37479306, \"span\": \"[22]\", \"start\": 1138, \"end\": 1142}, {\"corpusId\": 37479306, \"span\": \"[22]\", \"start\": 1138, \"end\": 1142}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 15}, {"paragraphId": "11896", "title": "Shaping the Design of Smartphone-Based Interventions for Self-Harm", "sectionTitle": "Studies of Online Behaviour", "text": "Several studies of digital self-harm have focused on the use of hashtags to identify relevant content. Pater et al. [50] identified nineteen hashtags related to self-injury in their analysis of eating disorder content on Twitter, Instagram and Tumblr. These 19 tags have significant overlap with tags co-occurring (on Instagram) with #depression in an analysis by Andalibi, Ozturk & Forte [2]. One heavily-used tag from both datasets, #selfharmmm, was used by Moreno et al.'s [41] to establish a 'parlance' of self-harm that incorporated a set of otherwise ambiguous terms. Using Instagram to identify an initial set of tags that were often used alongside #selfharmmm, Moreno et al. resolved ambiguous tags by studying their use on other social media platforms and Google Images. In so-doing, they were able to triangulate and identify a set of relevant tags that might otherwise have been considered innocuous (e.g. #blithe); of the eighteen tags determined to be self-harm related, only six triggered Instagram's in-built content advisory redirect service. Similar efforts to build a corpus of terms used in social media hashtags for (German) self-harm related content have also been made by Brown et al. [13].", "spans": "[{\"corpusId\": 2776444, \"span\": \"[50]\", \"start\": 116, \"end\": 120}, {\"corpusId\": 2776444, \"span\": \"[50]\", \"start\": 116, \"end\": 120}, {\"corpusId\": 3331765, \"span\": \"[2]\", \"start\": 389, \"end\": 392}, {\"corpusId\": 3331765, \"span\": \"[2]\", \"start\": 389, \"end\": 392}, {\"corpusId\": 25252954, \"span\": \"[41]\", \"start\": 476, \"end\": 480}, {\"corpusId\": 25252954, \"span\": \"[41]\", \"start\": 476, \"end\": 480}, {\"corpusId\": 2505089, \"span\": \"[13]\", \"start\": 1207, \"end\": 1211}, {\"corpusId\": 2505089, \"span\": \"[13]\", \"start\": 1207, \"end\": 1211}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "11897", "title": "Shaping the Design of Smartphone-Based Interventions for Self-Harm", "sectionTitle": "Studies of Online Behaviour", "text": "Visual social media platforms have been an important area of concern in the study of digital self harm [2,5,13,31,36,40,41,50,56,70]. Pater et al. [50] noted the presence of selfharm related images in their study of eating disorder content on Twitter, Instagram and Tumblr. Miguel et al. [40] conducted a manual review of items tagged with #cutting and posted to Twitter, Tumblr and Instagram platforms over a period of six months. They found a high prevalence of graphic posts (i.e., cuts/scars 51%, blood 17%, or injury paraphernalia 22%; total 60%) and negative self-evaluations (46%), particularly on Instagram. References to other mental health conditions were also very common (e.g., depression 78%, eating disorder 43%). A significant minority of posts were used for more positive purposes, actively discouraging self-harm (10%) and providing or signposting recovery resources (5%).", "spans": "[{\"corpusId\": 3331765, \"span\": \"[2,\", \"start\": 103, \"end\": 106}, {\"corpusId\": 3331765, \"span\": \"[2,\", \"start\": 103, \"end\": 106}, {\"corpusId\": 191905862, \"span\": \"5,\", \"start\": 106, \"end\": 108}, {\"corpusId\": 191905862, \"span\": \"5,\", \"start\": 106, \"end\": 108}, {\"corpusId\": 2505089, \"span\": \"13,\", \"start\": 108, \"end\": 111}, {\"corpusId\": 2505089, \"span\": \"13,\", \"start\": 108, \"end\": 111}, {\"corpusId\": 23307695, \"span\": \"31,\", \"start\": 111, \"end\": 114}, {\"corpusId\": 23307695, \"span\": \"31,\", \"start\": 111, \"end\": 114}, {\"corpusId\": 20802109, \"span\": \"36,\", \"start\": 114, \"end\": 117}, {\"corpusId\": 20802109, \"span\": \"36,\", \"start\": 114, \"end\": 117}, {\"corpusId\": 4958509, \"span\": \"40,\", \"start\": 117, \"end\": 120}, {\"corpusId\": 4958509, \"span\": \"40,\", \"start\": 117, \"end\": 120}, {\"corpusId\": 25252954, \"span\": \"41,\", \"start\": 120, \"end\": 123}, {\"corpusId\": 25252954, \"span\": \"41,\", \"start\": 120, \"end\": 123}, {\"corpusId\": 2776444, \"span\": \"50,\", \"start\": 123, \"end\": 126}, {\"corpusId\": 2776444, \"span\": \"50,\", \"start\": 123, \"end\": 126}, {\"corpusId\": 4987460, \"span\": \"56,\", \"start\": 126, \"end\": 129}, {\"corpusId\": 4987460, \"span\": \"56,\", \"start\": 126, \"end\": 129}, {\"corpusId\": 2776444, \"span\": \"[50]\", \"start\": 147, \"end\": 151}, {\"corpusId\": 2776444, \"span\": \"[50]\", \"start\": 147, \"end\": 151}, {\"corpusId\": 4958509, \"span\": \"[40]\", \"start\": 288, \"end\": 292}, {\"corpusId\": 4958509, \"span\": \"[40]\", \"start\": 288, \"end\": 292}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "11898", "title": "Shaping the Design of Smartphone-Based Interventions for Self-Harm", "sectionTitle": "Studies of Online Behaviour", "text": "Other assessments of social media have focused on individual platforms. For example, studies of Instagram [13] and Tumblr content [56], posted in 2015 and 2016 respectively, verified the high prevalence of graphic wound depictions seen in prior studies. However, the latter study also noted the presence of content that did not directly depict self-harm (58%) such as selfies and snippets from popular media -these indirect images were more likely to carry recovery-related messages and to be reblogged by other users [56]. Attempts to automate detection of self-harm content have also emerged; Wang et al. used machine learning to automatically identify self-harm related content on Flickr, finding clear patterns in language (tags, captions), social responses (likes, comments) and time of posting for self-harm content when compared to a control image pool [70]. Similar temporal and social patterns have also been seen in manual analyses [13], with content depicting severe wounds generating more comments than moderate and mild injuries. Manikonda et al.'s [36] study of Instagram posts also leveraged learning techniques, identifying self-harm as one of several mental-health disclosures made on the platform.", "spans": "[{\"corpusId\": 2505089, \"span\": \"[13]\", \"start\": 106, \"end\": 110}, {\"corpusId\": 2505089, \"span\": \"[13]\", \"start\": 106, \"end\": 110}, {\"corpusId\": 4987460, \"span\": \"[56]\", \"start\": 130, \"end\": 134}, {\"corpusId\": 4987460, \"span\": \"[56]\", \"start\": 130, \"end\": 134}, {\"corpusId\": 4987460, \"span\": \"[56]\", \"start\": 518, \"end\": 522}, {\"corpusId\": 4987460, \"span\": \"[56]\", \"start\": 518, \"end\": 522}, {\"corpusId\": 2505089, \"span\": \"[13]\", \"start\": 942, \"end\": 946}, {\"corpusId\": 2505089, \"span\": \"[13]\", \"start\": 942, \"end\": 946}, {\"corpusId\": 20802109, \"span\": \"[36]\", \"start\": 1062, \"end\": 1066}, {\"corpusId\": 20802109, \"span\": \"[36]\", \"start\": 1062, \"end\": 1066}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "11899", "title": "Shaping the Design of Smartphone-Based Interventions for Self-Harm", "sectionTitle": "Studies of Online Behaviour", "text": "A small body of research has attempted to explicitly explore the role of social media use in real-world behaviours and clinical outcomes related to self-injury [5,31,15]. Jacob, Evans and Scourfield [31] conducted semi-structured interviews with twenty-one young people with a previous history of self-harm (sixteen had sought professional help for self-harm and eight had engaged with emergency healthcare as a result of selfharm). Individuals described how the internet reinforced their self-harm behaviours by embedding them in a community of peers for whom self-harm was as much a part of the daily routine as making a cup of tea, how digital communities allowed for sharing of previously unfamiliar techniques for self-harm, and how online shopping provided mechanisms to anonymously circumvent age-restrictions on razors and other blades. Interviewees highlighted the importance of online visual media in triggering an immediate desire to self harm, and its role in encouraging more extreme self-harm behaviours. Carey et al. [15] conducted surveys and interviews with twenty-nine young people as they engaged with emergency healthcare for issues suicidal-or other self-harmful-behaviour. Whilst some participants reported that they posted to social media because of its anonymity and presence of like-minded individuals, others reported the presence of family members and peers as a motivation for avoiding posting personal content on the platforms -some participants explicitly referred to the creation of additional social media profiles to avoid this issue. Arendt et al. conducted a two-wave panel survey demonstrating that exposure to self-harm content on Instagram was associated with self-harm and negative emotional well-being, and also predicted self-harm and suicide-related outcomes one month later [5]. Our own interviews with adolescents target individuals who have a self-defined prior experience with self-harm but consider online behaviours as just one aspect of a broader technology ecosystem. Further, our interviews deliberately prompted young people to consider the role of technology in managing self-harm, a topic not explored in these studies.", "spans": "[{\"corpusId\": 191905862, \"span\": \"[5,\", \"start\": 160, \"end\": 163}, {\"corpusId\": 191905862, \"span\": \"[5,\", \"start\": 160, \"end\": 163}, {\"corpusId\": 23307695, \"span\": \"31,\", \"start\": 163, \"end\": 166}, {\"corpusId\": 23307695, \"span\": \"31,\", \"start\": 163, \"end\": 166}, {\"corpusId\": 46954352, \"span\": \"15]\", \"start\": 166, \"end\": 169}, {\"corpusId\": 46954352, \"span\": \"15]\", \"start\": 166, \"end\": 169}, {\"corpusId\": 23307695, \"span\": \"[31]\", \"start\": 199, \"end\": 203}, {\"corpusId\": 23307695, \"span\": \"[31]\", \"start\": 199, \"end\": 203}, {\"corpusId\": 46954352, \"span\": \"[15]\", \"start\": 1032, \"end\": 1036}, {\"corpusId\": 46954352, \"span\": \"[15]\", \"start\": 1032, \"end\": 1036}, {\"corpusId\": 191905862, \"span\": \"[5]\", \"start\": 1817, \"end\": 1820}, {\"corpusId\": 191905862, \"span\": \"[5]\", \"start\": 1817, \"end\": 1820}, {\"corpusId\": 216505674, \"span\": \"our interviews\", \"start\": 2041, \"end\": 2041}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "11900", "title": "Shaping the Design of Smartphone-Based Interventions for Self-Harm", "sectionTitle": "Understanding Self-Harm", "text": "Young people and counsellors reflected on their use of selftracking methods (e.g., mood diaries) to identify multiple factors related to mood fluctuations and self-harm, including tiredness, social isolation, crowded environments, and academic pressures -supporting past research with similar findings (e.g., [68,47]). While the findings suggest common triggers, the combination or sequence of these triggers, as well as the exact consequences for mood, were positioned as being unique to individuals. As such, both young people and counsellors emphasised the importance of understanding the mood dysregulation and triggers associated with self-harm on an individual case-by-case basis. These findings echo those of Berrouiguet et al. [8], who highlight the importance of taking an individual approach to treating mental health issues due to the diversity of triggers that might be seen.", "spans": "[{\"corpusId\": 4695263, \"span\": \"[68,\", \"start\": 309, \"end\": 313}, {\"corpusId\": 4695263, \"span\": \"[68,\", \"start\": 309, \"end\": 313}, {\"corpusId\": 19335701, \"span\": \"47]\", \"start\": 313, \"end\": 316}, {\"corpusId\": 19335701, \"span\": \"47]\", \"start\": 313, \"end\": 316}, {\"corpusId\": 34817803, \"span\": \"[8]\", \"start\": 735, \"end\": 738}, {\"corpusId\": 34817803, \"span\": \"[8]\", \"start\": 735, \"end\": 738}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "11901", "title": "Shaping the Design of Smartphone-Based Interventions for Self-Harm", "sectionTitle": "Predicting Self-Harm", "text": "Next, our findings have implications for those interested in the prediction of self-harm using smartphone-based technologies. Both young people and counsellors reflected on how smartphones could be used to identify patterns of emotions and behaviours associated with self-harm. In workshops, young people expressed that they would be generally be comfortable with the idea of behavioural tracking through smartphonebased sensing, and would give access to their relevant personal data for this purpose. Survey respondents also expressed a similar level of comfort with giving access to their data i.e. phone usage time, location, and the type of health website and apps they access. Young people wanted the self-tracking through apps to be as automated as possible; they preferred a passive relationship with the app preferably tracking their behaviours in the background. This echoes findings by [1] who developed a smartphone-based sensing to automatically detect social rhythms in bipolar disorder to address the challenges associated with manual tracking [37].", "spans": "[{\"corpusId\": 216505674, \"span\": \"our findings\", \"start\": 18, \"end\": 18}, {\"corpusId\": 5697836, \"span\": \"[1]\", \"start\": 896, \"end\": 899}, {\"corpusId\": 5697836, \"span\": \"[1]\", \"start\": 896, \"end\": 899}, {\"corpusId\": 7207913, \"span\": \"[37]\", \"start\": 1058, \"end\": 1062}, {\"corpusId\": 7207913, \"span\": \"[37]\", \"start\": 1058, \"end\": 1062}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "11902", "title": "Shaping the Design of Smartphone-Based Interventions for Self-Harm", "sectionTitle": "Predicting Self-Harm", "text": "However, understandably, not all participants were willing to share their data. Some young people felt apprehensive in relation to discussions of data for two reasons. First, they questioned the accuracy of collected data i.e. not carrying their phone at all times. Second, they initially did not want data to be stored about them, suggesting data should be obliterated on a daily basis. This indicates that, in future work aiming to engage large numbers of participants in such a sensitive topic area, we would need to take extreme care to ensure that any concerns about data capture and use were alleviated. This leaves us with two alternatives for future deployments; allow users to opt-out of particular data streams or further investigate people's concerns and inform them better. In previous healthcare monitoring research projects, participants were mo-tivated to share location-based data by the perceived benefit (economic or altruistic e.g. helping others suffering with the same condition [18]) and have reported being confident that it will be collected, transmitted, stored, and analysed following research guidelines agreed beforehand [61]. Additionally, the young people in our workshops were more willing to consider different types of data sharing once they knew more about the purpose of the data collection.", "spans": "[{\"corpusId\": 16116223, \"span\": \"[18]\", \"start\": 1000, \"end\": 1004}, {\"corpusId\": 16116223, \"span\": \"[18]\", \"start\": 1000, \"end\": 1004}, {\"corpusId\": 17734776, \"span\": \"[61]\", \"start\": 1149, \"end\": 1153}, {\"corpusId\": 17734776, \"span\": \"[61]\", \"start\": 1149, \"end\": 1153}, {\"corpusId\": 216505674, \"span\": \"our work\", \"start\": 1197, \"end\": 1197}]", "conference": "chi", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 15}
{"paperId": "6b1ae144bd17a1b60002abd52b19ac9234620ff2", "title": "Classification of telicity using cross-linguistic annotation projection", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2017, "citationCount": 15, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/D17-1271.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://aclanthology.org/D17-1271, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2017-09-01", "authors": [{"authorId": "33985877", "name": "Annemarie Friedrich"}, {"authorId": "24857771", "name": "Damyana Gateva"}], "abstract": "This paper addresses the automatic recognition of telicity, an aspectual notion. A telic event includes a natural endpoint (\u201cshe walked home\u201d), while an atelic event does not (\u201cshe walked around\u201d). Recognizing this difference is a prerequisite for temporal natural language understanding. In English, this classification task is difficult, as telicity is a covert linguistic category. In contrast, in Slavic languages, aspect is part of a verb\u2019s meaning and even available in machine-readable dictionaries. Our contributions are as follows. We successfully leverage additional silver standard training data in the form of projected annotations from parallel English-Czech data as well as context information, improving automatic telicity classification for English significantly compared to previous work. We also create a new data set of English texts manually annotated with telicity.", "corpusId": "9651031", "paragraphs": [{"paragraphId": "49171", "title": "Classification of telicity using cross-linguistic annotation projection", "sectionTitle": "Related work", "text": "Siegel and McKeown (2000, henceforth SMK2000) present the first machine-learning based approach to identifying completedness, i.e., telicity, determining whether an event reaches a culmination or completion point at which a new state is introduced. Their approach describes each verb occurrence exclusively using features reflecting corpus-based statistics of the corresponding verb type. For each verb type, they collect the co-occurrence frequencies with 14 linguistic markers (e.g., present tense, perfect, combination with temporal adverbs) in an automatically parsed background corpus. They call these features linguistic indicators and train a variety of machine learning models based on 300 clauses, of which roughly 2/3 are culminated, i.e., telic. Their test set also contains about 300 clauses, corresponding to 204 distinct non-stative verbs. Their data sets are not available, but as this work is the most closely related to ours, we reimplement their approach and compare to it in Section 5. Samard\u017ei\u0107 and Merlo (2016) create a model for real-world duration of events (as short or long) of English verbs as annotated in TimeBank (Pustejovsky et al., 2003). The model is informed by temporal boundedness information collected from parallel English-Serbian data. Their only features are how often the respective verb type was aligned to Serbian verbs carrying certain affixes that indicate perfectiveness or imperfectiveness. Their usage of \"verb type\" differs from ours as they do not lemmatize, i.e., they always predict that \"falling\" is a long event, while \"fall\" is short. Our approach shares the idea of projecting aspectual information from Slavic languages to English, but in contrast to classifying verb types, we classify whether an event type introduced by the verb constellation of a clause is telic or atelic, making use of a machinereadable dictionary for Czech instead of relying on affix information. Lo\u00e1iciga and Grisot (2016) create an automatic classifier for boundedness, defined as whether the endpoint of an event has occurred or not, and show that this is useful for picking the correct tense in French translations of the English Simple Past. Their classifier employs a similar but smaller feature set compared to ours. Other related work on predicting aspect include systems aiming at identifying lexical aspect (Siegel and McKeown, 2000;Friedrich and Palmer, 2014) or habituals (Mathew and Katz, 2009;Friedrich and Pinkal, 2015).", "spans": "[{\"corpusId\": 9651031, \"span\": \"this work\", \"start\": 905, \"end\": 905}, {\"corpusId\": 9651031, \"span\": \"Our approach\", \"start\": 1601, \"end\": 1601}, {\"corpusId\": 6433813, \"span\": \"(Siegel and McKeown, 2000;\", \"start\": 2348, \"end\": 2374}, {\"corpusId\": 1832412, \"span\": \"Friedrich and Palmer, 2014)\", \"start\": 2374, \"end\": 2401}, {\"corpusId\": 382217, \"span\": \"Friedrich and Pinkal, 2015)\", \"start\": 2438, \"end\": 2465}]", "conference": "emnlp", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "49172", "title": "Classification of telicity using cross-linguistic annotation projection", "sectionTitle": "Related work", "text": "Cross-linguistic annotation projection approaches mostly make use of existing manually created annotations in the source language; similar to our approach, Diab and Resnik (2002) and Marasovi\u0107 et al. (2016) leverage properties of the source language to automatically induce annotations on the target side.", "spans": "[{\"corpusId\": 9651031, \"span\": \"our approach\", \"start\": 154, \"end\": 154}, {\"corpusId\": 10091362, \"span\": \"Diab and Resnik (2002)\", \"start\": 156, \"end\": 178}, {\"corpusId\": 55383367, \"span\": \"Marasovi\\u0107 et al. (2016)\", \"start\": 183, \"end\": 206}]", "conference": "emnlp", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "49173", "title": "Classification of telicity using cross-linguistic annotation projection", "sectionTitle": "Gold standard: MASC (EN)", "text": "We create a new data set consisting of 10 English texts taken from MASC (Ide et al., 2010), annotated for telicity. Texts include two essays, a journal article, two blog texts, two history texts from travel guides, and three texts from the fic-  tion genre. Annotation was performed using the web-based SWAN system (G\u00fchring et al., 2016). Annotators were given a short written manual with instructions. We model telicity for dynamic (eventive) verb occurrences because stative verbs (e.g., \"like\") do not have built-in endpoints by definition. Annotators choose one of the labels telic and atelic or they skip clauses that they consider to be stative. In a first round, each verb occurrence was labeled by three annotators (the second author of this paper plus two paid student assistants). They unanimously agreed on telicity labels for 1166 verb occurrences; these are directly used for the gold standard. Cases in which only two annotators agreed on a telicity label (the third annotator may have either disagreed or skipped the clause) are labeled by a fourth independent annotator (the first author), who did not have access to the labels of the first rounds. This second annotation round resulted in 697 further cases in which three annotators gave the same telicity label. Statistics for our final gold standard, which consists of all instances for which at least three out of the four annotators agreed, are shown in Table 1; \"ambiguous\" verb types are those for which the gold standard contains both telic and atelic instances. 510 of the 567 verb types also occur in the InterCorp silver standard, which provides training instances for 69 out of the 70 ambiguous verb types. Finally, there are 446 cases for which no three annotators supplied the same label. Disagreement and skipping was mainly observed for verbs indicating attributions (\"critics claim\" or \"the film uses\"), which can be perceived either as statives or as instances of historic present. Other difficult cases include degree verbs (\"increase\"), aspectual verbs (\"begin\"), perception verbs (\"hear\"), iteratives (\"flash\") and the verb \"do.\" For these cases, decisions how to treat them may have to be made depending on the concrete application; for now, they are excluded from our gold standard. Another source of error is that despite the training, annotators sometimes conflate their world knowledge (i.e., that some events necessarily come to an end eventually, such as the \"swimming in the lake\" in (2)) with the annotation task of determining telicity at a linguistic level.", "spans": "[{\"corpusId\": 5865023, \"span\": \"(Ide et al., 2010)\", \"start\": 72, \"end\": 90}, {\"corpusId\": 51932177, \"span\": \"(G\\u00fchring et al., 2016)\", \"start\": 315, \"end\": 337}, {\"corpusId\": 9651031, \"span\": \"this paper\", \"start\": 755, \"end\": 755}]", "conference": "emnlp", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "49174", "title": "Classification of telicity using cross-linguistic annotation projection", "sectionTitle": "Computational modeling", "text": "Features. We model each instance by means of a variety of syntactic-semantic features, using the toolkit provided by . 6 Preprocessing is done using Stanford CoreNLP (Chen and Manning, 2014) based on dkpro (Eckart de Castilho and Gurevych, 2014). For the verb's lemma, the features include the WordNet (Fellbaum, 1998) sense and supersense and linguistic indicators (Siegel and McKeown, 2000) extracted from GigaWord (Graff et al., 2003). Using only the latter as features corresponds to the system by SMK2000 as described in Section 2. The feature set also describes the verb's subject and objects; among others their number, person, countability 7 , their most frequent WordNet sense and the respective supersenses, and dependency relations between the argument and its governor(s). In addition, tense, voice and whether the clause is in the Perfect or Progressive aspect is reflected, sample only 66% of Progressives received the label atelic. 5 Of the 2402 cases, annotators completely agreed on 1577 cases (1114 telic, 203 atelic, 260 skipped). 85 cases were 2x atelic + 1x skipped, 219 cases were 2x telic + 1x skipped. 6 https://github.com/annefried/sitent 7 http://celex.mpi.nl as well as the presence of clausal (e.g., temporal) modifiers. For replicability we make the configuration files for the feature set available.", "spans": "[{\"corpusId\": 11616343, \"span\": \"(Chen and Manning, 2014)\", \"start\": 166, \"end\": 190}, {\"corpusId\": 11163854, \"span\": \"(Eckart de Castilho and Gurevych, 2014)\", \"start\": 206, \"end\": 245}, {\"corpusId\": 6433813, \"span\": \"(Siegel and McKeown, 2000)\", \"start\": 366, \"end\": 392}]", "conference": "emnlp", "year": 2017, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 4}
{"paperId": "aa5b35dcf8b024f5352db73cc3944e8fad4f3793", "title": "Pointing the Unknown Words", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2016, "citationCount": 532, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/P16-1014.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1603.08148, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2016-03-26", "authors": [{"authorId": "1854385", "name": "\u00c7aglar G\u00fcl\u00e7ehre"}, {"authorId": "3103594", "name": "Sungjin Ahn"}, {"authorId": "1701451", "name": "Ramesh Nallapati"}, {"authorId": "145218984", "name": "Bowen Zhou"}, {"authorId": "1751762", "name": "Yoshua Bengio"}], "abstract": "The problem of rare and unknown words is an important issue that can potentially influence the performance of many NLP systems, including both the traditional count-based and the deep learning models. We propose a novel way to deal with the rare and unseen words for the neural network models using attention. Our model uses two softmax layers in order to predict the next word in conditional language models: one predicts the location of a word in the source sentence, and the other predicts a word in the shortlist vocabulary. At each time-step, the decision of which softmax layer to use choose adaptively made by an MLP which is conditioned on the context.~We motivate our work from a psychological evidence that humans naturally have a tendency to point towards objects in the context or the environment when the name of an object is not known.~We observe improvements on two tasks, neural machine translation on the Europarl English to French parallel corpora and text summarization on the Gigaword dataset using our proposed model.", "corpusId": "969555", "paragraphs": [{"paragraphId": "60130", "title": "Pointing the Unknown Words", "sectionTitle": "Related Work", "text": "Several approaches have been proposed towards solving the rare words/unknown words problem, which can be broadly divided into three categories. The first category of the approaches focuses on improving the computation speed of the softmax output so that it can maintain a very large vocabulary. Because this only increases the shortlist size, it helps to mitigate the unknown word problem, but still suffers from the rare word problem. The hierarchical softmax (Morin and Bengio, 2005), importance sampling (Bengio and Sen\u00e9cal, 2008;Jean et al., 2014), and the noise contrastive estimation (Gutmann and Hyv\u00e4rinen, 2012;Mnih and Kavukcuoglu, 2013) methods are in the class.", "spans": "[{\"corpusId\": 1326925, \"span\": \"(Morin and Bengio, 2005)\", \"start\": 461, \"end\": 485}, {\"corpusId\": 9147661, \"span\": \"(Bengio and Sen\\u00e9cal, 2008;\", \"start\": 507, \"end\": 533}, {\"corpusId\": 2863491, \"span\": \"Jean et al., 2014)\", \"start\": 533, \"end\": 551}, {\"corpusId\": 11583904, \"span\": \"(Gutmann and Hyv\\u00e4rinen, 2012;\", \"start\": 590, \"end\": 619}, {\"corpusId\": 14992849, \"span\": \"Mnih and Kavukcuoglu, 2013)\", \"start\": 619, \"end\": 646}]", "conference": "acl", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "60131", "title": "Pointing the Unknown Words", "sectionTitle": "Related Work", "text": "The second category, where our proposed method also belongs to, uses information from the context. Notable works are (Luong et al., 2015) and (Hermann et al., 2015). In particular, applying to machine translation task, (Luong et al., 2015) learns to point some words in source sentence and copy it to the target sentence, similarly to our method. However, it does not use attention mechanism, and by having fixed sized soft-max output over the relative pointing range (e.g., -7, . . . , -1, 0, 1, . . . , 7), their model (the Positional All model) has a limitation in applying to more general problems such as summarization and question answering, where, unlike machine translation, the length of the context and the pointing locations in the context can vary dramatically. In question answering setting, (Hermann et al., 2015) have used placeholders on named entities in the context. However, the placeholder id is directly predicted in the softmax output rather than predicting its location in the context.", "spans": "[{\"corpusId\": 969555, \"span\": \"our proposed method\", \"start\": 46, \"end\": 46}, {\"corpusId\": 1245593, \"span\": \"(Luong et al., 2015)\", \"start\": 117, \"end\": 137}, {\"corpusId\": 6203757, \"span\": \"(Hermann et al., 2015)\", \"start\": 142, \"end\": 164}, {\"corpusId\": 1245593, \"span\": \"(Luong et al., 2015)\", \"start\": 219, \"end\": 239}, {\"corpusId\": 969555, \"span\": \"our method\", \"start\": 345, \"end\": 345}, {\"corpusId\": 6203757, \"span\": \"(Hermann et al., 2015)\", \"start\": 805, \"end\": 827}]", "conference": "acl", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 2}
{"paperId": "e4afb5f166a82e5ff55d1a2fac2312c93a71b036", "title": "\"It's only when somebody says a tool worked for them that I believe it will work for me\": Socio-tecture as a lens for Digital Transformation", "venue": "Proc. ACM Hum. Comput. Interact.", "year": 2022, "citationCount": 8, "openAccessPdf": {"url": "https://dl.acm.org/doi/pdf/10.1145/3555584", "status": "BRONZE", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3555584?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3555584, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2022-11-07", "authors": [{"authorId": "40650554", "name": "Kagonya Awori"}, {"authorId": "67004873", "name": "M. Allela"}, {"authorId": "2190502922", "name": "Stephanie Nyairo"}, {"authorId": "2212460959", "name": "Samuel C. Maina"}, {"authorId": "1403047666", "name": "J. O'Neill"}], "abstract": "Small and Medium sized Businesses (SMBs) make up majority of employment in Africa (around 80%). Understanding the digital transformation that SMBs in Africa went through during the pandemic can play an important role in uncovering how to build solutions that better support the African business and African worker. In this paper we report on findings from a qualitative study with 40 SMBs in Kenya. The study aimed to understand the lived experience of digital transformation, the impacts of COVID-19 on their businesses, and how they responded to such impacts using technology. We found that COVID-prompted digital transformation was reactive and opportunistic, plus social and collective. Moreover, the socialness of business goes way beyond digital transformation, and influences how SMBs in Kenya start, develop and are sustained. In illustrating this, we offer a lens to understanding work and workers of SMBs in Kenya and similar contexts across the globe.", "corpusId": "253460030", "paragraphs": [{"paragraphId": "29204", "title": "\u201cIt\u2019s only when somebody says a tool worked for them that I believe it will work for me\u201d: Socio-tecture as a lens for digital transformation", "sectionTitle": "Init", "text": "impacted economic activity in many sectors. There was a turn to online learning and working from home, as well as the adoption of new digital business models as a strategy to keep organisations operational [1]. HCI studies focusing on how businesses adapted to the pandemic, primarily focused on remote work mediated by video-conferencing tools (such as Zoom, Microsoft Teams and Google Meet). Such studies expound on productivity [2][3][4], collaboration [5], as well as best practices on ways to stay connected in spite of the physical distance amongst knowledge workers. Whilst it is important to understand the role of video conferencing tools, it is equally important to critically examine nuances around the businesses who use them, and how they have navigated the move to remote work and technology adoption in general.", "spans": "[{\"corpusId\": 231719812, \"span\": \"[2]\", \"start\": 431, \"end\": 434}, {\"corpusId\": 213659985, \"span\": \"[3]\", \"start\": 434, \"end\": 437}, {\"corpusId\": 214430567, \"span\": \"[4]\", \"start\": 437, \"end\": 440}, {\"corpusId\": 220871075, \"span\": \"[5]\", \"start\": 456, \"end\": 459}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "29205", "title": "\u201cIt\u2019s only when somebody says a tool worked for them that I believe it will work for me\u201d: Socio-tecture as a lens for digital transformation", "sectionTitle": "Init", "text": "In this paper, we report on the findings from an interview study with SMBs in Kenya that sought to understand their lived experience of digital transformation over the course of the pandemic. We elucidate how SMBs in Kenya adapted to the impact of COVID-19, and in particular, how technology was employed to assist in addressing the challenges of this period. Research has evidenced that the COVID-19 pandemic was not only a health crisis, but also prompted widespread technological disruption [7]. This phenomenon was reflected in our research through the widespread digital transformation of SMBs. However, the majority of the technologies adopted were not designed with the African business in mind. Rather they were designed in and for the Global North. Research shows that just porting such technologies from one setting -with its specific orientations and concerns -to another setting is not always effective nor beneficial [8][9][10][11]. If we wish to enable digital transformation which enhances productivity among businesses in Africa, it is important to design with the opportunities and contingencies of work in Africa in mind. This research is a step in this direction, providing a rich understanding of the impact of COVID-19 on the digital transformation of SMBs in Kenya.", "spans": "[{\"corpusId\": 253460030, \"span\": \"this paper\", \"start\": 13, \"end\": 13}, {\"corpusId\": 225164424, \"span\": \"[7]\", \"start\": 494, \"end\": 497}, {\"corpusId\": 253460030, \"span\": \"our research\", \"start\": 544, \"end\": 544}, {\"corpusId\": 3128663, \"span\": \"[8]\", \"start\": 930, \"end\": 933}, {\"corpusId\": 5660190, \"span\": \"[10]\", \"start\": 936, \"end\": 940}, {\"corpusId\": 29771746, \"span\": \"[11]\", \"start\": 940, \"end\": 944}, {\"corpusId\": 253460030, \"span\": \"This research\", \"start\": 1153, \"end\": 1153}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "29206", "title": "\u201cIt\u2019s only when somebody says a tool worked for them that I believe it will work for me\u201d: Socio-tecture as a lens for digital transformation", "sectionTitle": "Impact of the COVID-19 pandemic on Small Businesses", "text": "The job market in African countries, including Kenya, is dominated by the informal economy. Africa has the highest proportion of informal employment in the world at 85.8% [12]. While some sectors such as Agriculture remained largely unaffected, projections during the first few months of the pandemic indicated that businesses that predicate on face-to-face interactions such restaurants, hotels and transportation, were more likely to be negatively affected [13]. Further to this, the impact on essential businesses was significantly lower compared to businesses that were deemed as non-essential [13]. In ensuing months since the peak of the pandemic in 2020, it has become apparent that the impact of the pandemic falls largely in the following dimensions: operation status, sales/demand, supply chain, employment, and lastly, emotional and psychological well-being. A survey conducted by the World Bank across 51 countries involving both small and large businesses in key sectors, indicated that while the pandemic led to sectorwide business closures, gradual reopening was significantly lower in the tourism sector and amongst small businesses [14]. This in turn saw a reduction in number of employees and an increase in unemployment due layoffs and furloughs [13]. In addition, many businesses experienced a rapid decrease in sales which can be attributed to reduced demand as a result of lowered spending and cutting back on social activities as well as commutes [15,16]. The movement restrictions due to the lockdowns affected supply chain related activities making it more difficult for businesses to access materials and goods [16]. The pandemic has also been considered a traumatic event causing undue emotional and psychological stress to workers and business owners [15] prompting businesses to actively address workplace stress and anxiety during the pandemic period.", "spans": "[{\"corpusId\": 220277665, \"span\": \"[12]\", \"start\": 171, \"end\": 175}, {\"corpusId\": 221459956, \"span\": \"[13]\", \"start\": 459, \"end\": 463}, {\"corpusId\": 221459956, \"span\": \"[13]\", \"start\": 598, \"end\": 602}, {\"corpusId\": 221459956, \"span\": \"[13]\", \"start\": 1265, \"end\": 1269}, {\"corpusId\": 220267566, \"span\": \"16]\", \"start\": 1474, \"end\": 1477}, {\"corpusId\": 220267566, \"span\": \"[16]\", \"start\": 1637, \"end\": 1641}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "29207", "title": "\u201cIt\u2019s only when somebody says a tool worked for them that I believe it will work for me\u201d: Socio-tecture as a lens for digital transformation", "sectionTitle": "Digital Transformation in Africa", "text": "For SMBs in Kenya, digital transformation and online commerce are facilitated by the pervasiveness of mobile technologies and increased access to the internet. In particular, phone applications that support mobile money, mobile banking and mobile credit, such as M-Pesa 3 and M-Shwari 4 , have significantly contributed to the growth of SMBs [23][24][25]. The literature on SMBs and digital transformation in Africa is framed within three broad categories of potential constraints, adoption and diffusion, and support and implementation [25]. Studies report that various gains have been realised. For instance, operational efficiency in the move to paperless systems can increase productivity and reduce staff fraud, cash handling errors and contributes to client acquisition [24,26]. The convenience of digital financial services can reduce the need for physical mobility and expand access to a wider range of services that customers can access remotely [26]. Customers can also create a digital transaction history. However, digital transformation for SMBs is not without its challenges, including resistance to change, lack of data or ineffective use of data in drawing inferences, bridging employee skill gaps, cybersecurity, and access to high-speed internet [26].", "spans": "[{\"corpusId\": 144418405, \"span\": \"[23]\", \"start\": 342, \"end\": 346}, {\"corpusId\": 168032421, \"span\": \"[24]\", \"start\": 346, \"end\": 350}, {\"corpusId\": 158216832, \"span\": \"[25]\", \"start\": 350, \"end\": 354}, {\"corpusId\": 158216832, \"span\": \"[25]\", \"start\": 537, \"end\": 541}, {\"corpusId\": 168032421, \"span\": \"[24,\", \"start\": 776, \"end\": 780}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "29208", "title": "\u201cIt\u2019s only when somebody says a tool worked for them that I believe it will work for me\u201d: Socio-tecture as a lens for digital transformation", "sectionTitle": "Data and Digital Transformation.", "text": "Many studies on business intelligence focus on large organisations such as banks and telecommunications [31,32]. Unlike SMBs, larger businesses have access to the requisite resources for deployment such as technical competencies and adequate financial resources. In many cases, the available technology (software/enterprise systems) targets larger entities [33]. These challenges prompt the need for solutions that are accessible to SMBs and that take their limited resources into consideration [34].", "spans": "[{\"corpusId\": 52314905, \"span\": \"[31,\", \"start\": 104, \"end\": 108}, {\"corpusId\": 70264975, \"span\": \"32]\", \"start\": 108, \"end\": 111}, {\"corpusId\": 174801562, \"span\": \"[34]\", \"start\": 495, \"end\": 499}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "29209", "title": "\u201cIt\u2019s only when somebody says a tool worked for them that I believe it will work for me\u201d: Socio-tecture as a lens for digital transformation", "sectionTitle": "2.3", "text": "Studies have indicated that the growth and success of SMBs in Kenya is impacted by social components such as sustained good relationships with customers [35], business networks, access to information, access to innovation, access to finance [36], and family support [37,38]. This is due to the value of their social networks which entails bonding with similar people as well as bridging the gap between diverse people with norms of reciprocity [39]. Significant leaps in technology, such as a preference of social over electronic commerce [46][47][48][49][50][51][52], can be attributed to the socio-cultural business environment in Kenya and similar African contexts, where for example there is a preference of collective over individualistic business approaches [40][41][42][43][44][45]. This section discusses literature on this further.", "spans": "[{\"corpusId\": 54801174, \"span\": \"[37,\", \"start\": 266, \"end\": 270}, {\"corpusId\": 227275986, \"span\": \"[46]\", \"start\": 539, \"end\": 543}, {\"corpusId\": 14862434, \"span\": \"[47]\", \"start\": 543, \"end\": 547}, {\"corpusId\": 145790470, \"span\": \"[42]\", \"start\": 772, \"end\": 776}, {\"corpusId\": 158910207, \"span\": \"[43]\", \"start\": 776, \"end\": 780}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "29210", "title": "\u201cIt\u2019s only when somebody says a tool worked for them that I believe it will work for me\u201d: Socio-tecture as a lens for digital transformation", "sectionTitle": "Situating HCI research in Africa", "text": "To address these questions the recent focus on HCI in Africa -for the deployment of digital solutions -has taken two parallel routes. The first emphasises the issues that arise from implementations which are disconnected from the social, cultural, and physical attributes that are unique to the African context. The second suggests HCI methods that incorporate indigenous concepts in order to make research outputs relevant to end users [57]. In this regard, HCI has been examined through the African philosophy of Ubuntu. Ubuntu and its philosophical underpinnings have been used as a structural basis which grants situated orientation [58] and provides a relevant framework for design innovation, technology use, its adoption, and how it can drive business innovation in Africa. In recent years, HCI has gained traction in Africa with a strong emphasis on opportunities availed by mobile technologies and increased access to internet and affordability of devices. This has led to great emphasis on design and deployment of usercentered digital solutions that are enmeshed with the needs of an African audience to solve African problems. Building on this work, this paper thus situates itself not in a development discourse -where the researcher designs from an assumption that the non-western community is in need of development and would unquestionably benefit from western technologies [8] -but instead from an afro-centric discourse where knowledge and innovation from the continent is legitimate and equal to others, and can spark innovation and problem-solving in similar contexts on and off the continent.", "spans": "[{\"corpusId\": 45049366, \"span\": \"[57]\", \"start\": 437, \"end\": 441}, {\"corpusId\": 253460030, \"span\": \"this work\", \"start\": 1160, \"end\": 1160}, {\"corpusId\": 253460030, \"span\": \"this paper\", \"start\": 1172, \"end\": 1172}, {\"corpusId\": 3128663, \"span\": \"[8]\", \"start\": 1390, \"end\": 1393}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "29211", "title": "\u201cIt\u2019s only when somebody says a tool worked for them that I believe it will work for me\u201d: Socio-tecture as a lens for digital transformation", "sectionTitle": "Impact of COVID-19 and responses using technology", "text": "By disrupting the physical workplace, businesses moved to hybrid and online workplaces, as found elsewhere [13,59]. For several, but not all SMBs, this led to a change in attitude to the workplace. RP27 (VSB, event marketing) for example realised they could \"achieve all our goals but from our home spaces.\" Consequently, as SMBs moved to online or hybrid workspaces they discovered these spaces could sustain income and productivity. SMBs learned from experience that through online tools, businesses could accomplish tasks even when remotely located, and that working with them was not \"something that is weird\", RP16 (VSB, AI training). ", "spans": "[{\"corpusId\": 221459956, \"span\": \"[13,\", \"start\": 107, \"end\": 111}, {\"corpusId\": 224928726, \"span\": \"59]\", \"start\": 111, \"end\": 114}, {\"corpusId\": 253460030, \"span\": \"our goals\", \"start\": 280, \"end\": 280}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "29212", "title": "\u201cIt\u2019s only when somebody says a tool worked for them that I believe it will work for me\u201d: Socio-tecture as a lens for digital transformation", "sectionTitle": "DT in COVID-19 times", "text": "The COVID-prompted emergency digital transformation started SMBs on a bigger digital transformation journey as they discovered the benefits of digitisation for themselves in practice. This presents an opportunity to understand what is missing in COVID-prompted digital transformation, and to consider how to support SMBs on their journey to becoming digitally empowered. We propose that doing so should involve taking into account the fundamental bedrock on which business is conducted for SMBs in Kenya, socio-tecture. For example, data was rarely part of this initial digital transformation, except as a beneficial by product. However, as discussed in the literature, data is becoming increasingly important for business in the modern world [27,28]. We agree with Lopez, Segura and Sant\u00f3rum [34] on the need for solutions accessible to SMBs, taking into account their limited resources, but crucially we add on the importance of taking socio-tecture into account, even, or perhaps especially, when thinking of data-driven business for SMBs. There is a tendency for the personal and social to be designed out, as we move to data-driven business [68] and we saw this here (e.g. RP07 (MB, trade logistics), RP06 (VSB, financier)). However, research has pointed to the importance of designing for rather than designing out relationships in settings such as crowdsourcing [69] and fintech [68,70,71]. A related example is the importance of intermediaries in technology use and adoption, for users rather different from ours [72][73][74][75]. Designing for socio-tecture extends this concern and elaborates a framework or lens through which we can more systematically conceive of these features in business, i.e., a heavy reliance on networks, relational over transactional, and people as knowledge. Taking into account socio-tecture, raises questions such as how do we create algorithms and data-driven businesses which enhance and value the social instead of removing it?", "spans": "[{\"corpusId\": 253460030, \"span\": \"We propose\", \"start\": 381, \"end\": 381}, {\"corpusId\": 55540519, \"span\": \"[27,\", \"start\": 743, \"end\": 747}, {\"corpusId\": 174801562, \"span\": \"[34]\", \"start\": 793, \"end\": 797}, {\"corpusId\": 28227169, \"span\": \"70,\", \"start\": 1390, \"end\": 1393}, {\"corpusId\": 211138345, \"span\": \"71]\", \"start\": 1393, \"end\": 1396}, {\"corpusId\": 14042948, \"span\": \"[75]\", \"start\": 1533, \"end\": 1537}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "29213", "title": "\u201cIt\u2019s only when somebody says a tool worked for them that I believe it will work for me\u201d: Socio-tecture as a lens for digital transformation", "sectionTitle": "DT in COVID-19 times", "text": "Secondly, the pandemic reveals the extent to which digital transformation for SMBs is social and collective. We can understand the pandemic as acting as a 'breaching experiment' [76,77], which enables us to see facets of a phenomenon otherwise hidden. COVID-19 pushed the whole ecosystem into digital transformation together, creating the social, cultural and economic conditions in which digitisation could occur. This is unlikely to be recreated in normal times. Certainly, the ecosystem can promote digital transformation -as larger more powerful organisations encourage (or force) others in their ecosystem to change. This has been seen elsewhere, in particular through the disruption that large platforms have caused to traditional industries such as taxis and autorickshaws [78,79]. Such disruptions by big players may have mixed benefits, often coming with a hefty dose of negative consequences for the smaller actors within them, such as the drivers [78,[80][81][82][83]. By contrast, in our data these transformations appeared more benign, often being done in partnership with the customers who end up being digitised. It is likely that this is due to the importance of socio-tecture in the ecosystem combined with the conditions in which transformation took place. That is, in this case the digitisation was done to sustain relationships between the bigger and smaller players given the pandemic. Thus, unlike many platform economies, the interventions were locally designed with relationships in mind. These interventions either enabled interpersonal interaction, for example, RP38's (SB, engineering) augmented reality glasses enabling the engineer and customer to troubleshoot together, or where interactions were not supported by the available technology, interactions around the technology were designed into the workflow, e.g. RP07 (MB, trade logistics)) created a customer ordering platform and gave each customer a tablet for ordering but also each customer had a dedicated sales agent regularly checking in. Notably, the ecosystem is just as likely to act as a barrier to digital transformation outside of these exceptional circumstances, especially for SMBs, given that even the SMBs in our study who prompted ecosystem digital transformation were part of larger conglomerates, with their own IT department, and so in this aspect acted more like larger enterprises. When thinking of digital transformation, more broadly, whether within or outside of the pandemic it is important to take an ecosystem perspective.", "spans": "[{\"corpusId\": 9112052, \"span\": \"[76,\", \"start\": 178, \"end\": 182}, {\"corpusId\": 144914782, \"span\": \"77]\", \"start\": 182, \"end\": 185}, {\"corpusId\": 33388252, \"span\": \"[78,\", \"start\": 780, \"end\": 784}, {\"corpusId\": 33388252, \"span\": \"[78,\", \"start\": 958, \"end\": 962}, {\"corpusId\": 52014737, \"span\": \"[80]\", \"start\": 962, \"end\": 966}, {\"corpusId\": 182803737, \"span\": \"[83]\", \"start\": 974, \"end\": 978}, {\"corpusId\": 253460030, \"span\": \"our study\", \"start\": 2216, \"end\": 2216}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 6}], "paragraphCount": 10}
{"paperId": "03c321a8610db95dd15a772a58c2a48776090236", "title": "MYND: Unsupervised Evaluation of Novel BCI Control Strategies on Consumer Hardware", "venue": "ACM Symposium on User Interface Software and Technology", "year": 2020, "citationCount": 3, "openAccessPdf": {"url": "https://doi.org/10.1145/3379337.3415844", "status": "BRONZE", "license": null, "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2002.11754, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science", "Biology"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2020-02-26", "authors": [{"authorId": "2175677", "name": "Matthias Hohmann"}, {"authorId": "1509426814", "name": "Lisa Konieczny"}, {"authorId": "117349865", "name": "Michelle Hackl"}, {"authorId": "2067376675", "name": "Brian Wirth"}, {"authorId": "118457185", "name": "Talha Zaman"}, {"authorId": "2973045", "name": "R. Enficiaud"}, {"authorId": "1399050539", "name": "M. Grosse-Wentrup"}, {"authorId": "1707625", "name": "B. Scholkopf"}], "abstract": "Neurophysiological laboratory studies are often constraint to immediate geographical surroundings and access to equipment may be temporally restricted. Limitations of ecological validity, scalability, and generalizability of findings pose a significant challenge for the development of brain-computer interfaces (BCIs), which ultimately need to function in any context, on consumer-grade hardware. We introduce MYND: An open-source framework that couples consumer-grade recording hardware with an easy-to-use application for the unsupervised evaluation of BCI control strategies. Subjects are guided through experiment selection, hardware fitting, recording, and data upload in order to self-administer multi-day studies that include neurophysiological recordings and questionnaires at home. As a use case, thirty subjects evaluated two BCI control strategies \"Positive memories\" and \"Music imagery\" by using a four-channel electroencephalogram (EEG) with MYND. Neural activity in both control strategies could be decoded with an average offline accuracy of 68.5% and 64.0% across all days.", "corpusId": "211532665", "paragraphs": [{"paragraphId": "17933", "title": "MYND: Unsupervised Evaluation of Novel BCI Control Strategies on Consumer Hardware", "sectionTitle": "Init", "text": "Apart from more developer-oriented approaches, several \"direct-to-consumer\" EEGs emerged recently. These systems are typically accompanied by smartphone software that is designed for meditation assistance and self-quantification [20]. The Muse EEG 2 , which is used for the current study, provides a smartphone application that assists users with guided meditation and feedback on attention and relaxation levels. The Dreem EEG 3 , a headset that is specifically designed to be worn at night, offers an application that analyses and classifies sleep patterns through an online service. Headsets by Emotiv 4 feature between five and fourteen channels and are bundled with software subscriptions for private or business use. These devices are designed for self-administration and longer recording sessions. Through custom software, several of them have been used in laboratory studies: In [21] the Muse EEG was successfully used for a spelling system, noting its ease-of-use and sufficient data quality for a BCI application. Emotiv headsets have been used in several BCI studies as well [22], [23]. The Dreem EEG and its bundled proprietary sleep classification platform are promoted as a research tool for sleep studies by the developer [24]. However, the bundled end-user applications are not intended for BCI research and do not expose processing or data storage interfaces. The custom tools that are developed by researchers to interface with these consumer-grade systems are typically not meant for use by non-experts outside of the laboratory.", "spans": "[{\"corpusId\": \"52165335\", \"span\": \"[20]\", \"start\": 229, \"end\": 233}, {\"corpusId\": \"14685881\", \"span\": \"[21]\", \"start\": 887, \"end\": 891}, {\"corpusId\": \"16185740\", \"span\": \"[22]\", \"start\": 1086, \"end\": 1090}, {\"corpusId\": \"10024788\", \"span\": \"[23]\", \"start\": 1092, \"end\": 1096}, {\"corpusId\": \"196661528\", \"span\": \"[24]\", \"start\": 1237, \"end\": 1241}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "17934", "title": "MYND: Unsupervised Evaluation of Novel BCI Control Strategies on Consumer Hardware", "sectionTitle": "Results", "text": "Regarding the overall satisfaction with the platform, 25 subjects participated in a post-experiment online survey. On the Technology Acceptance Model dimensions [25,TAM], subjects rated perceived ease-of-use with a median score of 5.8/7, perceived enjoyment with a score of 5.6/7, and perceived control over the application with a 6.3/7. On the NASA Task Load Index dimensions [26,TLX], ratings for frustration, temporal demand, and required effort were low with a median score of 5/21, 8/21, and 7/21. Subjects rated their median overall satisfaction with an 8/10. Figure 4 shows the results of the unsupervised, daily use of both control strategies on consumer-grade hardware. In (A), we show the average classification accuracies for both strategies in the at-home study, with an overall average accuracy of 68.5% for \"Positive memories\" and 64.0% for \"Music imagery.\" Grey circles indicate the achieved accuracies per day, where we observe within-subject differences with an average standard deviation of 20.3%. We find a small negative trend between mean accuracy and standard deviation (Pearson's r(58) = \u2212.25, p = .0505). In (B), we relate these accuracies to the signal quality during trials. We find a small positive trend between daily signal quality and daily accuracies (r(224) = .13, p = .06). We relate accuracies to the day of study in (C). In general, we find a small negative correlation between the day of study and performance (r(224) = \u2212.18, p = .006). \"Positive memories\" shows a median accuracy of 72.2% on day 1, and then exhibits a drop in median accuracy to 63.3% during repeated execution from day 1 to day 2. After not executing the strategy on day 3, we observe an increase to 77.8% on day 4, and a subsequent drop to 72.2% and 55.6% on days 5 and 6, respectively. Thirty-six \"Positive memories\" trials were scheduled on days 2 and 6, which is the highest daily amount in this study. In \"Music imagery\", we find a median accuracy of 72.2% on day 3, where it was introduced as the only scheduled strategy. Then, we find a decrease to 59.7% on day 5, where both strategies were scheduled, and a subsequent increase to 66.6% on day 7, where only \"Music imagery\" was scheduled. With respect to the two potential mediators meditation experience and daily self-reported motivation, we found that meditation experience is unrelated to accuracies (M = 1. ", "spans": "[{\"corpusId\": \"16792474\", \"span\": \"[25,\", \"start\": 161, \"end\": 165}, {\"corpusId\": \"15252590\", \"span\": \"[26,\", \"start\": 377, \"end\": 381}, {\"corpusId\": 211532665, \"span\": \"this study\", \"start\": 1910, \"end\": 1910}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "17935", "title": "MYND: Unsupervised Evaluation of Novel BCI Control Strategies on Consumer Hardware", "sectionTitle": "Discussion", "text": "Interestingly, maintaining a high signal quality, i.e., a low signal variance, after self-supervised fitting did not necessarily lead to high task performance in this study. On the other hand, we found a high variation of daily accuracies within subjects. The consumer-grade EEG and our fitting algorithm allowed subjects to record neural data quickly, but the hardware may also pose new challenges for the BCI user: Even when perfectly fitted, the dry sensors at distant ends of the scalp may require users to induce strong, consistent modulations in neural activity in order to be reliably detected. As one potential mediator, meditation experience may affect the ability to maintain focus in unsupervised environments [27]. However, in a post-hoc analysis, we found that self-reported meditation experience is unrelated to accuracies in this study. On the other hand, daily motivational scores correlate positively with accuracy in this study. Therefore, using the MYND platform to combine easily accessible control strategies with motivating, daily feedback could further improve performance and help with more consistent execution. This feedback will need to be robust to the lower signal-to-noise ratio and higher susceptibility to involuntary head-muscle artifacts around the ears and the forehead, where the sensors are located. As one promising approach to implement robust feedback, concurrent work in [28] explored an adaptive signal-filtering method that relies on signal-variation, similar to the fitting algorithm presented here. Providing immediately accessible daily decoding scores could be implemented on the device by utilizing prior information from higher quality laboratory data via transfer-learning, as shown in this offline analysis.", "spans": "[{\"corpusId\": 211532665, \"span\": \"this study\", \"start\": 172, \"end\": 172}, {\"corpusId\": \"38035138\", \"span\": \"[27]\", \"start\": 721, \"end\": 725}, {\"corpusId\": 211532665, \"span\": \"this study\", \"start\": 850, \"end\": 850}, {\"corpusId\": 211532665, \"span\": \"this study\", \"start\": 945, \"end\": 945}, {\"corpusId\": \"198968172\", \"span\": \"[28]\", \"start\": 1412, \"end\": 1416}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "17936", "title": "MYND: Unsupervised Evaluation of Novel BCI Control Strategies on Consumer Hardware", "sectionTitle": "Materials and Methods", "text": "Choice of laboratory-based BCI control strategies. We utilized a set of stimulus-free two-task BCI control strategies that were previously evaluated in laboratory experiments with healthy subjects. The control strategies have shown to be immediately executable by subjects without the need for prior training, and they are unrelated to motor processes, which limits accidental movement artifacts. Most importantly, they induce modulation of neural activity in broad areas of the cortex, which could make them particularly suitable for use with consumer-grade EEG equipment with few sensors. We could show that both BCI control strategies could be used in a laboratory study to induce significant differences in neural activity [3], [11], [30], [4]. Now, we complement the laboratory results with MYND to investigate whether these strategies can be executed in an uncontrolled, realistic environment, by utilizing a consumer-grade EEG, and if repeated execution affects performance.", "spans": "[{\"corpusId\": \"16769462\", \"span\": \"[11]\", \"start\": 732, \"end\": 736}, {\"corpusId\": \"42288017\", \"span\": \"[30]\", \"start\": 738, \"end\": 742}, {\"corpusId\": \"52959000\", \"span\": \"[4]\", \"start\": 744, \"end\": 747}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "17937", "title": "MYND: Unsupervised Evaluation of Novel BCI Control Strategies on Consumer Hardware", "sectionTitle": "Materials and Methods", "text": "In the \"Positive memories\" strategy, subjects are asked to switch between thinking about a positive memory of their past or consecutively subtract a small number from a larger number [3], [11], [30]. Changing between daydreaming and a task that requires attention modulates activity in the \"default mode network,\" a large-scale network that is involved in self-referential processes [31], [32]. It was found that thinking about positive memories increases activity in the alpha-band, while mental calculations decrease activity. Similarly, the \"Music imagery\" strategy instructs subjects to switch between playing their favorite song in their head or consecutively subtract a small number from a larger number, which has also been found to modulate parietal alpha-activity [33], [4]. Self-referential thoughts have shown to modulate activity in the theta-(3-7 Hz) alpha-(8-13 Hz) and beta-bands (17)(18)(19)(20)(21)(22)(23)(24)(25)(26)(27)(28)(29)(30) of the human EEG [34], [35]. Further, it was found that the dominant frequency of the EEG spectrum, the \"alpha peak frequency,\" is modulated by these strategies as well [30]. In figure 5, we used the laboratory data from previous studies [3], [4] to illustrate the induced bandpower modulations parietal and prefrontal cortex with the two BCI control strategies. We computed the coefficient of determination (R 2 ) per subject and channel to visualize the average induced differences in normalized theta-alpha-and beta-bands, as well as the dominant frequency of the EEG spectrum. Lab recordings used a 128-channel \"BrainAmp\" EEG system (Brain Products GmbH, Germany) with wet electrodes in a single-day recording. Eleven participants completed 40 trials of \"Positive memories\" [3], and 10 different participants completed 20 trials of \"Music imagery\" [4].", "spans": "[{\"corpusId\": \"16769462\", \"span\": \"[11]\", \"start\": 188, \"end\": 192}, {\"corpusId\": \"42288017\", \"span\": \"[30]\", \"start\": 194, \"end\": 198}, {\"corpusId\": \"18377781\", \"span\": \"[31]\", \"start\": 383, \"end\": 387}, {\"corpusId\": \"15497198\", \"span\": \"[32]\", \"start\": 389, \"end\": 393}, {\"corpusId\": \"5383176\", \"span\": \"[33]\", \"start\": 773, \"end\": 777}, {\"corpusId\": \"52959000\", \"span\": \"[4]\", \"start\": 779, \"end\": 782}, {\"corpusId\": \"44812294\", \"span\": \"(17)\", \"start\": 895, \"end\": 899}, {\"corpusId\": \"8667640\", \"span\": \"(18)\", \"start\": 899, \"end\": 903}, {\"corpusId\": \"44224053\", \"span\": \"(19)\", \"start\": 903, \"end\": 907}, {\"corpusId\": \"52165335\", \"span\": \"(20)\", \"start\": 907, \"end\": 911}, {\"corpusId\": \"14685881\", \"span\": \"(21)\", \"start\": 911, \"end\": 915}, {\"corpusId\": \"16185740\", \"span\": \"(22)\", \"start\": 915, \"end\": 919}, {\"corpusId\": \"10024788\", \"span\": \"(23)\", \"start\": 919, \"end\": 923}, {\"corpusId\": \"196661528\", \"span\": \"(24)\", \"start\": 923, \"end\": 927}, {\"corpusId\": \"16792474\", \"span\": \"(25)\", \"start\": 927, \"end\": 931}, {\"corpusId\": \"15252590\", \"span\": \"(26)\", \"start\": 931, \"end\": 935}, {\"corpusId\": \"38035138\", \"span\": \"(27)\", \"start\": 935, \"end\": 939}, {\"corpusId\": \"198968172\", \"span\": \"(28)\", \"start\": 939, \"end\": 943}, {\"corpusId\": \"27851593\", \"span\": \"(29)\", \"start\": 943, \"end\": 947}, {\"corpusId\": \"42288017\", \"span\": \"(30)\", \"start\": 947, \"end\": 951}, {\"corpusId\": \"17918510\", \"span\": \"[34]\", \"start\": 969, \"end\": 973}, {\"corpusId\": \"12005293\", \"span\": \"[35]\", \"start\": 975, \"end\": 979}, {\"corpusId\": \"42288017\", \"span\": \"[30]\", \"start\": 1121, \"end\": 1125}, {\"corpusId\": \"52959000\", \"span\": \"[4]\", \"start\": 1195, \"end\": 1198}, {\"corpusId\": \"52959000\", \"span\": \"[4]\", \"start\": 1804, \"end\": 1807}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 21}, {"paragraphId": "17938", "title": "MYND: Unsupervised Evaluation of Novel BCI Control Strategies on Consumer Hardware", "sectionTitle": "Materials and Methods", "text": "Choice of consumer-grade recording hardware. We chose the Muse EEG headset (2016) by InteraXon as recording hardware. The Muse features a rigid plastic headband design and four dry EEG sensors at AF7, AF8, TP9 and TP10 of the International 10-20 system [36], and a 256 Hz sampling rate. Figure 5 illustrates the sensor locations. Despite possible improvements in future sensor technology, the headband-like shape of the Muse may approximate (A) and \"Music imagery\" (B), based on laboratory data from [11] and [4]. White circles represent the sensor locations of the employed consumer-grade EEG headset in the current study.", "spans": "[{\"corpusId\": \"27778550\", \"span\": \"[36]\", \"start\": 253, \"end\": 257}, {\"corpusId\": \"16769462\", \"span\": \"[11]\", \"start\": 500, \"end\": 504}, {\"corpusId\": \"52959000\", \"span\": \"[4]\", \"start\": 509, \"end\": 512}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "17939", "title": "MYND: Unsupervised Evaluation of Novel BCI Control Strategies on Consumer Hardware", "sectionTitle": "Platform usability.", "text": "Concerning the usability of the system, we first analyzed the time that subjects required to fit the headset at the beginning of every recording session. We reconstructed the retained signal quality during trial execution with the same processing pipeline as described earlier, and we plotted the \"Resting-state\" EEG spectrum, averaged over both parietal channels, for a visual inspection of the recorded data. During the \"Resting-state,\" subjects are asked to either open or close their eyes and let their mind wander. Alpha-band-power increases visibly during closed-eyes resting. Therefore this strategy is often used as a benchmark for EEG recording setups (e.g., [37]). Concerning the subject's satisfaction with the system, we present the post-experiment ratings of the application in an online survey, to which 25 subjects responded. We report the dimensions \"perceived ease-of-use\", \"perceived enjoyment\", and \"perceived external control\" of the Technology Acceptance Model [25,TAM], as well as \"temporal demand\", \"frustration\", and \"effort\" of the NASA Task Load Index [26,TLX], and a 10-point total satisfaction score, as proposed in [38] for BCI development.", "spans": "[{\"corpusId\": \"455476\", \"span\": \"\", \"start\": -37934, \"end\": -37931}, {\"corpusId\": \"25572537\", \"span\": \"[37]\", \"start\": 668, \"end\": 672}, {\"corpusId\": \"16792474\", \"span\": \"[25,\", \"start\": 982, \"end\": 986}, {\"corpusId\": \"15252590\", \"span\": \"[26,\", \"start\": 1078, \"end\": 1082}, {\"corpusId\": \"11076580\", \"span\": \"[38]\", \"start\": 1144, \"end\": 1148}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "17940", "title": "MYND: Unsupervised Evaluation of Novel BCI Control Strategies on Consumer Hardware", "sectionTitle": "Platform usability.", "text": "Control strategy evaluation. With this study, we aim to evaluate how well the BCI control strategies can be performed in an uncontrolled, realistic setting and consumer-grade hardware, outside of the laboratory. The small amount of trials scheduled per day (18 to 36), recorded with a consumer-grade EEG, makes it challenging to learn a good decoding model per subject, day, and strategy. To solve this problem, we leveraged the information obtained from previous laboratory trials with a transfer-learning approach ( [39], toolbox available online 6 , additional details in [11]). Here, a linear regression model for each subject in the at-home study is learned while regularizing the regression weights with a Gaussian prior that is learned on existing laboratory data. The three-step implementation, which we describe below, also resembles a possible procedure for daily on-device feedback that would be immediately accessible to subjects in future studies.", "spans": "[{\"corpusId\": 211532665, \"span\": \"this study\", \"start\": 44, \"end\": 44}, {\"corpusId\": \"16142276\", \"span\": \"[39]\", \"start\": 518, \"end\": 522}, {\"corpusId\": \"16769462\", \"span\": \"[11]\", \"start\": 575, \"end\": 579}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "17941", "title": "MYND: Unsupervised Evaluation of Novel BCI Control Strategies on Consumer Hardware", "sectionTitle": "Platform usability.", "text": "First, we performed the following EEG preprocessing steps per subject, day, and strategy, to obtain the feature space for pattern classification: We windowed the EEG time-series at every channel with a Hann window and computed the log-band-power for every trial for both laboratory studies and the at-home study. Muscular artifacts in the laboratory studies were removed from the data with an independent component analysis (ICA) before band-power computations, as described in [11]. We extracted four features: theta-(3-7 Hz) alpha-(8-13 Hz) and beta-log-band-power (17)(18)(19)(20)(21)(22)(23)(24)(25)(26)(27)(28)(29)(30), as well as the dominant frequency of the EEG spectrum as described in [30]. Then, we used mean and standard-deviation to normalize band-powers and the dominant frequency for every subject across the whole session in the laboratory study, and within each day in the at-home study. We extracted theta-, alpha-, and beta-band-power, and the dominant frequency at the electrode locations of the consumer-grade headset (TP8, TP10, AF1, and AF2, see figure 5 for illustration), resulting in a total of sixteen features per trial and control strategy.", "spans": "[{\"corpusId\": \"16769462\", \"span\": \"[11]\", \"start\": 478, \"end\": 482}, {\"corpusId\": \"44812294\", \"span\": \"(17)\", \"start\": 567, \"end\": 571}, {\"corpusId\": \"8667640\", \"span\": \"(18)\", \"start\": 571, \"end\": 575}, {\"corpusId\": \"44224053\", \"span\": \"(19)\", \"start\": 575, \"end\": 579}, {\"corpusId\": \"52165335\", \"span\": \"(20)\", \"start\": 579, \"end\": 583}, {\"corpusId\": \"14685881\", \"span\": \"(21)\", \"start\": 583, \"end\": 587}, {\"corpusId\": \"16185740\", \"span\": \"(22)\", \"start\": 587, \"end\": 591}, {\"corpusId\": \"10024788\", \"span\": \"(23)\", \"start\": 591, \"end\": 595}, {\"corpusId\": \"196661528\", \"span\": \"(24)\", \"start\": 595, \"end\": 599}, {\"corpusId\": \"16792474\", \"span\": \"(25)\", \"start\": 599, \"end\": 603}, {\"corpusId\": \"15252590\", \"span\": \"(26)\", \"start\": 603, \"end\": 607}, {\"corpusId\": \"38035138\", \"span\": \"(27)\", \"start\": 607, \"end\": 611}, {\"corpusId\": \"198968172\", \"span\": \"(28)\", \"start\": 611, \"end\": 615}, {\"corpusId\": \"27851593\", \"span\": \"(29)\", \"start\": 615, \"end\": 619}, {\"corpusId\": \"42288017\", \"span\": \"(30)\", \"start\": 619, \"end\": 623}, {\"corpusId\": \"42288017\", \"span\": \"[30]\", \"start\": 695, \"end\": 699}]", "conference": "uist", "year": 2020, "likelyRelatedWorkSection": true, "refCount": 15}], "paragraphCount": 9}
{"paperId": "d6b87816ae50fa110369e2bcb439c29edb8e36b7", "title": "Karamad: A Voice-based Crowdsourcing Platform for Underserved Populations", "venue": "International Conference on Human Factors in Computing Systems", "year": 2021, "citationCount": 20, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3411764.3445417?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3411764.3445417, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference", "Review"], "publicationDate": "2021-05-06", "authors": [{"authorId": "3124430", "name": "Shan Randhawa"}, {"authorId": "29399141", "name": "Tallal Ahmad"}, {"authorId": "51520051", "name": "Jay Chen"}, {"authorId": "2046780", "name": "Agha Ali Raza"}], "abstract": "Crowdsourcing enables the completion of large-scale and hard-to-automate tasks, while allowing people to earn money. However, 3.6 billion people \u2013 a workforce comprising 46.4% of the world population \u2013 who could benefit most from this source of income lack the access and literacy to use computers, smartphones, and the internet. In this paper we present Karamad, a voice-based crowdsourcing platform that allows workers in low-resource regions to complete crowd work using low-end phones and receive payments as mobile airtime balance. We explore the usefulness, scalability, and sustainability of Karamad in Pakistan through a 6-month deployment. Without any advertising, training, or airtime subsidies, Karamad organically engaged 725 workers who completed 3,939 tasks (involving 43,006 components) including translations, dataset generation, and surveys on demographics, accessibility, disability, health, employment, and literacy. Collectively, the workers produced a valuable service market for potential customers and included female, unemployed, non-literate, and blind users.", "corpusId": "231845372", "paragraphs": [{"paragraphId": "85853", "title": "Karamad: A Voice-based Crowdsourcing Platform for Underserved Populations", "sectionTitle": "Inclusion and Developing Contexts", "text": "Some modern crowdsourcing platforms such as Samasource [54] have extended crowd work to developing areas, but Samasource still requires workers to work from cybercafes and to undergo extensive training in English. Other than the access barriers preventing the inclusion of rural or low-income workers, Calvo et al. [7] also found that access to crowd work could be particularly useful for workers with disabilities. Hara et al. [25] explored how crowd work could be made accessible to workers with autism spectrum disorder. Vashistha et al. [66] have made further explorations into making crowd work accessible to visually impaired workers in India.", "spans": "[{\"corpusId\": \"17538367\", \"span\": \"[7]\", \"start\": 315, \"end\": 318}, {\"corpusId\": \"7007084\", \"span\": \"[25]\", \"start\": 428, \"end\": 432}, {\"corpusId\": \"5046823\", \"span\": \"[66]\", \"start\": 541, \"end\": 545}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "85854", "title": "Karamad: A Voice-based Crowdsourcing Platform for Underserved Populations", "sectionTitle": "Inclusion and Developing Contexts", "text": "In parallel with developments in crowdsourcing, Interactive Voice Response (IVR) systems have increased in maturity and presence in developing contexts. Although IVRs are more constrained than an internet-enabled computer, IVR-based systems have far greater reach in rural developing contexts and their capabilities closely complement the competence of low-income, rural, and visually impaired users. Consequently, IVR-based platforms have generated increased interest over the past decade in developing contexts and have been aggressively deployed in developing regions to enable a wide range of services including social media [49,62], education [50,61], agriculture [45], healthcare [41], citizen journalism [35], job search [51], and data collection [32].", "spans": "[{\"corpusId\": \"5041422\", \"span\": \"[49,\", \"start\": 629, \"end\": 633}, {\"corpusId\": \"15305511\", \"span\": \"62]\", \"start\": 633, \"end\": 636}, {\"corpusId\": \"140268301\", \"span\": \"[50,\", \"start\": 648, \"end\": 652}, {\"corpusId\": \"203347488\", \"span\": \"61]\", \"start\": 652, \"end\": 655}, {\"corpusId\": \"8438564\", \"span\": \"[45]\", \"start\": 669, \"end\": 673}, {\"corpusId\": \"212712710\", \"span\": \"[41]\", \"start\": 686, \"end\": 690}, {\"corpusId\": \"12554978\", \"span\": \"[35]\", \"start\": 711, \"end\": 715}, {\"corpusId\": \"2898051\", \"span\": \"[51]\", \"start\": 728, \"end\": 732}, {\"corpusId\": \"527487\", \"span\": \"[32]\", \"start\": 754, \"end\": 758}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "85855", "title": "Karamad: A Voice-based Crowdsourcing Platform for Underserved Populations", "sectionTitle": "Inclusion and Developing Contexts", "text": "Our work is situated at the intersection of crowdsourcing and speech-based services for developing regions. The closest literature to Karamad include Respeak [65], BSpeak [66], Recall [63], and work by Chopra et al. [9]. Respeak is a voice-based system built as an Android application that employs low-income users to transcribe audio files in English and Hindi. BSpeak is a similar platform that allows blind users to transcript audio via speech and automatic-speech recognition. Recall is similar to Respeak, but uses an IVR rather than an Android application, and focuses on evaluating the error rate of transcription tasks over an 8kHz voice channel. Each of these systems leverages users' speaking and listening abilities, and Respeak and Bspeak also require users to have access to smartphones. Recently, Chopra et al. [9] explored an Android-based crowdsourcing platform for allowing low-income users to perform digitization tasks in India in a two-week study. Karamad differs from these systems in that it is a general crowdsourcing platform that enables data collection tasks beyond audio transcription or digitization. Furthermore, Karamad runs on a feature phone without the need of and internet access. Our work focuses on the in-situ scalability and long-term sustainability of crowd work rather than controlled short-term experiments.", "spans": "[{\"corpusId\": 231845372, \"span\": \"Our work\", \"start\": 8, \"end\": 8}, {\"corpusId\": \"10647812\", \"span\": \"[65]\", \"start\": 158, \"end\": 162}, {\"corpusId\": \"5046823\", \"span\": \"[66]\", \"start\": 171, \"end\": 175}, {\"corpusId\": \"140227355\", \"span\": \"[63]\", \"start\": 184, \"end\": 188}, {\"corpusId\": \"115144999\", \"span\": \"[9]\", \"start\": 216, \"end\": 219}, {\"corpusId\": \"115144999\", \"span\": \"[9]\", \"start\": 825, \"end\": 828}, {\"corpusId\": 231845372, \"span\": \"Our work\", \"start\": 1223, \"end\": 1223}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "85856", "title": "Karamad: A Voice-based Crowdsourcing Platform for Underserved Populations", "sectionTitle": "Design", "text": "To map out the potential of the task types that are both realizable through an IVR and by our workers, we considered the types of tasks available on Mturk and we excluded tasks that involved images or videos due to the limitations of the voice-based modality and tasks that require high bandwidth or cognitive load that are not likely to be suitable for a phone call (e.g. sifting through large documents). Compared to the types of tasks on MTurk [1], image or video processing tasks are not feasible via IVR interfaces. Based on the literature [8,20,44,49,50,60,61,63], information gathering and data processing tasks such as conducting surveys and gathering speech recordings are the most viable for our workers and in demand. We focused on supporting these two types of tasks.", "spans": "[{\"corpusId\": 231845372, \"span\": \"our work\", \"start\": 98, \"end\": 98}, {\"corpusId\": \"16869793\", \"span\": \"[8,\", \"start\": 545, \"end\": 548}, {\"corpusId\": \"202797271\", \"span\": \"20,\", \"start\": 548, \"end\": 551}, {\"corpusId\": \"108293834\", \"span\": \"44,\", \"start\": 551, \"end\": 554}, {\"corpusId\": \"5041422\", \"span\": \"49,\", \"start\": 554, \"end\": 557}, {\"corpusId\": \"140268301\", \"span\": \"50,\", \"start\": 557, \"end\": 560}, {\"corpusId\": \"208609276\", \"span\": \"60,\", \"start\": 560, \"end\": 563}, {\"corpusId\": \"203347488\", \"span\": \"61,\", \"start\": 563, \"end\": 566}, {\"corpusId\": \"140227355\", \"span\": \"63]\", \"start\": 566, \"end\": 569}, {\"corpusId\": 231845372, \"span\": \"our work\", \"start\": 710, \"end\": 710}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "85857", "title": "Karamad: A Voice-based Crowdsourcing Platform for Underserved Populations", "sectionTitle": "Capabilities", "text": "To map out the set of potentially useful task types, we examined the literature for works that have conducted IVR surveys or quizzes (e.g. [8,20,44,50,60,61]). We then implemented sufficient capabilities in Karamad to accommodate all tasks that we intended to deploy. Karamad currently supports Yes-No (binary) questions, multiple choice questions (MCQ), short and long answer questions. Binary questions and multiple choice questions require a single key press as input. Short and long answer questions require free-form 30 and 60 second voice recordings. We did not implement longer speech recordings or multiple digit inputs in Karamad that have been used in the past by IVR-based services [8,41,49,50]. We made Prior work reports that multiple-digit input can be complex for users and suggests incorporating examples to address this issue [8]. We took the approach of restructuring multi-digit input prompts into multiple-choices by segmenting possible answers into ranges. For example, rather than asking for a user's age as multi-digit answer, we reframe the question into a multiple choice question with responses in the form of ranges such as <20, 21-30, 31-40, >40. This approach is less precise, but it is also less complex for users and less expensive overall as including usage examples in the question statement requires more airtime. Similarly, when MCQs exceed 9 choices, we divide into sets of 8 options followed by the \"other\" choice, leading to the next 8 options.", "spans": "[{\"corpusId\": \"16869793\", \"span\": \"[8,\", \"start\": 139, \"end\": 142}, {\"corpusId\": \"202797271\", \"span\": \"20,\", \"start\": 142, \"end\": 145}, {\"corpusId\": \"108293834\", \"span\": \"44,\", \"start\": 145, \"end\": 148}, {\"corpusId\": \"140268301\", \"span\": \"50,\", \"start\": 148, \"end\": 151}, {\"corpusId\": \"208609276\", \"span\": \"60,\", \"start\": 151, \"end\": 154}, {\"corpusId\": \"203347488\", \"span\": \"61]\", \"start\": 154, \"end\": 157}, {\"corpusId\": \"16869793\", \"span\": \"[8,\", \"start\": 693, \"end\": 696}, {\"corpusId\": \"212712710\", \"span\": \"41,\", \"start\": 696, \"end\": 699}, {\"corpusId\": \"5041422\", \"span\": \"49,\", \"start\": 699, \"end\": 702}, {\"corpusId\": \"140268301\", \"span\": \"50]\", \"start\": 702, \"end\": 705}, {\"corpusId\": \"16869793\", \"span\": \"[8]\", \"start\": 843, \"end\": 846}, {\"corpusId\": 231845372, \"span\": \"This approach\", \"start\": 1188, \"end\": 1188}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 9}, {"paragraphId": "85858", "title": "Karamad: A Voice-based Crowdsourcing Platform for Underserved Populations", "sectionTitle": "EVALUATION", "text": "All four authors are HCI4D researchers who have previously conducted a variety of surveys, data collection campaigns, and IVR deployments in Pakistan and elsewhere. On the basis of our own experience, existing literature on crowd work and IVRs, and based on the market value of surveys conducted on Mturk, we considered surveys conducted by the World Bank and the government of Pakistan to select a breadth of topics that would be useful to collect from hard-to-reach populations. We also came up with our own surveys on topics that we thought would have relevance to the demographics of typical IVR users. Other than surveys, we created 4 speech corpus collection tasks based on prior speech corpus creation efforts [31,38,48,64].", "spans": "[{\"corpusId\": \"2550425\", \"span\": \"[31,\", \"start\": 717, \"end\": 721}, {\"corpusId\": \"121369880\", \"span\": \"38,\", \"start\": 721, \"end\": 724}, {\"corpusId\": \"26353228\", \"span\": \"48,\", \"start\": 724, \"end\": 727}, {\"corpusId\": \"140307377\", \"span\": \"64]\", \"start\": 727, \"end\": 730}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "85859", "title": "Karamad: A Voice-based Crowdsourcing Platform for Underserved Populations", "sectionTitle": "Tasks -Batch 2", "text": "After analyzing the results from the first batch of tasks, we designed two more sets of tasks and a validation task. The first set of tasks focused on sensitive but important topics that are typically embarrassing or taboo. Because prior work in low income countries has shown that IVR-based surveys have less social desirability bias as compared to telephone surveys by interviewers, respondents are more likely to answer truthfully regarding sensitive topics [17,44,56]. We designed surveys around HIV/AIDS and non-communicable diseases (NCD). The HIV/AIDS survey is based on the World Bank health report [4] and in it we asked questions related to knowledge of HIV prevention methods, misconceptions regarding it, and discriminatory attitudes towards people living with HIV. The NCD survey adapts questions from the World Health Organization Stepwise Approach to Surveillance of NCD risk factors (STEPs) surveys, which has previously been successfully conducted using IVRs in multiple low-and middle-income countries of Bangladesh, Uganda, and Tanzania [20,44,60]. Because many of our workers are blind, we also created three surveys about living with blindness and its challenges. The second set of tasks was focused on collecting Urdu speech corpora. We designed tasks that collect isolated digits and complex sentence-translations in free speech form. Though many approaches could be taken to collect speech data, for isolated digits, we designed three tasks based on prior works collecting corpora of isolated Urdu digits [38,48] that asked participants to record spoken digits in ascending, descending, and random order. We also asked participants to repeat the prompted sentences in their mother tongue, which could be different from the language in the prompts.", "spans": "[{\"corpusId\": \"125238026\", \"span\": \"[17,\", \"start\": 461, \"end\": 465}, {\"corpusId\": \"108293834\", \"span\": \"44,\", \"start\": 465, \"end\": 468}, {\"corpusId\": \"11502619\", \"span\": \"56]\", \"start\": 468, \"end\": 471}, {\"corpusId\": \"202797271\", \"span\": \"[20,\", \"start\": 1056, \"end\": 1060}, {\"corpusId\": \"108293834\", \"span\": \"44,\", \"start\": 1060, \"end\": 1063}, {\"corpusId\": \"208609276\", \"span\": \"60]\", \"start\": 1063, \"end\": 1066}, {\"corpusId\": 231845372, \"span\": \"our work\", \"start\": 1092, \"end\": 1092}, {\"corpusId\": \"121369880\", \"span\": \"[38,\", \"start\": 1529, \"end\": 1533}, {\"corpusId\": \"26353228\", \"span\": \"48]\", \"start\": 1533, \"end\": 1536}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 8}, {"paragraphId": "85860", "title": "Karamad: A Voice-based Crowdsourcing Platform for Underserved Populations", "sectionTitle": "Task Pricing", "text": "Based on our formulation and considerations, Table 1 summarizes the estimated cost of each task and the completion reward. The pricing of rewards for tasks we requested on Karamad were set generously for several reasons. First, we wanted to ensure that our workers were not losing money due to airtime costs, particularly if users made mistakes while learning to use the system. Our workers being very poor have low tolerance to risk. Second, we wanted to ensure that they were paid at least minimum wage [59]. Third, we wanted to pay at a comparable market rate per task relative to existing tasks on MTurk [24]. Given the minimum wage in Pakistan for unskilled labor is set to PKR 15,000 per month, for 8 hours a day, and 26 days a month, the per-hour wage is roughly PKR 72 (0.43 USD) per hour. Based on these considerations, we paid roughly PKR 1,400 (8.43 USD) per hour, which is 20x federal minimum wage in Pakistan. This is a modest sum even in the context of Pakistan because the minimum wage is very low. To put this in perspective, the cost of the smallest monthly internet package for Ufone, a local mobile network provider, is 390 rupees or approximately 5 times the minimum wage. In absolute terms, workers spent on average 81 minutes using Karamad in total during the course of our deployment. Our pricing is also roughly in line with recent closely related IVR-based pilot studies conducted in India (we paid approximately $0.042 per question and approximately $8.43 per hour after accounting for airtime costs compared to $0.046 per question for Learn2Earn [61] and $9.81 per hour in the case of ReCall [63]).", "spans": "[{\"corpusId\": 231845372, \"span\": \"our work\", \"start\": 261, \"end\": 261}, {\"corpusId\": 231845372, \"span\": \"Our work\", \"start\": 387, \"end\": 387}, {\"corpusId\": \"203347488\", \"span\": \"[61]\", \"start\": 1573, \"end\": 1577}, {\"corpusId\": \"140227355\", \"span\": \"[63]\", \"start\": 1619, \"end\": 1623}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "85861", "title": "Karamad: A Voice-based Crowdsourcing Platform for Underserved Populations", "sectionTitle": "INTRODUCTION", "text": "Crowdsourcing has been a highly productive area for HCI research for over a decade. Mainstream platforms such as Amazon Mechanical Turk [1] provide a marketplace where requesters issue tasks to workers that, upon completion, produce value in the form of tagging, translation, surveys etc. For the workers, completing such tasks can be fun and also serve as a source of supplementary income yielding roughly $2 per hour [24]. Unfortunately, despite over a decade of HCI research in crowdsourcing, crowd work is still not generally accessible to many underserved communities.", "spans": "[{\"corpusId\": \"5041422\", \"span\": \"\", \"start\": 31849, \"end\": 31853}, {\"corpusId\": \"140268301\", \"span\": \"\", \"start\": 31853, \"end\": 31857}, {\"corpusId\": \"2898051\", \"span\": \"\", \"start\": 31857, \"end\": 31861}, {\"corpusId\": \"15305511\", \"span\": \"\", \"start\": 31875, \"end\": 31879}, {\"corpusId\": \"5041422\", \"span\": \"\", \"start\": 31995, \"end\": 31999}, {\"corpusId\": \"140268301\", \"span\": \"\", \"start\": 31999, \"end\": 32003}, {\"corpusId\": \"2898051\", \"span\": \"\", \"start\": 32003, \"end\": 32007}, {\"corpusId\": \"15305511\", \"span\": \"\", \"start\": 32007, \"end\": 32009}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "85862", "title": "Karamad: A Voice-based Crowdsourcing Platform for Underserved Populations", "sectionTitle": "4.5.6", "text": "\"Money should be sent to the mobile wallets because often it was too much for my usage and it expires after 90 days. \" (Male, 26, daily wage worker, more than 10 years of education) 4.5.8 Quality and Reliability of Responses. Quality control mechanisms are an important aspect of crowdsourcing platforms, particularly given the perception of potential unreliability of workers from low-resource communities. We created a validation survey that seeks to determine the consistency of responses provided by the workers. The validation survey consisted of 4 MCQ's, 4 Yes-No, and 2 open-ended short answer questions ( Table 4). Each of these 10 questions either had their answers shuffled or questions rephrased to create another 10 questions. We gathered a total of 250 worker-responses for the validation survey.", "spans": "[{\"corpusId\": \"5041422\", \"span\": \"\", \"start\": -46290, \"end\": -46286}, {\"corpusId\": \"140268301\", \"span\": \"\", \"start\": -46286, \"end\": -46283}, {\"corpusId\": \"203347488\", \"span\": \"\", \"start\": -46283, \"end\": -46280}, {\"corpusId\": \"140227355\", \"span\": \"\", \"start\": -46280, \"end\": -46277}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "85863", "title": "Karamad: A Voice-based Crowdsourcing Platform for Underserved Populations", "sectionTitle": "DISCUSSION", "text": "In this section, we reflect on the results of our work, its limitations, and the research opportunities in crowdsourcing. Over the last decade, IVR platforms for underserved communities seem to have settled on several de facto standards of interface design. These include airtime subsidies, social features, and advertisements to attract and retain users. Prior work shows that lack of airtime subsidy leads to low call volume and engagement [51,62], which causes IVR services to struggle with long-term sustainability [63]. Successful IVR forums have also engaged and retained users through social features (e.g. voting and comments) [49,62], spreading mechanisms such as the ability to forward content to friends [49,50], incentivized referrals [61], and advertisements [41]. Contrary to these prevailing norms, we designed and deployed Karamad without subsidies, social features, spreading mechanisms, or advertisements. Our work advances the existing HCI literature on IVR services for underserved populations by showing that in the absence of such features, paid crowd work can similarly achieve trust, engagement, spread, retention, and self-training.", "spans": "[{\"corpusId\": 231845372, \"span\": \"our work\", \"start\": 54, \"end\": 54}, {\"corpusId\": \"2898051\", \"span\": \"[51,\", \"start\": 442, \"end\": 446}, {\"corpusId\": \"15305511\", \"span\": \"62]\", \"start\": 446, \"end\": 449}, {\"corpusId\": \"140227355\", \"span\": \"[63]\", \"start\": 519, \"end\": 523}, {\"corpusId\": \"5041422\", \"span\": \"[49,\", \"start\": 635, \"end\": 639}, {\"corpusId\": \"15305511\", \"span\": \"62]\", \"start\": 639, \"end\": 642}, {\"corpusId\": \"5041422\", \"span\": \"[49,\", \"start\": 715, \"end\": 719}, {\"corpusId\": \"140268301\", \"span\": \"50]\", \"start\": 719, \"end\": 722}, {\"corpusId\": \"203347488\", \"span\": \"[61]\", \"start\": 747, \"end\": 751}, {\"corpusId\": \"212712710\", \"span\": \"[41]\", \"start\": 772, \"end\": 776}, {\"corpusId\": 231845372, \"span\": \"Our work\", \"start\": 932, \"end\": 932}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 8}, {"paragraphId": "85864", "title": "Karamad: A Voice-based Crowdsourcing Platform for Underserved Populations", "sectionTitle": "Compensation and Fairness", "text": "In our design and deployment of Karamad our foremost consideration after usability was how much to pay workers to complete tasks while protecting them in our study. We carefully considered the nuances described in prior HCI works that explored the asymmetries in labor relations, the ethics of perpetuating inequality, and both of these issues in the context of globalized markets [14,26,53]. Our eventual decision to pay 20 times the Pakistan federal minimum wage was largely predicated on the ethical grounds, rather than an attempt to minimize price. We intentionally 'overcompensated' our workers, but our pricing is generally in line with similar IVR-based pilot studies recently conducted in India [61,63].", "spans": "[{\"corpusId\": 231845372, \"span\": \"our study\", \"start\": 163, \"end\": 163}, {\"corpusId\": \"24531664\", \"span\": \"[14,\", \"start\": 381, \"end\": 385}, {\"corpusId\": \"207203679\", \"span\": \"26,\", \"start\": 385, \"end\": 388}, {\"corpusId\": \"16272139\", \"span\": \"53]\", \"start\": 388, \"end\": 391}, {\"corpusId\": 231845372, \"span\": \"our work\", \"start\": 597, \"end\": 597}, {\"corpusId\": \"203347488\", \"span\": \"[61,\", \"start\": 704, \"end\": 708}, {\"corpusId\": \"140227355\", \"span\": \"63]\", \"start\": 708, \"end\": 711}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "85865", "title": "Karamad: A Voice-based Crowdsourcing Platform for Underserved Populations", "sectionTitle": "Compensation and Fairness", "text": "We do not believe that such a high amount is required for robust participation from workers in long term operation due to increased familiarity and reduced risks. On the contrary, our survey findings echo Ekbia and Nardi's observation [15] that, beyond purely financial reasons, there are other motivations such as feelings of empowerment and independence that promote participation in heteromated labor arrangements. Based on prior work and given the overall enthusiasm that our workers expressed, we speculate that as long as airtime is subsidized very little financial compensation would be needed to motivate them. However, although lower prices would enable local employers to participate in our system, lower prices could also contribute to exploitation by more powerful international employers as previously described regarding crowd work [15,27,53].", "spans": "[{\"corpusId\": 231845372, \"span\": \"our work\", \"start\": 484, \"end\": 484}, {\"corpusId\": 231845372, \"span\": \"our system\", \"start\": 707, \"end\": 707}, {\"corpusId\": \"2328795\", \"span\": \"27,\", \"start\": 850, \"end\": 853}, {\"corpusId\": \"16272139\", \"span\": \"53]\", \"start\": 853, \"end\": 856}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "85866", "title": "Karamad: A Voice-based Crowdsourcing Platform for Underserved Populations", "sectionTitle": "Compensation and Fairness", "text": "This paper makes two main contributions. First, we explore the design of Karamad, a general purpose voice-based crowdsourcing platform for low-resource workers that does not require users to have access to a smartphone or the internet. Second, this paper presents lessons learned from a 6 month long in-situ deployment in Pakistan without airtime subsidies, user-training, or advertisement. In this paper, we do not focus on the results of the tasks themselves other than as a means to assess Karamad in terms of the workers who used our system, the ability of the workers to complete tasks, and Karamad's sustainability. Instead, we focus on a quantitative analysis of worker behavior on our platform and present qualitative findings from 35 telephone interviews.", "spans": "[{\"corpusId\": 231845372, \"span\": \"This paper\", \"start\": 10, \"end\": 10}, {\"corpusId\": 231845372, \"span\": \"this paper\", \"start\": 254, \"end\": 254}, {\"corpusId\": 231845372, \"span\": \"this paper\", \"start\": 404, \"end\": 404}, {\"corpusId\": 231845372, \"span\": \"our system\", \"start\": 544, \"end\": 544}, {\"corpusId\": 231845372, \"span\": \"Instead, we\", \"start\": 633, \"end\": 633}, {\"corpusId\": \"207203679\", \"span\": \"\", \"start\": 55064, \"end\": 55068}, {\"corpusId\": \"134722052\", \"span\": \"\", \"start\": 55068, \"end\": 55071}, {\"corpusId\": \"17990859\", \"span\": \"\", \"start\": 55071, \"end\": 55074}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "85867", "title": "Karamad: A Voice-based Crowdsourcing Platform for Underserved Populations", "sectionTitle": "Unique Challenges and Opportunities", "text": "Building on prior work on crowdsourcing behavioral research [19,30,36,47], we found high response rate and survey completion rate of Karamad's surveys on sensitive topics including hepatitis and tuberculosis (attempted by 316 workers, completed by 300), and HIV (attempted by 175 workers, completed by 174). In our interviews, respondents did not mention any discomfort while attempting surveys on these potentially sensitive topics. We believe that voice-based crowdsourcing provides a unique opportunity, beyond accessibility, for engaging difficult to reach respondents at scale regarding sensitive and taboo topics that they would not discuss with a person directly, or over phone.", "spans": "[{\"corpusId\": \"29634677\", \"span\": \"[19,\", \"start\": 60, \"end\": 64}, {\"corpusId\": \"1442595\", \"span\": \"30,\", \"start\": 64, \"end\": 67}, {\"corpusId\": \"14270987\", \"span\": \"36,\", \"start\": 67, \"end\": 70}, {\"corpusId\": \"120097026\", \"span\": \"47]\", \"start\": 70, \"end\": 73}, {\"corpusId\": 231845372, \"span\": \"our interviews\", \"start\": 325, \"end\": 325}]", "conference": "chi", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 5}], "paragraphCount": 15}
{"paperId": "6bf2f1dc081b319ed55f2e185278c7ebfacd9e45", "title": "Bridging CNNs, RNNs, and Weighted Finite-State Machines", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2018, "citationCount": 24, "openAccessPdf": {"url": "https://doi.org/10.18653/v1/p18-1028", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1805.06061, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2018-05-15", "authors": [{"authorId": "2279023325", "name": "Roy Schwartz"}, {"authorId": "38094552", "name": "Sam Thomson"}, {"authorId": "144365875", "name": "Noah A. Smith"}], "abstract": "Recurrent and convolutional neural networks comprise two distinct families of models that have proven to be useful for encoding natural language utterances. In this paper we present SoPa, a new model that aims to bridge these two approaches. SoPa combines neural representation learning with weighted finite-state automata (WFSAs) to learn a soft version of traditional surface patterns. We show that SoPa is an extension of a one-layer CNN, and that such CNNs are equivalent to a restricted version of SoPa, and accordingly, to a restricted form of WFSA. Empirically, on three text classification tasks, SoPa is comparable or better than both a BiLSTM (RNN) baseline and a CNN baseline, and is particularly useful in small data settings.", "corpusId": "21719302", "paragraphs": [{"paragraphId": "85161", "title": "Bridging CNNs, RNNs, and Weighted Finite-State Machines", "sectionTitle": "Introduction", "text": "Recurrent neural networks (RNNs; Elman, 1990) and convolutional neural networks (CNNs; Le-Cun, 1998) are two of the most useful text representation learners in NLP (Goldberg, 2016). These methods are generally considered to be quite different: the former encodes an arbitrarily long sequence of text, and is highly expressive (Siegelmann and Sontag, 1995). The latter is more local, encoding fixed length windows, and accordingly less expressive. In this paper, we seek to bridge the gap between RNNs and CNNs, presenting SoPa (for Soft Patterns), a model that lies in between them.", "spans": "[{\"corpusId\": 2763403, \"span\": \"Elman, 1990)\", \"start\": 33, \"end\": 45}, {\"corpusId\": 8273530, \"span\": \"(Goldberg, 2016)\", \"start\": 164, \"end\": 180}, {\"corpusId\": 44597102, \"span\": \"(Siegelmann and Sontag, 1995)\", \"start\": 326, \"end\": 355}, {\"corpusId\": 21719302, \"span\": \"this paper\", \"start\": 460, \"end\": 460}]", "conference": "acl", "year": 2018, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "85162", "title": "Bridging CNNs, RNNs, and Weighted Finite-State Machines", "sectionTitle": "Introduction", "text": "is able to capture a soft notion of surface patterns (e.g., \"what a great X !\"; Hearst, 1992), where some words may be dropped, inserted, or replaced with similar words (see Figure 1). From a modeling perspective, SoPa is interesting because WF-SAs are well-studied and come with efficient and flexible inference algorithms (Mohri, 1997;Eisner, 2002) that SoPa can take advantage of. SoPa defines a set of soft patterns of different lengths, with each pattern represented as a WFSA (Section 3). While the number and lengths of the patterns are hyperparameters, the patterns themselves are learned end-to-end. SoPa then represents a document with a vector that is the aggregate of the scores computed by matching each of the patterns with each span in the document. Because SoPa defines a hidden state that depends on the input token and the previous state, it can be thought of as a simple type of RNN. We show that SoPa is an extension of a onelayer CNN (Section 4). Accordingly, one-layer CNNs can be viewed as a collection of linearchain WFSAs, each of which can only match fixed-length spans, while our extension allows matches of flexible-length. As a simple type of RNN that is more expressive than a CNN, SoPa helps to link CNNs and RNNs.", "spans": "[{\"corpusId\": 15763200, \"span\": \"Hearst, 1992)\", \"start\": 80, \"end\": 93}, {\"corpusId\": 5548799, \"span\": \"(Mohri, 1997;\", \"start\": 324, \"end\": 337}, {\"corpusId\": 715063, \"span\": \"Eisner, 2002)\", \"start\": 337, \"end\": 350}]", "conference": "acl", "year": 2018, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "85163", "title": "Bridging CNNs, RNNs, and Weighted Finite-State Machines", "sectionTitle": "Background", "text": "Surface patterns. Patterns (Hearst, 1992) are particularly useful tool in NLP (Lin et al., 2003;Etzioni et al., 2005;. The most basic definition of a pattern is a sequence of words and wildcards (e.g., \"X is a Y\"), which can either be manually defined or extracted from a corpus using cooccurrence statistics. Patterns can then be matched against a specific text span by replacing wildcards with concrete words.  introduced a flexible notion of patterns, which supports partial matching of the pattern with a given text by skipping some of the words in the pattern, or introducing new words. In their framework, when a sequence of text partially matches a pattern, hard-coded partial scores are assigned to the pattern match. Here, we represent patterns as WFSAs with neural weights, and support these partial matches in a soft manner.", "spans": "[{\"corpusId\": 15763200, \"span\": \"(Hearst, 1992)\", \"start\": 27, \"end\": 41}, {\"corpusId\": 2220173, \"span\": \"(Lin et al., 2003;\", \"start\": 78, \"end\": 96}, {\"corpusId\": 7162988, \"span\": \"Etzioni et al., 2005;\", \"start\": 96, \"end\": 117}]", "conference": "acl", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "85164", "title": "Bridging CNNs, RNNs, and Weighted Finite-State Machines", "sectionTitle": "Related Work", "text": "Weighted finite-state automata. WFSAs and hidden Markov models 19 were once popular in automatic speech recognition (Hetherington, 2004;Moore et al., 2006;Hoffmeister et al., 2012) 19 HMMs are a special case of WFSAs (Mohri et al., 2002). and remain popular in morphology (Dreyer, 2011;Cotterell et al., 2015). Most closely related to this work, neural networks have been combined with weighted finite-state transducers to do morphological reinflection (Rastogi et al., 2016). These prior works learn a single FSA or FST, whereas our model learns a collection of simple but complementary FSAs, together encoding a sequence. We are the first to incorporate neural networks both before WFSAs (in their transition scoring functions), and after (in the function that turns their vector of scores into a final prediction), to produce an expressive model that remains interpretable.", "spans": "[{\"corpusId\": 15124727, \"span\": \"(Hetherington, 2004;\", \"start\": 116, \"end\": 136}, {\"corpusId\": 8366542, \"span\": \"Moore et al., 2006;\", \"start\": 136, \"end\": 155}, {\"corpusId\": 644936, \"span\": \"(Mohri et al., 2002)\", \"start\": 217, \"end\": 237}, {\"corpusId\": 16038823, \"span\": \"Cotterell et al., 2015)\", \"start\": 286, \"end\": 309}, {\"corpusId\": 21719302, \"span\": \"this work\", \"start\": 344, \"end\": 344}, {\"corpusId\": 7045397, \"span\": \"(Rastogi et al., 2016)\", \"start\": 453, \"end\": 475}]", "conference": "acl", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "85165", "title": "Bridging CNNs, RNNs, and Weighted Finite-State Machines", "sectionTitle": "Related Work", "text": "Recurrent neural networks. The ability of RNNs to represent arbitrarily long sequences of embedded tokens has made them attractive to NLP researchers. The most notable variants, the long short-term memory (LSTM; Hochreiter and Schmidhuber, 1997) and gated recurrent units (GRU; Cho et al., 2014), have become ubiquitous in NLP algorithms (Goldberg, 2016). Recently, several works introduced simpler versions of RNNs, such as recurrent additive networks (Lee et al., 2017) and Quasi-RNNs (Bradbury et al., 2017). Like SoPa, these models can be seen as points along the bridge between RNNs and CNNs.", "spans": "[{\"corpusId\": 1915014, \"span\": \"Hochreiter and Schmidhuber, 1997)\", \"start\": 212, \"end\": 245}, {\"corpusId\": 5590763, \"span\": \"Cho et al., 2014)\", \"start\": 278, \"end\": 295}, {\"corpusId\": 8273530, \"span\": \"(Goldberg, 2016)\", \"start\": 338, \"end\": 354}]", "conference": "acl", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "85166", "title": "Bridging CNNs, RNNs, and Weighted Finite-State Machines", "sectionTitle": "Related Work", "text": "Other works have studied the expressive power of RNNs, in particular in the context of WFSAs or HMMs (Cleeremans et al., 1989;Giles et al., 1992;Visser et al., 2001;Chen et al., 2018). In this work we relate CNNs to WFSAs, showing that a one-layer CNN with max-pooling can be simulated by a collection of linear-chain WFSAs.", "spans": "[{\"corpusId\": 7741931, \"span\": \"(Cleeremans et al., 1989;\", \"start\": 101, \"end\": 126}, {\"corpusId\": 19666035, \"span\": \"Giles et al., 1992;\", \"start\": 126, \"end\": 145}, {\"corpusId\": 145352328, \"span\": \"Visser et al., 2001;\", \"start\": 145, \"end\": 165}, {\"corpusId\": 3666178, \"span\": \"Chen et al., 2018)\", \"start\": 165, \"end\": 183}, {\"corpusId\": 21719302, \"span\": \"this work\", \"start\": 197, \"end\": 197}]", "conference": "acl", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "85167", "title": "Bridging CNNs, RNNs, and Weighted Finite-State Machines", "sectionTitle": "Related Work", "text": "Convolutional neural networks. CNNs are prominent feature extractors in NLP, both for generating character-based embeddings (Kim et al., 2016), and as sentence encoders for tasks like text classification (Yin and Sch\u00fctze, 2015) and machine translation (Gehring et al., 2017). Similarly to SoPa, several recently introduced variants of CNNs support varying window sizes by either allowing several fixed window sizes (Yin and Sch\u00fctze, 2015) or by supporting non-consecutive n-gram matching (Lei et al., 2015;Nguyen and Grishman, 2016).", "spans": "[{\"corpusId\": 686481, \"span\": \"(Kim et al., 2016)\", \"start\": 124, \"end\": 142}, {\"corpusId\": 7146903, \"span\": \"(Yin and Sch\\u00fctze, 2015)\", \"start\": 204, \"end\": 227}, {\"corpusId\": 3648736, \"span\": \"(Gehring et al., 2017)\", \"start\": 252, \"end\": 274}, {\"corpusId\": 7146903, \"span\": \"(Yin and Sch\\u00fctze, 2015)\", \"start\": 415, \"end\": 438}, {\"corpusId\": 2146847, \"span\": \"(Lei et al., 2015;\", \"start\": 488, \"end\": 506}, {\"corpusId\": 11331864, \"span\": \"Nguyen and Grishman, 2016)\", \"start\": 506, \"end\": 532}]", "conference": "acl", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "85168", "title": "Bridging CNNs, RNNs, and Weighted Finite-State Machines", "sectionTitle": "Related Work", "text": "Interpretability. There have been several efforts to interpret neural models. The weights of the attention mechanism (Bahdanau et al., 2015) are often used to display the words that are most significant for making a prediction. LIME (Ribeiro et al., 2016) is another approach for visualizing neural models (not necessarily textual). Yogatama and Smith (2014) introduced structured sparsity, which encodes linguistic information into the regularization of a model, thus allowing to visualize the contribution of different bag-of-word features.", "spans": "[{\"corpusId\": 11212020, \"span\": \"(Bahdanau et al., 2015)\", \"start\": 117, \"end\": 140}, {\"corpusId\": 13029170, \"span\": \"(Ribeiro et al., 2016)\", \"start\": 233, \"end\": 255}, {\"corpusId\": 78441, \"span\": \"Yogatama and Smith (2014)\", \"start\": 333, \"end\": 358}]", "conference": "acl", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "85169", "title": "Bridging CNNs, RNNs, and Weighted Finite-State Machines", "sectionTitle": "Related Work", "text": "Other works jointly learned to encode text and extract the span which best explains the model's prediction (Yessenalina et al., 2010;Lei et al., 2016). Li et al. (2016) and K\u00e1d\u00e1r et al. (2017) suggested a method that erases pieces of the text in order to analyze their effect on a neural model's decisions. Finally, several works presented methods to visualize deep CNNs (Zeiler and Fergus, 2014;Simonyan et al., 2014;Yosinski et al., 2015), focusing on visualizing the different layers of the network, mainly in the context of image and video understanding. We believe these two types of research approaches are complementary: inventing general purpose visualization tools for existing black-box models on the one hand, and on the other, designing models like SoPa that are interpretable by construction.", "spans": "[{\"corpusId\": 9021280, \"span\": \"(Yessenalina et al., 2010;\", \"start\": 107, \"end\": 133}, {\"corpusId\": 7205805, \"span\": \"Lei et al., 2016)\", \"start\": 133, \"end\": 150}, {\"corpusId\": 3960646, \"span\": \"(Zeiler and Fergus, 2014;\", \"start\": 371, \"end\": 396}, {\"corpusId\": 1450294, \"span\": \"Simonyan et al., 2014;\", \"start\": 396, \"end\": 418}, {\"corpusId\": 9591565, \"span\": \"Yosinski et al., 2015)\", \"start\": 418, \"end\": 440}]", "conference": "acl", "year": 2018, "likelyRelatedWorkSection": true, "refCount": 5}], "paragraphCount": 9}
{"paperId": "5fefc28ae503c465b1801da2b457f5a2cb5bd51f", "title": "PASTA: Table-Operations Aware Fact Verification via Sentence-Table Cloze Pre-training", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2022, "citationCount": 54, "openAccessPdf": {"url": "https://arxiv.org/pdf/2211.02816", "status": "GREEN", "license": null, "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2211.02816, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2022-11-05", "authors": [{"authorId": "2082344591", "name": "Zihui Gu"}, {"authorId": "1704755170", "name": "Ju Fan"}, {"authorId": "8669763", "name": "N. Tang"}, {"authorId": "1683562", "name": "Preslav Nakov"}, {"authorId": "48551684", "name": "Xiaoman Zhao"}, {"authorId": "2152944669", "name": "Xiaoyong Du"}], "abstract": "Fact verification has attracted a lot of attention recently, e.g., in journalism, marketing, and policymaking, as misinformation and dis- information can sway one\u2019s opinion and affect one\u2019s actions. While fact-checking is a hard task in general, in many cases, false statements can be easily debunked based on analytics over tables with reliable information. Hence, table- based fact verification has recently emerged as an important and growing research area. Yet, progress has been limited due to the lack of datasets that can be used to pre-train language models (LMs) to be aware of common table operations, such as aggregating a column or comparing tuples. To bridge this gap, this paper introduces PASTA for table-based fact verification via pre-training with synthesized sentence\u2013table cloze questions. In particular, we design six types of common sentence\u2013table cloze tasks, including Filter, Aggregation, Superlative, Comparative, Ordinal, and Unique, based on which we synthesize a large corpus consisting of 1.2 million sentence\u2013table pairs from WikiTables. PASTA uses a recent pre-trained LM, DeBERTaV3, and further pre- trains it on our corpus. Our experimental results show that PASTA achieves new state-of-the-art (SOTA) performance on two table-based fact verification datasets TabFact and SEM-TAB- FACTS. In particular, on the complex set of TabFact, which contains multiple operations, PASTA largely outperforms previous SOTA by 4.7% (85.6% vs. 80.9%), and the gap between PASTA and human performance on the small test set is narrowed to just 1.5% (90.6% vs. 92.1%).", "corpusId": "253384265", "paragraphs": [{"paragraphId": "59614", "title": "PASTA: Table-Operations Aware Fact Verification via Sentence-Table Cloze Pre-training", "sectionTitle": "Introduction", "text": "Fact verification, which checks the factuality of a statement, is crucial for journalism (Shu et al., * Xiaoman Zhao is the corresponding author. 1 The pre-trained model, the pre-training corpus, and the source code are released at https://github.com/ruc-datalab/PASTA 2017), and is increasingly being applied in other fields (Ott et al., 2011;Yoon et al., 2019). According to Duke Reporters' Lab, there are 300+ active certified fact-checking organizations worldwide. 2 Automatic and explainable approaches, a.k.a. reference-based approaches, are widely used to assist fact-checkers. They verify the input statement against a trusted source, such as relevant passages from Wikipedia (Popat et al., 2017;Thorne et al., 2018;Shaar et al., 2020). Recently, table-based fact verification has been extensively studied (Chen et al., 2020a;Zhong et al., 2020; due to the wide availability of tabular data.", "spans": "[{\"corpusId\": 2510724, \"span\": \"(Ott et al., 2011;\", \"start\": 326, \"end\": 344}, {\"corpusId\": 53712798, \"span\": \"Yoon et al., 2019)\", \"start\": 344, \"end\": 362}, {\"corpusId\": 4837028, \"span\": \"(Popat et al., 2017;\", \"start\": 684, \"end\": 704}, {\"corpusId\": 4711425, \"span\": \"Thorne et al., 2018;\", \"start\": 704, \"end\": 724}, {\"corpusId\": 218613630, \"span\": \"Shaar et al., 2020)\", \"start\": 724, \"end\": 743}, {\"corpusId\": 198917339, \"span\": \"(Chen et al., 2020a;\", \"start\": 814, \"end\": 834}, {\"corpusId\": 216562233, \"span\": \"Zhong et al., 2020;\", \"start\": 834, \"end\": 853}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 7}, {"paragraphId": "59615", "title": "PASTA: Table-Operations Aware Fact Verification via Sentence-Table Cloze Pre-training", "sectionTitle": "Introduction", "text": "Most previous work (Herzig et al., 2020;Wang et al., 2021a;Schlichtkrull et al., 2021) leverages pre-trained language models (LMs) (Devlin et al., 2019;Liu et al., 2019), which are originally designed for unstructured data, and have a key limitation of overlooking such operations. Some approaches (Zhong et al., 2020; attempt to explicitly capture the operations by generating a logical form (e.g., a tree) containing the operations from the statement via semantic parsing techniques. However, such approaches face the problem of \"spurious programs\" (Chen et al., 2020a), due to weak supervision signals in semantic parsing.", "spans": "[{\"corpusId\": 214802901, \"span\": \"(Herzig et al., 2020;\", \"start\": 19, \"end\": 40}, {\"corpusId\": 237452759, \"span\": \"Wang et al., 2021a;\", \"start\": 40, \"end\": 59}, {\"corpusId\": 229923350, \"span\": \"Schlichtkrull et al., 2021)\", \"start\": 59, \"end\": 86}, {\"corpusId\": 52967399, \"span\": \"(Devlin et al., 2019;\", \"start\": 131, \"end\": 152}, {\"corpusId\": 216562233, \"span\": \"(Zhong et al., 2020;\", \"start\": 298, \"end\": 318}, {\"corpusId\": 198917339, \"span\": \"(Chen et al., 2020a)\", \"start\": 551, \"end\": 571}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 6}, {"paragraphId": "59616", "title": "PASTA: Table-Operations Aware Fact Verification via Sentence-Table Cloze Pre-training", "sectionTitle": "Introduction", "text": "\u2022 We propose a new benchmark for pre-training LMs to be aware of common table-based operations by automatically synthesizing sentencetable cloze questions from WikiTables. In particular, we synthesize a large corpus consisting of 1.2 million sentence-table cloze questions, which we release for future research. \u2022 We evaluate PASTA, which is DeBER-TaV3 pre-trained with our table-operations aware pre-training approach, on two widelyadopted table-based fact verification benchmark datasets, TabFact (Chen et al., 2020a) and SEM-TAB-FACTS (Wang et al., 2021b ", "spans": "[{\"corpusId\": 253384265, \"span\": \"We propose\", \"start\": 12, \"end\": 12}, {\"corpusId\": 198917339, \"span\": \"(Chen et al., 2020a)\", \"start\": 499, \"end\": 519}, {\"corpusId\": 235248022, \"span\": \"(Wang et al., 2021b\", \"start\": 538, \"end\": 557}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 3}, {"paragraphId": "59617", "title": "PASTA: Table-Operations Aware Fact Verification via Sentence-Table Cloze Pre-training", "sectionTitle": "DeBERTa for Sentence-Table Encoding", "text": "Inspired by the success of BERT-like models (Devlin et al., 2019;Liu et al., 2019;Clark et al., 2020) in natural language understanding (NLU) tasks, many existing studies leverage pre-trained LMs for table understanding, achieving superior results (Chen et al., 2020b;Schlichtkrull et al., 2021). In this paper, we apply DeBERTa (He et al., 2021b) for sentence-table encoding, as it can effectively capture positional information of the input with its positional encoding scheme, which is useful for sentence-table encoding.", "spans": "[{\"corpusId\": 52967399, \"span\": \"(Devlin et al., 2019;\", \"start\": 44, \"end\": 65}, {\"corpusId\": 213152193, \"span\": \"Clark et al., 2020)\", \"start\": 82, \"end\": 101}, {\"corpusId\": 218684696, \"span\": \"(Chen et al., 2020b;\", \"start\": 248, \"end\": 268}, {\"corpusId\": 229923350, \"span\": \"Schlichtkrull et al., 2021)\", \"start\": 268, \"end\": 295}, {\"corpusId\": 253384265, \"span\": \"this paper\", \"start\": 310, \"end\": 310}, {\"corpusId\": 219531210, \"span\": \"(He et al., 2021b)\", \"start\": 329, \"end\": 347}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "59618", "title": "PASTA: Table-Operations Aware Fact Verification via Sentence-Table Cloze Pre-training", "sectionTitle": "Baselines", "text": "ProgVGAT  integrates programs and execution into a natural language inference model. This method uses a verbalization with a program execution model to accumulate evidences and constructs a graph attention network to combine various evidences. Tapas (Herzig et al., 2020) extends BERT with additional structure-aware positional embeddings to represent the tables. Eisenschlos et al., 2020 further pre-train Tapas on counterfactually-augmented and grammar-based synthetic statements. Schlichtkrull et al., 2021 study table-based fact verification in an open-domain setting, and combine a TF-IDF retrieval model with a RoBERTabased joint reranking-and-verification model. Tapex  guides the pre-trained BART model to mimic an SQL executor via an execution-centric table pre-training approach. The pre-training corpus of Tapex is synthesized via sampling SQL queries from the SQUALL dataset (Shi et al., 2020). SaMoE (Zhou et al., 2022) develops a mixtureof-experts network based on the RoBERTa-large model (Liu et al., 2019). The MoE network consists of different experts, and then a management module decides the contribution of each expert network to the verification result. Volta (Gautam et al., 2021) analyzes how transfer learning and standardizing tables to contain a single header row can boost the effectiveness of tablebased fact verification. LKA (Zhao and Yang, 2022) studies the sentencetable's evidence correlation. It develops a dualview alignment module based on the statement and table views to identify the most important words through various interactions.", "spans": "[{\"corpusId\": 253384265, \"span\": \"This method\", \"start\": 96, \"end\": 96}, {\"corpusId\": 214802901, \"span\": \"(Herzig et al., 2020)\", \"start\": 250, \"end\": 271}, {\"corpusId\": 225039884, \"span\": \"(Shi et al., 2020)\", \"start\": 887, \"end\": 905}, {\"corpusId\": 248239888, \"span\": \"(Zhou et al., 2022)\", \"start\": 913, \"end\": 932}, {\"corpusId\": 235265891, \"span\": \"(Gautam et al., 2021)\", \"start\": 1181, \"end\": 1202}, {\"corpusId\": 252819168, \"span\": \"(Zhao and Yang, 2022\", \"start\": 1355, \"end\": 1375}]", "conference": "emnlp", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 6}], "paragraphCount": 5}
{"paperId": "7e8cd8729e2991942c50804133a88fa11f18587f", "title": "The Workplace Playbook VR: Exploring the Design Space of Virtual Reality to Foster Understanding of and Support for Autistic People", "venue": "Proc. ACM Hum. Comput. Interact.", "year": 2022, "citationCount": 21, "openAccessPdf": {"url": "https://dl.acm.org/doi/pdf/10.1145/3555082", "status": "BRONZE", "license": null, "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3555082?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3555082, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2022-11-07", "authors": [{"authorId": "2109208547", "name": "Jennifer G. Kim"}, {"authorId": "2111182575", "name": "Taewan Kim"}, {"authorId": "2109560881", "name": "Sung-In Kim"}, {"authorId": "2190155529", "name": "So-youn Jang"}, {"authorId": "2190502352", "name": "Eun Bin (Stephanie) Lee"}, {"authorId": "47111399", "name": "H. Yoo"}, {"authorId": "35655049", "name": "Kyungsik Han"}, {"authorId": "39887691", "name": "Hwajung Hong"}], "abstract": "A growing number of organizations are hiring autistic individuals as they start to recognize the value of a neurodiverse workforce. Despite this trend, the lack of support for autistic employees in workplaces complicates their employment. However, little is known about how people around autistic individuals can support them to create pleasant employment experiences. In this work, we develop the concept of the Workplace Playbook VR to investigate how virtual reality (VR) can help autistic people develop their work-related social communication skills in partnership with people in their support network. Using a video prototype to present the concept, we interviewed 28 participants, including 10 autistic people and 18 members of their support networks, which included family members and professionals. Our interviews revealed that the Workplace Playbook VR program can provide common ground for autistic people and members of their support network to participate in more empathetic communication regarding workplace challenges. Despite the benefits, we identified the potential misuse of social communication skills training features of the VR program to correct the personal characteristics of autistic individuals. Furthermore, to cultivate inclusive workplace environments, we found the needs of VR development not only for autistic people but also for neurotypical employees to promote their understanding of autism and empathy toward autistic employees. We suggest VR designs that promote a sense of agency and self-advocacy for autistic employees, and autism awareness and acceptance training for neurotypical employees.", "corpusId": "253460211", "paragraphs": [{"paragraphId": "48636", "title": "The Workplace Playbook VR: Exploring the Design Space of Virtual Reality to Foster Understanding of and Support for Autistic People", "sectionTitle": "INTRODUCTION", "text": "There is a growing interest in building inclusive workplaces as organizations begin to recognize the value of a neurodiverse workforce. An increasing number of companies are making endeavors to hire autistic people 1 as the strengths, values, and talents of this population gain wider recognition. However, the employment rate of autistic people is only 15%-much lower than the 54% employment rate of people with other types of disabilities [19,85]. Studies have shown that a lack of support and accommodations regarding the challenges autistic people encounter at work-such as social communication skills-complicates their successful employment [33,65]. Moreover, the lack of appropriate understanding about autism among employers and co-workers is identified as one of the most common barriers preventing autistic people from finding and retaining employment [22,54].", "spans": "[{\"corpusId\": 41265596, \"span\": \"85]\", \"start\": 445, \"end\": 448}, {\"corpusId\": 53533745, \"span\": \"[33,\", \"start\": 646, \"end\": 650}, {\"corpusId\": 18759399, \"span\": \"65]\", \"start\": 650, \"end\": 653}, {\"corpusId\": 3904860, \"span\": \"[22,\", \"start\": 861, \"end\": 865}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "48637", "title": "The Workplace Playbook VR: Exploring the Design Space of Virtual Reality to Foster Understanding of and Support for Autistic People", "sectionTitle": "INTRODUCTION", "text": "Virtual reality (VR) has been studied as an effective medium to provide vocational support for autistic people, for instance through training in social communication skills for job interviews [89] or job tasks (e.g., money management) [14]. Simulated reality provides an interactive learning environment that enables autistic people to practice skills multiple times in various scenarios [23,92]. Moreover, sensing technologies that measure the behavioral and physiological signals of autistic individuals during VR interactions can personalize VR experiences and provide helpful insight and feedback about their behaviors [13,55]. This rich body of past work, although not specific to work-related settings, has also shown the effectiveness of VR interventions in increasing autistic people's vocational skills [16,41].", "spans": "[{\"corpusId\": 17263937, \"span\": \"[89]\", \"start\": 192, \"end\": 196}, {\"corpusId\": 26805087, \"span\": \"[14]\", \"start\": 235, \"end\": 239}, {\"corpusId\": 46374031, \"span\": \"[23,\", \"start\": 388, \"end\": 392}, {\"corpusId\": 6379839, \"span\": \"92]\", \"start\": 392, \"end\": 395}, {\"corpusId\": 5040819, \"span\": \"[13,\", \"start\": 623, \"end\": 627}, {\"corpusId\": 6770985, \"span\": \"55]\", \"start\": 627, \"end\": 630}, {\"corpusId\": 49353119, \"span\": \"[16,\", \"start\": 812, \"end\": 816}, {\"corpusId\": 1990470, \"span\": \"41]\", \"start\": 816, \"end\": 819}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 8}, {"paragraphId": "48638", "title": "The Workplace Playbook VR: Exploring the Design Space of Virtual Reality to Foster Understanding of and Support for Autistic People", "sectionTitle": "Neurodiversity in the Workplace", "text": "Recent efforts have been made to create an inclusive workplace environment where every employee feels valued while their differences and contributions are recognized [35,65]. Increasingly many IT companies (e.g. SAP and Microsoft) run diversity and inclusion divisions to support the work lives of neurodiverse people [4,69]. In these programs, the strengths of neurodiverse people such as attention to detail and intense focus [88] are leveraged to the company's best advantage, such as by assigning IT product Quality Assurance (QA) to autistic employees. Workplace inclusion programs also provide opportunities to improve autistic employees' work experiences [28,69,95]; for instance, Cornell University's Yang-Tan Institute offers an Autism at Work program to educate human resource professionals about how to actively hire autistic individuals and foster an inclusive workplace culture [95]. Despite such efforts to develop inclusive workplace environments, barriers experienced by autistic individuals at work persist [33]. Communication and social difficulties are often identified as challenges to engaging in interactions with co-workers and supervisors [18,45,65,96]. In addition, the negative attitudes of employers, managers, and co-workers often discourage autistic people and heighten their social anxiety [18,83,90]. A lack of individualized workplace training opportunities such as social skills and self-advocacy instruction hinders the successful employment of autistic people [29,36].", "spans": "[{\"corpusId\": 41686365, \"span\": \"[35,\", \"start\": 166, \"end\": 170}, {\"corpusId\": 18759399, \"span\": \"65]\", \"start\": 170, \"end\": 173}, {\"corpusId\": 151360212, \"span\": \"[4,\", \"start\": 318, \"end\": 321}, {\"corpusId\": 199162870, \"span\": \"[28,\", \"start\": 662, \"end\": 666}, {\"corpusId\": 53533745, \"span\": \"[33]\", \"start\": 1024, \"end\": 1028}, {\"corpusId\": 146507484, \"span\": \"[18,\", \"start\": 1163, \"end\": 1167}, {\"corpusId\": 272426, \"span\": \"45,\", \"start\": 1167, \"end\": 1170}, {\"corpusId\": 18759399, \"span\": \"65,\", \"start\": 1170, \"end\": 1173}, {\"corpusId\": 16511641, \"span\": \"96]\", \"start\": 1173, \"end\": 1176}, {\"corpusId\": 146507484, \"span\": \"[18,\", \"start\": 1320, \"end\": 1324}, {\"corpusId\": 682311, \"span\": \"83,\", \"start\": 1324, \"end\": 1327}, {\"corpusId\": 55287400, \"span\": \"90]\", \"start\": 1327, \"end\": 1330}, {\"corpusId\": 142220872, \"span\": \"[29,\", \"start\": 1495, \"end\": 1499}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 11}, {"paragraphId": "48639", "title": "The Workplace Playbook VR: Exploring the Design Space of Virtual Reality to Foster Understanding of and Support for Autistic People", "sectionTitle": "Neurodiversity in the Workplace", "text": "On a more positive note, research has shown that having a group of supportive and understanding people around autistic individuals can facilitate their employment [33]. A support network that includes family, friends, co-workers, and support staff who are familiar with the individual characteristics, strengths, and weaknesses of an autistic person can provide personalized and practical support in unexpected and challenging situations [39,66,99]. Several approaches for facilitating workplace collaboration between neurotypical and autistic employees have been reported such as mentoring or coaching for autistic employees [76] and autism awareness training for neurotypical workers [28]. For instance, a recent study examined the co-work experience of eight autistic individuals and neurotypical colleagues across a three-month internship period [76]. For this study, autistic interns were assigned neurotypical \"buddies\" (i.e., mentors) and guided to email their buddies if they had work-related questions. Through this individualized support, autistic interns reported feeling accepted within the workplace. More importantly, managers reported the importance of identifying the needs, strengths, and weaknesses of autistic employees for successful collaboration, and suggested that modifications such as giving very specific instructions, communicating in writing, or addressing sensory issues could help.", "spans": "[{\"corpusId\": 53533745, \"span\": \"[33]\", \"start\": 163, \"end\": 167}, {\"corpusId\": 145686525, \"span\": \"[39,\", \"start\": 438, \"end\": 442}, {\"corpusId\": 201348393, \"span\": \"66,\", \"start\": 442, \"end\": 445}, {\"corpusId\": 149478831, \"span\": \"[76]\", \"start\": 626, \"end\": 630}, {\"corpusId\": 199162870, \"span\": \"[28]\", \"start\": 686, \"end\": 690}, {\"corpusId\": 149478831, \"span\": \"[76]\", \"start\": 850, \"end\": 854}, {\"corpusId\": 253460211, \"span\": \"this study\", \"start\": 870, \"end\": 870}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "48640", "title": "The Workplace Playbook VR: Exploring the Design Space of Virtual Reality to Foster Understanding of and Support for Autistic People", "sectionTitle": "VR for Autistic People", "text": "VR has the benefit of providing a safe, controlled environment for autistic individuals to practice social skills without worrying about the negative consequences of making common mistakes associated with face-to-face interactions [1,6,13,16,24]. Furthermore, the flexible and scalable nature of VR can manipulate environments and interactions tailored to autistic people to provide personalized interventions for people with various levels of cognition, language, and social skills [62]. Based on these advantages, VR-based interventions can be applied to a range of domains such as socio-emotional skills [24], safety skills [40,81,82], adaptive skills [49], and communication [24,43].", "spans": "[{\"corpusId\": 703677, \"span\": \"6,\", \"start\": 234, \"end\": 236}, {\"corpusId\": 5040819, \"span\": \"13,\", \"start\": 236, \"end\": 239}, {\"corpusId\": 49353119, \"span\": \"16,\", \"start\": 239, \"end\": 242}, {\"corpusId\": 7426111, \"span\": \"24]\", \"start\": 242, \"end\": 245}, {\"corpusId\": 51909066, \"span\": \"[62]\", \"start\": 483, \"end\": 487}, {\"corpusId\": 7426111, \"span\": \"[24]\", \"start\": 607, \"end\": 611}, {\"corpusId\": 141810128, \"span\": \"[40,\", \"start\": 627, \"end\": 631}, {\"corpusId\": 550833, \"span\": \"81,\", \"start\": 631, \"end\": 634}, {\"corpusId\": 144863901, \"span\": \"82]\", \"start\": 634, \"end\": 637}, {\"corpusId\": 22776278, \"span\": \"[49]\", \"start\": 655, \"end\": 659}, {\"corpusId\": 7426111, \"span\": \"[24,\", \"start\": 679, \"end\": 683}, {\"corpusId\": 144209211, \"span\": \"43]\", \"start\": 683, \"end\": 686}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 10}, {"paragraphId": "48641", "title": "The Workplace Playbook VR: Exploring the Design Space of Virtual Reality to Foster Understanding of and Support for Autistic People", "sectionTitle": "VR for Autistic People", "text": "Despite the promising results of previous studies, limitations on VR interventions for autistic people have also been reported [30,47,68]. While previous studies found VR intervention to be effective when acquiring daily living skills [47,63,78], a recent meta-review study pointed out that VR had moderate effects on improving communication skills and emotion regulation skills, perhaps due to the complicated and nuanced nature of these skills [47]. Regarding methodological rigor, results of VR intervention studies are often difficult to validate and generalize due to substantial variations among autistic individuals [40,43,68]. Furthermore, the lack of sufficient precedent and theoretical guidance for VR intervention design and the fact that actual users were not sufficiently involved in the design process were pointed out as limitations [30,68]. This critical view emphasized the importance of understanding the characteristics, needs, and preferences of autistic individuals and stakeholders when designing VR experiences for them [68]. Thus, our research aims to improve the understanding of how VR experiences should be designed to enhance social and communication skills by involving autistic people and members of their support networks in the early stages of VR design. Our work seeks to perform the inclusive, participatory design of VR experiences with and for autistic adults who currently face various challenges in the workplace.", "spans": "[{\"corpusId\": 239070499, \"span\": \"[30,\", \"start\": 127, \"end\": 131}, {\"corpusId\": 151923159, \"span\": \"68]\", \"start\": 134, \"end\": 137}, {\"corpusId\": 198965104, \"span\": \"63,\", \"start\": 239, \"end\": 242}, {\"corpusId\": 206716744, \"span\": \"78]\", \"start\": 242, \"end\": 245}, {\"corpusId\": 141810128, \"span\": \"[40,\", \"start\": 623, \"end\": 627}, {\"corpusId\": 144209211, \"span\": \"43,\", \"start\": 627, \"end\": 630}, {\"corpusId\": 151923159, \"span\": \"68]\", \"start\": 630, \"end\": 633}, {\"corpusId\": 239070499, \"span\": \"[30,\", \"start\": 849, \"end\": 853}, {\"corpusId\": 151923159, \"span\": \"68]\", \"start\": 853, \"end\": 856}, {\"corpusId\": 151923159, \"span\": \"[68]\", \"start\": 1044, \"end\": 1048}, {\"corpusId\": 253460211, \"span\": \"our research\", \"start\": 1068, \"end\": 1068}, {\"corpusId\": 253460211, \"span\": \"Our work\", \"start\": 1296, \"end\": 1296}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "48642", "title": "The Workplace Playbook VR: Exploring the Design Space of Virtual Reality to Foster Understanding of and Support for Autistic People", "sectionTitle": "VR for Autistic People", "text": "2.2.1 VR to train employment skills. Several researchers have investigated how VR technologies support autistic individuals to acquire employment skills [14,21]. Employment skills can be divided into two broad categories: job-specific skills called hard skills (e.g., folding, photocopying, and sweeping), and more generic employment-related skills called soft skills (e.g., time management, social skills, and interview skills) [98]. Prior technology-related studies focused more on hard skills rather than soft skills [15], even though autistic people often experience more challenges at work due to their soft skills [33]. Social situations that may arise at work (e.g., working with co-workers, managing conflict, dealing with office politics) have been identified as major challenges that autistic people face in the workplace [65]. Although some studies investigate the use of VR to develop autistic people's soft skills, many focus on learning skills for job interviews such as how to properly communicate and respond in interview situations (e.g., emotional regulatory strategies and self-advocacy methods), use non-verbal communication (e.g., eye contact) when interviewing, and manage attire or hygiene when preparing for an interview [41,64,89,93], rather than on skills related to navigating social situations associated with ongoing employment (e.g., having lunch with co-workers and working with customers). While interview skills are important for obtaining employment, more contextualized and practical support for the everyday social encounters of autistic people in workplaces would further advance their work experience, satisfaction, and success.", "spans": "[{\"corpusId\": 26805087, \"span\": \"[14,\", \"start\": 153, \"end\": 157}, {\"corpusId\": 147977173, \"span\": \"21]\", \"start\": 157, \"end\": 160}, {\"corpusId\": 151718839, \"span\": \"[98]\", \"start\": 429, \"end\": 433}, {\"corpusId\": 18842992, \"span\": \"[15]\", \"start\": 520, \"end\": 524}, {\"corpusId\": 53533745, \"span\": \"[33]\", \"start\": 620, \"end\": 624}, {\"corpusId\": 18759399, \"span\": \"[65]\", \"start\": 832, \"end\": 836}, {\"corpusId\": 1990470, \"span\": \"[41,\", \"start\": 1245, \"end\": 1249}, {\"corpusId\": 34887858, \"span\": \"64,\", \"start\": 1249, \"end\": 1252}, {\"corpusId\": 17263937, \"span\": \"89,\", \"start\": 1252, \"end\": 1255}, {\"corpusId\": 23742338, \"span\": \"93]\", \"start\": 1255, \"end\": 1258}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 10}, {"paragraphId": "48643", "title": "The Workplace Playbook VR: Exploring the Design Space of Virtual Reality to Foster Understanding of and Support for Autistic People", "sectionTitle": "VR to promote shared understanding and communication.", "text": "Beyond its effectiveness in the acquisition of job-related skills, it has been found that immersive VR can be an effective medium for building empathy-the ability to share and understand others' emotions by taking someone else's perspective [8,26,46]. Previous research on VR and empathy has shown that people who underwent a virtual reality experience simulating life events such as becoming homeless were likely to have a positive attitude toward the homeless and present pro-social behaviors (e.g., sign petitions) [37]. Empathy-building among family, professionals, and co-workers is also critical for autistic people to have pleasant work experiences [33]. Building on the previous research, we investigate how VR systems can be designed to successfully mediate communication between autistic people and members of their support network, who can help address whatever issues and concerns autistic individuals may have regarding workplace social situations. Only a few studies have examined the use of VR technologies to facilitate functional communication between autistic people and caregivers (e.g., teachers, family members, and therapists). For example, studies have used a monitoring module that allows caregivers to observe a learner's VR situations in real-time and adjust task levels and scenarios accordingly to provide appropriate feedback [60,75]. In another study, a therapist directly participated in a VR situation as a peer character, providing responses and feedback tailored to the behaviors of autistic people [24].", "spans": "[{\"corpusId\": 140269481, \"span\": \"[8,\", \"start\": 241, \"end\": 244}, {\"corpusId\": 237283855, \"span\": \"26,\", \"start\": 244, \"end\": 247}, {\"corpusId\": 13138325, \"span\": \"46]\", \"start\": 247, \"end\": 250}, {\"corpusId\": 52985843, \"span\": \"[37]\", \"start\": 518, \"end\": 522}, {\"corpusId\": 53533745, \"span\": \"[33]\", \"start\": 656, \"end\": 660}, {\"corpusId\": 221437356, \"span\": \"[60,\", \"start\": 1355, \"end\": 1359}, {\"corpusId\": 203639904, \"span\": \"75]\", \"start\": 1359, \"end\": 1362}, {\"corpusId\": 7426111, \"span\": \"[24]\", \"start\": 1533, \"end\": 1537}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 8}, {"paragraphId": "48644", "title": "The Workplace Playbook VR: Exploring the Design Space of Virtual Reality to Foster Understanding of and Support for Autistic People", "sectionTitle": "VR to promote shared understanding and communication.", "text": "To foster understanding of an autistic individual, it is important to acquire a wide range of the individual's behavioral data, which can provide a foundation for collaborative reflections between the individual and members of their support network [71,86]. Recent studies have proposed the exploitation of sensors integrated with VR platforms (e.g., eye-trackers and motion trackers) to detect users' affective states in real-time [74,97]. Previous studies examining sensor integration have focused on collecting behavioral and physiological data in VR-based data-driven interventions. For example, vrSocial's use of visualization of proximity, voice volume, and speech duration of autistic children in real-time within virtual spaces was an effective way for the children to better regulate their proximity in VR [13]. Another VR-based system correlated children's physiological signals with their affective states while participating in given social tasks, which resulted in a VRbased system that was adaptive to participants' performance [48]. With VR, user data such as voice volume or affective state can be collected while they interact in the virtual environments, while stakeholders (e.g., caregivers, professionals, co-workers) can contribute to the learning process [5,[57][58][59]. Thus, such user-generated data could facilitate information sharing, perspective-taking, and communication among both autistic people and other stakeholders [77].", "spans": "[{\"corpusId\": 16721833, \"span\": \"[71,\", \"start\": 249, \"end\": 253}, {\"corpusId\": 18665127, \"span\": \"86]\", \"start\": 253, \"end\": 256}, {\"corpusId\": 211073617, \"span\": \"[74,\", \"start\": 432, \"end\": 436}, {\"corpusId\": 49738090, \"span\": \"97]\", \"start\": 436, \"end\": 439}, {\"corpusId\": 5040819, \"span\": \"[13]\", \"start\": 815, \"end\": 819}, {\"corpusId\": 17567374, \"span\": \"[48]\", \"start\": 1042, \"end\": 1046}, {\"corpusId\": 85517958, \"span\": \"[5,\", \"start\": 1277, \"end\": 1280}, {\"corpusId\": 3916407, \"span\": \"[57]\", \"start\": 1280, \"end\": 1284}, {\"corpusId\": 218482804, \"span\": \"[58]\", \"start\": 1284, \"end\": 1288}, {\"corpusId\": 18120379, \"span\": \"[59]\", \"start\": 1288, \"end\": 1292}, {\"corpusId\": 233354225, \"span\": \"[77]\", \"start\": 1451, \"end\": 1455}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 11}, {"paragraphId": "48645", "title": "The Workplace Playbook VR: Exploring the Design Space of Virtual Reality to Foster Understanding of and Support for Autistic People", "sectionTitle": "DESIGN PROCESS AND THE RATIONALE OF THE WORKPLACE PLAYBOOK VR", "text": "We developed the concept of the Workplace Playbook VR to elicit concrete feedback about how VR could be designed to help autistic individuals and members of their support network address the challenges that autistic people might face in their current or future workplaces. To present the concept, we created a video prototype of the Workplace Playbook VR. The concept presented in the video prototype primarily targeted autistic people to support their work-related social and communication skills. We made this design decision because VR has been shown to be effective for training the social and communication skills of autistic individuals [41]. Those skills are known to be some of the most pressing challenges that autistic people face in workplaces [18,33,65]. However, as we will report in the findings section, our study revealed that such social and communication skills training VR programs have the potential to enforce \"normative behaviors\" on autistic people rather than respect their values and diversity. Moreover, to advance the positive work experiences of autistic employees in workplaces, we found the importance of practicing design interventions not only for neurodiverse people but also for neurotypical co-workers and employees. Therefore, this work ultimately offers VR design spaces of workplace environments for two target groups-autistic people and members of their community and their neurotypical coworkers.", "spans": "[{\"corpusId\": 1990470, \"span\": \"[41]\", \"start\": 643, \"end\": 647}, {\"corpusId\": 146507484, \"span\": \"[18,\", \"start\": 755, \"end\": 759}, {\"corpusId\": 53533745, \"span\": \"33,\", \"start\": 759, \"end\": 762}, {\"corpusId\": 18759399, \"span\": \"65]\", \"start\": 762, \"end\": 765}, {\"corpusId\": 253460211, \"span\": \"our study\", \"start\": 828, \"end\": 828}, {\"corpusId\": 253460211, \"span\": \"this work\", \"start\": 1272, \"end\": 1272}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "48646", "title": "The Workplace Playbook VR: Exploring the Design Space of Virtual Reality to Foster Understanding of and Support for Autistic People", "sectionTitle": "Data-driven Reflection", "text": "For the purpose of the video prototype, we visualized turn-taking [67], voice volume [13,67], eye contact [6,42,84], and use of language [11] in the reflection interface, as they have been identified as essential social skills for autistic people [94]. Furthermore, we included physiological sensing data-heart rate (HR) and electrodermal activity (EDA) 4 -in the reflection interface to highlight situations where users experienced physical correlates of anxiety.", "spans": "[{\"corpusId\": 208768328, \"span\": \"[67]\", \"start\": 66, \"end\": 70}, {\"corpusId\": 5040819, \"span\": \"[13,\", \"start\": 85, \"end\": 89}, {\"corpusId\": 208768328, \"span\": \"67]\", \"start\": 89, \"end\": 92}, {\"corpusId\": 703677, \"span\": \"[6,\", \"start\": 106, \"end\": 109}, {\"corpusId\": 16693674, \"span\": \"42,\", \"start\": 109, \"end\": 112}, {\"corpusId\": 207088430, \"span\": \"84]\", \"start\": 112, \"end\": 115}, {\"corpusId\": 6842414, \"span\": \"[11]\", \"start\": 137, \"end\": 141}, {\"corpusId\": 149664864, \"span\": \"[94]\", \"start\": 247, \"end\": 251}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 7}, {"paragraphId": "48647", "title": "The Workplace Playbook VR: Exploring the Design Space of Virtual Reality to Foster Understanding of and Support for Autistic People", "sectionTitle": "DISCUSSION", "text": "Our initial intention in developing the concept of Workplace Playbook VR was to help autistic people practice requisite skills for a variety of social situations that could arise in the workplace and discuss challenges and successes together with members of their support network. The spirit of this design was aligned with the findings of past research that have shown the efficacy of VR in training functional skills for autistic individuals [14,16,41,89]. Despite our intended goal, we found that VR technology designed to develop the social and communication skills of autistic people has the potential to be misused to correct their characteristics and enforce normative behaviors from the perspective of a neurotypical society. This finding reveals important design implications that HCI researchers should consider when designing technology to develop autistic people's social communication skills. In Section 6.1, we discuss how such VR systems should be designed to avoid enforcing normative behaviors and promote autistic individuals' self-advocacy and sense of agency in workplaces.", "spans": "[{\"corpusId\": 26805087, \"span\": \"[14,\", \"start\": 444, \"end\": 448}, {\"corpusId\": 49353119, \"span\": \"16,\", \"start\": 448, \"end\": 451}, {\"corpusId\": 1990470, \"span\": \"41,\", \"start\": 451, \"end\": 454}, {\"corpusId\": 17263937, \"span\": \"89]\", \"start\": 454, \"end\": 457}, {\"corpusId\": 253460211, \"span\": \"This finding\", \"start\": 746, \"end\": 746}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "48648", "title": "The Workplace Playbook VR: Exploring the Design Space of Virtual Reality to Foster Understanding of and Support for Autistic People", "sectionTitle": "DISCUSSION", "text": "Furthermore, our interviews revealed the potential for VR to promote neurotypical employees' understanding of autistic employees, and potential applications of VR to cultivate inclusive workplace environments. Although the efforts of neurotypical employees are critical for developing an inclusive workforce, a large body of VR research mostly focuses on building the competencies of autistic employees through training in target skills [16,41,89]. Therefore, we aim to take a step toward investigating how VR designs can better facilitate the understanding of autistic employees at work and ignite a discussion about changing attitudes and policies at work.", "spans": "[{\"corpusId\": 253460211, \"span\": \"our interviews\", \"start\": 27, \"end\": 27}, {\"corpusId\": 49353119, \"span\": \"[16,\", \"start\": 437, \"end\": 441}, {\"corpusId\": 1990470, \"span\": \"41,\", \"start\": 441, \"end\": 444}, {\"corpusId\": 17263937, \"span\": \"89]\", \"start\": 444, \"end\": 447}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": false, "refCount": 4}, {"paragraphId": "48649", "title": "The Workplace Playbook VR: Exploring the Design Space of Virtual Reality to Foster Understanding of and Support for Autistic People", "sectionTitle": "Design Recommendations of Inclusive VR Design for Autistic People", "text": "6.2 VR to Promote Self-advocacy and Sense of Agency for Autistic Employees Bolte et al. [9] called for future research to push the importance of rethinking the way autism is perceived, thus emphasizing the use of words that promote respect and an accurate understanding of autistic people. Researchers have re-conceptualized autism as neurodiversity [27,87], contesting the understanding of independent living or the concept of autonomy. A central premise of neurodiversity is to support self-advocacy and personal autonomy in autistic individuals, allowing them to exert more control over their own lives [51]. To achieve autonomy, one must have functional communication, so any intervention promoting neurodiversity should provide opportunities to express agency and-more importantly-build effective and respectful communication between autistic persons and others in their environment [51]. The concept of agency can be used as an effective framework to understand the social interactions between neurodiverse communication facilitators [79].", "spans": "[{\"corpusId\": 53023123, \"span\": \"[9]\", \"start\": 88, \"end\": 91}, {\"corpusId\": 140972381, \"span\": \"[27,\", \"start\": 350, \"end\": 354}, {\"corpusId\": 233206102, \"span\": \"[51]\", \"start\": 606, \"end\": 610}, {\"corpusId\": 233206102, \"span\": \"[51]\", \"start\": 888, \"end\": 892}, {\"corpusId\": 22558142, \"span\": \"[79]\", \"start\": 1040, \"end\": 1044}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "48650", "title": "The Workplace Playbook VR: Exploring the Design Space of Virtual Reality to Foster Understanding of and Support for Autistic People", "sectionTitle": "VR to Cultivate Inclusive Workplace Culture for Neurotypical Employees", "text": "Our findings revealed some occasional misunderstandings among neurotypical employees about autistic employees at work, such as perceiving inadequate eye contact as rude or strict rule adherence as stubborn. Misunderstanding and conflicts can happen because of a lack of understanding about autism [22,54] and autistic people's different ways of thinking and perceiving situations are often invisible [73]. Therefore, we suggest VR designs that allow neurotypical employees to experience invisible differences of autistic employees. Past research has shown that perspective-taking, the act of perceiving situations from the other's perspective, is effective at eliciting empathy, personal distress, and in turn, maximizing motivation to help [38,80]. Therefore, we suggest an immersive and interactive VR simulation that can help neurotypical employees experience their autistic co-workers' various challenges. Using such VR, neurotypical employees could imagine how neurodiverse coworkers would feel in the simulated situation. The various sensing effects, such as distorting the VR screen to simulate dizziness or visualizing fast heartbeats on a VR screen may further help neurotypical employees experience how autistic people might feel differently in specific situations. When designing and implementing VR, researchers should investigate ways of co-designing it with autistic employees to reflect how they actually feel in specific social situations, and how VR can best reflect their thoughts and feelings.", "spans": "[{\"corpusId\": 253460211, \"span\": \"Our findings\", \"start\": 12, \"end\": 12}, {\"corpusId\": 3904860, \"span\": \"[22,\", \"start\": 297, \"end\": 301}, {\"corpusId\": 152019484, \"span\": \"[73]\", \"start\": 400, \"end\": 404}, {\"corpusId\": 52985843, \"span\": \"[38,\", \"start\": 741, \"end\": 745}, {\"corpusId\": 13144304, \"span\": \"80]\", \"start\": 745, \"end\": 748}]", "conference": "cscw", "year": 2022, "likelyRelatedWorkSection": true, "refCount": 5}], "paragraphCount": 15}
{"paperId": "dfe4e373bab4f089ac5f6fc1990a5d195d4d85b8", "title": "On Looking at the Vagina through Labella", "venue": "International Conference on Human Factors in Computing Systems", "year": 2016, "citationCount": 115, "openAccessPdf": {"url": "https://eprint.ncl.ac.uk/fulltext.aspx?url=219030/22DBEF2E-68DE-4B21-B6B0-458E5D280F3C.pdf&pub_id=219030", "status": "GREEN", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/2858036.2858119?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/2858036.2858119, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2016-05-07", "authors": [{"authorId": "144694825", "name": "Teresa Almeida"}, {"authorId": "2573595", "name": "R. Comber"}, {"authorId": "1483713701", "name": "Gavin Wood"}, {"authorId": "38643932", "name": "Dean Saraf"}, {"authorId": "2599601", "name": "Madeline Balaam"}], "abstract": "Women's understandings of their own intimate anatomy has been identified as critical to women's reproductive health and sexual wellbeing. However, talking about it, seeking medical help when necessary as well as examining oneself in order to 'know' oneself is complicated by social-cultural constructions of the vagina, i.e. it is something private, shameful and not to be talked about. In response to this, we designed Labella, an augmented system that supports intimate bodily knowledge and pelvic fitness in women. It combines a pair of underwear and a mobile phone as a tool for embodied intimate self-discovery. In this paper, we describe Labella, and its evaluation with fourteen women, aged 25-63. We show how through situated embodied perception Labella empowers 'looking'. We highlight how the simple act of augmented looking enables the construction of knowledge which ranges from establishing the 'very basics' through to a nuanced understanding of pelvic muscle structure. Finally, we highlight the role of awkwardness and humour in the design of interactions to overcome taboo.", "corpusId": "32673625", "paragraphs": [{"paragraphId": "87036", "title": "On Looking at the Vagina through Labella", "sectionTitle": "INTRODUCTION", "text": "Recent work in wearable e-textiles has begun to explore the impact of on-body technologies in learning [29,30]. Further work has investigated interactions within clothing that interface with mobile technology [32]. In addition mobile interfaces for women's health and wellbeing have investigated the design of technologies with a focus on intimate care work in relation to hidden parts of the body [6] and involved in sexual functioning [7]. This work situates itself in this previous research by exploring how body-worn and digital interactions might support health and education in relation to intimate parts of the self. We argue that wearable and mobile technologies can support women's bodily experiences in relation to the reproductive system, continence and sexual pleasure [14,26] by promoting literacy to enable self-care.", "spans": "[{\"corpusId\": 9473421, \"span\": \"[29,\", \"start\": 103, \"end\": 107}, {\"corpusId\": 9228738, \"span\": \"30]\", \"start\": 107, \"end\": 110}, {\"corpusId\": 3236927, \"span\": \"[32]\", \"start\": 209, \"end\": 213}, {\"corpusId\": 20539237, \"span\": \"[6]\", \"start\": 398, \"end\": 401}, {\"corpusId\": 7007273, \"span\": \"[7]\", \"start\": 437, \"end\": 440}, {\"corpusId\": 32673625, \"span\": \"This work\", \"start\": 451, \"end\": 451}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": false, "refCount": 6}, {"paragraphId": "87037", "title": "On Looking at the Vagina through Labella", "sectionTitle": "Pelvic Fitness in Women's Health", "text": "Nonetheless, literature shows that women have misconceptions about their intimate personal bodies [10], and this hidden part of the body (pelvic floor) is mostly learned about after the woman becomes a patient body, for instance during or after childbirth. As such, the preventative health practice of pelvic floor exercise is generally overlooked in women's health care and inhibited by a lack of body knowledge [35]. This lack of body knowledge can be thought of as intertwined with taboo, since these parts of the body are both hidden, and related to bodily fluids, bodily and sexual functioning [1]. We developed Labella as a tool for use by women, which provides a unique perspective on women's pelvic fitness. This incorporates learning about the biological (i.e. reproductive system), medical and personal health (i.e. incontinence), and positive health and wellbeing (i.e. sexual pleasure).", "spans": "[{\"corpusId\": 145198475, \"span\": \"[10]\", \"start\": 98, \"end\": 102}, {\"corpusId\": 28980869, \"span\": \"[35]\", \"start\": 413, \"end\": 417}, {\"corpusId\": 232574, \"span\": \"[1]\", \"start\": 599, \"end\": 602}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "87038", "title": "On Looking at the Vagina through Labella", "sectionTitle": "Wellness Awareness Through Wearable Interfaces", "text": "Most relevant to the focus of this paper are [14,26], which combine smartphones with smart objects to encourage and support assisted tracking in pelvic fitness. Both kGoal and Elvie are interactive training systems that guide, correct, and visualize pelvic exercises in real-time. Moreover, [2] recognizes a lack of literacy that might hinder these wearable digital products from being useful, by identifying a gap between these items and practical or anatomical knowledge of the intimate part of a woman's body. In spite of the fact that self-tracking technologies that make accessible the continued monitoring of personal health proliferate, so do misconceptions and misunderstandings about intimate care work, and the intimate anatomy [10].", "spans": "[{\"corpusId\": 32673625, \"span\": \"this paper\", \"start\": 40, \"end\": 40}, {\"corpusId\": 23432247, \"span\": \"[2]\", \"start\": 291, \"end\": 294}, {\"corpusId\": 145198475, \"span\": \"[10]\", \"start\": 738, \"end\": 742}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "87039", "title": "On Looking at the Vagina through Labella", "sectionTitle": "On-Body Technologies in Learning", "text": "Wearables for teaching and learning that speak about and to the body vary in approaches that support and enable the construction of knowledge. We focus here on technologies that combine embodied learning and intimate selfdiscovery. Body literacy among school children is developed through exploring tangible \"body organs\" in [29,30], and body organs that are intimate, but also problematized by touch and visibility, are explored in [2]. All of these examples explore engagement and learning with technology to stimulate knowledge of body organs that are \"invisible and untouchable\" by composing and mapping material representations of the body landscape.", "spans": "[{\"corpusId\": 9473421, \"span\": \"[29,\", \"start\": 325, \"end\": 329}, {\"corpusId\": 9228738, \"span\": \"30]\", \"start\": 329, \"end\": 332}, {\"corpusId\": 23432247, \"span\": \"[2]\", \"start\": 433, \"end\": 436}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "87040", "title": "On Looking at the Vagina through Labella", "sectionTitle": "On-Body Technologies in Learning", "text": "Furthermore, [30] shows evidence of how such on-body approaches can successfully engage children in learning about anatomy and physiology by exploring wearable interactions. A wearable technology that embodies playfulness can be seen in [37], where a 'body object' is used to perform in unexpected ways, with the self and in interaction with others, in order to compose sounds. This work can also be understood to enable learning about how bodies are particular in their morphology, material similarities, and differences from other bodies [39], as demonstrated by the amusement provided by each individual performance.", "spans": "[{\"corpusId\": 9228738, \"span\": \"[30]\", \"start\": 13, \"end\": 17}, {\"corpusId\": 15972611, \"span\": \"[37]\", \"start\": 237, \"end\": 241}, {\"corpusId\": 32673625, \"span\": \"This work\", \"start\": 387, \"end\": 387}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "87041", "title": "On Looking at the Vagina through Labella", "sectionTitle": "Augmented Reality and Embodied intimate Interaction", "text": "Broadly defined, augmented reality (AR) supplements reality, rather than completely replacing it [5]. To date, AR systems have been used in combination with a wide range of wearable interfaces for a variety of purposes, such as entertainment and education [22]. In healthcare, medical handheld projection devices have been explored to improve doctor-patient communication, such as in [28], where AR technology is projected onto the body to embody in an outward form and render visible a variety of bone fractures. AR and medical imaging that explore intimacy within the body and self-perception is discussed in [19], and tangible 3D interactions using mobile devices for medical imaging specialists exploring internal body parts (for example chest), in [34]. In each of these the use of AR by specialists promotes communication with patients in clinical settings.", "spans": "[{\"corpusId\": 469744, \"span\": \"[5]\", \"start\": 97, \"end\": 100}, {\"corpusId\": 17024419, \"span\": \"[22]\", \"start\": 256, \"end\": 260}, {\"corpusId\": 954289, \"span\": \"[28]\", \"start\": 384, \"end\": 388}, {\"corpusId\": 2024797, \"span\": \"[34]\", \"start\": 753, \"end\": 757}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "87042", "title": "On Looking at the Vagina through Labella", "sectionTitle": "Humour in Interactions", "text": "While there are well defined cultural differences in the expression of humour [24], humour enables the expression of ideas which would otherwise be rejected, criticized or censored. It can facilitate communication, prompt amusement, and it has a disinhibiting effect [40]. In its review of humour theories, [9] refers to \"humour as the enjoyment of the socially taboo\". As a therapeutic tool, humour has been broadly discussed in health care. It is regarded as valuable for promoting patient-centered care [33] and coping with diagnosis and treatment of illness [9], positive for managing embarrassment [25], or advantageous for teaching [40]. Further, it is regarded as a method to support learning of sensitive topics [20].", "spans": "[{\"corpusId\": 19434491, \"span\": \"[40]\", \"start\": 267, \"end\": 271}, {\"corpusId\": 3785779, \"span\": \"[9]\", \"start\": 307, \"end\": 310}, {\"corpusId\": 144032342, \"span\": \"[33]\", \"start\": 506, \"end\": 510}, {\"corpusId\": 3785779, \"span\": \"[9]\", \"start\": 562, \"end\": 565}, {\"corpusId\": 19434491, \"span\": \"[40]\", \"start\": 638, \"end\": 642}, {\"corpusId\": 151592259, \"span\": \"[20]\", \"start\": 720, \"end\": 724}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "87043", "title": "On Looking at the Vagina through Labella", "sectionTitle": "Humour in Interactions", "text": "Moreover, the design of systems that promote learning through play within digital gaming [15] explore humour as a mediating tool to make the game experience more enjoyable and stimulate affective learning. Humour as a method of support in engaging an audience has been explored in [37,38], where an augmented body-device doubles as a musical instrument. Here, the interface is primarily concerned with the body and its design interaction incorporates humour, which is instrumental in welcoming the social awkwardness of core-body movement necessary to enact the interface as a sonic system. We contend that humour is beneficial for managing bodily awkwardness. Further, it contributes to promote access to learning and it helps diminish the taboo nature associated with sensitive topics, such as looking or talking about intimate parts of the body, which we explore in our work.", "spans": "[{\"corpusId\": 144183114, \"span\": \"[15]\", \"start\": 89, \"end\": 93}, {\"corpusId\": 15972611, \"span\": \"[37,\", \"start\": 281, \"end\": 285}, {\"corpusId\": 54792262, \"span\": \"38]\", \"start\": 285, \"end\": 288}, {\"corpusId\": 32673625, \"span\": \"our work\", \"start\": 877, \"end\": 877}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "87044", "title": "On Looking at the Vagina through Labella", "sectionTitle": "FINDINGS", "text": "The interview data were analysed using an inductive thematic analysis approach [11], with the coding of the entire dataset undertaken by one researcher. Three researchers then discussed the coded data set, and worked together to develop themes based on these codes. Our interest in this analysis was broad, to understand participants' experiences of Labella. In what follows we show how Labella can act as a device for transforming learning on the body and awkward learning as a valuable tool to talk about the 'unmentionable' [12]. As women talked, their experiences with Labella were naturally intertwined with their own personal histories. This coupling of stories and experiences is presented in what follows. In accordance with the consent given by our participants pseudonyms are used throughout.", "spans": "[{\"corpusId\": 10075179, \"span\": \"[11]\", \"start\": 79, \"end\": 83}, {\"corpusId\": 146773361, \"span\": \"[12]\", \"start\": 527, \"end\": 531}, {\"corpusId\": 32673625, \"span\": \"our participants\", \"start\": 770, \"end\": 770}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "87045", "title": "On Looking at the Vagina through Labella", "sectionTitle": "Strange, But Fun", "text": "The role of the intimate wearable is critical to enable situated learning about intimate parts of the body through exploring the physicality of the interaction. Awkward learning, as discussed previously, combines 'weird funny' and 'weird not funny', challenging weirdness as prohibitive although helpful in breaking awkwardness. Avoiding problematic knowledge or feeling self-conscious contributes to inhibit discussion. Moreover, laughter makes the conversation more accessible and puts people at ease therefore contributing to the social component of the interaction required to talk about bodies that are 'funny' and look 'kind of weird'. Alexandra relates how amusing situations and humorous products can contribute to get the message across:  [8,17,21]. With Labella, we bring these topics forward and explore how digital technologies can be harnessed in support of managing embarrassment and sexuality in self-care and care of others in these intimate spaces [25]. In the following sections we outline how embodied interactions inform looking to promote learning about hidden parts of the body. We discuss how learning is awkward when applied to sensitive and intimate topics, but that such awkward learning can be facilitated by humour. Finally, we show how a contextualized exploration of the body is embedded in our physical, social, and emotional settings, and is affected by different kinds of everyday technology.", "spans": "[{\"corpusId\": 17014760, \"span\": \"[8,\", \"start\": 748, \"end\": 751}, {\"corpusId\": 13343476, \"span\": \"17,\", \"start\": 751, \"end\": 754}, {\"corpusId\": 14213568, \"span\": \"21]\", \"start\": 754, \"end\": 757}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "87046", "title": "On Looking at the Vagina through Labella", "sectionTitle": "Awkward Learning", "text": "A small body of existing literature promotes humorous interactions and design in an attempt to help break social awkwardness [37,38]. We note also that the expression of humour in health care interactions is a mechanism for managing awkwardness [25], since it provides relaxation and physical ease [9,24]. Similarly, the giggly and funny experience of interacting with Labella provides both psychological and physical ease to look at and understand the self, sometimes for the first time. In addition, the technology provides a (physical and digital) space in which looking at oneself is acceptable (the app suggests so) and legitimate (research). Moreover, women's accounts of the body being \"weird\" or \"funny\" seek to strengthen the notion that humorous interactions within the body can be advantageous to encourage conversations and breaking taboos. In this regard, interactions that incorporate humour in design have the possibility to support awkward learning, which may be charged with not only physical or social but also emotional stigma and taboo. More so, we find evidence that this awkward, funny interaction which involves physicality and the social emotive taboo results in an affective experience [36], that may contribute to making an impression and a memorable learning experience.", "spans": "[{\"corpusId\": 15972611, \"span\": \"[37,\", \"start\": 125, \"end\": 129}, {\"corpusId\": 54792262, \"span\": \"38]\", \"start\": 129, \"end\": 132}, {\"corpusId\": 3785779, \"span\": \"[9,\", \"start\": 298, \"end\": 301}, {\"corpusId\": 13401924, \"span\": \"[36]\", \"start\": 1211, \"end\": 1215}]", "conference": "chi", "year": 2016, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 11}
{"paperId": "3ac4e5e444ad558575f51a4b547aefb756f3fe34", "title": "Learning Transferable Feature Representations Using Neural Networks", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2019, "citationCount": 1, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: Paper or abstract available at https://aclanthology.org/P19-1404, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2019-07-01", "authors": [{"authorId": "2559473", "name": "H. Bhatt"}, {"authorId": "2482992", "name": "Shourya Roy"}, {"authorId": "143952254", "name": "A. Rajkumar"}, {"authorId": "150305296", "name": "Sriranjani Ramakrishnan"}], "abstract": "Learning representations such that the source and target distributions appear as similar as possible has benefited transfer learning tasks across several applications. Generally it requires labeled data from the source and only unlabeled data from the target to learn such representations. While these representations act like a bridge to transfer knowledge learned in the source to the target; they may lead to negative transfer when the source specific characteristics detract their ability to represent the target data. We present a novel neural network architecture to simultaneously learn a two-part representation which is based on the principle of segregating source specific representation from the common representation. The first part captures the source specific characteristics while the second part captures the truly common representation. Our architecture optimizes an objective function which acts adversarial for the source specific part if it contributes towards the cross-domain learning. We empirically show that two parts of the representation, in different arrangements, outperforms existing learning algorithms on the source learning as well as cross-domain tasks on multiple datasets.", "corpusId": "196182023", "paragraphs": [{"paragraphId": "51253", "title": "Learning Transferable Feature Representations Using Neural Networks", "sectionTitle": "Related Work", "text": "The problem of domain adaptation has gained a lot of attention due to its huge practical implications.  focuses on learning a common representation minimizing the divergence between the source and target domains. Many body of work exists in literature including learning nonlinear mappings (Daum\u00e9 III, 2009;Pan et al., 2011;Blitzer et al., 2007;Barnes et al., 2018), mappings to mitigate domain divergence , common features (Dai et al., 2007;Dhillon et al., 2003), ensemble based approaches (Bhatt et al., 2015), subspace based methods (Gopalan et al., 2011;Gong et al., 2012;Harel and Mannor, 2010;Fernando et al., 2013) and neural networks based methods (Glorot et al., 2011;Chopra et al., 2013;Long and Wang, 2015;Tzeng et al., 2014).", "spans": "[{\"corpusId\": 788838, \"span\": \"Pan et al., 2011;\", \"start\": 307, \"end\": 324}, {\"corpusId\": 14688775, \"span\": \"Blitzer et al., 2007;\", \"start\": 324, \"end\": 345}, {\"corpusId\": 48352816, \"span\": \"Barnes et al., 2018)\", \"start\": 345, \"end\": 365}, {\"corpusId\": 7518182, \"span\": \"(Dai et al., 2007;\", \"start\": 424, \"end\": 442}, {\"corpusId\": 12286784, \"span\": \"Dhillon et al., 2003)\", \"start\": 442, \"end\": 463}, {\"corpusId\": 10517033, \"span\": \"(Bhatt et al., 2015)\", \"start\": 491, \"end\": 511}, {\"corpusId\": 10337178, \"span\": \"(Gopalan et al., 2011;\", \"start\": 536, \"end\": 558}, {\"corpusId\": 6742009, \"span\": \"Gong et al., 2012;\", \"start\": 558, \"end\": 576}, {\"corpusId\": 9440223, \"span\": \"Fernando et al., 2013)\", \"start\": 599, \"end\": 621}, {\"corpusId\": 18235792, \"span\": \"(Glorot et al., 2011;\", \"start\": 656, \"end\": 677}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 10}, {"paragraphId": "51254", "title": "Learning Transferable Feature Representations Using Neural Networks", "sectionTitle": "Related Work", "text": "A variant of unsupervised models namely marginalized stacked denoising autoencoders (mSDA) (Chen et al., 2012a) learn robust representation to input corruption noise, which is stable across changes in domains, allowing cross-domain transfer. Existing literature exploits the principle of representations generalizing across domains for classification, without labelled data from target ((Sarma et al., 2018), (Bhatt et al., 2016) and with labelled data from target ( (Zhang et al., 2018)). Our work emphasizes on domain discrimination by incorporating domain divergence and source risk minimization into the objective for learning better transferable representation without any labelled data from target domain. Another line of work aims to achieve distribution consistency between the source and target domains with linear data reconstruction such as co-regularization based augmented space (Kumar et al., 2010), coupled learning to link target-specific features to source features (Blitzer et al., 2011) and transfer of the source examples to the target and vice-versa (Zhou et al., 2016).", "spans": "[{\"corpusId\": 17532005, \"span\": \"), (Bhatt et al., 2016\", \"start\": 406, \"end\": 428}, {\"corpusId\": 51879969, \"span\": \"(Zhang et al., 2018)\", \"start\": 467, \"end\": 487}, {\"corpusId\": 196182023, \"span\": \"Our work\", \"start\": 498, \"end\": 498}, {\"corpusId\": 12789480, \"span\": \"(Kumar et al., 2010)\", \"start\": 892, \"end\": 912}, {\"corpusId\": 8226838, \"span\": \"(Blitzer et al., 2011)\", \"start\": 983, \"end\": 1005}, {\"corpusId\": 12271006, \"span\": \"(Zhou et al., 2016)\", \"start\": 1071, \"end\": 1090}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 6}, {"paragraphId": "51255", "title": "Learning Transferable Feature Representations Using Neural Networks", "sectionTitle": "Related Work", "text": "Domain adversarial neural networks (DANN) (Ajakan et al., 2014;Ganin et al., 2016), closely similar in philosophy to our work, learns a single representation by using an adversarial (Liu et al., 2017) gradient reversal component for domain divergence. In DANN, the entire hidden layer contributes unanimously towards the source classification and domain divergence objective. Unlike DANN, our approach segregates the hidden layer where the two components of hidden layer are treated differently for different objectives. Both the source specific and common parts contribute positively to the source classification objective. However, for the domain divergence objective, the common part contributes positively (i.e., tries to minimize divergence by maximizing the domain regressor's loss); whereas, the source specific part contributes negatively (i.e., tries to maximize divergence by minimizing domain regressor's loss) Generative adversarial networks (GAN) (Goodfellow et al., 2014) build generative models to synthesize samples and falls closely in the same cat-egory due to the similar method of measuring and minimizing the discrepancy between the feature distributions. The GAN model learns the representation in generative mode while our work is based on discriminative learning.", "spans": "[{\"corpusId\": 2871880, \"span\": \"Ganin et al., 2016)\", \"start\": 63, \"end\": 82}, {\"corpusId\": 196182023, \"span\": \"our work\", \"start\": 125, \"end\": 125}, {\"corpusId\": 630188, \"span\": \"(Liu et al., 2017)\", \"start\": 182, \"end\": 200}, {\"corpusId\": 196182023, \"span\": \"our approach\", \"start\": 401, \"end\": 401}, {\"corpusId\": 1033682, \"span\": \"(Goodfellow et al., 2014)\", \"start\": 960, \"end\": 985}, {\"corpusId\": 196182023, \"span\": \"our work\", \"start\": 1250, \"end\": 1250}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "51256", "title": "Learning Transferable Feature Representations Using Neural Networks", "sectionTitle": "Experimental Protocol", "text": "Performance of proposed architecture is compared with standard neural network architecture with one hidden layer (\"NN\") (as described in Eq. 1) and a support vector machine (\"SVM\") (Chih-Wei Hsu and Lin, 2003) with linear kernel where the training is performed on labelled source domain and performance is reported on the target domain. \"Gold-standard\" refers to target domain supervised performance of the SVM. The performance is further compared with popular shared representation learning approaches for domain adaptation including Structural Correspondance Learning (\"SCL\") (Blitzer et al., 2006), (Blitzer et al., 2007), Spectral Feature Alignment (\"SFA\")  and \"PJNMF\" (Zhou et al., 2015).", "spans": "[{\"corpusId\": 15978939, \"span\": \"(Blitzer et al., 2006)\", \"start\": 578, \"end\": 600}, {\"corpusId\": 14688775, \"span\": \"(Blitzer et al., 2007)\", \"start\": 602, \"end\": 624}, {\"corpusId\": 15483466, \"span\": \"(Zhou et al., 2015)\", \"start\": 674, \"end\": 693}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "51257", "title": "Learning Transferable Feature Representations Using Neural Networks", "sectionTitle": "Experimental Protocol", "text": "We also compared the performance with \"DANN\" (Ajakan et al., 2014), stacked Denoising Auto-encoders (\"SDA\") (Glorot et al., 2011), and marginalized SDA (\"mSDA\") (Chen et al., 2012b) and transfer learning with deep auto-encoders (\"TLDA\") (Pan et al., 2008) , \"BTDNNs\" (Zhou et al., 2016) and \"DSN\" (Bousmalis et al., 2016) which are some of the popular approaches in cross-domain sentiment analysis. The performance is also compared with different components of the learned representations i.e. source specific (\"SS\"), common (\"Proposed\"), and \"SS+common\" representations. For SDA, mSDA, TLDA, BTDNNs, SS, SS+common and the proposed, a standard SVM is trained on the learned representation and is applied to predict the sentiment labels for target data.", "spans": "[{\"corpusId\": 18235792, \"span\": \"(Glorot et al., 2011)\", \"start\": 108, \"end\": 129}, {\"corpusId\": 10686834, \"span\": \"(Chen et al., 2012b)\", \"start\": 161, \"end\": 181}, {\"corpusId\": 6953522, \"span\": \"(Pan et al., 2008)\", \"start\": 237, \"end\": 255}, {\"corpusId\": 12271006, \"span\": \"(Zhou et al., 2016)\", \"start\": 267, \"end\": 286}]", "conference": "acl", "year": 2019, "likelyRelatedWorkSection": true, "refCount": 4}], "paragraphCount": 5}
{"paperId": "73ebd89b20bb1c1a93e79e4b0175e0825b0aecda", "title": "Filling the Gaps in Ancient Akkadian Texts: A Masked Language Modelling Approach", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2021, "citationCount": 27, "openAccessPdf": {"url": "https://aclanthology.org/2021.emnlp-main.384.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2109.04513, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2021-09-09", "authors": [{"authorId": "2126054589", "name": "Koren Lazar"}, {"authorId": "2126417027", "name": "Benny Saret"}, {"authorId": "2126416248", "name": "Asaf Yehudai"}, {"authorId": "51902973", "name": "W. Horowitz"}, {"authorId": "120396713", "name": "N. Wasserman"}, {"authorId": "2126417012", "name": "Gabriel Stanovsky"}], "abstract": "We present models which complete missing text given transliterations of ancient Mesopotamian documents, originally written on cuneiform clay tablets (2500 BCE - 100 CE). Due to the tablets\u2019 deterioration, scholars often rely on contextual cues to manually fill in missing parts in the text in a subjective and time-consuming process. We identify that this challenge can be formulated as a masked language modelling task, used mostly as a pretraining objective for contextualized language models. Following, we develop several architectures focusing on the Akkadian language, the lingua franca of the time. We find that despite data scarcity (1M tokens) we can achieve state of the art performance on missing tokens prediction (89% hit@5) using a greedy decoding scheme and pretraining on data from other languages and different time periods. Finally, we conduct human evaluations showing the applicability of our models in assisting experts to transcribe texts in extinct languages.", "corpusId": "237485553", "paragraphs": [{"paragraphId": "1585", "title": "Filling the Gaps in Ancient Akkadian Texts: A Masked Language Modelling Approach", "sectionTitle": "Introduction", "text": "In this paper, we identify that the task of masked language modeling, used ubiquitously in recent years for pretraining other downstream tasks (Peters et al., 2018;Howard and Ruder, 2018;Liu et al., 2019) lends itself directly to missing sign prediction in the transliterated texts. We experiment with various adaptations of BERT-based models (Devlin et al., 2019) trained and tested on Oracc, combined with a greedy decoding scheme to extend the prediction from single tokens to multiple words. We specifically focus on the effect multilingual pretraining has on downstream performance, which was recently shown beneficial for low-resource settings (Chau et al., 2020).", "spans": "[{\"corpusId\": 237485553, \"span\": \"this paper\", \"start\": 13, \"end\": 13}, {\"corpusId\": 3626819, \"span\": \"(Peters et al., 2018;\", \"start\": 143, \"end\": 164}, {\"corpusId\": 40100965, \"span\": \"Howard and Ruder, 2018;\", \"start\": 164, \"end\": 187}, {\"corpusId\": 52967399, \"span\": \"(Devlin et al., 2019)\", \"start\": 343, \"end\": 364}, {\"corpusId\": 221995566, \"span\": \"(Chau et al., 2020)\", \"start\": 650, \"end\": 669}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": false, "refCount": 5}, {"paragraphId": "1586", "title": "Filling the Gaps in Ancient Akkadian Texts: A Masked Language Modelling Approach", "sectionTitle": "Multilingual Masked Language Modeling", "text": "In particular, recent work has noticed that joint training on various languages greatly helps downstream applications, especially where labeled data is sparse (Pires et al., 2019;Chau et al., 2020;Conneau et al., 2020).", "spans": "[{\"corpusId\": 174798142, \"span\": \"(Pires et al., 2019;\", \"start\": 159, \"end\": 179}, {\"corpusId\": 221995566, \"span\": \"Chau et al., 2020;\", \"start\": 179, \"end\": 197}, {\"corpusId\": 207853017, \"span\": \"Conneau et al., 2020)\", \"start\": 197, \"end\": 218}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}, {"paragraphId": "1587", "title": "Filling the Gaps in Ancient Akkadian Texts: A Masked Language Modelling Approach", "sectionTitle": "Masked Language Models", "text": "First, we pretrained from scratch a monolingual BERT model with a reduced number of parameters (750K) following conclusions from Kaplan et al. (2020). Second, following recent research suggesting that pretraining on similar languages is beneficial for many NLP tasks, including in low-resource settings (Pires et al., 2019;Wu and Dredze, 2019;Chau et al., 2020;Conneau et al., 2020), we finetuned a pretrained multilingual BERT (M-BERT) model (Devlin et al., 2019). 3 M-BERT was trained on the 104 most common languages of Wikipedia, including Hebrew and Arabic -Semitic languages that are typologically similar to Akkadian.", "spans": "[{\"corpusId\": 174798142, \"span\": \"(Pires et al., 2019;\", \"start\": 303, \"end\": 323}, {\"corpusId\": 126167342, \"span\": \"Wu and Dredze, 2019;\", \"start\": 323, \"end\": 343}, {\"corpusId\": 221995566, \"span\": \"Chau et al., 2020;\", \"start\": 343, \"end\": 361}, {\"corpusId\": 207853017, \"span\": \"Conneau et al., 2020)\", \"start\": 361, \"end\": 382}, {\"corpusId\": 52967399, \"span\": \"(Devlin et al., 2019)\", \"start\": 443, \"end\": 464}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 5}, {"paragraphId": "1588", "title": "Filling the Gaps in Ancient Akkadian Texts: A Masked Language Modelling Approach", "sectionTitle": "Results", "text": "Zero-shot multilingual pretraining outperforms monolingual training. Surprisingly, in most tested settings, the zero-shot version of M-BERT outperforms both BERT+AKK(mono) and the LSTM models, despite never training on Akkadian. This suggests that the signal from pretraining is stronger than that of the Akkadian texts, likely due to the relatively small amounts of data. Moreover, as M-BERT was trained over the MLM task in other languages during its pretraining, this evaluation can be seen as a . We find that both languages do well on 1 token and 1 sign, where the correct answer is expected to be in the models' top 5 predictions for half of the instances. Performance drops sharply for longer sequences, possibly due to the large search space. We directly measure the model's applicability in user studies in Section 6. zero-shot cross-lingual transfer learning, on which M-BERT was found to be competitive in many NLP tasks (Pires et al., 2019;Wu and Dredze, 2019;Conneau et al., 2020).", "spans": "[{\"corpusId\": 237485553, \"span\": \"this evaluation\", \"start\": 481, \"end\": 481}, {\"corpusId\": 174798142, \"span\": \"(Pires et al., 2019;\", \"start\": 932, \"end\": 952}, {\"corpusId\": 126167342, \"span\": \"Wu and Dredze, 2019;\", \"start\": 952, \"end\": 972}, {\"corpusId\": 207853017, \"span\": \"Conneau et al., 2020)\", \"start\": 972, \"end\": 993}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 4}, {"paragraphId": "1589", "title": "Filling the Gaps in Ancient Akkadian Texts: A Masked Language Modelling Approach", "sectionTitle": "Related Work", "text": "Other works have used Oracc and other Akkadian resources and may benefit from our language model for Akkadian. Jauhiainen et al. Several recent works also noticed the crosslingual transfer capabilities of M-BERT. Wu and Dredze (2019) and Conneau et al. (2020) found that M-BERT can successfully learn various NLP tasks in a zero-shot setting using cross-lingual transfer, pointing at the shared parameters across languages as the most important factor. Pires et al. (2019) showed that M-BERT is capable of zero-shot transfer learning even between languages with different writing systems.", "spans": "[{\"corpusId\": 126167342, \"span\": \"Wu and Dredze (2019)\", \"start\": 213, \"end\": 233}, {\"corpusId\": 207853017, \"span\": \"Conneau et al. (2020)\", \"start\": 238, \"end\": 259}, {\"corpusId\": 174798142, \"span\": \"Pires et al. (2019)\", \"start\": 453, \"end\": 472}]", "conference": "emnlp", "year": 2021, "likelyRelatedWorkSection": true, "refCount": 3}], "paragraphCount": 5}
